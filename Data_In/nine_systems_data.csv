static_text,log_level,project
No serialized RegionInfo in ,warn,HBase
Scanning META |  starting at row= |  stopping at row= |  for max= |  with caching=,trace,HBase
Got exception in closing the meta scanner visitor,debug,HBase
Ignoring invalid region for server  | ; cell=,error,HBase
Added region *,debug,HBase
Added * regions to meta.,info,HBase
Updated * in hbase:meta,info,HBase
Deleted table  |  state from META,info,HBase
Updated row * with server=,info,HBase
Deleted ,info,HBase
Deleted * regions from META,info,HBase
Deleted regions: *,debug,HBase
Overwritten  |  regions to Meta,info,HBase
Overwritten regions: * ,debug,HBase
"Deleted merge references in  | , deleted qualifiers  | , ",info,HBase
* *,debug,HBase
Failed to parse the passed region name: ,warn,HBase
No serialized RegionInfo in ,warn,HBase
Scanning META |  starting at row= |  stopping at row= |  for max= |  with caching=,debug,HBase
Ignoring invalid region for server  | ; cell=,error,HBase
Region is split but NOT offline: ,warn,HBase
"TimeRange failed, likely caused by integer overflow. ",error,HBase
"table=*, state=*",debug,HBase
$$$Empty Message$$$,debug,HBase
$$$Empty Message$$$,debug,HBase
", ",error,HBase
$$$Empty Message$$$,debug,HBase
Failed to run HBCK chore,debug,HBase
Failed to get PID from [ | ],warn,HBase
Don't know how to get PID from [ | ],warn,HBase
Failed to get IP address bytes,warn,HBase
"Skipping flush region, because the located region  |  is different than  |  requested region ",info,HBase
Using  |  for intercepting the RpcRetryingCaller,trace,HBase
Got exception making request  |  to ,info,HBase
"Scanner= |  expired, current region location is ",info,HBase
Failed to relocate region,info,HBase
"Scanner= |  has received an exception, and the server  | asked us to reset the scanner state.",info,HBase
Took  | ms to fetch  |  rows from scanner=,info,HBase
"Ignore, probably already closed. Current scan: ",warn,HBase
Open scanner= |  for scan= |  on region ,info,HBase
Throwing PFFE :  |  tries : ,debug,HBase
 been failing for a long time. clearing out.,error,HBase
Preemptive failure enabled for : ,warn,HBase
Clearing out PFFE for server ,info,HBase
"Call:  | , ",trace,HBase
$$$Empty Message$$$,debug,HBase
$$$Empty Message$$$,info,HBase
"* is true, but * is not sethbase.status.publishedhbase.status.listener.class",warn,HBase
"Failed to create ClusterStatusListener, not a critical problem, ignoring...",warn,HBase
There is a new dead server: ,info,HBase
"Unexpected exception, continuing.",error,HBase
waitForTermination interrupted,warn,HBase
Error calling coprocessor service  |  for row ,warn,HBase
"No regions were selected by key range start= | , end=",info,HBase
Left over  |  task(s) are processed on server(s): ,info,HBase
Regions against which left over task(s) are processed: ,info,HBase
"The  |  setting:  |  is smaller than  | , will use  |  instead.",warn,HBase
"hbase.status.published is true, but hbase.status.listener.class is not set - not listening status",warn,HBase
connection construction failed,debug,HBase
Nonce generator is being replaced by test code for ,warn,HBase
Retrieve cluster id failed,warn,HBase
"clusterid came back null, using default ",debug,HBase
Table * not enabled,debug,HBase
Table * has not deployed region *,debug,HBase
Table * has * regions not deployed,debug,HBase
"Table * expected to have * regions, but only * available",debug,HBase
Table * should be available,trace,HBase
Table * does not exist,warn,HBase
"locateRegionInMeta parentTable='*', attempt=* of * failed; retrying after sleep of *",debug,HBase
$$$Empty Message$$$,info,HBase
Master connection is not running anymore,info,HBase
Checking master connection,warn,HBase
Closing master protocol: ,info,HBase
"Coding error, see method javadoc. row= | null | , tableName= | null",warn,HBase
Region  |  moved to  | : |  according to ,trace,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
0x%x |  stop prefetching when scanning  |  as the cache size  |  is greater than the maxCacheSize ,debug,HBase
0x%x |  resume prefetching,debug,HBase
Call failed on IOException,warn,HBase
$$$Empty Message$$$,error,HBase
Exception occurred! Exception details:  | ;\nActions: ,error,HBase
Closing scanner id=,trace,HBase
Scan with primary region returns ,debug,HBase
Imposible? Arrive at an unreachable line...,error,HBase
Setting current scanner as id= |  associated with replica=,trace,HBase
"Closing scanner id= | , replica= |  because slow and replica= |  succeeded",trace,HBase
 server-side Connection retries=,info,HBase
"Can not resolve  | , please check your network",warn,HBase
cannot determine my address,error,HBase
"* cache is null, try fetching from registry",trace,HBase
Start fetching* from registry,debug,HBase
"The * setting: * ms is less than the * setting: * ms, use the greater one insteadhbase.client.pause.cqtbehbase.client.pause",warn,HBase
Replica  |  returns ,debug,HBase
Cannot process the put ,debug,HBase
resubmitting after  | ms: ,debug,HBase
Caught some exceptions when flushing puts to region server ,debug,HBase
"Processed  |  put requests for  |  and  |  failed | , latency for this send: ",debug,HBase
Caught some exceptions  |  when flushing puts to region server ,debug,HBase
Caught some exceptions  |  when flushing puts to region server ,debug,HBase
"The  |  setting:  |  is smaller than  | , will use  |  instead.",warn,HBase
Failed to get region location ,error,HBase
Region is split but NOT offline: ,warn,HBase
Exception during timerCallbackForWriteBufferPeriodicFlush --> ,error,HBase
close() failed to terminate pool after 10 minutes. Abandoning pool.,warn,HBase
waitForTermination interrupted,warn,HBase
Primary replica returns ,debug,HBase
Imposible? Arrive at an unreachable line...,error,HBase
"Configured value of pauseForCQTBENs is * ms, which is less than the normal pause value * ms, use the greater one instead",warn,HBase
Clear meta cache for *,debug,HBase
Clear meta cache for *,debug,HBase
"Process batch for  |  in  |  from  |  failed, tries=",warn,HBase
Server  |  sent us neither result nor exception for row ' | ' of ,error,HBase
"Try updating * , the old value is *, error=*",debug,HBase
The actual exception when updating * is *,debug,HBase
Will not update * because the exception is null or not the one we care about,debug,HBase
Try updating * with the new location * constructed by *,debug,HBase
Try removing * from cache,debug,HBase
"Configured value of pauseForCQTBENs is * ms, which is less than the normal pause value * ms, use the greater one instead",warn,HBase
Taking restore-failsafe snapshot: ,info,HBase
 completed,info,HBase
 failed with ,info,HBase
 completed,info,HBase
 failed with ,info,HBase
 completed,info,HBase
 failed with ,info,HBase
"Scan table= | , startRow=",trace,HBase
close scanner for  |  failed,debug,HBase
Finished ,trace,HBase
"Advancing internal scanner to startKey at ' | ',  | inclusive",debug,HBase
Heartbeat message received and cache contains Results. Breaking out of scan loop,trace,HBase
scanner failed to close,debug,HBase
scanner failed to close.,warn,HBase
scanner failed to renew lease,debug,HBase
Interrupted while sleeping for expected sleep time  |  ms,warn,HBase
Failed to delete table ,info,HBase
Started truncating ,info,HBase
Started enable of ,info,HBase
Failed to enable table ,info,HBase
Started disable of ,info,HBase
Failed to disable table ,info,HBase
Table is disabled: ,info,HBase
Trying to |  major |  compact  | : ,debug,HBase
Failed to clear block cache for  |  on  | : ,debug,HBase
No serialized HRegionInfo in ,warn,HBase
Waiting a max of  |  ms for snapshot ' | '' to complete. (max  |  ms per retry),debug,HBase
(# | ) Sleeping:  | ms while waiting for snapshot completion.,debug,HBase
Getting current status of snapshot from master...,debug,HBase
Taking restore-failsafe snapshot: ,info,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
Deleting restore-failsafe snapshot: ,info,HBase
Unable to remove the failsafe snapshot: ,error,HBase
Waiting a max of  |  ms for procedure ' |  :  | '' to complete. (max  |  ms per retry),debug,HBase
(# | ) Sleeping:  | ms while waiting for procedure completion.,debug,HBase
Getting current status of procedure from master...,debug,HBase
Failed to delete snapshot  |  for table ,info,HBase
Successfully deleted snapshot: ,debug,HBase
Failed to delete snapshot: ,error,HBase
"Call:  | , ",trace,HBase
"Call:  | , ",trace,HBase
Trying to get compaction state of  | : ,debug,HBase
Trying to get compaction state of  | : ,debug,HBase
Cancelling the procedure with procId= |  throws exception ,warn,HBase
Failed to get the procedure with procId= |  throws exception ,warn,HBase
failed to get the procedure result procId=,warn,HBase
Proc-v2 is unsupported on this master: ,warn,HBase
 completed,info,HBase
 failed with ,info,HBase
"Table  |  was not enabled, sleeping. tries=",debug,HBase
No serialized HRegionInfo in ,warn,HBase
"Call to  |  for scanner id =  |  for  |  of  |  failed, , tries =  | , maxAttempts =  | , timeout =  |  ms, time elapsed =  |  ms",warn,HBase
decode scan response failed,warn,HBase
"The future is already done, canceled=*, give up retrying",debug,HBase
", tries =  | , maxAttempts =  | , timeout =  |  ms, time elapsed =  |  ms",warn,HBase
"TimeRange failed, likely caused by integer overflow. ",error,HBase
Cached location: ,trace,HBase
Changed cached location to: ,trace,HBase
Cached location: ,trace,HBase
Merged cached locations: ,trace,HBase
Removed all cached region locations that map to ,trace,HBase
Removed all cached region locations for table ,trace,HBase
Removed  |  from cache,trace,HBase
Removed  |  from cache,trace,HBase
"Removed locations of table:  |  ,row:  |  mapping to server:  |  from cache",trace,HBase
Removed  |  from cache,trace,HBase
Removed  |  from cache,trace,HBase
"The  |  setting:  |  is smaller than  | , will use  |  instead.",warn,HBase
Replica thread interrupted - no replica calls *,error,HBase
No replicas found for *,warn,HBase
"id= | , caught throwable. Unexpected. |  Retrying. Server= | , tableName=",error,HBase
id= |  error for  |  processing ,error,HBase
$$$Empty Message$$$,error,HBase
"id= | , task rejected by pool. Unexpected. |  Server=",warn,HBase
Caught unexpected exception/error: ,warn,HBase
id= |  replica task rejected by pool; no replica calls,warn,HBase
$$$Empty Message$$$,info,HBase
"# | , not sent:  |  operations, ",warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,info,HBase
"Server sent us neither results nor exceptions for  | , numAttempt:",error,HBase
Couldn't update cached region locations: ,error,HBase
"User callback threw an exception for  | , ignoring",error,HBase
"# | , waiting for  |   actions to finish on table: ",info,HBase
"The result is assigned repeatedly! current: | , new:",debug,HBase
Try adding * to cache,trace,HBase
Will not add * to cache because the old value *  is newer than us or has the same server name. Maybe it is updated before we replace it,trace,HBase
"The newnly fetch region * is different from the old one * for row '*', try replaing the old one...",debug,HBase
"Failed to locate region in ' | ', row=' | ', locateType=",warn,HBase
"The fetched location of '*', row='*', locateType=* is *",debug,HBase
"Found * in cache for *, row='*', locateType=*, replicaId=*",trace,HBase
"Found * in cache for *, row='*', locateType=*, replicaId=*",trace,HBase
"Try locate ' | ', row=' | ', locateType= |  in meta",trace,HBase
incorrect format:,info,HBase
"Can't parse the hostname, port and startCode from this string:  | , continuing",warn,HBase
invalid charset,error,HBase
Registering new filter ,info,HBase
Relogin failed,warn,HBase
Connecting to *,trace,HBase
call write error for call #,debug,HBase
Received exception in connection setup.\n,debug,HBase
Received exception in connection setup.\n,debug,HBase
Retrying connect to server:  |  after sleeping  | ms. Already tried  |  time(s).,info,HBase
": starting, connections ",trace,HBase
": stopped, connections ",trace,HBase
Exception encountered while connecting to  | the server : ,debug,HBase
$$$Empty Message$$$,warn,HBase
Exception encountered while connecting to  | the server : ,warn,HBase
$$$Empty Message$$$,error,HBase
Not trying to connect to  |  this server is in the failed servers list,debug,HBase
Connecting to ,debug,HBase
Length of response for connection header:,debug,HBase
"Can't get the connection header response for rpc timeout, please check if server has the correct configuration to support the additional function.",error,HBase
"Error while writing call, call_id:",trace,HBase
ignored,trace,HBase
"got response header  | , totalSize:  |  bytes",trace,HBase
"Unknown callId:  | , skipping over this response of  |  bytes",debug,HBase
shutdown connection to  |  because idle for a long time,trace,HBase
Unrecognized idle state ,warn,HBase
"Codec= | , compressor= | , tcpKeepAlive= | , tcpNoDelay= | , connectTO= | , readTO= | , writeTO= | , minIdleTimeBeforeClose= | , maxRetries= | , fallbackAllowed= | , bind address= | null",debug,HBase
Cleanup idle connection to ,trace,HBase
Not trying to connect to  |  this server is in the failed servers list,debug,HBase
"Call:  | , callTime:  | ms",trace,HBase
The server on  |  is dead - stopping the connection ,info,HBase
Stopping rpc client,debug,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
Added failed server with address  |  to list caused by ,debug,HBase
Master Result is value=,trace,HBase
No token selector found for type ,debug,HBase
RPC Server Kerberos principal name for service= |  is ,debug,HBase
"Use  |  authentication for service  | , sasl=",debug,HBase
Buffer grew from initial bufferSize= |  to  | ; up hbase.ipc.cellblock.building.initial.buffersize?,trace,HBase
Skip exceedThrottleQuota row-key when parse quota result,debug,HBase
unexpected row-key: ,warn,HBase
Failed getting scanner and then failed close on cleanup,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
Use authentication/integrity/privacy as value for rpc protection configurations instead of auth/auth-int/auth-conf.,warn,HBase
Error disposing of SASL client,error,HBase
Error disposing of SASL server,error,HBase
Creating SASL  |  client to authenticate to service at ,debug,HBase
Creating SASL  |  client. Server's Kerberos principal name is ,debug,HBase
SASL client callback: setting username: ,debug,HBase
SASL client callback: setting userPassword,debug,HBase
SASL client callback: setting realm: ,debug,HBase
Sending token size=* from initSASLContext.,trace,HBase
Reading input token size=* for processing by initSASLContext,trace,HBase
SASL client context established. Negotiated QoP *,trace,HBase
Have sent token of size  |  from initSASLContext.,debug,HBase
Server asks us to fall back to simple auth.,debug,HBase
Will read input token of size  |  for processing by initSASLContext,debug,HBase
Will send token of size  |  from initSASLContext.,debug,HBase
Will read input token of size  |  for processing by initSASLContext,debug,HBase
SASL client context established. Negotiated QoP: ,debug,HBase
reading next wrapped RPC packet,debug,HBase
unwrapping token of length:,debug,HBase
wrapping token of length:,debug,HBase
Unable to unwrap key with current master key ' | ',debug,HBase
Ignoring unknown action code ' | ',error,HBase
Ignoring unknown action code '*',error,HBase
Returning token ,debug,HBase
No matching token found,debug,HBase
$$$Empty Message$$$,error,HBase
Exception while reading cells from result.Resetting the scanner to scan again.,error,HBase
"Connect * to * with session timeout=*ms, retries *, retry interval *ms, keepAlive=*ms",debug,HBase
"* to * session expired, close and reconnect",warn,HBase
"* to * failed for * of *, code = *, retries = *",warn,HBase
"* to * failed for * of *, code = *, retries = *, give up",warn,HBase
"* to * failed to connect to zk fo * of *, retries = *",warn,HBase
"* to * failed to connect to zk fo * of *, retries = *, give up",warn,HBase
* to * inactive for *ms; closing (Will reconnect when new requests),trace,HBase
Close zookeeper connection * to *,debug,HBase
"Unexpected getShortMidpointKey result, fakeKey: | , firstKeyInBlock:",error,HBase
"Unexpected getShortMidpointKey result, lastKeyOfPreviousBlock: | , fakeKey:",error,HBase
instantiating HBaseConfiguration() is deprecated. Please use HBaseConfiguration#create() to construct a plain Configuration,warn,HBase
Error thrown: ,warn,HBase
ClassNotFound: ConfServlet,debug,HBase
Config option \,warn,HBase
Config option \ |  the Configuration getPassword method.,debug,HBase
Config option \,debug,HBase
Credential.getPassword method is not available. |  Falling back to configuration.,debug,HBase
Chore:  |  missed its start time,info,HBase
Chore:  |  was stopped,info,HBase
Caught error,error,HBase
"Trying to login with a different user: *, existed user is *.",warn,HBase
"Error while trying to login as user * through *, with message: *.hbase.client.keytab.principalhbase.client.keytab.file",error,HBase
Error resolving host name: ,error,HBase
Error while trying to perform the initial login: ,error,HBase
Got exception while trying to refresh credentials: ,error,HBase
Could not successfully schedule chore: ,info,HBase
Chore service for:  |  had  |  on shutdown,info,HBase
$$$Empty Message$$$,trace,HBase
$$$Empty Message$$$,trace,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
Error getting available for error message - ignoring,trace,HBase
Partial cell read caused by EOF,trace,HBase
$$$Empty Message$$$,debug,HBase
Created with bufferSize=* and maxPoolSize=*,info,HBase
Pool already reached its max capacity :  |  and no free buffers now. Consider increasing the value for ' | ' ?,debug,HBase
Pool already reached its max capacity :  |  and no free buffers now. Consider increasing the value for ' | ' ?,info,HBase
Creating a new offheap ByteBuffer of size: ,trace,HBase
"Trying to put a buffer, not created by this pool! Will be just ignored",warn,HBase
Retrieved compressor  |  from pool.,trace,HBase
Compressor obtained from CodecPool is already finished(),warn,HBase
Returning compressor  |  to pool.,trace,HBase
Retrieved decompressor  |  from pool.,trace,HBase
Deompressor obtained from CodecPool is already finished(),warn,HBase
Returning decompressor  |  to pool.,trace,HBase
Ending decompressor ,trace,HBase
Unable to decrypt data with current cipher algorithm ' | '. Trying with the alternate cipher algorithm ' | ' configured.,debug,HBase
Installed  |  into key provider cache,debug,HBase
"Could not instantiate specified RNG, falling back to default",warn,HBase
"Could not instantiate specified RNG, falling back to default",warn,HBase
"RowNumber:  | , onDiskDataSize:  | , totalOnDiskSize: ",trace,HBase
Current user name is *,trace,HBase
SpanReceiver  |  was loaded successfully.,info,HBase
Unable to close SpanReceiver correctly: ,warn,HBase
Warning: using deprecated configuration key  | .  Please use  |  instead.,warn,HBase
Conflicting values for  |  and  | .  Using ,warn,HBase
"Given interval value is not a number, parsing for human readable format",debug,HBase
Tool configuration is not initialized,error,HBase
$$$Empty Message$$$,error,HBase
Use -h or --help for usage instructions.,error,HBase
Error when parsing command-line arguments,error,HBase
Use -h or --help for usage instructions.,error,HBase
Error running command-line tool,error,HBase
Error running command-line tool,error,HBase
Not able to load class or method for com.sun.management.UnixOperatingSystemMXBean.,warn,HBase
Not able to get the number of open file descriptors,warn,HBase
Not able to close the BufferedReader,warn,HBase
Not able to close the InputStreamReader,warn,HBase
Not able to close the InputStream,warn,HBase
Not able to close the BufferedReader,warn,HBase
Not able to close the InputStreamReader,warn,HBase
Not able to close the InputStream,warn,HBase
Not able to get the max number of file descriptors,warn,HBase
Not able to close the reader,warn,HBase
Not able to close the InputStream,warn,HBase
$$$Empty Message$$$,error,HBase
Using Unsafe to estimate memory layout,debug,HBase
Not using Unsafe to estimate memory layout,debug,HBase
  |  ,debug,HBase
"Primitives= | , arrays= | , references= | , refSize  | , size= | , prealign_size=",debug,HBase
sun.misc.Unsafe is not available/accessible,warn,HBase
"Allocating buffers total= | , sizePerBuffer= | , count=",info,HBase
Buffer creation interrupted,error,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
sun.misc.Unsafe is not accessible,warn,HBase
Thread: |  exited with Exception:,warn,HBase
; joinwait=,warn,HBase
sleep interrupted,warn,HBase
"Can not find hadoop 2.7+ printThreadInfo method, try hadoop hadoop 2.6 and earlier",info,HBase
Cannot find printThreadInfo method. Check hadoop jars linked,warn,HBase
"We slept  | ms instead of  | ms, this is likely due to a long  | garbage collecting pause and it's usually bad, see  | http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired",warn,HBase
Exception caught during division,error,HBase
"* is trying to release lock entry *, but it is not the holder.",warn,HBase
Constructed invalid call. class= |  method= |  types=,error,HBase
SecurityException calling method. class= |  method= |  types=,error,HBase
Sleeping * ms before retry #*...,trace,HBase
FileSystem doesn't support getDefaultBlockSize,info,HBase
Doesn't have access to getDefaultBlockSize on FileSystems,info,HBase
FileSystem doesn't support getDefaultReplication,info,HBase
Doesn't have access to getDefaultReplication on FileSystems,info,HBase
"Creating file= |  with permission= | , overwrite=",trace,HBase
"Incorrect umask attempted to be created:  | , using default file permissions.",warn,HBase
We have chosen not to throw exception but some unexpectedly thrown out,warn,HBase
"We were passed a null storagePolicy, exiting early.",trace,HBase
"We were passed an empty storagePolicy, exiting early.",trace,HBase
"We were passed the defer-to-hdfs policy *, exiting early.",trace,HBase
Failed to invoke set storage policy API on FS,trace,HBase
"FileSystem doesn't support setStoragePolicy; HDFS-6584, HDFS-9345 not available. This is normal and expected on earlier Hadoop versions.",warn,HBase
"FileSystem doesn't support setStoragePolicy; HDFS-6584, HDFS-9345 not available. This is normal and expected on earlier Hadoop versions.",debug,HBase
"No access to setStoragePolicy on FileSystem from the SecurityManager; HDFS-6584, HDFS-9345 not available. This is unusual and probably warrants an email to the user@hbase mailing list. Please be sure to include a link to your configs, and logs that include this message and period of time before it. Logs around service start up will probably be useful as well.",warn,HBase
"No access to setStoragePolicy on FileSystem from the SecurityManager; HDFS-6584, HDFS-9345 not available. This is unusual and probably warrants an email to the user@hbase mailing list. Please be sure to include a link to your configs, and logs that include this message and period of time before it. Logs around service start up will probably be useful as well.",debug,HBase
Set storagePolicy= |  for path=,debug,HBase
Unable to set storagePolicy= |  for path= | .  | DEBUG log level might have more details.,warn,HBase
Unable to set storagePolicy= |  for path=,debug,HBase
"Given storage policy, ' | ', was rejected and probably  | isn't a valid policy for the version of Hadoop you're running. I.e. if you're  | trying to use SSD related policies then you're likely missing HDFS-7228. For  | more information see the 'ArchivalStorage' docs for your Hadoop release.",debug,HBase
"The underlying FileSystem implementation doesn't support setStoragePolicy. This is probably intentional on their part, since HDFS-9345 appears to be present in your version of Hadoop. For more information check the Hadoop documentation on 'ArchivalStorage', the Hadoop FileSystem specification docs from HADOOP-11981, and/or related documentation from the provider of the underlying FileSystem (its name should appear in the stacktrace that accompanies this message). Note in particular that Hadoop's local filesystem implementation doesn't support storage policies.",debug,HBase
 doesn't exist,trace,HBase
 doesn't exist,trace,HBase
File system contents for path ,debug,HBase
/,debug,HBase
$$$Empty Message$$$,debug,HBase
"Configuration \ | be set to true. |  HBase checksum doesn't require  | it, see https://issues.apache.org/jira/browse/HBASE-6868.",warn,HBase
Couldn't use reflection with builder API,warn,HBase
Couldn't use reflection with builder API,warn,HBase
"Your Hadoop installation's StreamCapabilities implementation doesn't match our understanding of how it's supposed to work. Please file a JIRA and include the following stack trace. In the mean time we're interpreting this behavior difference as a lack of capability support, which will probably cause a failure.",warn,HBase
$$$Empty Message$$$,info,HBase
"Failed to identify the fs of dir  | , ignored",warn,HBase
Class  |  not found - using dynamical class loader,debug,HBase
Class  |  already loaded,debug,HBase
Finding class: ,debug,HBase
"Loading new jar files, if any",debug,HBase
Finding class again: ,debug,HBase
Failed to load new jar ,warn,HBase
Failed to check remote dir status ,warn,HBase
Ignored non-jar file ,debug,HBase
Failed to load new jar ,warn,HBase
Found classloader  |  for ,debug,HBase
Found classloader  |  for ,debug,HBase
"THIS SHOULD NOT HAPPEN, a class loader |  is already cached for ",warn,HBase
Skipping exempt class  |  - delegating directly to parent,debug,HBase
Class  |  already loaded,debug,HBase
Finding class: ,debug,HBase
Class  |  not found - delegating to parent,debug,HBase
Class  |  not found in parent loader,debug,HBase
Checking parent first for resource ,debug,HBase
$$$Empty Message$$$,info,HBase
Could not write thread info about ' | ' due to a string encoding issue.,warn,HBase
= |  is inferior to ,warn,HBase
= |  is superior to ,warn,HBase
before:  |  ,info,HBase
after:  |  ,info,HBase
No resource analyzer,info,HBase
No resource analyzer,info,HBase
No initial values,warn,HBase
Looking in  | ; isJar=,debug,HBase
Failed to look for classes in  | : ,warn,HBase
Failed to get next entry from  | : ,warn,HBase
Ignoring duplicate class ,warn,HBase
 does not exist,warn,HBase
Failed to get files from ,warn,HBase
Ignoring duplicate class ,warn,HBase
Failed to instantiate or check  | : ,debug,HBase
Failed to instantiate or check  | : ,debug,HBase
"Sleep interrupted, {0}",warn,HBase
Waiting up to [{0}] milli-secs(wait.for.ratio=[{1}]),info,HBase
Waiting interrupted after [{0}] msec,warn,HBase
Waiting timed out after [{0}] msec,warn,HBase
"Failed to get explanation, ",error,HBase
Min fom all regions is: ,debug,HBase
Maximum from this region is  | : ,info,HBase
Minimum from this region is  | : ,info,HBase
Sum from this region is  | : ,debug,HBase
Row counter from this region is  | : ,info,HBase
"compressed= | , compression type= | , compression codec= | , userToken=",info,HBase
"Hadoop security is enable, but no found of user token",warn,HBase
$$$Empty Message$$$,error,HBase
"No found of user credentials, but a token was got from user request",warn,HBase
SecureBulkLoadEndpoint is deprecated. It will be removed in future releases.,warn,HBase
Secure bulk load has been integrated into HBase core.,warn,HBase
Setting sum result to -1 to indicate error,info,HBase
Setting sum result to -1 to indicate error,info,HBase
Returning sum  |  for region ,info,HBase
Setting sum result to -1 to indicate error,info,HBase
Setting sum result to -1 to indicate error,info,HBase
Returning result ,info,HBase
Setting sum result to -1 to indicate error,info,HBase
Setting sum result to -1 to indicate error,info,HBase
Warmed up region location cache for  |  got ,info,HBase
Failed to sent put  | .,info,HBase
exception while creating/destroying Connection or BufferedMutator,info,HBase
Done refreshing HFiles,debug,HBase
Refresh HFiles from table  |   failed: ,error,HBase
Create table took: ,info,HBase
Refreshing HFiles for region:  |  and store:  | class:,debug,HBase
Exception while trying to refresh store files: ,error,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
Creating MemcachedBlockCache,info,HBase
MemcachedBlockCache can not cache Cacheable's of type ,debug,HBase
Exception pulling from memcached [  |  ]. Treating as a miss.,debug,HBase
Error deleting ,warn,HBase
Error deleting ,debug,HBase
Error deserializing data from memcached,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
Ignoring unknown Metric class ,info,HBase
Ignoring Gauge ( | ) with unhandled type: ,warn,HBase
doRun called: ,trace,HBase
Registering adapter for the MetricRegistry: ,debug,HBase
Registering  |  ,info,HBase
Removing adapter for the MetricRegistry: ,debug,HBase
Error trying to remove  |  from ,info,HBase
Creating new MetricsRegionSourceImpl for table  |  ,debug,HBase
Removing region Metrics: ,trace,HBase
Error trying to remove  |  from ,info,HBase
Creating new MetricsTableSourceImpl for table '*',debug,HBase
Removing table Metrics for table ,trace,HBase
clearing JMX Cache,trace,HBase
Clearing JMX mbean cache.,trace,HBase
error clearing the jmx it appears the metrics system hasn't been started,debug,HBase
$$$Empty Message$$$,trace,HBase
Unable to remove object name from cache: ,trace,HBase
Received exception while trying to access Hadoop Metrics classes via reflection.,trace,HBase
 is incomplete. Sending auto-refresh header.,info,HBase
Jetty request log can only be enabled using Log4j,warn,HBase
Http request log for  |  could not be created,warn,HBase
Http request log for  |  is not defined,info,HBase
Jetty request log for  |  was of the wrong class,warn,HBase
adding path spec: ,info,HBase
ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.,info,HBase
"addJerseyResourcePackage: packageName= | , pathSpec=",info,HBase
Adding Kerberos (SPNEGO) filter to ,info,HBase
Added filter  |  (class= | ) to context ,info,HBase
Added filter  |  (class= | ) to context ,info,HBase
Added global filter ' | ' (class= | ),info,HBase
HttpServer.start() threw a non Bind IOException,info,HBase
HttpServer.start() threw a MultiException,info,HBase
Jetty bound to port ,info,HBase
Error while stopping listener for webapp,error,HBase
Error while stopping web app context for webapp ,error,HBase
Error while stopping web server for webapp ,error,HBase
Servlet process PID:  |  asyncProfilerHome: ,info,HBase
Unable to acquire lock in  |  seconds. Another instance of profiler might be running.,warn,HBase
Interrupted while acquiring profile lock.,warn,HBase
Caught an exception while processing JMX request,error,HBase
Caught an exception while processing JMX request,error,HBase
"dfs.web.ugi should not be used. Instead, use hbase.http.staticuser.user.",warn,HBase
Unable to get value from MBean=  | for attribute= |  ,error,HBase
keys and values arrays must be same size,error,HBase
keys and values arrays can not be empty;,error,HBase
Running command async: ,info,HBase
Listing beans for ,trace,HBase
Getting attribute  |  of  |  threw ,trace,HBase
Getting attribute  |  of  |  threw an exception,error,HBase
getting attribute  |  of  |  threw an exception,error,HBase
getting attribute  |  of  |  threw an exception,error,HBase
getting attribute  |  of  |  threw an exception,error,HBase
getting attribute  |  of  |  threw an exception,error,HBase
Problem while trying to process JMX query:  |  with MBean ,error,HBase
Problem while trying to process JMX query:  |  with MBean ,error,HBase
Getting attribute  |  of  |  threw ,trace,HBase
getting attribute  |  of  |  threw an exception,error,HBase
getting attribute  |  of  |  threw an exception,debug,HBase
getting attribute  |  of  |  threw an exception,error,HBase
getting attribute  |  of  |  threw an exception,error,HBase
getting attribute  |  of  |  threw an exception,error,HBase
"get:  | = | ,  | =",info,HBase
Performing  |  command against  |  on  | ...,info,HBase
Executing POST against  |  with body  | ...,info,HBase
Executing GET against  | ...,info,HBase
Running with SSH user [ | ] and options [ | ],info,HBase
Executing full command [ | ],info,HBase
"Executing remote command:  |   |  , hostname:",info,HBase
"Executed remote command, exit code: |  , output:",info,HBase
Sleep Interrupted:,warn,HBase
"Remote command:  |   |  , hostname: |  failed at attempt  | . Retrying until maxAttempts:  | . Exception: ",warn,HBase
Starting RS on: ,info,HBase
Aborting RS: ,info,HBase
Stopping RS: ,info,HBase
Starting ZooKeeper node on: ,info,HBase
Aborting ZooKeeper node on: ,info,HBase
Stopping ZooKeeper node: ,info,HBase
Starting data node on: ,info,HBase
Aborting data node on: ,info,HBase
Stopping data node on: ,info,HBase
Starting name node on: ,info,HBase
Aborting name node on: ,info,HBase
Stopping name node on: ,info,HBase
Waiting for service:  |  to stop: ,info,HBase
Waiting for service:  |  to start: ,info,HBase
Starting Master on:  | :,info,HBase
Aborting Master: ,info,HBase
Stopping Master: ,info,HBase
Master not started yet ,warn,HBase
Failed to connect to ZK ,warn,HBase
Cannot find region server holding region ,warn,HBase
Restoring cluster - started,info,HBase
Restoring cluster - done,info,HBase
Restoring cluster - Initial active master :  |  has changed to : ,info,HBase
Restoring cluster - starting initial active master at:,info,HBase
Restoring cluster - stopping backup master: ,info,HBase
Restoring cluster - stopping active master: ,info,HBase
Restoring cluster - starting initial backup master: ,info,HBase
Restoring cluster - starting initial backup master: ,info,HBase
Restoring cluster - stopping backup master: ,info,HBase
Restoring cluster - restoring region servers reported  |  errors:,warn,HBase
$$$Empty Message$$$,warn,HBase
Restoring cluster - starting initial region server: ,info,HBase
Restoring cluster - stopping initial region server: ,info,HBase
Restoring cluster - restoring region servers reported  |  errors:,warn,HBase
$$$Empty Message$$$,warn,HBase
While closing the old connection,warn,HBase
Added new HBaseAdmin,info,HBase
Initializing/checking cluster has 1 servers,debug,HBase
Done initializing/checking cluster,debug,HBase
Deleting table,info,HBase
Deleted table,info,HBase
Restoring the cluster,info,HBase
Done restoring the cluster,info,HBase
Write failed,error,HBase
Read failed,error,HBase
STATUS ,info,HBase
Test does not make a lot of sense for minicluster. Will set flush size low.,warn,HBase
Performing action: Restart active namenode,info,HBase
Found active namenode host:,info,HBase
Restarting Active NameNode :,info,HBase
"Performing action: Compact random region of table  | , major=",info,HBase
Table  |  doesn't have regions to compact,info,HBase
Major compacting region ,debug,HBase
Compacting region ,debug,HBase
"Compaction failed, might be caused by other chaos: ",warn,HBase
Performing action: Change split policy of table ,info,HBase
Changing  |  split policy to ,info,HBase
Performing action: Restart random region server,info,HBase
Performing action: Merge random adjacent regions of table ,info,HBase
Table  |  doesn't have enough regions to merge,info,HBase
Merging  |  and ,debug,HBase
"Merge failed, might be caused by other chaos: ",warn,HBase
Performing action: Move regions of table *,info,HBase
Table * doesn't have regions to move,info,HBase
Moving * to *,debug,HBase
"Move failed, might be caused by other chaos: *",warn,HBase
Performing action: Restart random RS holding table ,info,HBase
Performing action: Restart random data node,info,HBase
Performing action: Rolling batch restarting %d%% of region servers,info,HBase
Problem killing but presume successful; code=,info,HBase
"Problem starting, will retry; code=",info,HBase
Killed ,info,HBase
Started ,info,HBase
Performing action: Split all regions of  ,info,HBase
Skipping split of all regions.,info,HBase
Not killing server because it holds hbase:meta.,info,HBase
Killing master ,info,HBase
Killed master ,info,HBase
Starting master ,info,HBase
Started master ,info,HBase
Killing regionserver ,info,HBase
Killed regionserver  | . Reported num of rs:,info,HBase
Starting regionserver ,info,HBase
Started regionserver  | . Reported num of rs:,info,HBase
Killing zookeeper node ,info,HBase
Killed zookeeper node  | . Reported num of rs:,info,HBase
Starting zookeeper node ,info,HBase
Started zookeeper node ,info,HBase
Killing datanode ,info,HBase
Killed datanode  | . Reported num of rs:,info,HBase
Starting datanode ,info,HBase
Started datanode ,info,HBase
Killing namenode :-,info,HBase
Killed namenode: | . Reported num of rs:,info,HBase
Starting Namenode :-,info,HBase
Started namenode:,info,HBase
Removing  |  regions from ,debug,HBase
Moving  |  regions from  |  servers to  |  different servers,info,HBase
Got exception while doing balance ,warn,HBase
Balancer didn't succeed,error,HBase
"Performing action: Compact table  | , major=",info,HBase
"Compaction failed, might be caused by other chaos: ",warn,HBase
Performing action: Snapshot table ,info,HBase
Performing action: Split random region of table ,info,HBase
Table  |  doesn't have regions to split,info,HBase
Splitting region ,debug,HBase
"Split failed, might be caused by other chaos: ",warn,HBase
Performing action: Removing  |  from ,debug,HBase
Performing action: Restart random zookeeper node,info,HBase
Performing action: Flush random region of table ,info,HBase
Table  |  doesn't have regions to flush,info,HBase
Flushing region ,debug,HBase
"Flush failed, might be caused by other chaos: ",warn,HBase
Performing action: Changing encodings on ,debug,HBase
Performing action: Restart region server holding META,info,HBase
No server is holding hbase:meta right now.,warn,HBase
Performing action: Flush table ,info,HBase
"Flush failed, might be caused by other chaos: ",warn,HBase
Unbalancing regions,info,HBase
Performing action: Batch restarting %d%% of region servers,info,HBase
Killing region server:,info,HBase
Killed  |  region servers. Reported num of rs:,info,HBase
Starting region server:,info,HBase
Started  |  region servers. Reported num of rs:,info,HBase
Balancing regions,info,HBase
Performing action: Truncate table  | preserve splits ,info,HBase
Performing action: Change bloom filter on all columns of table ,info,HBase
Performing action: Just set bloom filter types on table ,debug,HBase
Sleeping for:,info,HBase
"Performing action: Changing compression algorithms to  |  is not supported, pick another one",info,HBase
Performing action: Changing compression algorithms on  |  to ,debug,HBase
Performing action: Move random region of table ,info,HBase
Table  |  doesn't have regions to move,info,HBase
Move random region *,debug,HBase
Performing action: Adding  |  to ,debug,HBase
Performing action: Changing versions on  |  to ,debug,HBase
Performing action: Just changed versions on ,debug,HBase
Performing action: Restart active master,info,HBase
Performing action: Dump cluster status,debug,HBase
Cluster status\n,info,HBase
"Performing action: Compact mob of table  | , major=",info,HBase
"Mob Compaction failed, might be caused by other chaos: ",warn,HBase
Error trying to create  |  could not load it by class name,error,HBase
Exception occurred during performing action: ,warn,HBase
Sleeping for * ms to add jitter,info,HBase
Sleeping for * ms,info,HBase
"Using ChaosMonkey Policy *, period=* ms",info,HBase
Exception performing action: ,warn,HBase
Exception occurred during performing action: ,warn,HBase
Exception occurred during performing action: ,warn,HBase
Exception occurred during performing action: ,warn,HBase
Chaos monkeys are running.,info,HBase
Chaos monkeys are stopped.,info,HBase
Interruption occurred while stopping chaos monkeys ,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
"TIFB.restart, firstRow:  | , endRow: ",debug,HBase
"TIFB.restart, firstRow:  | , no endRow",debug,HBase
Current scan=,info,HBase
Error closing table,warn,HBase
Mapper took  | ms to process  |  rows,info,HBase
recovered from ,debug,HBase
"We are restarting the first next() invocation, if your mapper has restarted a few other times like this then you should consider killing this job and investigate why it's taking so long.",warn,HBase
Mapper took  | ms to process  |  rows,info,HBase
$$$Empty Message$$$,info,HBase
lastSuccessfulRow=,info,HBase
split:  | ->,info,HBase
initializeTable called multiple times. Overwriting connection and table reference; TableInputFormatBase will not close these old references when done.,warn,HBase
Interrupted obtaining user authentication token,info,HBase
Interrupted obtaining user authentication token,info,HBase
"The addDependencyJars(Configuration, Class<?>...) method has been deprecated since it is easy to use incorrectly. Most users should rely on addDependencyJars(Job) instead. See HBASE-8386 for more details.",warn,HBase
Could not find jar for class  |  in order to ship it to the cluster.,warn,HBase
Could not validate jar file  |  for class ,warn,HBase
"For class %s, using jar %s",debug,HBase
Considering the row.,trace,HBase
Considering the row.,trace,HBase
Considering the row.,trace,HBase
Considering the row.,trace,HBase
Considering the row.,trace,HBase
Setting up  |  mapper.,info,HBase
setting WAL durability to ,info,HBase
setting WAL durability to default.,info,HBase
Problem connecting to ZooKeper during task setup,error,HBase
Problem reading ZooKeeper data during task setup,error,HBase
Problem setting up task,error,HBase
"No configured filter class, accepting all keyvalues.",debug,HBase
Attempting to create filter:,debug,HBase
Couldn't instantiate filter!,error,HBase
Couldn't instantiate filter!,error,HBase
Couldn't instantiate filter!,error,HBase
Couldn't instantiate filter!,error,HBase
Couldn't instantiate filter!,error,HBase
Filter returned: |  for the cell:,trace,HBase
Use Large Result!!,info,HBase
writing to hfiles for bulk load.,info,HBase
writing directly to table from Mapper.,info,HBase
Flushing all data that skipped the WAL.,info,HBase
An error occurred.,error,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
Read source hash manifest: ,info,HBase
Read  |  partition keys,info,HBase
Table name mismatch - manifest indicates hash was taken from:  |  but job is reading from: ,warn,HBase
Read source hash manifest: ,info,HBase
Read  |  partition keys,info,HBase
Hash mismatch.  Key range:  |  to  |  sourceHash:  |  targetHash: ,debug,HBase
Target missing row: ,info,HBase
Source missing row: ,info,HBase
Target missing cell: ,debug,HBase
Source missing cell: ,debug,HBase
Different values: ,debug,HBase
  source cell:  |  value: ,debug,HBase
  target cell:  |  value: ,debug,HBase
Suppressing exception from closing tables,error,HBase
Map-reduce job failed!,info,HBase
Created new MultiTableRecordReader with WAL  | on,debug,HBase
Opening HTable \ | \,debug,HBase
add incremental job : |  from ,debug,HBase
Region size calculation disabled.,info,HBase
Region size calculation disabled for system tables.,info,HBase
Calculating region sizes for table \ | \,info,HBase
Region  |  has size ,debug,HBase
Region sizes calculated,debug,HBase
Unknown region:,debug,HBase
Initialize HFileRecordReader for *,info,HBase
Seeking to start,info,HBase
Failed to convert Scan to String,warn,HBase
Table '%s' does not exist.,warn,HBase
Dry run: Table will be deleted at end of dry run.,warn,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
Creating table '%s' with '%s' columns and default descriptors.,warn,HBase
"Dry mode: Table:  |  already disabled, so just deleting it.",debug,HBase
***Dry run: Failed to delete table '%s'.***%n%s,error,HBase
Dry run: Deleted table '%s'.,info,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
Opening reader for ,info,HBase
Corrupted entry detected. Ignoring the rest of the file. (This is normal when a RegionServer crashed.),warn,HBase
Skipped  |  entries.,info,HBase
Reached end of file.,info,HBase
"Skipped  |  entries, until ts:  | .",info,HBase
Reached ts:  |  ignoring the rest of the file.,info,HBase
Closing reader,info,HBase
File  |  is missing. Skipping it.,warn,HBase
Scanning  |  for WAL files,debug,HBase
Found: ,info,HBase
File  |  does not appear to be an WAL file. Skipping...,warn,HBase
Setting Row Filter for counter.,info,HBase
Setting TimeRange for counter.,info,HBase
Load exported file using deserializer for HBase 0.94 format,info,HBase
Failing job because count of ' | ' does not match expected count of ' | ',error,HBase
Setting Scan Filter for Export.,info,HBase
Batching could not be set,error,HBase
Caching could not be set,error,HBase
"versions= | , starttime= | , endtime= | , keepDeletedCells= | , visibility labels=",info,HBase
Restoring snapshot  |  into  |  for MultiTableSnapshotInputFormat,info,HBase
Error opening 'labels' table,error,HBase
Error scanning 'labels' table,error,HBase
Failed reading 'labels' tags,error,HBase
Error closing 'labels' table,warn,HBase
Failed close of temporary connection,warn,HBase
Configuring multithread runner to use  |  threads,debug,HBase
Problem in running map.,error,HBase
HFiles will be stored at ,info,HBase
Map-reduce job failed!,info,HBase
Files are not bulkloaded!,info,HBase
Trying to bulk load data to destination table: ,info,HBase
command: ./bin/hbase org.apache.hadoop.hbase.tool.LoadIncrementalHFiles * *,info,HBase
Deleting folder  |  failed!,error,HBase
Using deprecated configuration  |  - please use static accessor methods instead.,warn,HBase
$$$Empty Message$$$,info,HBase
"startkey= | , endkey=",info,HBase
Writing  |  partition keys to ,info,HBase
Map-reduce job failed!,info,HBase
Closing the previously opened scanner object.,info,HBase
Current scan=,info,HBase
Error closing table,warn,HBase
Mapper took  | ms to process  |  rows,info,HBase
recovered from ,info,HBase
"We are restarting the first next() invocation, if your mapper has restarted a few other times like this then you should consider killing this job and investigate why it's taking so long.",warn,HBase
Mapper took  | ms to process  |  rows,info,HBase
$$$Empty Message$$$,info,HBase
lastSuccessfulRow=,info,HBase
can't update counter.,debug,HBase
Failed to convert Scan to String,warn,HBase
Input split length: {0} bytes.,info,HBase
getSplits: split ->  |  -> ,debug,HBase
Combined %d Put(s) into %d.,debug,HBase
Combined %d Put(s) into %d.,debug,HBase
There's something wrong when locating rowkey:  |  for tablename: ,warn,HBase
"failed to get region location, so use default writer for rowkey: ",trace,HBase
first rowkey: [ | ],debug,HBase
"failed to resolve bind address:  | : | , so use default writer",trace,HBase
use favored nodes writer: ,debug,HBase
Writer= | ,info,HBase
Looking up current regions for table ,info,HBase
SplitPoint startkey for table [ | ]: [ | ],debug,HBase
Writing partition information to ,info,HBase
Unknown map output value type:,warn,HBase
bulkload locality sensitive enabled,info,HBase
Configuring  |  reduce partitions  | to match current region count for all tables,info,HBase
"Incremental output configured for tables:  | ,",info,HBase
Incremental table  |  output configured.,info,HBase
Input split length:  |  bytes.,info,HBase
Failed resolve ,warn,HBase
getSplits: split ->  |  -> ,debug,HBase
"The averageRegionSize is not positive:  | ,  | set it to Long.MAX_VALUE ",warn,HBase
initializeTable called multiple times. Overwriting connection and table reference; TableInputFormatBase will not close these old references when done.,warn,HBase
Created table instance for ,info,HBase
$$$Empty Message$$$,error,HBase
Setting number of version inside map as: ,info,HBase
Using peer snapshot: |  with temp dir: |  peer root uri: |  peerFSAddress:,info,HBase
Good row key: ,info,HBase
Good row key (with recompare): ,info,HBase
"recompare fail after sleep, rowkey=",error,HBase
", rowkey=",error,HBase
fail to scan peer table in cleanup,error,HBase
fail to close source table in cleanup,error,HBase
fail to close source connection in cleanup,error,HBase
fail to close replicated table in cleanup,error,HBase
fail to close replicated connection in cleanup,error,HBase
"Peer Quorum Address:  | , Peer Configuration: ",info,HBase
Peer Quorum Address: ,info,HBase
Peer Table Name: ,info,HBase
Number of version: ,info,HBase
Number of versions set to ,info,HBase
Using source snapshot- |  with temp dir:,info,HBase
Compact table= |  region= |  family=,info,HBase
Create input file= |  with  |  dirs to compact.,info,HBase
Using bufferSize=,info,HBase
snapshot does not keeps WALs: ,warn,HBase
Injecting failure. Count: ,debug,HBase
"Skip copy  |  to  | , same file.",info,HBase
You may have to run manually chown on: ,warn,HBase
Unable to get the status for file=,warn,HBase
Unable to set the permission for file= | : ,warn,HBase
Unable to set the owner/group for file= | : ,warn,HBase
The user/group may not exist on the destination cluster: user= |  group=,warn,HBase
copy completed for input= |  output=,info,HBase
size= |  ( | ) |  time= |  %.3fM/sec,info,HBase
Error copying  |  to ,error,HBase
Unable to open source file=,error,HBase
Unable to get the status for source file=,error,HBase
Unable to get the status for source file=,error,HBase
Unable to get checksum for file=,warn,HBase
Loading Snapshot ' | ' hfile list,info,HBase
export split= |  size=,debug,HBase
Use -h or --help for usage instructions.,error,HBase
Use -h or --help for usage instructions.,error,HBase
inputFs= |  inputRoot=,debug,HBase
outputFs= |  outputRoot=,debug,HBase
Copy Snapshot Manifest from  |  to ,info,HBase
 to  |  |  to ,warn,HBase
Change the permission of  |  to ,warn,HBase
Finalize the Snapshot Export,info,HBase
Verify snapshot integrity,info,HBase
Export Completed: ,info,HBase
Snapshot export failed,error,HBase
needsDelete,debug,HBase
 split  | : ,debug,HBase
Table  |  created,info,HBase
Created  |  connections for  |  threads,info,HBase
$$$Empty Message$$$,info,HBase
Finished  |  in  | ms over  |  rows,info,HBase
[ | ] Summary of timings (ms): ,info,HBase
[ |  duration ] | \tMin:  | ms | \tMax:  | ms | \tAvg:  | ms,info,HBase
[ Avg latency (us)]\t,info,HBase
[ Avg TPS/QPS]\t | \t row per second,info,HBase
"Client= | , input=",info,HBase
Sampling 1 every  |  out of  |  total rows.,info,HBase
Timed test starting in thread ,info,HBase
Cycle= |  of ,info,HBase
MultiGet enabled. Sending GETs in batches of  | .,info,HBase
$$$Empty Message$$$,trace,HBase
MultiPut enabled. Sending PUTs in batches of  | .,info,HBase
Scan for key range %s - %s returned %s rows,info,HBase
MultiGet enabled. Sending GETs in batches of  | .,info,HBase
$$$Empty Message$$$,trace,HBase
MultiPut enabled. Sending PUTs in batches of  | .,info,HBase
"Option ""rows"" unspecified. Using default value 1048576. This could take a very long time.",warn,HBase
 test run options=,info,HBase
Loaded MetricRegistries ,info,HBase
Found multiple MetricRegistries implementations:  | . Using first found implementation: ,warn,HBase
Executing *,trace,HBase
CODE-BUG unknown timeout task type *,error,HBase
"ADDED *; timeout=*, timestamp=*",info,HBase
Ignoring * exception: *,error,HBase
CHILD LATCH INCREMENT SET ,trace,HBase
CHILD LATCH INCREMENT ,trace,HBase
CHILD LATCH DECREMENT ,trace,HBase
"* bypassed, returning null to finish it",info,HBase
"* bypassed, skipping rollback",info,HBase
"* didn't hold the lock before restarting, skip acquiring lock.",debug,HBase
"* is already finished, skip acquiring lock.",debug,HBase
"* is already bypassed, skip acquiring lock.",debug,HBase
"* is in WAITING STATE, and holdLock=false, skip acquiring lock.",debug,HBase
"* held the lock before restarting, call acquireLock to restore it.",debug,HBase
Suspend ,trace,HBase
Found procedures suspended in a ready event! Size=,warn,HBase
Unsuspend ,trace,HBase
  | ; cycles=,trace,HBase
*,trace,HBase
Abort requested for *,debug,HBase
Ignore abort request on * because it has already been finished,warn,HBase
Ignore abort request on * because it does not support rollback,warn,HBase
Ignoring abort request on state=' | ' for ,warn,HBase
"Waiting termination of thread *, *; sending interrupt",warn,HBase
* join wait got interrupted,warn,HBase
Add procedure * as the *th rollback step,debug,HBase
No completed procedures to cleanup.,trace,HBase
Evict completed *,trace,HBase
Already running,warn,HBase
"Instantiated, coreThreads=* (allowCoreThreadTimeOut=true), queueMaxSize=*, operationDelay=*",info,HBase
Stopping procedure remote dispatcher,info,HBase
Waiting for thread-pool to terminate,warn,HBase
Interrupted while waiting for thread-pool termination,warn,HBase
"since no node for this key *, we can't removed the finished remote procedure",warn,HBase
"Waiting termination of thread  | , ",warn,HBase
 join wait got interrupted,warn,HBase
Toggle KILL before store update to: ,warn,HBase
Toggle KILL after store update to: ,warn,HBase
"Procedure * has already been finished and parent is succeeded, skip force updating",debug,HBase
"No pending procedure with id = *, skip force updating.",debug,HBase
"Procedure * has already been finished and expired, skip force updating",debug,HBase
Force update procedure *,debug,HBase
Corrupt ,error,HBase
Completed *,debug,HBase
Loading *,debug,HBase
$$$Empty Message$$$,error,HBase
Starting * core workers (bigger of cpus/4 or 16) with max (burst) worker count=*,info,HBase
Recovered * lease in *,info,HBase
Loaded * in *,info,HBase
Already running,warn,HBase
Start workers *,trace,HBase
Stopping,info,HBase
ThreadGroup * contains running threads; *: See STDOUT,error,HBase
Waiting for pid= |  to be submitted,trace,HBase
"Procedure pid=* does not exist, skipping bypass",debug,HBase
"Begin bypass * with lockWait=*, override=*, recursive=*",debug,HBase
"Waited * ms, but * is still running, skipping bypass with force=*",debug,HBase
"Waited * ms, but * is still running, begin bypass with force=*",debug,HBase
"* is already finished, skipping bypass",debug,HBase
Recursive bypass on children of pid=*,info,HBase
"* has children, skipping bypass",debug,HBase
"Bypassing procedures in RUNNABLE, WAITING and WAITING_TIMEOUT states (with no parent), *",debug,HBase
Bypassing *,debug,HBase
transform procedure * from WAITING_TIMEOUT to RUNNABLE,debug,HBase
removed procedure * from timeoutExecutor,debug,HBase
"Bypassing * and its ancestors successfully, adding to queue",debug,HBase
"Bypassing * and its ancestors successfully, but since it is already running, skipping add to queue",debug,HBase
Stored *,debug,HBase
Stored ,debug,HBase
pid=* already removed by the cleaner.,debug,HBase
Listener  |  had an error: ,error,HBase
Listener  |  had an error: ,error,HBase
Listener  |  had an error: ,error,HBase
"* is already finished, skipping execution",debug,HBase
Rollback because parent is done/rolledback proc=,warn,HBase
RootProcedureState is null for ,warn,HBase
LOCK_EVENT_WAIT rollback...,info,HBase
LOCK_EVENT_WAIT can't rollback child running?...,info,HBase
 ,info,HBase
 ,debug,HBase
Finished  |  in ,info,HBase
Rolled back * exec-time=*,info,HBase
Roll back attempt failed for *,debug,HBase
CODE-BUG: Uncaught runtime exception for ,error,HBase
$$$Empty Message$$$,debug,HBase
Suspend *,trace,HBase
Yield *,trace,HBase
Yield interrupt *,trace,HBase
$$$Empty Message$$$,error,HBase
Short-circuit to next step on pid=*,trace,HBase
Initialized subprocedures=,info,HBase
Added to timeoutExecutor *,trace,HBase
$$$Empty Message$$$,debug,HBase
"Finished subprocedure pid=*, resume processing parent *",info,HBase
"Stored  | , children ",trace,HBase
Store update *,trace,HBase
Interrupt during *. suspend and retry it later.,trace,HBase
"Usually this should not happen, we will release the lock before if the procedure is finished, even if the holdLock is true, arrive here means we have some holes where we do not release the lock. And the releaseLock below may fail since the procedure may have already been deleted from the procedure store.",warn,HBase
CODE-BUG: uncatched runtime exception for procedure: ,error,HBase
CODE-BUG: uncatched runtime exception for completion cleanup: *,error,HBase
"Execute pid=* runningCount=*, activeCount=*",trace,HBase
ASSERT pid=,info,HBase
"Halt pid=* runningCount=*, activeCount=*",trace,HBase
Worker terminating UNNATURALLY *,warn,HBase
Worker terminated.,trace,HBase
"Worker stuck *, run time *",warn,HBase
Added new worker thread *,debug,HBase
Wake ,trace,HBase
the scheduler is not running,debug,HBase
Wake *,trace,HBase
"The BitSetNode for procId=* does not exist, maybe a double deletion?",warn,HBase
"NOT INCREASING! current= | , candidate=",warn,HBase
unable to close the wal file: ,warn,HBase
Archiving  |  to ,info,HBase
"Failed archive of  | , deleting",warn,HBase
Failed delete of ,warn,HBase
Procedure * stack ids=*,debug,HBase
unexpected active children for root-procedure: *,error,HBase
"Missing stack id *, max stack id is *, root procedure is *",error,HBase
"Multiple procedures * have the same stack id *, max stack id is *, root procedure is *",error,HBase
Rebuilding tracker for *,info,HBase
"Nothing left to decode. Exiting with missing EOF, log=*",warn,HBase
Read * entries in *,info,HBase
While reading entry #* in *,error,HBase
Read * entry *,trace,HBase
delete entry *,trace,HBase
Created Procedure Store WAL archive dir *,debug,HBase
Failed create of *,warn,HBase
Got an exception from the sync-loop,error,HBase
"Stopping the WAL Procedure Store, isAbort= |  (self aborting)",info,HBase
join interrupted,warn,HBase
Starting WAL Procedure Store lease recovery,debug,HBase
Sleep * ms after first lease recovery attempt.,trace,HBase
Someone else is active and deleted logs. retrying.,warn,HBase
Someone else has already created log *. Retrying.,debug,HBase
Someone else created new logs. Expected maxLogId < *,debug,HBase
Lease acquired for flushLogId=*,debug,HBase
No state logs to replay.,debug,HBase
WALs cleanup on load is not enabled: ,debug,HBase
Unable to cleanup logs on load: ,warn,HBase
"Insert  | , subproc=",trace,HBase
"Unable to serialize one of the procedure: proc= | , subprocs=",error,HBase
Insert ,trace,HBase
Unable to serialize one of the procedure: ,error,HBase
Update ,trace,HBase
Unable to serialize the procedure: ,error,HBase
Delete *,trace,HBase
Unable to serialize the procedure: ,error,HBase
Update  |  and Delete ,trace,HBase
Unable to serialize the procedure: ,error,HBase
Delete ,trace,HBase
Unable to serialize the procedures: ,error,HBase
Waiting for data. flushed=%s (%s/sec),trace,HBase
"Sync wait %s, slotIndex=%s , totalSynced=%s (%s/sec)",trace,HBase
"unable to sync slots, retry=",warn,HBase
"Sync slots after log roll failed, abort.",error,HBase
"Sync slots= | , flushed=",trace,HBase
"Unable to roll the log, attempt=",warn,HBase
Unable to roll the log,error,HBase
Unable to roll the log,warn,HBase
no active procedures,trace,HBase
all the active procedures are in the latest log,trace,HBase
someone else has already created log *,warn,HBase
Someone else created new logs. Expected maxLogId < *,warn,HBase
Log file with id=* already exists,error,HBase
failed to create log file with id=*,warn,HBase
Encountered exception writing header,warn,HBase
procedure WALs count=* above the warning threshold *. check running procedures to see if something is stuck.,warn,HBase
"Rolled new Procedure Store WAL, id=*",info,HBase
Unable to write the trailer,warn,HBase
Unable to close the stream,error,HBase
Remove the oldest log *,info,HBase
"Remove all state logs with ID less than *, since *",info,HBase
Removing log=*,trace,HBase
"Removed log=*, activeLogs=*",debug,HBase
Unable to remove log: ,error,HBase
Log directory not found: ,warn,HBase
Remove uninitialized log: *,warn,HBase
Opening Pv2 *,debug,HBase
Remove uninitialized log: *,warn,HBase
$$$Empty Message$$$,error,HBase
Unable to read tracker for *,warn,HBase
" znode expired, triggering replicatorRemoved event",info,HBase
* already deleted when removing log,warn,HBase
"Bad version(or node exist) when persist the last pushed sequence id to zookeeper  | storage, Retry =  | , serverName= | , queueId= | , fileName=",warn,HBase
"Failed to parse log position (region= | , peerId= | ), data=",warn,HBase
"Failed parse log position (serverName=*, queueId=*, fileName=*)",warn,HBase
Atomically moving */*'s WALs to *,info,HBase
Removed empty */*,info,HBase
Creating * with data *,debug,HBase
The multi list size is *,trace,HBase
Atomically moved */*'s WALs to *,info,HBase
"Claim queue queueId=* from * to * failed with *, someone else took the log?",info,HBase
"Didn't find a RegionServer that replicates, won't prevent deletions.",debug,HBase
"Replication queue node cversion changed from %d to %d, retry = %d",info,HBase
Adding peer * to hfile reference queue.,info,HBase
Peer * not found in hfile reference queue.,debug,HBase
Removing peer * from hfile reference queue.,info,HBase
Adding hfile references * in queue *,debug,HBase
The multi list size for adding hfile references in zk for node * is *,debug,HBase
Removing hfile references * from queue *,debug,HBase
The multi list size for removing hfile references in zk for node * is *,debug,HBase
"Didn't find any peers with hfile references, won't prevent deletions.",debug,HBase
"Replication hfile references node cversion changed from %d to %d, retry = %d",debug,HBase
Found invalid server name:,error,HBase
Found invalid server name at the end:,error,HBase
Found dead servers:,debug,HBase
GET ,trace,HBase
Query parameters  : Table Name = >  |  Start Row =>  |  End Row =>  |  Columns =>  |  Start Time =>  |  End Time =>  |  Cache Blocks =>  |  Max Versions =>  |  Batch Size => ,trace,HBase
Scan family : ,trace,HBase
Scan family and column :  |   ,trace,HBase
$$$Empty Message$$$,warn,HBase
GET ,trace,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
GET ,trace,HBase
The row :  |  not found in the table.,trace,HBase
new scanner: ,trace,HBase
Exception occurred while processing  |  : ,error,HBase
PUT ,trace,HBase
POST ,trace,HBase
GET ,trace,HBase
PUT ,trace,HBase
PUT ,trace,HBase
POST ,trace,HBase
POST ,trace,HBase
DELETE ,trace,HBase
GET ,trace,HBase
Caught exception,info,HBase
PUT ,trace,HBase
PUT ,trace,HBase
DELETE ,trace,HBase
Invalid filter specification  |  - skipping,warn,HBase
GET ,trace,HBase
$$$Empty Message$$$,warn,HBase
GET ,trace,HBase
Created StreamingOutput with content type =  |  user limit :  |  scan fetch size : ,trace,HBase
Wrote  |  rows to stream successfully.,trace,HBase
Could not parse: ,error,HBase
port set to ,debug,HBase
readonly set to true,debug,HBase
Web UI port set to ,debug,HBase
Skipping Kerberos login for REST server,debug,HBase
Failed to start server,error,HBase
***** STARTING service ' | ' *****,info,HBase
***** STOPPING service ' | ' *****,info,HBase
GET ,trace,HBase
generator exhausted,trace,HBase
GET  |  as ,trace,HBase
generator exhausted,trace,HBase
DELETE ,trace,HBase
GET ,trace,HBase
GET  |  as ,trace,HBase
PUT ,trace,HBase
Exception received while closing the table,debug,HBase
PUT ,trace,HBase
Exception received while closing the table,debug,HBase
PUT  |  ,trace,HBase
PUT  |  as ,trace,HBase
POST  |  ,trace,HBase
POST  |  as ,trace,HBase
DELETE ,trace,HBase
DELETE ,trace,HBase
Exception received while closing the table,debug,HBase
"CHECK-AND-PUT  | , returns ",trace,HBase
Exception received while closing the table,debug,HBase
"CHECK-AND-DELETE  | , returns ",trace,HBase
Exception received while closing the table,debug,HBase
APPEND ,debug,HBase
Exception received while closing the table,debug,HBase
INCREMENT ,debug,HBase
Exception received while closing the table ,debug,HBase
GET ,trace,HBase
GET ,trace,HBase
GET  |  as ,trace,HBase
$$$Empty Message$$$,warn,HBase
filters not supported on gets,warn,HBase
too many results for get ( | ),warn,HBase
"MaxVersions on Gets do not match, using the first in the list ( | )",warn,HBase
filters not supported on gets,warn,HBase
"exists() is really get(), just use get()",warn,HBase
"exists(List<Get>) is really list of get() calls, just use get()",warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
classpath ,debug,HBase
Performing negotiation with the server.,debug,HBase
  |   |   |  in  |  ms,trace,HBase
Failed to negotiate with the server.,error,HBase
encountered ioe when obtaining body,debug,HBase
"Adding cross-site request forgery (CSRF) protection,  | headerName = %s, methodsToIgnore = %s, browserUserAgents = %s",info,HBase
Setting property  | =,trace,HBase
: read  |  bytes from ,trace,HBase
$$$Empty Message$$$,info,HBase
Blocking cluster status request,info,HBase
tableName= |  split[ | ]  |  startRow= |  rows= |  totalRows= |  clients= |  flushCommits= |  writeToWAL= |  useTags= |  noOfTags=,debug,HBase
Total # of splits: ,info,HBase
 split  | : ,debug,HBase
Table created with  |  splits,info,HBase
Table  |  created,info,HBase
client- |  ,info,HBase
Finished  |  in  | ms writing  |  rows,info,HBase
"Interrupted, continuing",debug,HBase
[ | ] Summary of timings (ms): ,info,HBase
[ | ] | \tMin:  | ms | \tMax:  | ms | \tAvg:  | ms,info,HBase
Timed test starting in thread ,info,HBase
Scan for key range %s - %s returned %s rows,info,HBase
$$$Empty Message$$$,info,HBase
Failed,error,HBase
Failed,error,HBase
" initiates rsgroup info retrieval, group=",info,HBase
" initiates rsgroup info retrieval, table=",info,HBase
 move servers  |  to rsgroup ,info,HBase
 move tables  |  to rsgroup ,info,HBase
 add rsgroup ,info,HBase
 remove rsgroup ,info,HBase
" balance rsgroup, group=",info,HBase
 list rsgroup,info,HBase
" initiates rsgroup info retrieval, server=",info,HBase
 move servers  |  and tables  |  to rsgroup,info,HBase
 remove decommissioned servers from rsgroup: ,info,HBase
Master has not initialized yet; temporarily using default RSGroup 'default' for deploy of system table,info,HBase
Pre-moving table  |  to RSGroup ,debug,HBase
Removing deleted table '%s' from rsgroup '%s',debug,HBase
Failed to perform RSGroup information cleanup for table: ,debug,HBase
"Moving server region *, which do not belong to RSGroup *",info,HBase
Server * has no more regions to move for RSGroup,info,HBase
Sleep interrupted,warn,HBase
Skipping move regions because the table * is disabled,debug,HBase
Moving region(s) for table * to RSGroup *,info,HBase
Moving region * to RSGroup *,info,HBase
Move servers done: * => *,info,HBase
moveTables() passed an empty set. Ignoring.,debug,HBase
Moving table * to RSGroup *,info,HBase
Not running balancer because * region(s) in transition: *,debug,HBase
Not running balancer because processing dead regionserver(s): *,debug,HBase
Creating partial plan for table * : *,info,HBase
Partial plan for table * : *,info,HBase
RSGroup balance * starting with plan count: *,info,HBase
RSGroup balance  |  completed,info,HBase
"Move servers and tables done. Severs: *, Tables: * => *",info,HBase
Remove decommissioned servers * from RSGroup done,info,HBase
Adding assignments for *: *,debug,HBase
Exception while balancing cluster.,warn,HBase
"Group not found for table  | , using default",debug,HBase
No available servers to assign regions: *,debug,HBase
"Group not found for table  | , using default",debug,HBase
"Group not found for table  | , using default",debug,HBase
RSGroup Information found to be null. Some regions might be unassigned.,warn,HBase
"Group not found for table  | , using default",debug,HBase
There is no assigned server for *,debug,HBase
Couldn't obtain rs group information for * on *,warn,HBase
Found misplaced region:  |  on server:  |  found in group:  |  outside of group:  | UNKNOWN,debug,HBase
"Group not found for table  | , using default",debug,HBase
RSGroup information null for region of table ,debug,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
Dropping  |  during move-to-default rsgroup because not online,debug,HBase
Server  |  does not belong to any rsgroup.,warn,HBase
Read ZK GroupInfo count:,debug,HBase
Refreshing in Online mode.,debug,HBase
Refreshing in Offline mode.,debug,HBase
Updating znode: ,debug,HBase
Writing ZK GroupInfo count: ,debug,HBase
Failed to write to rsGroupZNode,error,HBase
Reading online RS from zookeeper,debug,HBase
Updating default servers.,info,HBase
Updated with servers: ,info,HBase
Interrupted,warn,HBase
Failed to update default servers,warn,HBase
GroupBasedLoadBalancer is now online,info,HBase
Quit without making region group table online,warn,HBase
"RSGroup table= |  is online, refreshing cached information",info,HBase
Failed to perform check,warn,HBase
Setting Master Port to random.,debug,HBase
Setting RegionServer Port to random.,debug,HBase
Setting RS InfoServer Port to random.,debug,HBase
Setting Master InfoServer Port to random.,debug,HBase
Not alive ,info,HBase
Waiting on ,info,HBase
Waiting on ,info,HBase
Interrupted,debug,HBase
Interrupted,debug,HBase
"HealthChecker initialized with script at  | , timeout=",info,HBase
"Caught exception :  | ,exit code:",warn,HBase
Caught exception : ,warn,HBase
Health Check Chore runs every ,info,HBase
Health status at  |  : ,info,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
Error reading data from zookeeper for path ,error,HBase
Error deserializing namespace child from: ,error,HBase
The ZNode  |  for namespace  |  does not exist.,warn,HBase
Failed updating permissions for namespace ,error,HBase
Failed updating permissions for namespace ,error,HBase
Updating namespace cache from node  |  with data: ,trace,HBase
Environment variable HBASE_ZNODE_FILE not set; znodes will not be cleared on crash by start scripts (Longer MTTR!),warn,HBase
Can't write znode file ,warn,HBase
Can't write znode file ,warn,HBase
String  |  has wrong format,warn,HBase
Can't connect to zookeeper to read the master znode,warn,HBase
Can't find the znode file; presume non-fatal,warn,HBase
Can't read the content of the znode file,warn,HBase
ZooKeeper exception deleting znode,warn,HBase
"rmiSSL: | ,authenticate: | ,passwordFile: | ,accessFile:",info,HBase
ConnectorServer started!,info,HBase
fail to start connector server!,error,HBase
ConnectorServer stopped!,info,HBase
"Master rmiRegistryPort: | ,Master rmiConnectorPort:",info,HBase
"RegionServer rmiRegistryPort: | ,RegionServer rmiConnectorPort:",info,HBase
JMXListener should not be loaded in Region Environment!,error,HBase
JMXListener has been started at Registry port ,info,HBase
No archive directory could be found because tabledir ( | ) or regiondir ( | was null. Deleting files instead.,error,HBase
ARCHIVING *,debug,HBase
Directory * empty.,debug,HBase
Archiving ,debug,HBase
"No files to dispose of in *, family=*",debug,HBase
"Passed filesystem is null, so just deleting files without archiving for *,family=*",warn,HBase
"No files to dispose of, done!",debug,HBase
Archiving compacted files.,debug,HBase
Moving files to the archive directory *,trace,HBase
Created archive directory *,trace,HBase
Archiving *,trace,HBase
Couldn't archive  |  into backup directory: ,warn,HBase
"* is a directory, archiving children files",trace,HBase
Failed to archive *,warn,HBase
"* already exists in archive, moving to timestamped backup and overwriting current.",debug,HBase
"Could not rename archive file to backup:  | , deleting existing file in favor of newer.",error,HBase
Backed up archive file from ,debug,HBase
"No existing file in archive for *, free to archive original file.",trace,HBase
Created archive directory *,debug,HBase
Failed to create directory *,warn,HBase
Failed to archive  |  because it does not exist! Skipping and continuing on.,warn,HBase
Failed to archive  |  on try #,warn,HBase
Failed to archive ,error,HBase
Archived from * to *,debug,HBase
Deleted *,debug,HBase
Failed to delete directory *,debug,HBase
Deleting files without archiving.,debug,HBase
Failed to delete *,error,HBase
Archiver says to [ | delete | ] files for table:,debug,HBase
"Failed to lookup status of: | , keeping it just incase.",error,HBase
Error while configuring ,error,HBase
Error while configuring ,error,HBase
Stopping ,info,HBase
"Already archiving table:  | , ignoring it",debug,HBase
Starting hfile archive tracker...,debug,HBase
Finished starting hfile archive tracker!,debug,HBase
Archive node:  |  created,debug,HBase
"Couldn't read zookeeper data for table for path: | , not preserving a table.",warn,HBase
Archive node:  |  children changed.,debug,HBase
Failed to update tables to archive,error,HBase
Archive node:  |  deleted,debug,HBase
" znode does exist, checking for tables to archive",debug,HBase
"Archiving not currently enabled, waiting",debug,HBase
Failed to watch for archiving znode,warn,HBase
Updating watches on tables to archive.,debug,HBase
Starting archive for tables:,debug,HBase
No tables to archive.,debug,HBase
Disabling backups on all tables.,debug,HBase
Ensuring archiving znode exists,debug,HBase
"Creating:  | , data: []",debug,HBase
Attempting to delete table node:,debug,HBase
Stopping HFileArchiveManager...,debug,HBase
Delete restore directory for the snapshot failed. restoreDir: ,warn,HBase
Could not delete restore directory for the snapshot. restoreDir: ,warn,HBase
Exception while closing scanner,warn,HBase
Exception while closing region,warn,HBase
Lock already queued : ,info,HBase
Acquired ,info,HBase
Failed acquire in %s %s of %s,info,HBase
"Heartbeat failed, releasing ",error,HBase
"Interrupted, releasing ",error,HBase
Starting to notify all observers that config changed.,info,HBase
Encountered a throwable while notifying observers:  |  of type :  | ( | ),error,HBase
Loading constraint:,debug,HBase
"Corrupted configuration found for key: | ,  skipping it.",warn,HBase
Constraint:  |  is DISABLED - skipping it,debug,HBase
Finished loading  |  user Constraints on table: ,info,HBase
tasks arrived or departed on ,trace,HBase
retrying data watch on ,info,HBase
Failed parse,warn,HBase
"task  |  preempted from  | , current task state and owner=",info,HBase
Failed to get data for znode ,warn,HBase
Failed parse data for znode ,warn,HBase
worker  |  acquired task ,info,HBase
Interrupted while yielding for other region servers,warn,HBase
Failed to heartbeat the task,warn,HBase
zk.setData() returned null for path ,warn,HBase
NONODE failed to assert ownership for ,warn,HBase
BADVERSION failed to assert ownership for ,warn,HBase
failed to assert ownership for ,warn,HBase
Interrupted while trying to assert ownership of  |  ,warn,HBase
"Could not get tasks, did someone remove  |  ... worker thread exiting.",warn,HBase
"Current region server  |  is ready to take more tasks, will get task list and try grab tasks again.",trace,HBase
Current region server  |  has  |  tasks in progress and can't take more.,trace,HBase
Could not get children of znode ,warn,HBase
Retry listChildren of znode  |  after sleep for  | ms!,debug,HBase
Exception when checking for  |  ... retrying,warn,HBase
" znode does not exist, waiting for master to create",info,HBase
getdata rc =  |  ,warn,HBase
successfully transitioned task  |  to final state ,info,HBase
failed to transistion task  |  to end state  |  because of version mismatch ,warn,HBase
transisition task  |  to  |  failed because of version mismatch,warn,HBase
logic error - end task  |   |  failed because task doesn't exist,error,HBase
"failed to end task,  |  ",warn,HBase
Could not finish splitting of log file ,warn,HBase
Failed to check remaining tasks,warn,HBase
Resubmitting unassigned orphan task ,info,HBase
"Skipping the resubmit of  |   because the server  |  is not marked as dead, we waited for  |  while the timeout is ",trace,HBase
Skipping resubmissions of task  |  because threshold  |  reached,info,HBase
Resubmitting task ,info,HBase
Deleted task without in memory state ,debug,HBase
Failed to delete node  |  and will retry soon.,info,HBase
"logic failure, rescan failure must not happen",error,HBase
ZK session expired. Master is expected to shut down. Abandoning retries for  | action=,error,HBase
Put up splitlog task at znode ,debug,HBase
Failed to create task node ,warn,HBase
logic error - got null data ,error,HBase
"Task not yet acquired  | , ver=",debug,HBase
Task  |  entered state=,info,HBase
Task  |  entered state=,info,HBase
Task  |  entered state=,info,HBase
logic error - unexpected zk state for path =  |  data = ,error,HBase
Failed to set data watch ,warn,HBase
Unacquired orphan task is done ,debug,HBase
Done splitting ,info,HBase
Error splitting ,warn,HBase
Task  |  acquired by ,info,HBase
Could not get children of ,warn,HBase
Could not get children of  |  ,warn,HBase
Found orphan rescan node ,debug,HBase
Found orphan task ,info,HBase
Found  |  orphan tasks and  |  rescan nodes,info,HBase
Failed to resubmit task  |  version changed,debug,HBase
Failed to resubmit because znode doesn't exist  |  task done (or forced done by removing the znode),warn,HBase
Failed to re-resubmit task  |  because of deserialization issue,debug,HBase
Failed to resubmit task  |  version changed,debug,HBase
Failed to resubmit ,warn,HBase
Found pre-existing znode ,debug,HBase
Create rc= |  for  |  remaining retries=,warn,HBase
Task znode  |  vanished or not created yet.,warn,HBase
Getdata rc= |   | . Ignoring error. No error handling. No retrying.,warn,HBase
Getdata rc= |   |  remaining retries=,warn,HBase
Deserialization problem,warn,HBase
Delete rc= |  for  |  remaining retries=,warn,HBase
Delete failed ,warn,HBase
 does not exist. Either was created but deleted behind our |  back by another pending delete OR was deleted |  in earlier retry rounds. zkretries = ,info,HBase
Deleted ,debug,HBase
rc= |  for  |  remaining retries=,warn,HBase
Not starting coprocessor  |  because not inactive (state= | ),warn,HBase
Error stopping coprocessor ,error,HBase
Not stopping coprocessor  |  because not active (state= | ),warn,HBase
Attempted duplicate loading of  | ; skipped,warn,HBase
"System coprocessor * loaded, priority=*.",info,HBase
Loading coprocessor class  |  with path  |  and priority ,debug,HBase
Attempted duplicate loading of *; skipped,warn,HBase
Cannot load coprocessor ,error,HBase
Stop coprocessor ,debug,HBase
$$$Empty Message$$$,error,HBase
"No available Abortable, process was not aborted",warn,HBase
Removing coprocessor ' | ' from table ' | ',error,HBase
Removing coprocessor ' | ' from  | environment,error,HBase
Uncaught exception when shutting down coprocessor ' | ',error,HBase
 accepting received exception,debug,HBase
"Timer already marked completed, ignoring!",warn,HBase
Marking timer as complete - no error notifications will be received for this timer.,debug,HBase
"Timer already started, can't be started again. Ignoring second request.",warn,HBase
Scheduling process timer to run in:  |  ms,debug,HBase
"Timer already completed, not triggering.",warn,HBase
Triggering timer immediately!,debug,HBase
$$$Empty Message$$$,error,HBase
"Starting executor service name= | , corePoolSize= | , maxPoolSize=",debug,HBase
 had  |  on shutdown,info,HBase
Executor service  |  already running on ,debug,HBase
Cannot submit [ | ] because the executor is missing. |  Is this process shutting down?,error,HBase
Non-EventHandler  |  queued in ,warn,HBase
Non-EventHandler  |  running in ,warn,HBase
Not running balancer since exception was thrown ,warn,HBase
Encountered exception while doing favored-nodes assignment  |  Falling back to regular assignment,warn,HBase
Encountered exception while doing favored-nodes (random)assignment  |  Falling back to regular assignment,warn,HBase
"Unable to find favored nodes for parent,  |  generating new favored nodes for daughter",debug,HBase
Loaded default datanode port for FN: ,debug,HBase
Added  |  regions in META,info,HBase
Added  |  regions in META,info,HBase
Create the region * with favored nodes *,debug,HBase
Place the secondary and tertiary region server for region ,debug,HBase
Cannot place the favored nodes for region  |  because ,warn,HBase
Place the secondary and tertiary region server for region ,debug,HBase
Cannot place the favored nodes for region  |  because ,warn,HBase
Cannot place the secondary and tertiary |  region server for region ,error,HBase
"Cannot place the secondary, tertiary favored node for region ",error,HBase
Unable to generate additional favored nodes for %s after  | considering racks %s and skip rack %s with a unique rack list of %s and rack  | to RS map of %s and RS to rack map of %s,trace,HBase
Failed to get policy directly,trace,HBase
failed to get block storage policy of [ | ],warn,HBase
Failed to wrap filesystem: ,error,HBase
addLocationsOrderInterceptor configured to false,debug,HBase
Can't get the file system from the conf.,warn,HBase
The file system is not a DistributedFileSystem. Skipping on block location reordering,debug,HBase
"The DistributedFileSystem does not contain a DFSClient. Can't add the location block reordering interceptor. Continuing, but this is unexpected.",warn,HBase
"The DFSClient is not linked to a namenode. Can't add the location block reordering interceptor. Continuing, but this is unexpected.",warn,HBase
Added intercepting call to namenode#getBlockLocations so can do block reordering |  using class ,info,HBase
Can't modify the DFSClient#namenode field to add the location reorder.,warn,HBase
Can't modify the DFSClient#namenode field to add the location reorder.,warn,HBase
" is an WAL file, so reordering blocks, last hostname will be:",trace,HBase
Failed seekBefore ,warn,HBase
Failed seekTo first KV in the file,warn,HBase
Failed to find 'unbuffer' method in class  |  . So there may be a TCP socket connection  | left open in CLOSE_WAIT state.,trace,HBase
Failed to invoke 'unbuffer' method in class  |  . So there may be a TCP socket connection left open in CLOSE_WAIT state.,trace,HBase
Failed to find 'unbuffer' method in class  |  . So there may be a TCP socket connection  | left open in CLOSE_WAIT state. For more details check  | https://issues.apache.org/jira/browse/HBASE-9393,trace,HBase
link open path=,debug,HBase
link switch from path= |  to path=,trace,HBase
couldn't create the link= |  for ,error,HBase
"ClientProtocol::create wrong number of arguments, should be hadoop 2.x",debug,HBase
"create fan-out dfs output * failed, retry = *",warn,HBase
"create fan-out dfs output * failed, retry = *",warn,HBase
"complete file  |  not finished, retry = ",warn,HBase
"lease for file  |  is expired, give up",warn,HBase
"complete file  |  failed, retry = ",warn,HBase
"complete file  |  failed, retry = ",warn,HBase
"No decryptEncryptedDataEncryptionKey method in DFSClient, should be hadoop version with HDFS-12396",debug,HBase
"Verifying QOP, requested QOP =  | , negotiated QOP = ",debug,HBase
"SASL client doing encrypted handshake for addr =  | , datanodeId = ",debug,HBase
"SASL client skipping handshake in unsecured configuration for addr =  | , datanodeId = ",debug,HBase
"SASL client skipping handshake in secured configuration with  | privileged port for addr =  | , datanodeId = ",debug,HBase
"SASL client skipping handshake in secured configuration with  | unsecured cluster for addr =  | , datanodeId = ",debug,HBase
"SASL client doing general handshake for addr =  | , datanodeId = ",debug,HBase
"SASL client skipping handshake in secured configuration with no SASL  | protection configured for addr =  | , datanodeId = ",debug,HBase
Unable to set drop behind on *,trace,HBase
Unable to set drop behind on *,debug,HBase
Opening HFile v2 with v3 reader,debug,HBase
"dataLength= | , sizeWithHeader= | , checksumType= | , file= | , offset= | , headerSize= | , bytesPerChecksum=",info,HBase
HBase checksum verification failed for file  |  at offset  |  filesize  | . Retrying read with HDFS checksums turned on...,warn,HBase
$$$Empty Message$$$,warn,HBase
HDFS checksum verification succeeded for file  |  at offset  |  filesize ,warn,HBase
$$$Empty Message$$$,warn,HBase
"Reading * at offset=*, pread=*, verifyChecksum=*, cachedHeader=*, onDiskSizeWithHeader=*",trace,HBase
Extra see to get block size!,trace,HBase
Read * in * ns,trace,HBase
Writer |  for  |  |  initialized with cacheConf:  |  comparator:  |  fileContext: ,trace,HBase
Initialized with ,trace,HBase
Error parsing command-line options,error,HBase
Error parsing command-line options,error,HBase
Error reading ,error,HBase
No Comparator class for  | . Returning Null.,warn,HBase
Created cacheConfig:  |  |  with blockCache=,info,HBase
Trying to cache too large a block  |  @  |  is  |  which is larger than ,warn,HBase
"LruBlockCache current size  |  has exceeded acceptable size  | . |  The hard limit size is  | , failed to put cacheKey: |  into LruBlockCache.",trace,HBase
"counterVal overflow. Assertions unreliable. counterVal= | , mapSize=",trace,HBase
"delta between reported and actual size > 5%. counterVal= | , mapSize=",trace,HBase
Block cache LRU eviction started; Attempting to free  |  of total=,trace,HBase
freed  |  from single and multi buckets,trace,HBase
freed  |  total from all three buckets ,trace,HBase
"Block cache LRU eviction completed;  | freed= | ,  | total= | ,  | single= | ,  | multi= | ,  | memory=",trace,HBase
freeing  |  from ,trace,HBase
freed  |  from ,trace,HBase
Interrupted eviction thread ,warn,HBase
"totalSize= | ,  | freeSize= | ,  | max= | ,  | blockCount= | ,  | accesses= | ,  | hits= | ,  | hitRatio= | 0 | ,  | ,  | cachingAccesses= | ,  | cachingHits= | ,  | cachingHitsRatio= | 0, | ,  | evictions= | ,  | evicted= | ,  | evictedPerRun=",info,HBase
Interrupted while sleeping,warn,HBase
Still running ,debug,HBase
"The config key * is deprecated now, instead please use *. In future release we will remove the deprecated config.hbase.offheapcache.minblocksizehbase.blockcache.minblocksize",warn,HBase
From HBase 2.0 onwards only combined mode of LRU cache and bucket cache is available,warn,HBase
"Allocating onheap LruBlockCache size= | , blockSize=",info,HBase
Trying to use External l2 cache,debug,HBase
Creating external block cache of type: ,info,HBase
Error creating external block cache,warn,HBase
Configuration 'hbase.bucketcache.percentage.in.combinedcache' is no longer respected. See comments in http://hbase.apache.org/book.html#_changes_of_note,warn,HBase
Can't instantiate bucket cache,error,HBase
"Compacted Bloom chunk # |  from [ |  max keys,  |  bytes] to [ |  max keys,  |  bytes]",trace,HBase
"Prefetch requested for  | , delay= |  ms",debug,HBase
Prefetch request rejected for ,warn,HBase
Prefetch completed for ,debug,HBase
Prefetch cancelled for ,debug,HBase
Prefetch start ,trace,HBase
Prefetch ,trace,HBase
Stream moved/closed or prefetch cancelled?,warn,HBase
Prefetch ,warn,HBase
Returning the block : ,trace,HBase
Current pos =  | ; currKeyLen =  | ; currValLen =  | ; block limit =  | ; currBlock currBlockOffset =  | ; path=,error,HBase
"Evicting cached block with key  |  because of a data block encoding mismatch | ; expected:  | , actual:  | , path=",info,HBase
From Cache ,trace,HBase
Reader |  for  |  |  initialized with cacheConf:  |  comparator:  |  fileContext: ,trace,HBase
"Cached block contents differ by nextBlockOnDiskSize, the new block has nextBlockOnDiskSize set. Caching new block.",warn,HBase
"Cached block contents differ by nextBlockOnDiskSize, the existing block has nextBlockOnDiskSize set, Keeping cached block.",warn,HBase
Caching an already cached block: *. This is harmless and can happen in rare cases (see HBASE-8547),warn,HBase
"Wrote a  | -level index with root level at pos  | ,  |  root-level entries,  |  total entries,  |  on-disk size,  |  total uncompressed size.",trace,HBase
"Wrote a single-level  |  index with  |  entries,  |  bytes",trace,HBase
"Allocating  | , on the path:",info,HBase
Can't create bucket cache file ,error,HBase
Can't extend bucket cache file; insufficient space for ,error,HBase
Can't shutdown cleanly,error,HBase
Can't shutdown cleanly,error,HBase
File  |  already exists. Deleting!!,debug,HBase
$$$Empty Message$$$,warn,HBase
"Allocating cache  | , on the path:",info,HBase
Failed allocating cache on ,error,HBase
Failed to close FileChannel,warn,HBase
Failed syncing data to ,warn,HBase
Failed closing  |  when shudown the IOEngine,error,HBase
"Caught ClosedChannelException accessing BucketCache, reopening file: ",warn,HBase
"Instantiating BucketCache with acceptableFactor:  | , minFactor:  | , extraFreeFactor:  | , singleFactor:  | , multiFactor:  | , memoryFactor: ",info,HBase
Can't restore from file because of,error,HBase
Can't restore from file in rebuild because can't deserialise,error,HBase
"Started bucket cache; ioengine= | , capacity= | , blockSize= | , writerThreadNum= | , writerQLen= | , persistencePath= | , bucketAllocator=",info,HBase
"Caching key=*, item=*",trace,HBase
"Read offset= | , len=",trace,HBase
Failed reading block  |  from bucket cache,error,HBase
This block  |  is still referred by  |  readers. Can not be freed now,debug,HBase
This block  |  is still referred by  |  readers. Can not be freed now. Hence will mark this |  for evicting at a later point,debug,HBase
"failedBlockAdditions= | ,  | totalSize= | ,  | freeSize= | ,  | usedSize= | ,  | cacheSize= | ,  | accesses= | ,  | hits= | ,  | IOhitsPerSecond= | ,  | IOTimePerHit= | %.2f | ,  | hitRatio= | 0, | ,  | cachingAccesses= | ,  | cachingHits= | ,  | cachingHitsRatio= | 0, | ,  | evictions= | ,  | evicted= | ,  | evictedPerRun=",info,HBase
"Free started because \ | \ |  of current used= | , actual cacheSize= | , total=",debug,HBase
"Bucket cache free space completed;  | freed= | ,  | total= | ,  | single= | ,  | multi= | ,  | memory=",debug,HBase
Failed freeing space,warn,HBase
WriterThread encountered error,error,HBase
Failed doing drain,warn,HBase
" exiting, cacheEnabled=",info,HBase
Couldn't get entry or changed on us; who else is messing with it?,warn,HBase
Failed allocation for  |  | ; ,warn,HBase
Failed writing to bucket cache,error,HBase
Failed syncing IO engine,error,HBase
"IO errors duration time has exceeded  | ms, disabling cache, please check your IOEngine",error,HBase
Shutdown bucket cache: IO persistent= | ; path to write=,info,HBase
Unable to persist data on exit: ,error,HBase
Failed to persist data on exit,warn,HBase
"Cache totalSize= | , buckets= | , bucket capacity= | =( | * | )= | (FEWEST_ITEMS_IN_BUCKET*(largest configured bucketcache size))",info,HBase
There are  |  blocks which can't be rebuilt because  | there is no matching bucket size for these blocks,warn,HBase
There are  |  blocks which can't be rebuilt -  | did you shrink the cache?,warn,HBase
Bucket allocator statistics follow: ,info,HBase
  Free bytes= | ; total bytes=,info,HBase
  Object size  |  used= | ; free= | ; total=,info,HBase
"Got an exception while attempting to read information about the JVM heap. Please submit this log information in a bug report and include your JVM settings, specifically the GC in use and any -XX options. Consider restarting the service.",warn,HBase
hbase.regionserver.global.memstore.upperLimit is deprecated by hbase.regionserver.global.memstore.size,warn,HBase
Setting global memstore limit to default of 0.4 because supplied value outside allowed range of (0 -> 0.8],warn,HBase
Bad configuration value for  | :  | . Using 1.0f instead.,error,HBase
hbase.regionserver.global.memstore.lowerLimit is deprecated. Instead use hbase.regionserver.global.memstore.size.lower.limit,warn,HBase
Value of  |  ( | ) is greater than global memstore limit ( | ) set by  | / | . Setting memstore lower limit  | to ,error,HBase
There is no relevance of configuring 'hbase.regionserver.offheap.global.memstore.size' when 'hbase.hregion.memstore.mslab.enabled' is turned off. Going with on heap global memstore size ('hbase.regionserver.global.memstore.size'),warn,HBase
: skipped ,debug,HBase
Dropping timed out call: ,warn,HBase
 executing as  | NULL principal,trace,HBase
"Can not complete this request in time, drop it: ",warn,HBase
$$$Empty Message$$$,trace,HBase
", exception=",debug,HBase
: exiting on OutOfMemoryError,info,HBase
": caught a ClosedChannelException,  | this means that the server  | (channel closed) |  was processing a request but the client went away. The error message was: ",warn,HBase
: caught: ,warn,HBase
: skipped ,debug,HBase
": caught a ClosedChannelException,  | this means that the server  | (channel closed) |  was processing a request but the client went away. The error message was: ",warn,HBase
: caught: ,warn,HBase
Creating  |  hosting ,info,HBase
Connection *; # active connections=*,trace,HBase
Disconnection *; # active connections=*,trace,HBase
Connection *; caught unexpected downstream exception.,trace,HBase
Exception while creating response ,warn,HBase
Exception while running the Rpc Callback.,warn,HBase
Adding saslServer wrapped token of size  |  as call response.,trace,HBase
Connection: unable to set socket send buffer size to ,warn,HBase
$$$Empty Message$$$,warn,HBase
Ignored exception,trace,HBase
Ignored exception,trace,HBase
Using * as call queue; handlerCount=*; maxQueueLength=*; rsReportHandlerCount=*; rsReportMaxQueueLength=*,info,HBase
: starting,debug,HBase
: stopping,info,HBase
: couldn't close write selector,error,HBase
ignored,trace,HBase
ignored,trace,HBase
: asyncWrite,debug,HBase
: exiting on OutOfMemoryError,info,HBase
: OutOfMemoryError in server select,warn,HBase
Interrupted while sleeping,debug,HBase
: exception in Responder ,warn,HBase
: stopped,info,HBase
Exception while changing ops : ,warn,HBase
: output error -- closing,debug,HBase
 writeQueues= |  writeHandlers= |  readQueues= |  readHandlers= |  scanQueues= |  scanHandlers=,info,HBase
Using * as user call queue; handlerCount=*; maxQueueLength=*,info,HBase
********* WARNING! *********,warn,HBase
This server is configured to allow connections from INSECURE clients,warn,HBase
(hbase.ipc.server.fallback-to-simple-auth-allowed = true).,warn,HBase
"While this option is enabled, client identities cannot be secured, and user",warn,HBase
impersonation is possible!,warn,HBase
"For secure operation, please disable SIMPLE authentication as soon as possible,",warn,HBase
by setting hbase.ipc.server.fallback-to-simple-auth-allowed = false in hbase-site.xml,warn,HBase
****************************,warn,HBase
", response  |  queueTime:  |  processingTime:  |  totalTime: ",trace,HBase
Caught a ServiceException with null cause,debug,HBase
Unexpected throwable object ,error,HBase
(response | ): ,warn,HBase
Read input token of size=* for processing by saslServer.unwrap(),trace,HBase
Created SASL server with mechanism=*,debug,HBase
Read input token of size=* for processing by saslServer.evaluateResponse(),debug,HBase
:,warn,HBase
Will send token of size  |  from saslServer.,debug,HBase
SASL server context established. Authenticated client:  | . Negotiated QoP is ,debug,HBase
$$$Empty Message$$$,info,HBase
Received ping message,debug,HBase
Connection authorization failed: ,debug,HBase
Allowed fallback to SIMPLE auth for * connecting from *,warn,HBase
"Connection from *:*, version=*, sasl=*, ugi=*, service=*",info,HBase
RequestHeader  |  totalRequestSize:  |  bytes,trace,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
Bind to *,info,HBase
Stopping server on ,info,HBase
"hbase.ipc.server.callqueue.handler.factor is *ILLEGAL*, it should be in range [0.0, 1.0]",warn,HBase
Set hbase.ipc.server.callqueue.handler.factor 1.0f,warn,HBase
Set hbase.ipc.server.callqueue.handler.factor default value 0.0f,warn,HBase
"Instantiated * with queueClass=*; numCallQueues=*, maxQueueLength=*, handlerCount=*",info,HBase
"Started handlerCount=* with threadPrefix=*, numCallQueues=*, port=*",debug,HBase
$$$Empty Message$$$,warn,HBase
Error but can't abort because abortable is null: ,error,HBase
Handler errors ,warn,HBase
Handler  exception ,warn,HBase
: started  |  reader(s) listening on port=,info,HBase
: error closing read selector in ,error,HBase
 unexpectedly interrupted,info,HBase
: CancelledKeyException in Reader,error,HBase
: IOException in Reader,info,HBase
: starting,info,HBase
ignored,trace,HBase
: exiting on OutOfMemoryError,info,HBase
: OutOfMemoryError in server select,warn,HBase
Interrupted while sleeping,debug,HBase
: stopping,info,HBase
ignored,trace,HBase
: readAndProcess caught InterruptedException,info,HBase
Caught exception while reading:,debug,HBase
: exception in closing listener socket. ,info,HBase
Stopping server on ,info,HBase
"Connection from  | ; connections= | , queued calls size (bytes)= | , general queued calls= | , priority queued calls= | , meta priority queued calls=",trace,HBase
: disconnecting client  | . Number of active connections: ,trace,HBase
running,trace,HBase
hbase.master.hbck.chore.interval is <=0 hence disabling hbck chore,warn,HBase
hbckChore is either disabled or is already running. Can't run the chore,warn,HBase
Failed to load the regions from filesystem,warn,HBase
hbck chore is disabled! Set hbase.master.hbck.chore.interval > 0 to enable it.,warn,HBase
hbck chore already running. Can't run till it finishes.,warn,HBase
Loaded * regions from in-memory state of AssignmentManager,info,HBase
Loaded * regions from * regionservers' reports and found * orphan regions,info,HBase
Loaded * tables * regions from filesyetem and found * orphan regions,info,HBase
Failed initial janitorial scan of hbase:meta table,warn,HBase
"CatalogJanitor is disabled! Enabled= | , maintenanceMode= | , am= | , metaLoaded= | , hasRIT= |  clusterShutDown=",warn,HBase
Failed janitorial scan of hbase:meta table,warn,HBase
CatalogJanitor already running,debug,HBase
$$$Empty Message$$$,warn,HBase
Playing-it-safe skipping merge/split gc'ing of regions from hbase:meta while regions-in-transition (RIT),warn,HBase
Merged region does not exist: ,warn,HBase
Deleting parents (*) from fs; merged child * no longer holds references,debug,HBase
"Deleting region  |  because daughters --  | ,  |  -- no longer hold references",debug,HBase
"Error trying to determine if daughter region exists, assuming exists and has references",error,HBase
"Error trying to determine referenced files from :  | , to:  |  assuming has references",error,HBase
$$$Empty Message$$$,trace,HBase
INCONSISTENCY: Row name is not equal to serialized info:regioninfo content; row=* *; See if RegionInfo is referenced in another hbase:meta row? Delete?,warn,HBase
Failed getting table state,warn,HBase
Log4j check failed,error,HBase
empty,info,HBase
Failed to compact mob files,error,HBase
A master is now available,trace,HBase
No master available. Notifying waiting threads,debug,HBase
Deleting ZNode for  |  from backup master directory,info,HBase
Registered as active master=,info,HBase
Failed parse,warn,HBase
$$$Empty Message$$$,info,HBase
Interrupted waiting for master to die,debug,HBase
Received an unexpected KeeperException when checking  | isActiveMaster : ,info,HBase
Failed get of master address: ,warn,HBase
Failed delete of our master address node; ,debug,HBase
Removed  |  ; numProcessing=,debug,HBase
Added  | ; numProcessing=,debug,HBase
Added  | ; numProcessing=,debug,HBase
Started processing  | ; numProcessing=,debug,HBase
Finished processing  | ; numProcessing=,debug,HBase
Removed  |  ; numProcessing=,debug,HBase
Removed  |  ; numProcessing=,debug,HBase
ZK state for LoadBalancer could not be parsed ,error,HBase
"Server node * does not exist, already dead?",warn,HBase
"Invalid data for region server node * on zookeeper, data length = *",warn,HBase
"Starting RegionServerTracker; * have existing ServerCrashProcedures, * possibly 'live' servers, and * 'splitting'.",info,HBase
"RegionServer ephemeral node deleted, processing expiration [*]",info,HBase
"RegionServer ephemeral node created, adding [ | ]",info,HBase
 replica region state from zookeeper=,debug,HBase
 old location is same as current hbase:meta location; setting location as null...,info,HBase
Closing excess replica of meta region ,info,HBase
Ignoring exception ,warn,HBase
Initialization completed within allotted tolerance. Monitor exiting.,debug,HBase
Master failed to complete initialization after  | ms. Please |  consider submitting a bug report including a thread dump of this process.,error,HBase
Zombie Master exiting. Thread dump to stdout,error,HBase
InitMonitor thread interrupted. Existing.,trace,HBase
"Couldn't resolve ' | ' as an address local to this node and ' | ' is not set; client will get an HTTP 400 response. If  | your HBase deployment relies on client accessible names that the region server process  | can't resolve locally, then you should set the previously mentioned configuration variable  | to an appropriate hostname.",warn,HBase
Detected *=true via configuration.hbase.master.maintenance_mode,info,HBase
Detected *=true via environment variables.hbase.master.maintenance_mode,info,HBase
"hbase.rootdir= | , hbase.cluster.distributed=",info,HBase
" is true, but  |  is not set - not publishing status",warn,HBase
Failed construction of Master,error,HBase
Failed shutdown of clusterSchemaService,warn,HBase
$$$Empty Message$$$,error,HBase
"Active/primary master= | , sessionid=0x | , setting cluster-up flag (Was= | )",info,HBase
"Unsupported procedure type * found, please rollback your master to the old version to finish them, and then try to upgrade again. The full procedure list: *",error,HBase
"At least one ServerCrashProcedure is going to schedule a RecoverMetaProcedure, which is not supported any more. Please rollback your master to the old version to finish them, and then try to upgrade again.",error,HBase
hbase:meta *,info,HBase
$$$Empty Message$$$,info,HBase
Coprocessor preMasterInitialization() hook failed,error,HBase
Master has completed initialization %.3fsec,info,HBase
"Detected repair mode, skipping final initialization steps.",info,HBase
Coprocessor postStartMaster() hook failed,error,HBase
"Balancer post startup initialization complete, took  |  seconds",debug,HBase
"* is NOT online; state=*; ServerCrashProcedures=*. Master startup cannot progress, in holding-pattern until region onlined.",warn,HBase
"The period is  |  seconds, MobCompactionChore is disabled",info,HBase
Started service threads,trace,HBase
Stopping master jetty server,info,HBase
Failed to stop master jetty server,error,HBase
Stopping service threads,debug,HBase
"Master has not been initialized, don't run balancer.",debug,HBase
"Master is in maintenanceMode mode, don't run balancer.",info,HBase
unning balancer because  |  region(s) in transition:  | (truncated list),info,HBase
Not running balancer because processing dead regionserver(s): ,info,HBase
Coprocessor bypassing balancer request,debug,HBase
Error invoking master coprocessor preBalance(),error,HBase
Error invoking master coprocessor postBalance(),error,HBase
"Balancer plans size is  | , the balance interval is  |  ms, and the max number regions in transition is ",info,HBase
balance ,info,HBase
"Failed balance plan: *, just skip it",warn,HBase
No more balancing till next balance run; maxBalanceTime=,debug,HBase
"Master has not been initialized, don't run region normalizer.",debug,HBase
"Cluster is shutting down, don't run region normalizer.",info,HBase
"Master is in maintenance mode, don't run region normalizer.",info,HBase
"Region normalization is disabled, don't run region normalizer.",debug,HBase
"Master is in maintenance mode, stop running region normalizer.",debug,HBase
"Skipping normalization for *, as it's either system table or doesn't have auto normalization turned on",trace,HBase
* merge regions *,info,HBase
 split ,info,HBase
 can not move to  |  because the server is in exclude list,info,HBase
Passed destination servername is null/empty so choosing a server at random,info,HBase
Unable to determine a plan to assign ,debug,HBase
Unable to determine a plan to assign ,debug,HBase
"Skipping move of region  |  to avoid unnecessary region moving later by load balancer, |  because it should not be on master",debug,HBase
Skipping move of region  |  because region already assigned to the same server  | .,debug,HBase
" move  | , running balancer",info,HBase
 create ,info,HBase
 create ,info,HBase
Adding backup master ZNode ,info,HBase
Failed create of  |  by ,warn,HBase
HMaster started in backup mode. Stalling until master znode is written.,debug,HBase
Waiting for master address and cluster state znode to be written.,debug,HBase
Failed to become active master,error,HBase
 delete ,info,HBase
 truncate ,info,HBase
Unable to check for space quotas as the MasterQuotaManager is not enabled,trace,HBase
 enable ,info,HBase
 disable ,info,HBase
* modify table * from * to *,info,HBase
Unable to list backup servers,warn,HBase
"Failed parse, skipping registering backup server",warn,HBase
Unable to get information about  | backup servers,warn,HBase
Master server abort: loaded coprocessors are: ,error,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
Exception occurred while stopping master,error,HBase
ZooKeeper exception trying to set cluster as down in ZK,error,HBase
"Coprocessor service  |  already registered, rejecting request from ",error,HBase
Registered master coprocessor service: service=,debug,HBase
STARTING service ,info,HBase
 creating ,info,HBase
 modify ,info,HBase
 delete ,info,HBase
" creating replication peer, id= | , config= | , state= | ENABLED",info,HBase
" removing replication peer, id=",info,HBase
" enable replication peer, id=",info,HBase
" disable replication peer, id=",info,HBase
" get replication peer config, id=",info,HBase
" update replication peer config, id= | , config=",info,HBase
" list replication peers, regex=",info,HBase
Unknown region ,warn,HBase
Skipping move of region  |  because region already assigned to the same server  | .,info,HBase
"Remote procedure done, pid=*",debug,HBase
"Remote procedure failed, pid=*",debug,HBase
System coprocessor loading is *,trace,HBase
* is not of type MasterCoprocessor. Check the configuration of *hbase.coprocessor.master.classes,error,HBase
CatalogJanitor has not generated a report yet; run 'catalogjanitor_run' in shell or wait until CatalogJanitor chore runs.,info,HBase
No holes.,debug,HBase
Fixed hole by adding *; region is NOT assigned (assign to online).,info,HBase
"Skipping hole fix; left-side endKey is not less than right-side startKey; left=<*>, right=<*>",warn,HBase
"Skipping hole fix; both the hole left-side and right-side RegionInfos are UNDEFINED; left=<*>, right=<*>",warn,HBase
"Skipping hole fix; don't know what to do with left=<*>, right=<*>",warn,HBase
No overlaps.,debug,HBase
Fixed hole by adding *; region is NOT assigned (assign to online).,info,HBase
"Draining RS node created, adding to list [ | ]",info,HBase
"Draining RS node deleted, removing from list [ | ]",info,HBase
Cannot verify the region assignment for region  |  null  | because of ,error,HBase
Cannot verify the region assignment for region  |  null  | because of ,error,HBase
"THIS SHOULD NOT HAPPEN, RegionServerStartup |  could not record the server: ",warn,HBase
", existingValue= | , completeSequenceId=",trace,HBase
RegionServer  |  indicates a last flushed sequence id ( | ) that is less than the previous last flushed sequence id ( | ) for region  |  Ignoring.,warn,HBase
", family= | , existingValue= | , completeSequenceId=",trace,HBase
"RegionServerReport ignored, could not record the server: ",info,HBase
Server serverName= |  rejected; we already have  |  registered with same hostname and port,info,HBase
"Triggering server recovery; existingServer  |  looks stale, new server:",info,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,debug,HBase
": |  Server  |  came back up, |  removed it from the dead servers list",debug,HBase
Registering regionserver=,info,HBase
Waiting on regionserver(s) ,info,HBase
"ZK shows there is only the master self online, exiting now",info,HBase
Failed to list regionservers,warn,HBase
Expiration called on * but crash processing already in progress,warn,HBase
Cluster shutdown set;  |  expired; onlineServers=,info,HBase
Processing expiration of  |  on ,info,HBase
Expiration of * but server not online,trace,HBase
"Server  |  is not currently online.  | Removing from draining list anyway, as requested.",warn,HBase
Server  |  is not currently online.  | Ignoring request to add it to draining list.,warn,HBase
Server  |  is already in the draining server list. | Ignoring request to add it again.,warn,HBase
Server  |  added to draining server list.,info,HBase
Received exception in RPC for warmup server: | region:  | exception: ,error,HBase
Exception when closing region: ,warn,HBase
Exception when retrieving regioninfo from: ,warn,HBase
New admin connection to ,debug,HBase
"The value of '%s' (%d) is set less than '%s' (%d), ignoring.",warn,HBase
$$$Empty Message$$$,info,HBase
"Finished waiting on RegionServer count= | ; waited= | ms, |  expected min= |  server(s), max= |  server(s), |  master is  | stopped.",info,HBase
$$$Empty Message$$$,info,HBase
Could not parse: ,error,HBase
minRegionServers set to ,debug,HBase
minServers set to ,debug,HBase
localRegionServers set to ,debug,HBase
masters set to ,debug,HBase
Starting a zookeeper cluster,info,HBase
"Starting up instance of localHBaseCluster; master= | , regionserversCount=",info,HBase
Won't bring the Master up as a shutdown is requested,info,HBase
Master exiting,error,HBase
Failed to stop master,error,HBase
Master not running,error,HBase
ZooKeeper not available,error,HBase
Got IOException: ,error,HBase
"rootdir permissions do not contain 'excute' for user, group or other. Automatically adding 'excute' permission for all",warn,HBase
Please fix invalid configuration for hbase.rootdir,error,HBase
Please fix invalid configuration for  |  ,error,HBase
"Found HBase directory permissions NOT matching expected permissions for  |  permissions= | , expecting  | . Automatically setting the permissions.  | You can change the permissions by setting \ | \ | and restarting the master",warn,HBase
Failed to create or set permission on staging directory ,error,HBase
BOOTSTRAP: creating hbase:meta region,info,HBase
bootstrap,error,HBase
Start to scan the hbase:meta for the current region assignment snappshot,info,HBase
Insufficient favored nodes for region  |  fn: ,warn,HBase
Catche remote exception  |  when processing,error,HBase
Finished to scan the hbase:meta for the current region assignmentsnapshot,info,HBase
Namespace table not found. Creating...,info,HBase
$$$Empty Message$$$,error,HBase
Caught exception in initializing namespace table manager,warn,HBase
Failed NamespaceManager close,warn,HBase
Failed Namespace Table close,warn,HBase
Fail to clean the expired mob files,error,HBase
 doesn't exist. Nothing to do!,warn,HBase
"* dir is empty, no logs to split.",info,HBase
Cannot parse server name from ,warn,HBase
Started splitting  |  logs in  |  for ,info,HBase
error while splitting logs in  |  installed =  |  but only  |  done,warn,HBase
Unable to delete log src dir. Ignoring. ,warn,HBase
Returning success without actually splitting and  | deleting all the log files in path  | : ,warn,HBase
Unable to delete log src dir. Ignoring. ,warn,HBase
$$$Empty Message$$$,info,HBase
"Expected  |  active tasks, but actually there are ",warn,HBase
"Expected at least |  tasks remaining, but actually there are ",warn,HBase
"No more task remaining, splitting  | should have completed. Remaining tasks is  | , active tasks in map ",warn,HBase
Stopped while waiting for log splits to be completed,warn,HBase
Interrupted while waiting for log splits to be completed,warn,HBase
Previously orphan task  |  is now being waited upon,debug,HBase
wait for status of task  |  to change to DELETED,debug,HBase
Interrupted when waiting for znode delete callback,warn,HBase
Failure because previously failed task |  state still present. Waiting for znode delete callback |  path=,warn,HBase
Logic error. Deleted task still present in tasks map,error,HBase
Failure because two threads can't wait for the same task; path=,warn,HBase
Dead splitlog worker *,info,HBase
dead splitlog workers ,info,HBase
"Failed to resubmit task  |  owned by dead  | , will retry.",warn,HBase
"total= | , unassigned= | , tasks=",info,HBase
resubmitted  |  out of  |  tasks,info,HBase
resubmitting unassigned task(s) after timeout,debug,HBase
 set balanceSwitch=,info,HBase
Error flipping balance switch,warn,HBase
$$$Empty Message$$$,warn,HBase
assignRegion specifier type: expected:  |  actual: ,warn,HBase
 assign ,info,HBase
 procedure request for creating table:  |  procId is: ,info,HBase
 delete ,info,HBase
MergeRegions specifier type: expected:  |  actual: region  |  =,warn,HBase
 procedure request for: ,info,HBase
 procedure request for: ,info,HBase
Checking to see if procedure from request: |  is done,debug,HBase
Checking to see if snapshot from request: |  is done,debug,HBase
Checking to see if procedure is done pid=,debug,HBase
moveRegion specifier type: expected:  |  actual: ,warn,HBase
moveRegion specifier type: expected:  |  actual: ,warn,HBase
 offline ,info,HBase
 shutdown,info,HBase
Exception occurred in HMaster.shutdown(),error,HBase
 snapshot request for:,info,HBase
 stop,info,HBase
Exception occurred while stopping master,error,HBase
unassignRegion specifier type: expected:  |  actual: ,warn,HBase
 unassign  |  in current location if it is online and reassign.force=,debug,HBase
A minimum HFile version of 3 is required for MOB compaction. Compaction will not run.,error,HBase
Column family  |  is not a mob column family,error,HBase
No mob column families are assigned in the mob compaction,error,HBase
User-triggered mob compaction requested for table:  |  for column family: ,trace,HBase
Error flipping normalizer switch,warn,HBase
* set normalizerSwitch=*,info,HBase
Exception when queuing lock,warn,HBase
Exception when queuing lock,warn,HBase
"Received region space usage report but HMaster is not ready to process it, skipping",debug,HBase
"Received space quota region size report but HMaster is not ready to process it, skipping",debug,HBase
 clear dead region servers.,debug,HBase
"Some dead server is still under processing, won't clear the dead server list",debug,HBase
* request HBCK chore to run,info,HBase
* set table=* state from * to *,info,HBase
"* assigns, override=*",info,HBase
Unknown=*,info,HBase
"* unassigns, override=*",info,HBase
Unknown=*,info,HBase
"* bypass procedures=*, waitTime=*, override=*, recursive=*",info,HBase
* schedule ServerCrashProcedure for *,info,HBase
User * (remote address: *) granted permission *,trace,HBase
User * (remote address: *) revoked permission *,trace,HBase
"there is already a SCP of this server * running, pid *",info,HBase
failed to create procedures for splitting logs of *,error,HBase
"size of WALs of * is *, isMeta: *",info,HBase
acquired a worker * to split a WAL,debug,HBase
release a worker * to split a WAL,debug,HBase
Start to generate assignment plan for  |  regions from table  |  with  |  region servers,info,HBase
Generated the assignment plan for  |  regions from table  |  with  |  region servers,info,HBase
Assignment plan for secondary and tertiary generated using MunkresAssignment,info,HBase
Generated the assignment plan for  |  regions from table  |  with  |  region servers,info,HBase
Assignment plan for secondary and tertiary generated using placeSecondaryAndTertiaryWithRestrictions method,info,HBase
Start to generate the new assignment plan for the  |  tables,info,HBase
Get some exceptions for placing primary region server | for table  |  because ,error,HBase
Finish to generate the new assignment plan for the  |  tables,info,HBase
========== Start to print the assignment plan ================,info,HBase
Region: ,info,HBase
Its favored nodes: ,info,HBase
========== Finish to print the assignment plan ================,info,HBase
Start to update the hbase:meta with the new assignment plan,info,HBase
Updated the hbase:meta with the new assignment plan,info,HBase
Failed to update hbase:meta with the new assignment | plan because ,error,HBase
Start to update the region servers with the new assignment plan,info,HBase
Region server  |  has updated  |  /  |  regions with the assignment plan,info,HBase
Updated  |  region servers with  | the new assignment plan,info,HBase
 region servers with its corresponding favored nodes,error,HBase
Failed to update  |  because of ,error,HBase
Start to update the new assignment plan for the hbase:meta table and the region servers,info,HBase
Finish to update the new assignment plan for the hbase:meta table and the region servers,info,HBase
For Table:  |  ; #Total Regions:  |  ; The average dispersion score is ,info,HBase
For Table:  |  ; #Total Regions:  |  ; The average locality for  |  is  |  %,info,HBase
Setting the zk quorum: ,info,HBase
Setting the HDFS: ,info,HBase
Setting the hbase root directory: ,info,HBase
Going to update the region  |  with the new favored nodes ,info,HBase
Cannot find the region  |  from the META,error,HBase
Cannot parse the invalid favored nodes because ,error,HBase
Unable to get table  |  state,error,HBase
" has no table state in hbase:meta, assuming ENABLED",warn,HBase
Purged table state entry from zookeepr for table not in hbase:meta: ,info,HBase
"Migrating table state from zookeeper to hbase:meta; tableName= | , state=",info,HBase
Table=* has no state and zookeeper state is in-between=* (neither ENABLED or DISABLED); NOT MIGRATING table state,warn,HBase
Failed reading table state from zookeeper,warn,HBase
Failed deleting table state from zookeeper,warn,HBase
Master stopped while trying to get failed servers.,warn,HBase
"No log files to split, proceeding...",debug,HBase
Log folder  |  doesn't look like its name includes a  | region server name; leaving in place. If you see later errors about missing  | write ahead logs they may be saved in this location.,warn,HBase
"Log folder  |  doesn't belong  | to a known region server, splitting",info,HBase
Log folder  |  belongs to an existing region server,info,HBase
Failed getting failed servers to be recovered.,warn,HBase
"Bad Filesystem, exiting",warn,HBase
"Interrupted, aborting since cannot return w/o splitting",warn,HBase
Renamed region directory: ,debug,HBase
Log dir for server  |  does not exist,info,HBase
Unable to move   |  to ,warn,HBase
Archived meta log  |  to ,debug,HBase
Unable to delete log dir. Ignoring. ,warn,HBase
Failed archiving meta log for server ,warn,HBase
Failed setting table state to zookeeper mirrored for hbase-1.x clients,warn,HBase
Failed to mark end of mob compaction,error,HBase
The mob compaction is requested for the columns  |  of the table ,debug,HBase
Failed to perform the mob compaction,error,HBase
Failed to mark end of mob compaction,error,HBase
Waiting for  |  to finish...,info,HBase
Interrupted waiting for  |  to finish...,warn,HBase
 execute state=,trace,HBase
Error trying to GC merged regions *; retrying...,warn,HBase
Removing from regionOffline Map: ,trace,HBase
WORKING ON  |  ,trace,HBase
"Skipping, no server for ",info,HBase
"Added to offline, CURRENTLY NEVER CLEARED!!! ",info,HBase
"Received report * transition from * for *, pid=* but the new openSeqNum * is less than the current one *, ignoring...",warn,HBase
[T] LOAD META PERF ,trace,HBase
NULL result from meta - ignoring but this is strange.,debug,HBase
"Load hbase:meta entry region=*, regionState=*, lastHost=*, regionLocation=*, openSeqNum=*",info,HBase
$$$Empty Message$$$,info,HBase
$$$Empty Message$$$,error,HBase
 ,debug,HBase
"splitKey isn't explicitly specified, will try to find a best split key from RS",info,HBase
Splittable= |  ,debug,HBase
Clock skew; parent regions id is  |  but current time here is ,warn,HBase
* execute state=*,trace,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,error,HBase
* rollback state=*,trace,HBase
pid= |  failed rollback attempt step  |  for splitting the region  |  in table ,warn,HBase
Unsplittable; parent region is null; node=*,info,HBase
Split of  |  skipped; state is already SPLIT,info,HBase
Split of  |  skipped because offline/split.,info,HBase
pid= |  split switch is off! skip split of ,warn,HBase
"pid=*, split is disabled for the table! Skipping split of *",warn,HBase
Skipping split of  | ; presuming ready for archiving.,info,HBase
"pid= |  splitting  |  storefiles, region= | , threads=",info,HBase
"pid= |  split storefiles for region  |  Daughter A:  |  storefiles, Daughter B:  |  storefiles.",debug,HBase
pid= |  splitting started for store file:  |  for region: ,debug,HBase
pid= |  splitting complete for store file:  |  for region: ,debug,HBase
pid= |  row key of mutation from coprocessor not parsable as  | region name. | Mutations from coprocessor should only for hbase:meta table.,error,HBase
 execute state=,trace,HBase
Error trying to GC merged regions  |  &  | ; retrying...,warn,HBase
 execute state=,trace,HBase
Archiving region=,debug,HBase
Failed to delete *,debug,HBase
Failed to delete *,debug,HBase
Error trying to GC  | ; retrying...,warn,HBase
Tracking when we are set to null  | TRACE,trace,HBase
Setting lastHost as the region location *,info,HBase
"Starting *; *; forceNewPlan=*, retain=*",info,HBase
"No location specified for *, jump back to state * to get one",warn,HBase
Retry=* of max=*; *; *,info,HBase
"Failed transition, suspend *secs *; *; waiting on rectified condition fixed by other Procedure or operator intervention",warn,HBase
"There is no outstanding remote region procedure for *, serverName=*, code=*, seqId=*, proc=*, should be a retry, ignore",warn,HBase
"The pid of remote region procedure for * is *, the reported pid=*, serverName=*, code=*, seqId=*, proc=*, should be a retry, ignore",warn,HBase
Starting assignment manager,trace,HBase
Stopping assignment manager,info,HBase
Only one region server found and hence going ahead with the assignment,debug,HBase
Failed roundRobinAssignment,warn,HBase
Failed transition ,trace,HBase
Failed transition,warn,HBase
"The region server * is already dead, skip reportRegionStateTransition call",warn,HBase
Update region transition serverName=* region=* regionState=*,trace,HBase
RegionServer * *,info,HBase
No matching procedure found for * transition to *,warn,HBase
"Split request from  | , parent= |  splitKey=",debug,HBase
"Handling merge request from RS= | , merged=",debug,HBase
"ReportOnlineRegions * regionCount=*, metaLoaded=* *",trace,HBase
Got a report from a server result in state ,warn,HBase
no online region found on *,trace,HBase
"No region state node for *, it should already be on *",warn,HBase
* reported OPEN on server=* but state has otherwise,warn,HBase
* reported an unexpected OPEN on *; time since last update=*ms,warn,HBase
Found * OPEN regions on dead servers and * OPEN regions on unknown servers,info,HBase
The RIT * has no start time,warn,HBase
STUCK Region-In-Transition *,warn,HBase
Joining cluster...,debug,HBase
Waiting for RegionServers to join; current count=*,info,HBase
Number of RegionServers=*,info,HBase
Joined the cluster in *,info,HBase
Skipping empty row=*,warn,HBase
 regionState=null; presuming ,info,HBase
Skip to add SCP for * since this server should be OFFLINE already,info,HBase
"Skip to add SCP for * with meta= *, since there should be a SCP is processing or already done for this server node",info,HBase
"Added * to dead servers which carryingMeta=*, submitted ServerCrashProcedure pid=*",info,HBase
join interrupted,warn,HBase
got interrupted ,warn,HBase
PROCESS ASSIGN QUEUE regionCount=,trace,HBase
No servers available; cannot place  |  unassigned regions.,warn,HBase
Stopped! Dropping assign of  |  queued regions.,debug,HBase
Filtering old server versions and the excluded produced an empty set; instead considering all candidate servers!,warn,HBase
"Processing assignQueue; systemServersCount= | , allServersCount=",debug,HBase
Available servers count= | : ,trace,HBase
retain assign regions=,trace,HBase
unable to retain assignment,warn,HBase
round robin regions=,trace,HBase
unable to round-robin assignment,warn,HBase
ASSIGN ACCEPT  |  -> ,trace,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
* execute state=*,trace,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,error,HBase
* rollback state=*,trace,HBase
$$$Empty Message$$$,warn,HBase
Failed rollback attempt step  |  for merging the regions  |  in table ,warn,HBase
 ,debug,HBase
Merge switch is off! skip merge of ,warn,HBase
Merge is disabled for the table! Skipping merge of *,warn,HBase
$$$Empty Message$$$,warn,HBase
Row key of mutation from coprocessor is not parsable as region name. Mutations from coprocessor should only be for hbase:meta table.,error,HBase
"* for region *, targetServer * is dead, SCP will interrupt us, give up",debug,HBase
"* for region *, targetServer=* has already been woken up, ignore",warn,HBase
The remote operation * for region * to server * failed,warn,HBase
"Can not add remote operation * for region * to server *, this usually because the server is alread dead, give up and mark the procedure as complete, the parent procedure will take care of this.",warn,HBase
"Failed updating meta, suspend *secs *; *;",warn,HBase
Ignoring interruption,warn,HBase
Failed to balance.,error,HBase
"Loaded config; maxSteps= | , stepsPerRegion= | , maxRunningTime= | , isByTable= | , etc.",info,HBase
failed to get the size of all tables,error,HBase
Not running balancer because only  |  active regionserver(s),debug,HBase
* not needed,debug,HBase
"Skipping load balancing because balanced cluster;  | total cost is  | , sum multiplier is  |  min cost which need balance is ",trace,HBase
"calculatedMaxSteps:* for loadbalancer's stochastic walk is larger than maxSteps:*. Hence load balancing may not work well. Setting parameter ""hbase.master.balancer.stochastic.runMaxSteps"" to true can overcome this issue.(This config change does not require service restart)",warn,HBase
"start StochasticLoadBalancer.balancer, initCost= | , functionCost= |  computedMaxSteps: ",info,HBase
Finished computing new load balance plan. Computation took * to try * different iterations.  Found a solution that moves * regions; Going from a computed cost of * to a new cost of *,info,HBase
"Could not find a better load balance plan.  Tried * different configurations in *, and did not find anything with a computed cost less than *",info,HBase
Moving Region  |  from server  |  to ,trace,HBase
IOException during HDFSBlocksDistribution computation. for  | region = ,warn,HBase
tableName=*,debug,HBase
RegionLocationFinder top hosts is null,warn,HBase
HDFSBlocksDistribution not found in cache for *,trace,HBase
Error while fetching cache entry ,warn,HBase
ExecutionException during HDFSBlocksDistribution computation. for region = ,debug,HBase
"Update configuration of SimpleLoadBalancer, previous slop is  | , current slop is  | previous overallSlop is | , current overallSlop is ",info,HBase
Skipping load balancing because cluster is balanced at overall level,trace,HBase
$$$Empty Message$$$,debug,HBase
"regionsToMove= | , numServers= | , serversOverloaded= | , serversUnderloaded=",warn,HBase
Input ,warn,HBase
Done. Calculated a load balance in  | ms.  | Moving  |  regions off of  |  overloaded servers onto  |  less loaded servers,info,HBase
"During balanceOverall, we found  |  has no RegionInfo, no operation needed",debug,HBase
"Encounter incorrect region numbers after calculating move plan during balanceOverall,  | for this table,  |  originally has  |  regions and  |  regions have been added. Yet, max = | , min = | . Thus stop balance for this table",warn,HBase
Start Generate Balance plan for table: ,debug,HBase
TODO: Enable TRACE on BaseLoadBalancer. Empty servername); skipping; unassigned regions?,warn,HBase
EMPTY SERVERNAME ,trace,HBase
"SERVERNAME IS NULL, skipping ",warn,HBase
Lowest locality region is  |  with locality  |  and its region server contains  |  regions,trace,HBase
"slop=*, systemTablesOnMaster=*",info,HBase
"Refreshing region HDFS Block dist failed with exception, ignoring",warn,HBase
Not running balancer because only  |  active regionserver(s),debug,HBase
Skipping load balancing because balanced cluster;  | servers= |  regions= |  average= |  mostloaded= |  leastloaded=,trace,HBase
Wanted to do round robin assignment but no servers to assign to,warn,HBase
"Skipping the server,  |  , got the same server for the region ",trace,HBase
Wanted to retain assignment but no servers to assign to,warn,HBase
Wanted to do retain assignment but no servers to assign to,warn,HBase
Reassigned  |  regions.  |  retained the pre-restart assignment. ,info,HBase
Load Balancer stop requested: ,info,HBase
Encountered exception while doing favored-nodes (random)assignment ,warn,HBase
Can't generate FN for region:  |  falling back,warn,HBase
"Nothing to assign to, probably no servers or no regions",warn,HBase
Generating favored nodes for regions missing them.,debug,HBase
Generating favored nodes for:  |  with primary: ,debug,HBase
Region:  |  not hosted on favored nodes:  |  current:  |  moving to: ,warn,HBase
"Updating FN in meta for missing regions, count: ",debug,HBase
"Unable to find favored nodes for parent,  |  generating new favored nodes for daughter",debug,HBase
Could not pick lowest local region server,trace,HBase
Could not pick lowest local region even when region server held  |  regions,trace,HBase
"Ignoring, no favored nodes for region: ",trace,HBase
"Region not on favored nodes, unassign. Region:  |  current:  |  favored nodes: ",warn,HBase
Failed unassign,warn,HBase
"Found misplaced regions:  | , not on favored nodes.",debug,HBase
Large file deletion queue is full,trace,HBase
Small file deletion queue is full,trace,HBase
Starting for large file=*,debug,HBase
Starting for small files=*,debug,HBase
Interrupted while trying to take a task from queue,trace,HBase
Removing *,trace,HBase
Failed to delete *,warn,HBase
Exit *,debug,HBase
"Deleted more than Long.MAX_VALUE large files, reset counter to 0",debug,HBase
"Deleted more than Long.MAX_VALUE small files, reset counter to 0",debug,HBase
Stolen a small file deletion task in large file thread,trace,HBase
Stopping file delete threads,debug,HBase
"Wait more than  |  ms for deleting  | , exit...",warn,HBase
"Interrupted while waiting for result of deleting  | , will return false",warn,HBase
Update configuration triggered but nothing changed for this cleaner,debug,HBase
"Updating throttle point, from * to *",debug,HBase
"Updating largeQueueInitSize, from * to *",debug,HBase
"Updating smallQueueInitSize, from * to *",debug,HBase
"Updating largeFileDeleteThreadNumber, from * to *",debug,HBase
"Updating smallFileDeleteThreadNumber, from * to *",debug,HBase
"Log life: | , ttl: | , current: | , from: ",trace,HBase
"Found a log ( | ) newer than current time ( |  <  | ), probably a clock skew",warn,HBase
Cleaner pool size is *,info,HBase
"Size from configuration is same as previous=*, no need to update.",trace,HBase
Update chore's pool size from * to *,info,HBase
"HFile life: | , ttl: | , current: | , from: ",trace,HBase
"Found a hfile ( | ) newer than current time ( |  <  | ), probably a clock skew",warn,HBase
"Use full core processors to scan dir, size=*",warn,HBase
"Computed * threads for CleanerChore, using 1 instead",debug,HBase
"Unrecognized value:  |  for  | , use default config:  |  instead.",error,HBase
Initialize cleaner=*,debug,HBase
Can NOT create CleanerDelegate=*,warn,HBase
Cleaned all WALs under *,trace,HBase
WALs outstanding under *,trace,HBase
Cleaner chore disabled! Not cleaning.,trace,HBase
Failed to traverse and delete the dir: *,info,HBase
Failed to get space consumed by path=*,trace,HBase
Found a wrongly formatted file:  |  - will delete it.,warn,HBase
"A file cleaner |  is stopped, won't delete any more files in:",warn,HBase
 is not deletable according to:,trace,HBase
Removing * from archive,trace,HBase
"Attempted to delete: | , but couldn't. Run cleaner chain and attempt to delete on next pass.",warn,HBase
Error while deleting: ,warn,HBase
Stopping,warn,HBase
Failed to traverse and delete the path: *,debug,HBase
Start deleting * under *,trace,HBase
Couldn't delete '*' yet because it isn't empty w/exception.,debug,HBase
"Could not delete * under *. might be transient; we'll retry. if it keeps happening, use following exception when asking on mailing list.",info,HBase
unexpected exception: ,info,HBase
"Finish deleting * under *, deleted=",trace,HBase
"Procedure log life: | , ttl: | , current: | , from: ",trace,HBase
"Found a procedure log ( | ) newer than current time ( |  <  | ), probably a clock skew",warn,HBase
Failed to clean up replication barrier,warn,HBase
"Cleanup replication barriers: totalRows *, cleanedRows *, deletedRows *, deletedBarriers *, deletedLastPushedSeqIds *",info,HBase
"Size from configuration is the same as previous which is *, no need to update.",debug,HBase
Scheduling file * for deletion,trace,HBase
Old WAL files pending deletion: *,debug,HBase
Awaiting the results for deletion of old WAL file: *,trace,HBase
Creating * OldWALs cleaner threads,info,HBase
Interrupting thread: *,trace,HBase
Attempting to delete old WAL file: *,debug,HBase
Failed to clean old WAL file,warn,HBase
"Interrupted while cleaning old WALs, will try to clean it next round. Exiting.",warn,HBase
Exiting,debug,HBase
Cancelling LogCleaner,debug,HBase
Spend too much time [*ms] to delete old WAL file: *,warn,HBase
Interrupted while awaiting deletion of WAL file: *,warn,HBase
"Couldn't verify if the referenced file still exists, keep it just in case: ",debug,HBase
"Couldn't get the references, not deleting file, just in case. filePath= | , backRefDir=",debug,HBase
"Couldn't instantiate the file system, not deleting file, just in case.  | =",debug,HBase
Heartbeat ,debug,HBase
Timeout failure ,debug,HBase
Calling wake on ,debug,HBase
UNLOCKED ,debug,HBase
LOCKED ,debug,HBase
Failed acquire LOCK  | ; YIELDING,warn,HBase
Unknown level specified in ,error,HBase
Shared lock on namespace not supported for ,error,HBase
Unexpected lock type ,error,HBase
Unexpected lock type ,error,HBase
Only exclusive lock supported on regions for ,error,HBase
InterruptedException when waiting for lock: ,info,HBase
Timed out waiting to acquire procedure lock: ,info,HBase
Failed to normalize regions.,error,HBase
Normalization of system table  |  isn't allowed,debug,HBase
Unable to determine whether split is enabled,debug,HBase
Unable to determine whether split is enabled,debug,HBase
Both split and merge are disabled for table: ,debug,HBase
"Table  |  has  |  regions, required min number |  of regions for normalizer to run is  | , not running normalizer",debug,HBase
"Computing normalization plan for table:  | , number of regions: ",debug,HBase
"Table *:  target region count is *, target region size is *",debug,HBase
"cannot get the target number and target size of table *, they will be default value -1.",warn,HBase
"Table  | , total aggregated regions size: ",debug,HBase
"Table  | , average region size: ",debug,HBase
"Table  | , large region  |  has size  | , more than twice avg size, splitting",info,HBase
"Table  | , small region size:  |  plus its neighbor size:  | , less than the avg size  | , merging them",info,HBase
"No normalization needed, regions look good for table: ",debug,HBase
 was not found in RegionsLoad,debug,HBase
Executing merging normalization plan: ,info,HBase
Error during region merge: ,error,HBase
Executing splitting normalization plan: ,info,HBase
Error during region split: ,error,HBase
"Can not send remote operation * to *, this operation will be retried to send to another server",warn,HBase
"This procedure * is already finished, skip the rest processes",info,HBase
"procedure event for * is null, maybe the procedure is created when recovery",warn,HBase
 execute state=,trace,HBase
Retriable error trying to create table= |  state=,warn,HBase
"Unexpected error caught, this may cause the procedure to hang forever",error,HBase
unknown request type in the queue: ,warn,HBase
"request to * failed, try=*",debug,HBase
"waiting a little before trying on the same server=*, try=*, can wait up to *ms",warn,HBase
server * is not up for a while; try a new one,warn,HBase
"server * tells us do not retry due to *, try=*, give up",warn,HBase
"request to * failed due to *, try=*, this usually because server is overloaded, give up",warn,HBase
"request to * failed due to *, try=*, and the server is dead, give up",warn,HBase
"server * is aborted or stopped, for safety we still need to wait until it is fully dead, try=*",warn,HBase
"request to server * failed due to *, try=*, retrying...",warn,HBase
Building request with operations count=,trace,HBase
* execute state=*,trace,HBase
Retriable error trying to restore snapshot= |  to table= |  (in state= | ),warn,HBase
Starting restore snapshot=,info,HBase
$$$Empty Message$$$,error,HBase
Restore snapshot= |  on table= |  completed!,info,HBase
$$$Empty Message$$$,error,HBase
"Failed to store rpc throttle value *, sleep * secs and retry",warn,HBase
* execute state=*,trace,HBase
Retriable error trying to clone snapshot= |  to table= |  state=,warn,HBase
$$$Empty Message$$$,info,HBase
$$$Empty Message$$$,error,HBase
* execute state=*,trace,HBase
Retryable error in *,warn,HBase
"Not ENABLED, state=*, skipping disable; *",info,HBase
Set * to state=*,info,HBase
Set * to state=*,info,HBase
* execute state=*,trace,HBase
 META entries added for the given regionReplicaCount  |  for the table ,info,HBase
There is no change to the number of region replicas. |  Assigning the available regions. |  Current and previous | replica count is ,debug,HBase
The number of replicas  |   is more than the region replica count ,info,HBase
The regioninfo being removed is  |  ,info,HBase
The number of replicas has been changed(increased). |  Lets assign the new region replicas. The previous replica count was  | . The current replica count is ,info,HBase
Retriable error trying to enable table= |  (in state= | ),warn,HBase
Not DISABLED tableState=*; skipping enable; *,info,HBase
Attempting to enable the table ,info,HBase
Table ' | ' was successfully enabled.,info,HBase
Start ,info,HBase
* had * regions,info,HBase
"Assigning regions  | ,  | ; cycles=",trace,HBase
removed crashed server * after splitting done,info,HBase
"Failed state= | , retry  | ; cycles=",warn,HBase
"remove WAL directory of server * failed, ignore...",warn,HBase
check if splitting WALs of * done? isMeta: *,debug,HBase
"get filelist of serverName * failed, retry...",warn,HBase
"Splitting WALs *, isMeta: *",info,HBase
Splitting meta WALs *,debug,HBase
Done splitting meta WALs *,debug,HBase
Splitting WALs *,debug,HBase
Done splitting WALs *,debug,HBase
* found RIT *; *,info,HBase
Add * to run queue because: *,debug,HBase
Remove * from run queue because: *,debug,HBase
$$$Empty Message$$$,debug,HBase
Waiting on xlock for * held by pid=*,info,HBase
Took xlock for *,info,HBase
"Failed to check whether splitting wal * success, wait * seconds to retry",warn,HBase
"Failed to split wal * by server *, retry...",warn,HBase
split WAL * on * succeeded,info,HBase
"remove WAL * failed, ignore...",warn,HBase
"WAL split task of * send to a wrong server *, will retry on another server",warn,HBase
"split WAL * failed, retry...",warn,HBase
Failed to switch rpc throttle to * on server *,warn,HBase
* execute state=*,trace,HBase
Retriable error trying to modify table=* (in state=*),warn,HBase
Error while modifying table ' | ' Skipping procedure : ,error,HBase
Recover Procedure Store log lease: ,debug,HBase
 execute state=,trace,HBase
waiting for ' | ' regions in transition,debug,HBase
truncate ' | ' completed,debug,HBase
Retriable error trying to truncate table= |  state=,warn,HBase
 execute state=,trace,HBase
Retriable error trying to create namespace= |  (in state= | ),warn,HBase
"Table * is disabled, give up reopening its regions",info,HBase
"There are still * region(s) which need to be reopened for table * are in OPENING state, suspend *secs and try again later",info,HBase
$$$Empty Message$$$,info,HBase
Retriable error trying to delete namespace  |  (in state= | ),warn,HBase
Rollback of deleteFromNSTable throws exception: ,debug,HBase
Rollback of removeFromZKNamespaceManager throws exception: ,debug,HBase
deleteDirectory throws exception: ,debug,HBase
Rollback of deleteDirectory throws exception: ,debug,HBase
Rollback of removeNamespaceQuota throws exception: ,debug,HBase
Removing family= |  from table=,debug,HBase
 execute state=,trace,HBase
Waiting for RIT for *,debug,HBase
Deleting regions from filesystem for *,debug,HBase
Deleting regions from META for *,debug,HBase
Deleting assignment state for *,debug,HBase
Finished *,debug,HBase
Retriable error trying to delete table= |  state=,warn,HBase
Table '*' archived!,debug,HBase
Deleting some vestigial  |  rows of  |  from ,warn,HBase
Removing ' | ' from region states.,debug,HBase
Marking ' | ' as deleted.,debug,HBase
Removing ' | ' descriptor.,debug,HBase
 execute state=,trace,HBase
Retriable error trying to modify namespace= |  (in state= | ),warn,HBase
"Interrupted while sleeping, waiting on ",warn,HBase
waitFor ,trace,HBase
waitFor ,debug,HBase
Successfully enabled peer *,info,HBase
Skip settting last pushed sequence id for *,debug,HBase
"Update last pushed sequence id for *, *",trace,HBase
"* failed to call pre CP hook or the pre check is failed for peer *, mark the procedure as failure and give up",warn,HBase
"* failed to call post CP hook for peer *, ignore since the procedure has already done",warn,HBase
"Successfully added * peer *, config *",info,HBase
Successfully updated peer config of * to *,info,HBase
Successfully removed peer *,info,HBase
Successfully disabled peer *,info,HBase
Refresh peer * for * on * failed,warn,HBase
Refresh peer * for * on * suceeded,info,HBase
$$$Empty Message$$$,info,HBase
Marking snapshot |  as finished.,debug,HBase
"Corrupted in-progress snapshot file exception, ignored ",debug,HBase
"Exception while checking if files were valid, keeping them just in case.",error,HBase
Failed to create cleaner util,error,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
Snapshot information for  |  doesn't exist,error,HBase
Current user does not have access to  |  snapshot.  | Either you should be owner of this snapshot or admin user.,warn,HBase
Found a corrupted snapshot ,warn,HBase
Couldn't delete working snapshot directory: ,warn,HBase
Deleting snapshot: ,debug,HBase
"Snapshot ' | ' has completed, notifying client.",debug,HBase
Snapshoting ' | ' is still in progress!,debug,HBase
Couldn't delete working directory ( |  for snapshot:,error,HBase
Couldn't delete working directory ( |  for snapshot:,error,HBase
"No existing snapshot, attempting snapshot...",debug,HBase
$$$Empty Message$$$,error,HBase
"Table enabled, starting distributed snapshot.",debug,HBase
Started snapshot: ,debug,HBase
"Table is disabled, running snapshot entirely on master.",debug,HBase
Started snapshot: ,debug,HBase
"Can't snapshot table ' | ', isn't open or closed, we don't know what to do!",error,HBase
Exception occurred while cloning the snapshot  |  as table ,error,HBase
Clone snapshot= |  as table=,info,HBase
$$$Empty Message$$$,error,HBase
A Snapshot named ' | ' does not exist.,error,HBase
Exception occurred while restoring the snapshot  |  as table ,error,HBase
Restore snapshot= |  as table=,info,HBase
$$$Empty Message$$$,error,HBase
stop ProcedureCoordinator error,error,HBase
Snapshots from an earlier release were found under: ,error,HBase
Please rename the directory as .hbase-snapshot,error,HBase
"Snapshot log and hfile cleaners are present in the configuration,  | but the ' | ' property  | is set to 'false'.",warn,HBase
"Snapshot feature is not enabled, missing log and hfile cleaners.",info,HBase
"Snapshots are present, but cleaners are not enabled.",error,HBase
$$$Empty Message$$$,error,HBase
Done waiting - online snapshot for ,info,HBase
Take disabled snapshot of offline region=,info,HBase
Taking snapshot for mob files in table ,info,HBase
Failed to refresh snapshot hfile cache!,warn,HBase
Current cache:,debug,HBase
"Not checking unreferenced files since snapshot is running, it will skip to clean the HFiles this time",warn,HBase
"No snapshots on-disk, clear cache",debug,HBase
Failed to refresh snapshot hfile cache!,warn,HBase
$$$Empty Message$$$,info,HBase
$$$Empty Message$$$,info,HBase
$$$Empty Message$$$,error,HBase
Launching cleanup of working dir:,debug,HBase
Couldn't delete snapshot working directory:,error,HBase
Couldn't delete snapshot working directory:,error,HBase
"Sentinel is done, just moving the snapshot from  |  to ",debug,HBase
Stop taking snapshot= |  because: ,info,HBase
Starting ,debug,HBase
Znodes to watch: ,debug,HBase
Found no data from ,debug,HBase
"Set data for remote  | , client zk wather: ",debug,HBase
"Failed to create znode  |  due to:  | , will retry later",warn,HBase
"Failed to set data to client ZK, will retry later",debug,HBase
ZK session expired or lost. Retry a new connection...,warn,HBase
"Failed to reconnect to client zk after session expiration, will retry later",warn,HBase
Unexpected exception handling nodeCreated event,warn,HBase
Unexpected exception handling nodeDeleted event for path: ,warn,HBase
Interrupted while checking whether need to update meta location to client zk,debug,HBase
MOB HFiles older than  |  will be deleted!,info,HBase
Failed to find the mob file ,warn,HBase
Checking file ,debug,HBase
 is an expired file,debug,HBase
Cannot parse the fileName ,error,HBase
Failed to delete the mob files ,error,HBase
 expired mob files are deleted,info,HBase
$$$Empty Message$$$,info,HBase
"Failed to open mob file[ | ], keep it in temp directory.",error,HBase
Failed to compact the mob files for the column  |  in the table ,error,HBase
Failed to parse the date ,warn,HBase
Failed to parse date ,warn,HBase
Cleaning the expired MOB files of  |  in ,info,HBase
Failed to close the HBaseAdmin.,error,HBase
Failed to close the connection.,error,HBase
"hbase.mob.cache.evict.remain.ratio is less than 0.0, 0.0 is used.",warn,HBase
"hbase.mob.cache.evict.remain.ratio is larger than 1.0, 1.0 is used.",warn,HBase
"MobFileCache enabled with cacheSize= | , evictPeriods= | sec, evictRemainRatio=",debug,HBase
MobFileCache disabled,info,HBase
Failed to evict the file ,error,HBase
"MobFileCache, Exception happen during close ",error,HBase
Interrupted while sleeping,warn,HBase
Still running ,debug,HBase
"MobFileCache Statistics, access:  | , miss:  | , hit:  | , hit ratio:  | %, evicted files: ",info,HBase
"Failed to create mob writer, we will continue the compaction by writing MOB cells directly in store files",warn,HBase
"Failed to create del writer, we will continue the compaction by writing delete markers directly in store files",warn,HBase
"The value format of the KeyValue  |  is wrong, its length is less than ",warn,HBase
"Compaction progress: * *, rate=* KB/sec, throughputController is *",debug,HBase
"Mob store is flushed, sequenceid= | , memsize= |  | , hasBloomFilter= | , into tmp file ",info,HBase
Failed to delete the temp mob file,error,HBase
No candidate mob files,info,HBase
is allFiles: ,info,HBase
"The compaction type is  | , the request has  |  del files,  |  selected files, and  |  irrelevant files",info,HBase
"After merging, there are  |  del files",info,HBase
"After compaction, there are  |  mob files",info,HBase
"After a mob compaction with all files selected, archiving the del files ",info,HBase
$$$Empty Message$$$,info,HBase
Failed to archive the del files ,error,HBase
No partitions of mob files,info,HBase
Compacting mob files for partition ,info,HBase
Failed to compact the partition ,error,HBase
Failed to close the Table,error,HBase
Compaction is finished. The number of mob files is changed from  |  to ,info,HBase
Failed to close the reader on store file ,warn,HBase
Failed to archive the files ,error,HBase
Failed to close the writer of the file ,error,HBase
Failed to archive the old del files ,error,HBase
Failed to close the writer of the file ,error,HBase
Failed to close the writer of the ref file ,error,HBase
Failed to delete the file ,error,HBase
The file  |  links to can not be found,warn,HBase
Task may be stuck: ,warn,HBase
Status  |  appears to have been leaked,warn,HBase
Namespace State Manager started.,info,HBase
"The region  |  cannot be created. The region count  will exceed quota on the namespace.  | This may be transient, please retry later if there are any ongoing split |  operations in the namespace.",warn,HBase
Namespace state found null for namespace : ,warn,HBase
Error while fetching namespace descriptor for namespace : ,error,HBase
Finished updating state of  |  namespaces. ,info,HBase
NamespaceAuditor started.,info,HBase
Namespace auditor checks not performed for table ,debug,HBase
"Submitted null subprocedure, nothing to run here.",warn,HBase
Subproc name cannot be null or the empty string,error,HBase
Subproc ' | ' is already running. Bailing out,error,HBase
"A completed old subproc  |  is still present, removing",warn,HBase
Another thread has replaced existing subproc ' | '. Bailing out,error,HBase
Submitting new Subprocedure:,debug,HBase
Another thread has submitted subproc ' | '. Bailing out,error,HBase
Failed to start subprocedure ' | ',error,HBase
Unexpected reached globa barrier message for Sub-Procedure ' | ',warn,HBase
reached global barrier message for Sub-Procedure ' | ',trace,HBase
$$$Empty Message$$$,error,HBase
Request received to abort procedure ,debug,HBase
"Received abort on procedure with no local subprocedure  | , ignoring it.",info,HBase
$$$Empty Message$$$,error,HBase
User procedure  |  was loaded successfully.,info,HBase
Class  |  cannot be found. ,warn,HBase
Load procedure  |  failed. ,warn,HBase
Current zk system:,debug,HBase
$$$Empty Message$$$,debug,HBase
$$$Empty Message$$$,debug,HBase
"Clearing all znodes *, *, *",debug,HBase
Clearing all znodes for procedure  | including nodes  |   |  ,info,HBase
$$$Empty Message$$$,error,HBase
Creating acquire znode:,debug,HBase
Watching for acquire node:,debug,HBase
$$$Empty Message$$$,error,HBase
Creating reached barrier zk node:,debug,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
Attempting to clean out zk node for op:,debug,HBase
$$$Empty Message$$$,error,HBase
Node created: ,debug,HBase
Finished data from procedure '*' member '*': *,debug,HBase
Ignoring created notification for node:,debug,HBase
Unable to start the ZK-based Procedure Coordinator rpcs.,error,HBase
Starting controller for procedure member=,debug,HBase
Aborting procedure ' | ' in zk,debug,HBase
Creating abort znode:,debug,HBase
Finished creating abort node:,debug,HBase
Got an error notification for op: |  but we can't read the information. Killing the procedure.,warn,HBase
Got an error notification for op: |  but we can't read the information. Killing the procedure.,warn,HBase
Procedure  |  currently running.  Rejecting new request,warn,HBase
Procedure  |  was in running list but was completed.  Accepting new attempt.,debug,HBase
Procedure  |  has been resubmitted by another thread. Rejecting this request.,warn,HBase
Procedure  |  was in running list but has exception.  Accepting new attempt.,debug,HBase
Procedure  |  has been resubmitted by another thread. Rejecting this request.,warn,HBase
Submitting procedure ,debug,HBase
Another thread has submitted procedure ' | '. Ignoring this attempt.,error,HBase
Procedure  |  rejected by execution pool.  Propagating error.,warn,HBase
received connection failure: ,debug,HBase
connection failure - notify procedure: ,trace,HBase
abort procedure ,debug,HBase
Failed to submit procedure ' | ',error,HBase
Member ' | ' is trying to acquire an unknown procedure ' | ',warn,HBase
Member ' | ' acquired procedure ' | ',trace,HBase
Member ' | ' is trying to release an unknown procedure ' | ',warn,HBase
Member ' | ' released procedure ' | ',trace,HBase
Starting procedure ' | ',info,HBase
Procedure ' | ' starting 'acquire',debug,HBase
Waiting for all members to 'acquire',debug,HBase
Procedure ' | ' starting 'in-barrier' execution.,debug,HBase
Waiting for all members to 'release',debug,HBase
Procedure ' | ' execution completed,info,HBase
$$$Empty Message$$$,error,HBase
Running finish phase.,debug,HBase
"Starting procedure ' | ', kicking off acquire phase on members.",debug,HBase
Finished coordinator procedure - removing self from list of running procedures,debug,HBase
member: ' | ' joining acquired barrier for procedure ' | ' on coordinator,debug,HBase
Waiting on:  |  remaining members to acquire global barrier,debug,HBase
"Member  |  joined barrier, but we weren't waiting on it to join. |  Continuing on.",warn,HBase
"Member: ' | ' released barrier for procedure' | ', counting down latch.  Waiting for  |  more",debug,HBase
"Member: ' | ' released barrier for procedure' | ', but we weren't waiting on it to release!",warn,HBase
Received created event:,info,HBase
Ignoring created notification for node:,debug,HBase
Received procedure start children changed event: ,info,HBase
Received procedure abort children changed event: ,info,HBase
Received reached global barrier:,debug,HBase
Checking for aborted procedures on node: ' | ',debug,HBase
Looking for new procedures under znode:' | ',debug,HBase
No running procedures.,debug,HBase
No running procedures.,debug,HBase
Found procedure znode: ,debug,HBase
Not starting: |  because we already have an abort notification.,debug,HBase
$$$Empty Message$$$,error,HBase
start proc data length is ,debug,HBase
Found data for znode:,debug,HBase
Illegal argument exception,error,HBase
Illegal state exception ,error,HBase
Member: ' | ' joining acquired barrier for procedure ( | ) in zk,debug,HBase
Watch for global barrier reached:,debug,HBase
Marking procedure  ' | ' completed for member ' | ' in zk,debug,HBase
Failed due to null subprocedure,error,HBase
Aborting procedure ( | ) in zk,debug,HBase
Finished creating abort znode:,debug,HBase
Aborting procedure member for znode ,debug,HBase
$$$Empty Message$$$,error,HBase
Got an error notification for op: |  but we can't read the information. Killing the procedure.,warn,HBase
abort already in progress,warn,HBase
Starting procedure member ' | ',debug,HBase
"Was remote foreign exception, not redispatching error",debug,HBase
"Was KeeperException, not redispatching error",debug,HBase
"Can't reach controller, not propagating error",error,HBase
Starting subprocedure ' | ' with timeout  | ms,debug,HBase
Subprocedure ' | ' starting 'acquire' stage,debug,HBase
Subprocedure ' | ' locally acquired,debug,HBase
"Subprocedure ' | ' coordinator notified of 'acquire', waiting on |  'reached' or 'abort' from coordinator",debug,HBase
Subprocedure ' | ' received 'reached' from coordinator.,debug,HBase
Subprocedure ' | ' locally completed,debug,HBase
Subprocedure ' | ' has notified controller of completion,debug,HBase
Subprocedure ' | ' running cleanup.,debug,HBase
Subprocedure ' | ' completed.,debug,HBase
$$$Empty Message$$$,error,HBase
Procedure * initializing,debug,HBase
Procedure * initialized,debug,HBase
Procedure * starting,debug,HBase
Procedure * started,debug,HBase
Failed to close procedure  |  cleanly,warn,HBase
Start region server flush procedure manager ,debug,HBase
Stopping region server flush procedure manager  | .,info,HBase
Launching subprocedure to flush regions for ,debug,HBase
Waiting for local region flush to finish.,debug,HBase
unexpected future,warn,HBase
Completed  | / |  local region flush tasks.,debug,HBase
Completed  |  local region flush tasks.,debug,HBase
Got InterruptedException in FlushSubprocedurePool,warn,HBase
Rethrowing ForeignException from FlushSubprocedurePool,warn,HBase
Got Exception in FlushSubprocedurePool,warn,HBase
cancelling  |  flush region tasks ,debug,HBase
Starting region operation on ,debug,HBase
Flush region  |  started...,debug,HBase
Closing region operation on ,debug,HBase
Flush region tasks submitted for  |  regions,debug,HBase
Aborting all flush region subprocedure task threads for ' | ' due to error,info,HBase
stop: ,info,HBase
$$$Empty Message$$$,error,HBase
Done waiting - exec procedure  |  for ' | ',info,HBase
Master flush table procedure is successful!,info,HBase
Refreshing space quotas in RegionServer,trace,HBase
Failed to process quota reports and update quota state. Will retry.,warn,HBase
Found following tables with quotas: ,trace,HBase
Using  |  region space use reports: ,trace,HBase
"Filtered insufficiently reported tables, left with  |  regions reported",trace,HBase
Moving  |  out of violation because fewer region sizes were |  reported than required.,trace,HBase
"Unexpectedly did not find a space quota for  | , maybe it was recently deleted.",debug,HBase
"Processing  |  with current= | , target=",trace,HBase
"Could not get Namespace space quota for  | , maybe it was recently deleted.",debug,HBase
"Processing  |  with current= | , target=",trace,HBase
 moved into observance of table space quota.,debug,HBase
 moved into violation of table space quota with policy of ,debug,HBase
 remains in observance of quota.,trace,HBase
 remains in violation of quota.,trace,HBase
Not activating Namespace violation policy because a Table violation |  policy is already in effect for ,trace,HBase
 moving into observance of namespace space quota,info,HBase
Not activating Namespace violation policy because a Table violation |  policy is already in effect for ,trace,HBase
 moving into violation of namespace space quota with policy ,info,HBase
 remains in observance of quota.,trace,HBase
Not activating Namespace violation policy because Table violation |  policy is already in effect for ,trace,HBase
 moving into violation of namespace space quota,info,HBase
Removed  |  old region size reports that were older than  | .,trace,HBase
Adding  |  under  |  as having a namespace quota,trace,HBase
Adding  |  as having table quota.,trace,HBase
Filtering  |  because no regions were reported,trace,HBase
Filtering  |  because  |  of  |  regions were reported.,trace,HBase
Retaining  |  because  |  of  |  regions were reported.,trace,HBase
Quota support disabled,info,HBase
Initializing RPC quota support,info,HBase
Start rpc quota manager and rpc throttle enabled is *,info,HBase
Switch rpc throttle from * to *,info,HBase
Skip switch rpc throttle because previous value * is the same as current value *,warn,HBase
Skip switch rpc throttle to * because rpc quota is disabled,warn,HBase
get quota for ugi= |  table= |  userLimiter=,trace,HBase
get quota for ugi= |  table= |  userLimiter= |  tableLimiter= |  nsLimiter= |  rsLimiter= |  exceedThrottleQuotaEnabled=,trace,HBase
Throttling exception for user= |  table= |  numWrites= |  numReads= |  numScans= | : ,debug,HBase
"Quota support disabled, not starting space quota manager.",info,HBase
RegionServerSpaceQuotaManager has already been started!,warn,HBase
Enabling violation policy enforcement on  |  with policy ,trace,HBase
Failed to enable space violation policy for  | . This table will not enter violation.,error,HBase
Disabling violation policy enforcement on ,trace,HBase
Failed to disable space violation policy for  | . This table will remain in violation.,error,HBase
Computing sizes of snapshots for quota management.,trace,HBase
"Failed to compute the size of snapshots, will retry",warn,HBase
Paths for  | : ,trace,HBase
Files referenced by other snapshots: ,trace,HBase
Snapshot  |  solely references the files: ,trace,HBase
Computed size of  |  to be ,trace,HBase
Could not compute path for the archive directory for the region,warn,HBase
"Expected  |  to be a file but was a directory, ignoring reference",warn,HBase
Could not obtain the status of ,warn,HBase
"Expected  |  to exist but does not, ignoring reference.",warn,HBase
Failed to trim exception message,trace,HBase
Unable to parse user ' | ' quotas,error,HBase
Unable to parse  |  ' | ' quotas,error,HBase
Stopping QuotaRefresherChore chore.,debug,HBase
Unable to read if exceed throttle quota enabled from quota table,warn,HBase
evict  |  key=,trace,HBase
refresh  |  key= |  quotas=,trace,HBase
Unable to read  |  from quota table,warn,HBase
Get live region servers failed,warn,HBase
Get table regions failed: *,warn,HBase
Saw snapshot size of  |  for ,trace,HBase
Failed to parse snapshot size from cell: ,warn,HBase
Preempting execution of FileSystemUtilizationChore because it exceeds the maximum iteration configuration value. Will process remaining iterators on a subsequent invocation.,debug,HBase
"Computed the size of  |  Regions. Skipped computation |  of  |  regions due to not being online on this RS,  |  regions due to being the parent of a split, and |  regions due to being region replicas.",trace,HBase
Size of  |  is ,trace,HBase
Reading current quota snapshots from hbase:quota.,trace,HBase
" table quota snapshots are collected,  | read  |  from the quota table.",trace,HBase
": current= | , new=",trace,HBase
Enabling  |  on ,trace,HBase
Removing quota violation policy on ,trace,HBase
Switching quota violation policy on  |  from  |  to ,trace,HBase
Removing quota violation policy on ,trace,HBase
"Caught exception while refreshing enforced quota violation policies, will retry.",warn,HBase
$$$Empty Message$$$,error,HBase
Exceed throttle quota is enabled but no region server quotas found,warn,HBase
"Read/Write requests num exceeds quota: writes:* reads:* scan:*, try use region server quota",debug,HBase
Persisting a space quota snapshot  |  for ,trace,HBase
Quota support disabled,info,HBase
Quota table not found. Creating...,info,HBase
Initializing quota support,info,HBase
* switch rpc throttle from * to *,info,HBase
Skip switch rpc throttle to * because it's the same with old value,warn,HBase
Skip switch rpc throttle to * because rpc quota is disabled,warn,HBase
Skip get rpc throttle because rpc quota is disabled,warn,HBase
Skip switch exceed throttle quota to * because it's the same with old value,warn,HBase
* switch exceed throttle quota from * to *,info,HBase
Skip switch exceed throttle quota to * because quota is disabled,warn,HBase
Current quota for request( | ): ,trace,HBase
Deserialized quota from request: ,trace,HBase
Computed merged quota from current quota and user request: ,trace,HBase
Interrupted while waiting for Quota Manager to be initialized.,warn,HBase
Compactions were already disabled upon enabling the policy,trace,HBase
Compactions were already enabled upon disabling the policy,trace,HBase
High priority because region=,trace,HBase
Marking normal priority after getting exception=,trace,HBase
High priority scanner request ,trace,HBase
Failed checking low replication,warn,HBase
Failed to shutdown wal,warn,HBase
Wal roll period * ms elapsed,debug,HBase
WAL roll requested,debug,HBase
Log rolling failed,error,HBase
LogRoller exiting.,info,HBase
"Failed to schedule flush of *, because it is not online on us",warn,HBase
"Failed to schedule flush of *, region=*, because FlushRequester is null",warn,HBase
"Flushed memstore data size=* at sequenceid=* (bloomFilter=*), to=*",info,HBase
$$$Empty Message$$$,debug,HBase
Instantiated  | ; ,debug,HBase
"Failed initialize of region= *, starting to roll back memstore",warn,HBase
"Failed drop memstore of region= *, some chunks may not released forever since MSLAB is enabled",warn,HBase
writing seq id for *,debug,HBase
Failed to clean up wrong region WAL directory *,debug,HBase
Opened *; next sequenceid=*,info,HBase
Setting FlushNonSloppyStoresFirstPolicy for the region=,info,HBase
Could not initialize all stores for the region=,error,HBase
close store failed,warn,HBase
"Asked to modify this region's ( | ) memStoreSizing to a negative value which is incorrect. Current memStoreSizing= | , delta=",error,HBase
Region  |  is not mergeable because it is closing or closed,debug,HBase
Region  |  is not mergeable because it has references,debug,HBase
Region close journal:\n,debug,HBase
Region  |  already closed,warn,HBase
"Closing *, disabling compactions & flushes",debug,HBase
Running close preflush of *,info,HBase
Updates disabled for region ,debug,HBase
"Running extra flush,  |  (carrying snapshot?) ",info,HBase
Memstore data size is *,error,HBase
Closed ,info,HBase
waiting for  |  compactions |  & cache flush |  to complete for region ,debug,HBase
Interrupted while waiting,warn,HBase
waiting for cache flush to complete for region ,debug,HBase
Interrupted while waiting,warn,HBase
Waited  |  ms for flush to complete,debug,HBase
Skipping compaction on  |  because closing/closed,debug,HBase
"Store  |  on region  |  has been re-instantiated, cancel this compaction request.  |  It may be caused by the roll back of split transaction",warn,HBase
$$$Empty Message$$$,debug,HBase
$$$Empty Message$$$,info,HBase
Starting compaction of * in **,info,HBase
$$$Empty Message$$$,info,HBase
Compaction status journal:\n\t,debug,HBase
$$$Empty Message$$$,debug,HBase
$$$Empty Message$$$,debug,HBase
"NOT flushing memstore for region  | , flushing= | , writesEnabled=",debug,HBase
Flush status journal:\n\t,debug,HBase
Flush column family  |  of  |  because unflushed sequenceid= |  is >  |  from current=,debug,HBase
Flush column family:  |  of  |  because time of oldest edit= |  is >  |  from now =,debug,HBase
"Flushing  | / |  column families, |  dataSize= |  heapSize= |  | ",info,HBase
Received unexpected exception trying to write ABORT_FLUSH marker to WAL:,warn,HBase
 :  | Received exception while trying to write the flush request to wal,warn,HBase
$$$Empty Message$$$,trace,HBase
 :  | failed writing ABORT_FLUSH marker to WAL,warn,HBase
$$$Empty Message$$$,info,HBase
$$$Empty Message$$$,warn,HBase
No such column family in batch mutation. ,warn,HBase
$$$Empty Message$$$,warn,HBase
Batch Mutation did not pass sanity check. ,warn,HBase
$$$Empty Message$$$,warn,HBase
Batch mutation had a row that does not belong to this region. ,warn,HBase
"Failed getting lock, row=",warn,HBase
No family for  |  omit from reply.,info,HBase
 :  | Skipping  |  mutations with replaySeqId= |  which is < than lastReplayedOpenRegionSeqId=,trace,HBase
 : Skipping : ,trace,HBase
 : Enabling reads for region.,info,HBase
Failed delete of *,error,HBase
Deleted recovered.edits file=*,debug,HBase
Failed delete of *,error,HBase
Deleted recovered.edits file=*,debug,HBase
Found  |  recovered edits file(s) under ,debug,HBase
Null or non-existent edits file: ,warn,HBase
$$$Empty Message$$$,debug,HBase
The property 'hbase.skip.errors' has been deprecated. Please use hbase.hregion.edits.replay.skip.errors instead.,warn,HBase
=true so continuing. Renamed  |  as ,error,HBase
$$$Empty Message$$$,info,HBase
$$$Empty Message$$$,warn,HBase
 :  | Found decreasing SeqId. PreId= |  key= | ; edit=,error,HBase
No family for ,warn,HBase
Row of  |  is not within region boundary,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,debug,HBase
 :  | Skipping replaying compaction event : |  because its sequence id  |  is smaller than this regions  | lastReplayedOpenRegionSeqId of ,warn,HBase
 :  | Skipping replaying compaction event : |  because its sequence id  |  is smaller than this regions  | lastReplayedCompactionSeqId of ,warn,HBase
 :  | Replaying compaction marker  |  with seqId= |  and lastReplayedOpenRegionSeqId=,debug,HBase
 :  | Found Compaction WAL edit for deleted family:,warn,HBase
 :  | At least one of the store files in compaction:  |  doesn't exist any more. Skip loading the file(s),warn,HBase
 :  | Replaying flush marker ,debug,HBase
" :  | Received a flush event with unknown action, ignoring. ",warn,HBase
" :  | Received a flush start marker from primary, but the family is not found. Ignoring |  StoreFlushDescriptor:",warn,HBase
 :  | Skipping replaying flush event : |  because its sequence id is smaller than this regions lastReplayedOpenRegionSeqId  |  of ,warn,HBase
 :  |  Prepared flush with seqId:,debug,HBase
 :  |  Prepared empty flush with seqId:,debug,HBase
 :  | Received a flush prepare marker with the same seqId:  |  before clearing the previous one with seqId:  | . Ignoring,warn,HBase
 :  | Received a flush prepare marker with a smaller seqId:  |  before clearing the previous one with seqId:  | . Ignoring,warn,HBase
 :  | Received a flush prepare marker with a larger seqId:  |  before clearing the previous one with seqId:  | . Ignoring,warn,HBase
 :  | Skipping replaying flush event : |  because its sequence id is smaller than this regions lastReplayedOpenRegionSeqId  |  of ,warn,HBase
 :  | Received a flush commit marker with seqId: |  and a previous prepared snapshot was found,debug,HBase
" :  | Received a flush commit marker with smaller seqId:  |  than what we have prepared with seqId:  | . Picking up new file, but not dropping |   prepared memstore snapshot",warn,HBase
 :  | Received a flush commit marker with larger seqId:  |  than what we have prepared with seqId:  | . Picking up new file and dropping prepared |  memstore snapshot,warn,HBase
" :  | Received a flush commit marker with seqId: | , but no previous prepared snapshot was found",warn,HBase
 :  | At least one of the store files in flush:  |  doesn't exist any more. Skip loading the file(s),warn,HBase
" :  | Received a flush commit marker from primary, but the family is not found. | Ignoring StoreFlushDescriptor:",warn,HBase
 :  | Unexpected: flush commit marker received from store  |  but no associated flush context. Ignoring,warn,HBase
"Drop memstore for Store  |  in region  |  , dropped memstoresize: [ |  }",info,HBase
 :  | Dropping memstore contents as well since replayed flush seqId:  |  is greater than current seqId:,info,HBase
 :  | Not dropping memstore contents since replayed flush seqId:  |  is smaller than current seqId:,info,HBase
 :  | Skipping replaying flush event : |  because its sequence id  |  is smaller than this regions  | lastReplayedOpenRegionSeqId of ,warn,HBase
" :  | Unknown region event received, ignoring :",warn,HBase
 :  | Replaying region open event marker ,debug,HBase
 :  | Skipping replaying region event : |  because its sequence id is smaller than this regions lastReplayedOpenRegionSeqId  |  of ,warn,HBase
" :  | Received a region open marker from primary, but the family is not found.  | Ignoring. StoreDescriptor:",warn,HBase
 :  | At least one of the store files:  |  doesn't exist any more. Skip loading the file(s),warn,HBase
 :  | Replaying bulkload event marker ,debug,HBase
 :  | Skipping replaying bulkload event : |  because its sequence id is smaller than this region's lastReplayedOpenRegionSeqId |  =,warn,HBase
" :  | Received a bulk load marker from primary, but the family is not found.  | Ignoring. StoreDescriptor:",warn,HBase
 :  |  doesn't exist any more. Skip loading the file,warn,HBase
 :  | Refreshing store files to see whether we can free up memstore,debug,HBase
 : Store files for region: ,trace,HBase
"File  |  is zero-length, deleting.",warn,HBase
Thread interrupted waiting for lock on row: ,warn,HBase
"Error to get row lock for  | , cause: ",warn,HBase
There were one or more IO errors when checking if the bulk load is ok.,error,HBase
"There was a recoverable bulk load failure likely due to a |  split.  These (family, HFile) pairs were not loaded: ",warn,HBase
There was a partial failure due to IO when attempting to |  load  |  : ,error,HBase
Error while calling failedBulkLoad for family  |  with path ,error,HBase
Failed to find the size of hfile ,warn,HBase
There was a partial failure due to IO when attempting to |  load  |  : ,error,HBase
Error while calling failedBulkLoad for family  |  with path ,error,HBase
filter#hasFilterRow is true which prevents partial results from being  formed. Changing scope of limits that may create partials,trace,HBase
"creating  | , tableDescriptor= | null | , regionDir=",info,HBase
Opening region: ,debug,HBase
Opening region (readOnly filesystem): ,debug,HBase
HRegion.Warming up region: ,debug,HBase
"Failed getting lock, row=",warn,HBase
RowProcessor: |  throws Exception,warn,HBase
RowProcessor: |  throws Exception,warn,HBase
RowProcessor timeout: |  ms,error,HBase
$$$Empty Message$$$,debug,HBase
"Coprocessor service  |  already registered, rejecting request from ",error,HBase
Registered coprocessor service: region= |  service=,debug,HBase
Cannot split meta region in HBase 0.20 and above,warn,HBase
Ignoring invalid split,error,HBase
writing data to region  |  with WAL disabled. Data may be lost in the event of a crash.,info,HBase
Interrupted while waiting for a lock,info,HBase
Flush requested on ,debug,HBase
$$$Empty Message$$$,warn,HBase
"Splitting the stripe - ratio w/o split  | , ratio with split  |  configured ratio ",debug,HBase
Attempting to merge compaction results:  |  files replaced by ,debug,HBase
Attempting to delete compaction results: ,debug,HBase
Attempting to load  |  store files.,debug,HBase
"Unexpected metadata - start row [ | ], end row [ | ] in file [ | ], pushing to L0",error,HBase
"Store file doesn't fit into the tentative stripes - expected to start at [ | ], but starts at [ | ], to L0 it goes",warn,HBase
"The range of the loaded files does not cover full key space: from [ | ], to [ | ]",warn,HBase
"Inconsistent files, everything goes to L0.",warn,HBase
$$$Empty Message$$$,debug,HBase
The newly compacted file doesn't have stripes set: ,warn,HBase
"Stripes were created by a flush, but results of size  |  cannot be added because the stripes have changed",warn,HBase
 conflicting files (likely created by a flush)  |  of size  |  are moved to L0 due to concurrent stripe change,info,HBase
"Found an expired store file:  |  whose maxTimestamp is  | , which is below ",info,HBase
Failed to complete execution of proc pid=*,debug,HBase
Successfully complete execution of proc pid=*,debug,HBase
Failed report procedure  | ; retry (# | ) |  after  | ms delay (Master is coming online...).,info,HBase
"Setting  |  to  | , same value as  |  because supplied value greater than initial memstore size value.",warn,HBase
"Setting  |  to  | , same value as  |  because supplied value less than initial memstore size value.",warn,HBase
"Setting  |  to  | , same value as  |  because supplied value greater than initial block cache size.",warn,HBase
"Setting  |  to  | , same value as  |  because supplied value less than initial block cache size.",warn,HBase
"Starting, tuneOn=*",info,HBase
Stopping,info,HBase
heapOccupancyPercent  |  is above heap occupancy alarm watermark ( | ),warn,HBase
heapOccupancyPercent  |  is now below the heap occupancy alarm watermark ( | ),info,HBase
Exception thrown from the HeapMemoryTuner implementation,error,HBase
From HeapMemoryTuner new memstoreSize:  | . new blockCacheSize: ,debug,HBase
New memstoreSize from HeapMemoryTuner  |  is below min level  | . Resetting memstoreSize to min size,info,HBase
New memstoreSize from HeapMemoryTuner  |  is above max level  | . Resetting memstoreSize to max size,info,HBase
New blockCacheSize from HeapMemoryTuner  |  is below min level  | . Resetting blockCacheSize to min size,info,HBase
New blockCacheSize from HeapMemoryTuner  |  is above max level  | . Resetting blockCacheSize to min size,info,HBase
Current heap configuration from HeapMemoryTuner exceeds  | the threshold required for successful cluster operation.  | The combined value cannot exceed 0.8.  |  is  |  and  |  is ,info,HBase
Setting block cache heap size to  |  and memstore heap size to ,info,HBase
No changes made by HeapMemoryTuner.,debug,HBase
Tuner step size is too low; we will not perform any tuning this time.,debug,HBase
$$$Empty Message$$$,debug,HBase
close store scanner failed,warn,HBase
StoreScanner already has the close lock. There is no need to updateReaders,debug,HBase
StoreScanner already closing. There is no need to updateReaders,debug,HBase
"Storescanner.peek() is changed where before =  | ,and after = ",info,HBase
Switch to stream read (scanned=* bytes) of *,debug,HBase
failed to switch to stream read,warn,HBase
Region  |  not splittable because midkey=null,debug,HBase
"Splitting  | , ",debug,HBase
Could not execute split for ,info,HBase
Re-Initializing compactions because user switched on compactions,info,HBase
Interrupting running compactions because user switched off compactions,info,HBase
$$$Empty Message$$$,debug,HBase
Compaction requested:  | system | ; Because:  |  | ; ,debug,HBase
User has disabled compactions,info,HBase
$$$Empty Message$$$,debug,HBase
Waiting for  |  to finish...,info,HBase
Interrupted waiting for  |  to finish...,warn,HBase
Total number of regions is approaching the upper limit  | .  | Please consider taking a look at http://hbase.apache.org/book.html#ops.regionmgt,warn,HBase
Compaction selection failed ,error,HBase
Completed |  compaction  | ; duration=,info,HBase
Compaction failed ,error,HBase
Compaction failed at original callstack: ,info,HBase
Compaction failed ,error,HBase
Status *,debug,HBase
Compaction Rejected: ,debug,HBase
Changing the value of  |  from  |  to ,info,HBase
Changing the value of  |  from  |  to ,info,HBase
Changing the value of  |  from  |  to ,info,HBase
"Commit  |  writers, maxSeqId= | , majorCompaction=",debug,HBase
Failed to close the writer after an unfinished compaction.,error,HBase
 is a link,trace,HBase
 is a  |  reference to ,trace,HBase
Failed match of store file name ,warn,HBase
reference ' | ' to region= |  hfile=,trace,HBase
Skipping  |  because it is empty. HBASE-646 DATA LOSS?,warn,HBase
parse proto buffer of split WAL request failed ,error,HBase
split WAL * succeed.,info,HBase
failed to split WAL *.,warn,HBase
Failed to delete a file after failed flush: ,error,HBase
"Failed to close flush scanner, ignoring",warn,HBase
$$$Empty Message$$$,info,HBase
"Fail to open mob file[ | ], keep it in temp directory.",error,HBase
"The Cell result is null, assemble a new Cell with the same row,family,qualifier,timestamp,type and tags but with an empty value to return.",warn,HBase
"Fail to read the cell, the mob file  |  doesn't exist",debug,HBase
The mob file  |  is corrupt,error,HBase
Fail to read the cell,debug,HBase
Fail to read the cell,debug,HBase
The mob file  |  could not be found in the locations  |  or it is corrupt,error,HBase
Time to purge deletes set to *ms in store *,trace,HBase
"Compaction check period multiplier must be positive, setting default: *1000",error,HBase
"Store=*,  memstore type=*, storagePolicy=*, verifyBulkLoads=*, parallelPutCountPrintThreshold=*, encoding=*, compression=*",info,HBase
loaded *,debug,HBase
Could not close store file,warn,HBase
Clearing the compacted storefile * from this store,warn,HBase
Moving the files * to archive,debug,HBase
Refreshing store files for region  |  files to add:  |  files to remove: ,info,HBase
"tableName=*, encodedName=*, columnFamilyName=* is  | too busy!",trace,HBase
"tableName=*, encodedName=*, columnFamilyName=* is  | too busy!",trace,HBase
Validating hfile at  |  for inclusion in  | store  |  region ,info,HBase
HFile bounds: first= |  last=,debug,HBase
Region bounds: first= |  last=,debug,HBase
Trying to bulk load hfile  |  with size:  |  bytes can be problematic as it may lead to oversplitting.,warn,HBase
Full verification started for bulk load hfile: *,info,HBase
Full verification complete for bulk load hfile:  |  took  |  ms,info,HBase
Loaded HFile  |  into store ' | ' as  |  - updating store file list.,info,HBase
Successfully loaded store file * into store * (new location: *),info,HBase
Loaded HFile  |  into store ',info,HBase
$$$Empty Message$$$,trace,HBase
Closed *,trace,HBase
"Failed validating store file *, retrying num=*",warn,HBase
"Failed flushing store file, retrying num=*",warn,HBase
"Added  | , entries= | , sequenceid= | , filesize= | ",info,HBase
$$$Empty Message$$$,trace,HBase
"Starting compaction of  |  into tmpdir= | , totalSize= | ",info,HBase
$$$Empty Message$$$,info,HBase
$$$Empty Message$$$,trace,HBase
Completing compaction from the WAL marker,debug,HBase
"Replaying compaction marker, replacing input files:  |  with output files : ",info,HBase
StoreFile * has null Reader,debug,HBase
 -  | : Initiating  | major |  compaction |  (all files),debug,HBase
Skipping expired store file removal due to min version being *,debug,HBase
Completed removal of  |  unnecessary (expired) file(s) in  |  of  | ; total size for store is  | ,info,HBase
"Failed to open store file : *, keeping it in tmp location",error,HBase
StoreFile * has a null Reader,warn,HBase
Not splittable; has references: *,trace,HBase
Not splittable; has references: *,trace,HBase
Failed getting store size for *,warn,HBase
Compaction priority is USER despite there being no user compaction,warn,HBase
Failed to commit store file *,error,HBase
"Failed to delete store file we committed, halting *",error,HBase
"Region:  |  added  | , entries= | , sequenceid= | , filesize= | ",info,HBase
No compacted files to archive,trace,HBase
The file * was closed but still not archived,debug,HBase
Closing and archiving the file *,trace,HBase
"Can't archive compacted file  |  because of either isCompactedAway= |  or file has reference, isReferencedInReads= | , refCount= | , skipping for now.",info,HBase
Exception while trying to close the compacted store file *,error,HBase
Moving the files * to archive,debug,HBase
Clearing the compacted file * from this store,trace,HBase
failed to close stream reader,warn,HBase
Bad Delete Family bloom filter data -- proceeding without,error,HBase
Error reading bloom filter data -- proceeding without,error,HBase
Bad bloom filter data -- proceeding without,error,HBase
Loaded  |   |  metadata for ,trace,HBase
Loaded Delete Family Bloom ( | ) metadata for ,info,HBase
Error reading bloom filter meta for  |  -- proceeding without,error,HBase
Bad bloom filter meta  |  -- proceeding without,error,HBase
Exception while closing the scanner ,error,HBase
Scanner  |  lease expired on region ,info,HBase
Closing scanner for ,error,HBase
Closing scanner for ,error,HBase
"Scanner  |  lease expired, but no related |  scanner found, hence no chance to close that related scanner!",warn,HBase
$$$Empty Message$$$,debug,HBase
Closing scanner ,warn,HBase
Large batch operation detected (greater than  | ) (HBASE-18023). |  Requested Number of Rows:  |  Client:  | / |  first region in multi=,warn,HBase
hostname is configured to be ,info,HBase
Run out of memory;  |  will abort itself immediately,error,HBase
Close  |  without moving,info,HBase
"Close  | , moving to ",info,HBase
Compacting ,info,HBase
$$$Empty Message$$$,trace,HBase
$$$Empty Message$$$,trace,HBase
Flushing ,info,HBase
Client= | / |  clear compactions queue,debug,HBase
clear  |  compaction queue,debug,HBase
Unknown queue name ,warn,HBase
Clear compactions queue is executing by other admin.,warn,HBase
OpenRegionRequest for * does not have a start code,warn,HBase
CloseRegionRequest for * does not have a start code,warn,HBase
$$$Empty Message$$$,warn,HBase
Open ,info,HBase
"Receiving OPEN for the region: | , which we are already trying to OPEN |  - ignoring this new request for this region.",info,HBase
No executor executorService; skipping open request,info,HBase
Failed opening region ,warn,HBase
Region already online. Skipping warming up ,info,HBase
Region is in transition. Skipping warmup ,info,HBase
Warming up region ,info,HBase
Failed warming up region ,error,HBase
Error while skipping Cells in CellScanner for invalid Region Mutations,error,HBase
Client tried to access missing scanner ,warn,HBase
", closing...",warn,HBase
Getting exception closing ,warn,HBase
Getting exception closing ,warn,HBase
"Done scanning, limit of rows reached, moreRows:  |  scannerContext: ",trace,HBase
Server shutting down and client tried to access missing scanner ,debug,HBase
Un-able to cancel lease of scanner. It could already be closed.,trace,HBase
"Failed to get TableDescriptor of *, will try again in the handler",warn,HBase
"Failed to instantiating remote procedure *, pid=*",warn,HBase
"Executing remote procedure *, pid=*",debug,HBase
"Swapping pipeline suffix; before=*, new segment=*",debug,HBase
"Suffix data size=*, new segment data size=*, suffix heap size=*,new segment heap size=* 　suffix off heap size=*, new segment off heap size=*, suffix cells count=*, new segment cells count=*",debug,HBase
"Segment flattening failed, because versions do not match. Requester version:  | , actual version: ",warn,HBase
"Segment flattening failed, because versions do not match",warn,HBase
Compaction pipeline segment * flattened,debug,HBase
Ignoring bloom filter check for file  | :  | cfBloomType= |  (disabled in config),info,HBase
"HFile Bloom filter type for  | :  | , but  |  specified in column family  | configuration",info,HBase
Bloom filter turned off by CF config for ,info,HBase
Error reading timestamp range data from meta -- proceeding without,error,HBase
Error reading compacted storefiles from meta data,error,HBase
failed to close reader,warn,HBase
Unable to ask master to split ,error,HBase
Skipping split because server is stopping= |  or stopped=,debug,HBase
"globalMemStoreLimit= |  | , globalMemStoreLimitLowMark= |  | , Offheap=",info,HBase
Above memory mark but there are no flushable regions!,error,HBase
"Under global heap pressure:  | Region  |  has too many  | store files, but is  |  |  vs best flushable region's  |  | . Choosing the bigger.",debug,HBase
Above memory mark but there is no flushable region,debug,HBase
Refreshing storefiles of region  |  due to global heap pressure. Total memstore off heap size= |  |  memstore heap size= | ,info,HBase
Excluding secondary region  |  - trying to find a different region to refresh files.,info,HBase
"Flush of region  |  due to global heap pressure.  | Flush type= | Total Memstore Heap size= |  | Total Memstore Off-Heap size= |  | , Region memstore size= | ",info,HBase
Excluding unflushable region  |  - trying to find a different region to flush.,info,HBase
Flush thread woke up because memory above low water= | ,debug,HBase
Cache flusher failed for entry ,error,HBase
 exiting,info,HBase
Refreshing store files failed with exception,warn,HBase
Waited  | ms on a compaction to clean up 'too many store files'; waited  | long enough... proceeding with flush of ,info,HBase
* has too many store files(*); delaying flush up to * ms,warn,HBase
Cache flush failed for region ,error,HBase
Cache flush failed |  for region  | ,error,HBase
Interrupted while waiting,warn,HBase
Memstore is above high water mark and block * ms,warn,HBase
Unblocking updates for server ,info,HBase
Blocking updates: * * is >= blocking *,info,HBase
"Strategy=*, store=*; merging * segments",trace,HBase
"Strategy=*, store=*; flattening a segment",trace,HBase
* in-memory compaction for store=* compacting * segments,trace,HBase
Not starting a distinct region server because hbase.cluster.distributed is false,warn,HBase
Region server exiting,error,HBase
"Unable to load configured flush policy ' | ' for table ' | ', load default flush policy  |  instead",warn,HBase
Snapshot called again without clearing previous. Doing nothing. Another ongoing flush or did we fail last attempt?,warn,HBase
"vmName= | , vmVendor= | , vmVersion=",info,HBase
vmInputArguments=,info,HBase
memstore1 estimated size=*,info,HBase
memstore1 estimated size (2nd loading of same data)=*,info,HBase
memstore2 estimated size=*,info,HBase
Waiting 30 seconds while heap dump is taken,info,HBase
Exiting.,info,HBase
Failed construction RegionServer,error,HBase
"Coprocessor executorService  |  already registered, rejecting request from ",error,HBase
Registered regionserver coprocessor executorService: executorService=,debug,HBase
ClusterId : ,info,HBase
About to register with Master.,debug,HBase
reportForDuty failed; sleeping * ms and then retrying.,warn,HBase
Closing user regions,info,HBase
Waiting on ,debug,HBase
Initialize abort timeout task failed,warn,HBase
Stopping infoServer,info,HBase
Failed to stop infoServer,error,HBase
aborting server ,info,HBase
stopping server ,info,HBase
Attempt to close server's short circuit ClusterConnection failed.,warn,HBase
stopping server  | ; all regions closed.,info,HBase
Failed deleting my ephemeral node,warn,HBase
Exiting; stopping= | ; zookeeper connection closed.,info,HBase
Skipping Region size report to HMaster as stub is null,trace,HBase
Failed to report region sizes to Master because it is initializing. This will be retried.,trace,HBase
"master doesn't support ReportRegionSpaceUse, pause before retrying",debug,HBase
Failed to report region sizes to Master. This will be retried.,debug,HBase
Waiting on  |  regions to close,info,HBase
Online Regions=,debug,HBase
"We were exiting though online regions are not empty, because some regions failed closing",info,HBase
Interrupted while sleeping,warn,HBase
Shutdown / close of WAL failed: ,error,HBase
Shutdown / close exception details:,debug,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
Config from master:  | =,debug,HBase
"Serving as  | , RpcServer on  | , sessionid=0x",info,HBase
 runs every ,info,HBase
Failed major compaction check on ,warn,HBase
* requesting flush of * because * after random delay * ms,info,HBase
logDir=*,debug,HBase
SplitLogWorker Service NOT started; CoordinatedStateManager is null,warn,HBase
$$$Empty Message$$$,error,HBase
Failed binding http info server to port: ,error,HBase
Failed binding http info server to port: ,info,HBase
***** STOPPING region server ' | ' *****,info,HBase
The region server did not stop,warn,HBase
Skipping coprocessor exception on preStop() due to forced shutdown,warn,HBase
STOPPED: ,info,HBase
"Post open deploy tasks for *, openProcId=*, masterSystemTime=*",info,HBase
No sequence number found when opening ,error,HBase
Finished post open deploy task for ,debug,HBase
Failed to update meta location,info,HBase
Failed to update meta,info,HBase
TRANSITION FAILED  | : ,info,HBase
TRANSITION REPORTED ,info,HBase
Failed report transition  | ; retry (# | ) |  after  | ms delay (Master is coming online...).,info,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
RegionServer abort: loaded coprocessors are: ,error,HBase
Dump of metrics as JSON on abort: ,info,HBase
Failed dumping metrics,warn,HBase
Unable to report fatal error to master,warn,HBase
No master found and cluster is stopped; bailing out,debug,HBase
No master found; retry,debug,HBase
"Master isn't available yet, retrying",info,HBase
Unable to connect to master. Retrying. Error was:,warn,HBase
"reportForDuty to master= |  with port= | , startcode=",info,HBase
Master rejected startup because clock is out of sync,error,HBase
Master is not running yet,debug,HBase
error telling master we are up,warn,HBase
Unable to connect to the master to check the last flushed sequence id,warn,HBase
Unable to connect to the master to check the last flushed sequence id,warn,HBase
STARTING executorService ,info,HBase
Exception attempting to fetch wal coprocessor information for the common wal; skipping.,warn,HBase
Exception details for failure to fetch wal coprocessor information.,debug,HBase
Exception attempting to fetch wal coprocessor information for region  | ; skipping.,warn,HBase
Exception details for failure to fetch wal coprocessor information.,debug,HBase
Failed to close  |  - ignoring and continuing,warn,HBase
Failed to close  |  - ignoring and continuing,warn,HBase
Unable to close region: the coprocessor launched an error ,warn,HBase
"Received CLOSE for the region: |  , which we are already  | trying to OPEN. Cancelling OPENING.",info,HBase
The opening for region  |  was done before we could cancel it. |  Doing a standard close now,warn,HBase
The opening previously in progress has been cancelled by a CLOSE request.,info,HBase
"Received CLOSE for the region:  | , which we are already trying to CLOSE, but not completed yet",info,HBase
"Received CLOSE for a region which is not online, and we're not opening.",debug,HBase
NotServingRegionException; ,debug,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
Not adding moved region record:  |  to self.,warn,HBase
Adding  |  move to  |  record at close sequenceid=,info,HBase
Reloading the configuration from disk.,info,HBase
Failed to initialize SuperUsers on reloading of the configuration,warn,HBase
"Received procedure pid=*, which already submitted, just ignore it",warn,HBase
"Received procedure pid=*, which already executed, just ignore it",warn,HBase
"Aborting region server timed out, terminating forcibly and does not wait for any running shutdown hooks or finalizers to finish their work. Thread dump to stdout.",warn,HBase
STUCK: ,warn,HBase
Write stripe metadata for ,debug,HBase
Skip writing stripe metadata for ,debug,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
Stopping to use a writer after [ | ] row; wrote out  |  kvs,debug,HBase
Stopping to use a writer after [ | ] row; wrote out  |  kvs,debug,HBase
Creating new writer starting at [ | ],debug,HBase
Preparing to start a new writer after [ | ] row; observed  |  kvs and wrote out  |  kvs,debug,HBase
Stopping with  |  kvs in last writer |  |  KVs total,debug,HBase
"Merge expired stripes into one, create an empty file to preserve metadata.",debug,HBase
close KeyValueScanner error,warn,HBase
 not specified for table  | . Using default RegionSplitPolicy,error,HBase
Delimiter  |   not found for split key ,warn,HBase
Failed to get hedged metrics,warn,HBase
Computing regionserver metrics every  |  milliseconds,info,HBase
Caught exception! Will suppress and retry.,warn,HBase
 not specified for table  | . Using default RegionSplitPolicy,error,HBase
Number format exception when parsing  |  for table  | : | . ,error,HBase
Invalid value for  |  for table  | : | . Using default RegionSplitPolicy,error,HBase
Started compacted hfiles cleaner on ,trace,HBase
Completed archiving the compacted files for the region  |  under the store ,trace,HBase
Exception while trying to close and archive the compacted store  | files of the store   |  in the |  region ,error,HBase
Completed the compacted hfiles cleaner for the region ,trace,HBase
System coprocessor loading is  | enabled,info,HBase
Table coprocessor loading is  | enabled,info,HBase
* is not of type RegionServerCoprocessor. Check the configuration of *hbase.coprocessor.regionserver.classes,error,HBase
Storefile  |  Reader is null; cannot get split point,warn,HBase
cannot split * because midkey is the same as first or last row,debug,HBase
"Store=*, in-memory flush size threshold=*, immutable segments index type=*, compactor=*",info,HBase
Snapshot called again without clearing previous. Doing nothing. Another ongoing flush or did we fail last attempt?,warn,HBase
"FLUSHING TO DISK *, store=*",debug,HBase
Dispatching the MemStore in-memory flush for store ,trace,HBase
IN-MEMORY FLUSH: Pushing active segment into compaction pipeline,trace,HBase
Unable to run in-memory compaction on */*; exception=*,warn,HBase
"Multiple unsuccessful attempts to push the compaction pipeline to snapshot, while flushing to disk.",warn,HBase
$$$Empty Message$$$,debug,HBase
Stripe store is forced to take an arbitrary file list and compact it.,warn,HBase
Unexpected exception killed leases thread,error,HBase
lease listener is null for lease ,error,HBase
Closed leases,info,HBase
Could not load HFile info ,error,HBase
"Threshold for maximum blocked requests is set too low or too high,  resetting to default of 0.2",warn,HBase
Aggregation window size is too low:  | . Resetting it to default of ,warn,HBase
Going to split region  |  because it's too busy. Blocked Request rate: ,debug,HBase
"Split part count cannot be 1 ( | ), using the default",error,HBase
"Initial stripe count is 0, using the default",error,HBase
%s is set to 0 or negative; using default value of %f,warn,HBase
Installed shutdown hook thread: ,debug,HBase
Shutdown hook starting;  | = | ; fsShutdownHook=,info,HBase
Starting fs shutdown hook thread.,info,HBase
Shutdown hook finished.,info,HBase
Couldn't find field 'clientFinalizer' in FileSystem!,error,HBase
Couldn't access field 'clientFinalizer' in FileSystem!,error,HBase
"ShouldSplit because  |  size= | , sizeToCheck= | , regionsWithCommonTable=",debug,HBase
Failed getOnlineRegions ,debug,HBase
Loaded coprocessor  |  from HTD of  |  successfully.,info,HBase
Failed to load coprocessor ,error,HBase
* is not of type RegionCoprocessor. Check the configuration of *hbase.coprocessor.region.classes,error,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
hbase.bulkload.staging.dir  |  is deprecated. Bulkload staging directory is ,warn,HBase
Cleaned up  |  successfully.,info,HBase
Failed to close FileSystem for: ,error,HBase
token added  |  for user  |  return=,debug,HBase
unable to add token,warn,HBase
Failed to complete bulk load,error,HBase
 is already available in staging directory. Skipping copy or rename.,debug,HBase
Bulk-load file  |  is on different filesystem than  | the destination filesystem. Copying file over to destination staging dir.,debug,HBase
Bulk-load file  |  is copied to destination staging dir.,debug,HBase
Moving  |  to ,debug,HBase
Bulk Load done for: ,debug,HBase
 is already available in source directory. Skipping rename.,debug,HBase
Moving  |  back to ,debug,HBase
Can't find previous permission for path=,warn,HBase
The chunk pool is full. Reached maxCount=  | . Creating chunk onheap.,trace,HBase
Jumbo chunk size  |  must be more than regular chunk size  | . Converting to regular chunk.,warn,HBase
"* stats (chunk size=*): current pool size=*, created chunk count=*, reused chunk count=*, reuseRatio=*",debug,HBase
* not tuning the chunk pool as it is offheap,warn,HBase
* max count for chunks increased from * to *,info,HBase
* max count for chunks decreased from * to *,info,HBase
* poolSizePercentage is less than 0. So not using pool,info,HBase
"Allocating * MemStoreChunkPool with chunk size *, max count *, initial count *",info,HBase
Speculative compaction starting on */*,trace,HBase
Interrupting in-memory compaction for store=*,trace,HBase
"Since none of the CFs were above the size, flushing all.",debug,HBase
No * set in table * descriptor;using region.getMemStoreFlushHeapSize/# of families (*) instead.hbase.hregion.percolumnfamilyflush.size.lower.bound,debug,HBase
"Number format exception parsing * for table *: *, *; using region.getMemStoreFlushHeapSize/# of families (*) and region.getMemStoreFlushOffHeapSize/# of families (*) instead.hbase.hregion.percolumnfamilyflush.size.lower.bound",warn,HBase
Flush * of *; heap memstoreSize=* +off heap memstoreSize=* > memstore lowerBound=*,debug,HBase
"Exception while trying to refresh store files for region: | , exception:",warn,HBase
No StoreFiles for: ,trace,HBase
Invalid StoreFile: ,warn,HBase
No StoreFiles for: ,trace,HBase
Invalid StoreFile: ,warn,HBase
Reference *,trace,HBase
Committing  |  as ,debug,HBase
Bulk-load file  |  is on different filesystem than  | the destination store. Copying file over to destination filesystem.,info,HBase
Copied  |  to temporary path on destination filesystem: ,info,HBase
Cleaned up old failed split transaction detritus: ,info,HBase
The  |  directory exists.  Hence deleting it to recreate it,info,HBase
* directory exists. Deleting it to recreate it anew,info,HBase
 doesn't exist for region:  |  on table ,warn,HBase
Rewriting .regioninfo file at: ,info,HBase
 file not found for region:  |  on table ,warn,HBase
Trying to create a region that already exists on disk: ,warn,HBase
Unable to create the region directory: ,warn,HBase
Skipping creation of .regioninfo file for ,debug,HBase
Trying to open a region that do not exists on disk: ,warn,HBase
Skipping creation of .regioninfo file for ,debug,HBase
Trying to delete a region that do not exists on disk: ,warn,HBase
DELETING region ,debug,HBase
Failed delete of ,warn,HBase
", retries exhausted",debug,HBase
", sleeping  |  times ",debug,HBase
"Bloom filter type for  | :  | , param:  | , ",trace,HBase
Delete Family Bloom filter type for  | : ,trace,HBase
General Bloom and  |  | DeleteFamily |  was added to HFile ,trace,HBase
Nonce grace period  |  is less than a minute; might be too small to be useful,warn,HBase
"Conflict detected by nonce:  | , ",debug,HBase
"Conflict with running op ended:  | , ",debug,HBase
"Nonce collision during WAL recovery:  | ,  |  with ",warn,HBase
could not find root dir or fs,warn,HBase
"log splitting of  |  interrupted, resigning",warn,HBase
WAL * does not exist anymore,warn,HBase
"log replaying of  |  can't connect to the target regionserver,  | resigning",warn,HBase
"log splitting of  |  interrupted, resigning",warn,HBase
"log splitting of  |  failed, returning error",warn,HBase
SplitLogWorker  |  starting,info,HBase
SplitLogWorker interrupted. Exiting.  | ,info,HBase
unexpected error ,error,HBase
SplitLogWorker  |  exiting,info,HBase
Sending interrupt to stop the worker thread,info,HBase
Can not check for compaction: ,error,HBase
filesToCompact:  |  mcTime: ,debug,HBase
lowTimestamp:  |  lowTimestamp:  |  now:  |  mcTime: ,debug,HBase
Major compaction triggered on store  | ; for TTL maintenance,debug,HBase
"Major compaction triggered on store  | , because there are new files and time since last major compaction  | ms",debug,HBase
Major compaction triggered on store  | ; because file  |  has data with timestamps cross window boundaries,debug,HBase
Major compaction triggered on store  | ; because there are more than one file in some windows,debug,HBase
"Major compaction triggered on store  | ; to make hdfs blocks local, current blockLocalityIndex is  |  (min  | )",debug,HBase
"Skipping major compaction of  | , because the files are already major compacted",debug,HBase
Generated compaction request: ,debug,HBase
Processing files:  |  for window: ,debug,HBase
Value for  | :  | . All the files will be eligible for minor compaction.,warn,HBase
Exploring compaction algorithm has selected  |  files of size  |  because the store might be stuck,debug,HBase
Exploring compaction algorithm has selected *  files of size * starting at candidate #* after considering * permutations with * in ratio,debug,HBase
$$$Empty Message$$$,debug,HBase
"Executing compaction with  |  target file size, no more than  |  files, in [ | ] [ | ] range",debug,HBase
"Major compaction triggered on only store  | ; to make hdfs blocks local, current blockLocalityIndex is  |  (min  | )",debug,HBase
"Skipping major compaction of  |  because one (major) compacted file only, oldestTime  | ms is < TTL= |  and blockLocalityIndex is  |  (min  | )",debug,HBase
"Major compaction triggered on store  | , because keyvalues outdated; time since last major compaction  | ms",debug,HBase
Major compaction triggered on store  | ; time since last major compaction  | ms,debug,HBase
"Running an off-peak compaction, selection ratio = ",info,HBase
Default compaction algorithm has selected  |  files from  |  candidates,info,HBase
Ignoring invalid start/end hour for peak hour : start =  |  end =  | . Valid numbers are [0-23],warn,HBase
Not selecting compaction:  |  files compacting,debug,HBase
There are references in the store; compacting all files,debug,HBase
Selecting L0 compaction with  |  files,debug,HBase
No good compaction is possible in any stripe,debug,HBase
"Found compaction in a stripe with end key [ | ], with  |  files of total size ",debug,HBase
Adding  |  files to compaction to be able to drop deletes,debug,HBase
Creating  |  initial stripes with  |  kvs each via L0 compaction of  |  files,debug,HBase
Merging  |  stripes to delete expired store files,debug,HBase
Value for  | :  | . Will always promote to next tier.,warn,HBase
$$$Empty Message$$$,info,HBase
Failed to close the writer after an unfinished compaction.,warn,HBase
Failed to delete the leftover file  |  after an unfinished compaction.,warn,HBase
Major compaction is not supported for FIFO compaction policy. Ignore the flag.,warn,HBase
"Split detected, delegate selection to the parent policy.",info,HBase
"Split detected, delegate to the parent policy.",info,HBase
"Split detected, delegate to the parent policy.",info,HBase
"Executing compaction with  | windows, lower boundaries: ",debug,HBase
Null reader for ,warn,HBase
"Compacting *, keycount=*, bloomtype=*, size=*, encoding=*, compression=*, seqNum=**",debug,HBase
"Compaction progress: * *, rate=* KB/sec, throughputController is *",debug,HBase
"Selecting compaction from  |  store files,  |  compacting,  |  eligible,  |  blocking",debug,HBase
Some files are too large. Excluding  |  files from compaction candidates,debug,HBase
"Warning, compacting more than  |  files because of a user-requested major compaction",debug,HBase
Too many admissible files. Excluding  |  files from compaction candidates,debug,HBase
Not compacting files because we only have  |  files ready for compaction. Need  |  to initiate.,debug,HBase
Failed to delete the leftover file  |  after an unfinished compaction.,warn,HBase
$$$Empty Message$$$,info,HBase
totalCompactingKVs=* less than currentCompactedKVs=*,warn,HBase
$$$Empty Message$$$,error,HBase
task execution preempted ,warn,HBase
task execution interrupted because worker is exiting ,info,HBase
Worker  |  done with task  |  in  | ms. Status = ,info,HBase
Region  |  was already online when we started processing the opening.  | Marking this new attempt as failed,error,HBase
Region  |  opening cancelled,error,HBase
Opened  |  on ,debug,HBase
Bad state: we've just opened a region that was NOT in transition. Region=,error,HBase
"Race condition: we've finished to open a region, while a close was requested  |  on region= | . It can be a critical error, as a region that |  should be closed is now opened. Closing it now",error,HBase
Interrupting thread ,debug,HBase
Interrupted joining ,warn,HBase
$$$Empty Message$$$,warn,HBase
Open region aborted since it isn't opening any more,warn,HBase
Failed open of region=,error,HBase
Caught throwable while processing event ,error,HBase
Attempting to do an RPC to the primary region replica  |  of region  |  to trigger a flush,debug,HBase
Successfully triggered a flush of primary region replica  |  of region  |  Now waiting and blocking reads until observing a full flush cycle,debug,HBase
Successfully triggered an empty flush marker(memstore empty) of primary  | region replica  |  of region  |  Now waiting and  | blocking reads until observing a flush marker,debug,HBase
Was not able to trigger a flush from primary region due to old server version?  | Continuing to open the secondary region replica: ,warn,HBase
Processing close of *,trace,HBase
Received CLOSE for region * but currently not serving - ignoring,warn,HBase
"Can't close region *, was already closed during close()",warn,HBase
Closed ,debug,HBase
Error when call RSProcedureCallable: ,error,HBase
"Failed to open region *, will report to master",warn,HBase
"Received OPEN for the region:*, which is already online",warn,HBase
"Receiving OPEN for the region:*, which we are already trying to OPEN - ignoring this new request for this region.",info,HBase
"Receiving OPEN for the region:*, which we are trying to close, try again after *ms",info,HBase
Open *,info,HBase
Opened *,info,HBase
Bad state: we've just opened a region that was NOT in transition. Region=*,error,HBase
Bad state: we've just opened a region that was closing. Region=*,error,HBase
"Fatal error occurred while opening region *, aborting...",warn,HBase
"Received CLOSE for the region: *, which we are already trying to OPEN. try again after *ms",warn,HBase
"Received CLOSE for the region: *, which we are already trying to CLOSE, but not completed yet",info,HBase
"Received CLOSE for a region * which is not online, and we're not opening/closing.",debug,HBase
Close *,info,HBase
"Can't close region *, was already closed during close()",warn,HBase
Closed *,info,HBase
"Fatal error occurred while closing region *, aborting...",warn,HBase
Starting snapshot operation on ,debug,HBase
take snapshot without flush memstore first,debug,HBase
Flush Snapshotting region  |  started...,debug,HBase
... SkipFlush Snapshotting region  |  completed.,debug,HBase
... Flush Snapshotting region  |  completed.,debug,HBase
Closing snapshot operation on ,debug,HBase
Flush Snapshot Tasks submitted for  |  regions,debug,HBase
got interrupted exception for ,error,HBase
Aborting all online FLUSH snapshot subprocedure task threads for ' | ' due to error,info,HBase
Start Snapshot Manager ,debug,HBase
Stopping RegionServerSnapshotManager  | .,info,HBase
Launching subprocedure for snapshot  |  from table  |  type ,debug,HBase
Waiting for local region snapshots to finish.,debug,HBase
unexpected future,warn,HBase
Completed  | / |  local region snapshots.,debug,HBase
Completed  |  local region snapshots.,debug,HBase
Got InterruptedException in SnapshotSubprocedurePool,warn,HBase
Rethrowing ForeignException from SnapshotSubprocedurePool,warn,HBase
Got Exception in SnapshotSubprocedurePool,warn,HBase
cancelling  |  tasks for snapshot ,debug,HBase
"Unable to load configured throughput controller ' | ', load default throughput controller  |  instead",warn,HBase
" is deprecated, please use  |  instead",warn,HBase
"flushPressure is  | , tune flush throughput to ",debug,HBase
"Flush throughput configurations, upper bound:  | , lower bound  | , tuning period:  |  ms",info,HBase
deltaSize:  |  bytes; elapseTime:  |  ns,debug,HBase
" sleep= | ms because current throughput is  | , max allowed is  | , already slept  |  time(s) and total slept time is  |  ms till now.",debug,HBase
" average throughput is  | , slept  |  time(s) and total slept time is  |  ms.  |  active operations remaining, total limit is ",info,HBase
update config: ,debug,HBase
: preparePutCount= | ; currentParallelPutCount=,trace,HBase
$$$Empty Message$$$,trace,HBase
"Unable to load configured flush throughput controller ' | ', load default throughput controller  |  instead",warn,HBase
"CompactionPressure is  | , tune throughput to ",trace,HBase
"Compaction throughput configurations, higher bound:  | , lower bound  | , off peak:  | , tuning period:  |  ms",info,HBase
Appended compaction marker ,trace,HBase
Appended flush marker ,trace,HBase
Appended region event marker ,trace,HBase
Appended Bulk Load marker ,trace,HBase
 is not of type WALCoprocessor. Check the  | configuration ,error,HBase
"normal close failed, try recover",warn,HBase
"Got an old ROOT edit, ignoring ",info,HBase
"Flushing Map not cleaned up for  | , sequenceid=",warn,HBase
Couldn't find oldest sequenceid for ,warn,HBase
$$$Empty Message$$$,error,HBase
"WAL configuration: blocksize= | , rollsize= | , prefix= | , suffix= | , logDir= | , archiveDir=",info,HBase
"Too many WALs; count= | , max= | ; forcing flush of  |  regions(s): ",info,HBase
WAL file ready for archiving ,trace,HBase
Archiving  |  to ,info,HBase
"Rolled WAL * with entries=*, filesize=*; new WAL *",info,HBase
New WAL *,info,HBase
Interrupted,warn,HBase
WAL closed. Skipping rolling of writer,debug,HBase
Create new  |  writer with pipeline: ,debug,HBase
Moved  |  WAL file(s) to ,debug,HBase
Closed WAL: ,info,HBase
$$$Empty Message$$$,info,HBase
Please use the WALPerformanceEvaluation tool instead. i.e.:,error,HBase
\thbase org.apache.hadoop.hbase.wal.WALPerformanceEvaluation --iterations ,error,HBase
$$$Empty Message$$$,warn,HBase
"After parsing the trailer, we expect the total footer to be * bytes, but we calculate it as being *",warn,HBase
"After reading the trailer: walEditsStopOffset:  | , fileLength:  | ,  | trailerPresent:  | true, size:  | false | , currentPosition: ",trace,HBase
No trailer found.,trace,HBase
"Invalid trailer Size  | , ignoring the trailer",warn,HBase
Please investigate WALTrailer usage. Trailer size > maximum configured size :  |  > ,warn,HBase
Got IOE while reading the trailer. Continuing as if no trailer is present.,warn,HBase
Reached end of expected edits area at offset *,trace,HBase
WALKey has no KVs that follow it; trying the next one. current offset=*,trace,HBase
Error getting pos for error message - ignoring,trace,HBase
"Read WALTrailer while reading WALEdits. wal:  | , inputStream.getPos():  | , walEditsStopOffset: ",error,HBase
"Encountered a malformed edit, but can't seek back to last good position because originalPosition is negative. last offset=*",warn,HBase
"Encountered a malformed edit, seeking to the beginning of the WAL since current position and original position match at *",warn,HBase
Reached the end of file at position *,info,HBase
"Encountered a malformed edit, seeking back to last good position in file, from * to *",warn,HBase
"Sequence= | , event=",error,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
pre-sync failed but an optimization so keep going,warn,HBase
Failed sync-before-close but no outstanding appends; closing WAL,warn,HBase
"Riding over failed WAL close of  | , cause=\ | \ | ; THIS FILE WAS NOT CLOSED BUT ALL EDITS SYNCED SO SHOULD BE OK",warn,HBase
"Failed close of WAL writer  | , unflushedEntries=",error,HBase
Stale sync exception,trace,HBase
Timed out bringing down disruptor after  | ms; forcing halt  | (It is a problem if this is NOT an ABORT! -- DATALOSS!!!!),warn,HBase
Closing WAL writer in ,debug,HBase
"Error syncing, request close of WAL",error,HBase
UNEXPECTED,warn,HBase
"UNEXPECTED, continuing",warn,HBase
HDFS pipeline error detected.  | Found  |  replicas but expecting no less than  |  replicas.  |  Requesting close of WAL. current pipeline: ,warn,HBase
"Too many consecutive RollWriter requests, it's a sign of the total number of live datanodes is lower than the tolerable replicas.",warn,HBase
LowReplication-Roller was enabled.,info,HBase
"DFSOutputStream.getNumCurrentReplicas failed because of  | , continuing...",warn,HBase
$$$Empty Message$$$,info,HBase
UNEXPECTED!!! syncFutures.length=,error,HBase
Interrupted ,warn,HBase
$$$Empty Message$$$,warn,HBase
%s took %d ms appending an edit to wal; len~=%s,warn,HBase
Initialized secure protobuf WAL: cipher=,trace,HBase
"Initialized protobuf WAL= | , compression=",trace,HBase
WALTrailer is null. Continuing with default.,warn,HBase
Please investigate WALTrailer usage. Trailer size > maximum size :  |  > ,warn,HBase
"Failed to write trailer, non-fatal, continuing...",warn,HBase
"Can not get task queue of  | , this is not necessary, just give up",warn,HBase
sync failed,warn,HBase
RingBufferTruck with unexpected type: ,warn,HBase
We have waited  |  seconds but |  the close of async writer doesn't complete. | Please check the status of underlying filesystem |  or increase the wait time by the config \ | \,error,HBase
The wait for close of async writer is interrupted,error,HBase
Unable to unwrap key with WAL key ' | ',debug,HBase
Unable to unwrap key with current master key ' | ',debug,HBase
Initialized secure protobuf WAL: cipher=,trace,HBase
Lost the ZooKeeper connection for peer ,warn,HBase
Creation of ZookeeperWatcher failed for peer ,warn,HBase
The HBaseReplicationEndpoint corresponding to peer  |  was aborted for the following reason(s):,error,HBase
Fetch slaves addresses failed,debug,HBase
"Detected change to peer region servers, fetching updated list",info,HBase
Error reading slave addresses,error,HBase
Failed to get bulk load events information from the WAL file.,warn,HBase
Not tracking replication peer config changes for Peer Id  |  because there's no such peer,warn,HBase
Unable to create WALEntryFilter ,error,HBase
"Failed to read zookeeper, skipping checking deletable files",warn,HBase
"Found up in ZooKeeper, NOT deleting=*",debug,HBase
Error while configuring ,error,HBase
Error while configuring ,error,HBase
Stopping ,info,HBase
"Failed to read hfile references from zookeeper, skipping checking deletable files",warn,HBase
"Found hfile reference in ZK, keeping: ",debug,HBase
"Did not find hfile reference in ZK, deleting: ",debug,HBase
 is not enabled. Better to remove  |  from  |  configuration.,warn,HBase
Error while configuring ,error,HBase
Error while configuring ,error,HBase
Stopping ,info,HBase
"Failed to read hfile references from zookeeper, skipping checking deletable  | file for ",warn,HBase
upgrade tableCFs failed for peerId=,error,HBase
Copy table ColumnFamilies into peer=,info,HBase
No tableCFs in peerNode:,info,HBase
"NOTICE!! Update peerId failed, peerId=",warn,HBase
"NOTICE!! Update peerId failed, peerId=",warn,HBase
"NOTICE!! Update peerId failed, peerId=",warn,HBase
"* *, sleeping * times *",trace,HBase
* Interrupted while sleeping between retries,debug,HBase
* Failed to create connection for peer cluster,warn,HBase
* Submitting * entries of total size *,trace,HBase
"* No replication sinks found, returning without replicating. The source should retry with the same set of edits.",warn,HBase
* Can't replicate because of an error on the remote cluster: ,warn,HBase
"* Missing table detected at sink, local table also does not exist, filtering edits for '*'",info,HBase
* Exception checking for local table: ,warn,HBase
"* Peer encountered RemoteException, rechecking all sinks: ",warn,HBase
"* Peer is unavailable, rechecking all sinks: ",warn,HBase
* Can't replicate because of a local or network error: ,warn,HBase
* Failed to close the connection,warn,HBase
* Replicating batch * of * entries with total size * bytes to *,trace,HBase
* Completed replicating batch *,trace,HBase
* Failed replicating batch *,trace,HBase
"queueId= | , ReplicationSource :  | , currentBandwidth=",info,HBase
* Added log file * to queue of source *.,trace,HBase
WAL group  |  queue size:  |  exceeds value of replication.source.log.queue.warn: ,warn,HBase
HFiles will not be replicated belonging to the table * family * to peer id *,debug,HBase
* Someone has beat us to start a worker thread for wal group *,debug,HBase
* Starting up worker for wal group *,debug,HBase
Ignore the exception as the file size of HLog only affects the web ui,warn,HBase
"* No replication ongoing, waiting for new log",warn,HBase
Unexpected exception in * currentPath=*,error,HBase
* To sleep *ms for throttling control,trace,HBase
"ReplicationSource :  |  bandwidth throttling changed, currentBandWidth=",info,HBase
"* *, sleeping * times *",trace,HBase
* Interrupted while sleeping between retries,debug,HBase
"* error creating ReplicationEndpoint, retry",warn,HBase
"* Error starting ReplicationEndpoint, retry",warn,HBase
* Could not connect to Peer ZK. Sleeping for * millis,debug,HBase
"* Source: *, is now replicating from cluster: *; to peer cluster: *;",info,HBase
* Closing source * because: *,info,HBase
* Closing source * because an error occurred: *,error,HBase
* Interrupted while waiting * to stop,info,HBase
* ReplicationSourceWorker * terminated,info,HBase
* Got exception while waiting for endpoint to shutdown for replication source : *,warn,HBase
"Passed replication source implementation throws errors, defaulting to ReplicationSource",warn,HBase
"Couldn't get file length information about log *, it * closed cleanly *",warn,HBase
"Reached the end of WAL file '*'. It was not closed cleanly, so we did not parse * bytes of data. This is normally ok.",debug,HBase
"Processing end of WAL file '*'. At position *, which is too far away from reported file length *. Restarting WAL reading (see HBASE-15983 for details). *",warn,HBase
"Reached the end of log  | , and the length of the file is  | N/A",trace,HBase
Reached the end of log *,debug,HBase
"The provider tells us the valid length for  |  is  | , but we have advanced to ",debug,HBase
Log  |  was moved to ,info,HBase
Log  |  was moved to ,info,HBase
Couldn't locate log: ,error,HBase
Try to recover the WAL lease ,warn,HBase
"Got NPE opening reader, will retry.",warn,HBase
recover WAL lease: ,debug,HBase
unable to recover lease for WAL: ,warn,HBase
Received exception while creating connection :,warn,HBase
Got exception while trying to close OutputSink,warn,HBase
Failed to shutdown the thread pool after 10 seconds,warn,HBase
Got interrupted while waiting for the thread pool to shut down,warn,HBase
Got exception closing connection :,warn,HBase
Received IOException while trying to replicate,warn,HBase
Skipping  |  entries because table  |  is cached as a disabled or dropped table,trace,HBase
Skipping : ,trace,HBase
Skipping  |  entries because table  |  is dropped. Adding table to cache.,trace,HBase
Skipping : ,trace,HBase
Skipping  |  entries in table  |  because located region  |  is different than the original region  |  from WALEdit,trace,HBase
Skipping : ,trace,HBase
Skipping  |  entries in table  |  because received exception for dropped or disabled table,trace,HBase
Skipping : ,trace,HBase
Skipping  |  entries in table  |  because located region  |  is different than the original region  |  from WALEdit,trace,HBase
Skipping : ,trace,HBase
"peerClusterZnode= | , ReplicationSourceWALReaderThread :  |  inited, replicationBatchSizeCapacity= | , replicationBatchCountCapacity= | , replicationBatchQueueCapacity=",info,HBase
Read * WAL entries eligible for replication,trace,HBase
Failed to read stream of replication entries: ,debug,HBase
Failed to read stream of replication entries,error,HBase
Interrupted while sleeping between WAL reads,trace,HBase
Didn't read any new entries from WAL,trace,HBase
Forcing removal of 0 length log in queue: ,warn,HBase
Couldn't get file length information about log ,warn,HBase
Failed to deserialize bulk load entry from wal edit. Then its hfiles count will not be added into metric.,error,HBase
Failed to deserialize bulk load entry from wal edit. Size of HFiles part of cell will not be considered in replication request size calculation.,error,HBase
Skipping recording bulk load entries in preCommitStoreFile for bulkloaded data replication.,debug,HBase
Failed to initialize LoadIncrementalHFiles for replicating bulk loaded data.,error,HBase
Replication process did not find any files to replicate in directory ,warn,HBase
"Error occurred while replicating HFiles, retry attempt  |  with  |  files still remaining to replicate.",warn,HBase
Failed to delete the staging directory ,warn,HBase
Failed to close the table.,warn,HBase
Failed to copy hfile from  |  to  | . Trying to copy from hfile archive directory.,info,HBase
Failed to copy hfile from  |  to  | . Hence ignoring this hfile from replication..,debug,HBase
Interrupted while waiting for next replication entry batch,trace,HBase
Interrupted while sleeping for throttling control,debug,HBase
Replicated * entries or * operations in * ms,trace,HBase
* threw unknown exception:,warn,HBase
"*, sleeping * times *",trace,HBase
Interrupted while sleeping between retries,debug,HBase
Loading source cluster FS client conf for cluster ,info,HBase
hbase.replication.conf.dir is not configured.,debug,HBase
Loading source cluster  |  file system configurations from xml  | files under directory ,info,HBase
Current list of replicators:  |  other RSs: ,info,HBase
Number of deleted recovered sources for  | : ,info,HBase
Terminate replication source for ,info,HBase
Startup replication source for ,info,HBase
Done with the recovered queue ,info,HBase
Done with the queue ,info,HBase
Removing * logs in the list: *,debug,HBase
Start tracking logs for wal group * for peer *,debug,HBase
Cancelling the transfer of  |  because of ,info,HBase
Interrupted while waiting before transferring a queue.,warn,HBase
Not transferring queue since we are shutting down,info,HBase
Interrupted while waiting before transferring a queue.,warn,HBase
"ReplicationException: cannot claim dead region (%s)'s  | replication queue. Znode : (%s) |  Possible solution: check if znode size exceeds jute.maxBuffer value.  |  If so, increase it for both client and server side.",error,HBase
"Skipping failover for peer * of node *, peer is null",warn,HBase
Peer * is disabled. ReplicationSyncUp tool will skip replicating data to this peer.,warn,HBase
Failed creating a source,error,HBase
NB dead servers : ,info,HBase
Possible location ,info,HBase
Log  |  still exists at ,info,HBase
WAL Path %s doesn't exist and couldn't find its new location,error,HBase
Recovery queue size is incorrect,error,HBase
Log  |  found at ,info,HBase
Didn't find path for: ,error,HBase
Finished recovering queue * with the following stats: *,info,HBase
"Received a peer change event, peerId= | , type=",info,HBase
Replication barrier for *: *,debug,HBase
"* is before the first barrier, pass",debug,HBase
"Parent * has not been finished yet for entry *, give up",debug,HBase
"* is in the last range and the region is opening, give up",debug,HBase
"* is in the first range, pass",debug,HBase
"Previous range for * has not been finished yet, give up",debug,HBase
"* is in the last range and the region is opening, give up",debug,HBase
"The previous range for * has been finished, pass",debug,HBase
"* is before the end barrier *, pass",trace,HBase
"* is beyond the previous end barrier *, remove from cache",debug,HBase
"The sequence id for * is continuous, pass",trace,HBase
"Can not push *, wait",debug,HBase
Finished recovering queue for group * of peer *,debug,HBase
"Error while locating recovered queue paths, attempt #",error,HBase
Recovered queue started with log * at position *,trace,HBase
Closing worker for wal group * because: *,info,HBase
Closing worker for wal group  |  because an error occurred: ,error,HBase
ReplicationSourceWorker * terminated,info,HBase
Replication stats-in-log period=* seconds,debug,HBase
Failed to add hfile references in the replication queue.,error,HBase
$$$Empty Message$$$,info,HBase
"Current list of sinks is out of date or empty, updating",info,HBase
Failed to instantiate ,warn,HBase
Started replicating mutations.,debug,HBase
Finished replicating mutations.,debug,HBase
Started replicating bulk loaded data.,debug,HBase
Finished replicating bulk loaded data.,debug,HBase
Unable to accept edit because:,error,HBase
IOException while closing the connection,warn,HBase
Our Quorum: ,info,HBase
No tables with a configured replication peer were found.,info,HBase
Replicated Tables: ,info,HBase
Replication is enabled but no peer configuration was found.,info,HBase
"Found [--distributed], will poll each RegionServer.",info,HBase
"WAL  |  couldn't be found, skipping",warn,HBase
"Can't get file status of WAL  | , skipping",warn,HBase
"DumpReplicationQueue received abort, ignoring.  Reason: ",warn,HBase
$$$Empty Message$$$,debug,HBase
"DumpReplicationQueue received stop, ignoring.  Reason: ",warn,HBase
Kerberos principal name is ,debug,HBase
SASL server DIGEST-MD5 callback: setting password  | for client: ,trace,HBase
SASL server DIGEST-MD5 callback: setting  | canonicalized client ID: ,trace,HBase
SASL server GSSAPI callback: setting  | canonicalized client ID: ,debug,HBase
ZooKeeper initialization failed,error,HBase
Skipping permission cache refresh because writable data is empty,info,HBase
Skipping permission cache refresh because writable data is empty,debug,HBase
Perms for user * in table * in cell *: *,trace,HBase
Failed parse of ACL tag in cell ,error,HBase
$$$Empty Message$$$,error,HBase
Interrupted while waiting for start,warn,HBase
Error reading data from zookeeper,error,HBase
Error reading data from zookeeper for node ,error,HBase
Error reading permissions writables,error,HBase
"Could not cancel processing node children changed event, please file a JIRA and attach logs if possible.",warn,HBase
Error reading data from zookeeper for path ,error,HBase
aclZNode changed after ZKPermissionWatcher was shutdown,warn,HBase
Failed parsing permissions for table ' | ' from zk,error,HBase
Updating permissions cache from * with data *,debug,HBase
Failed updating permissions for entry ' | ',error,HBase
No acl notify node of table ' | ',warn,HBase
Failed deleting acl node of table ' | ',error,HBase
No acl notify node of namespace ' | ',warn,HBase
Failed deleting acl node of namespace ' | ',error,HBase
$$$Empty Message$$$,warn,HBase
Writing permission with rowKey  |   | : ,debug,HBase
Removed permission ,debug,HBase
Removing permissions of removed table ,debug,HBase
Removing permissions of removed namespace ,debug,HBase
Removing permissions of removed column  |  from table ,debug,HBase
No permissions found in  |  for acl entry ,info,HBase
"Read acl: entry[ | ], kv [ | :  | ]",debug,HBase
Failed updating permissions mirror for ' | null | ',error,HBase
Empty family map passed for permission check,debug,HBase
Scanning for cells with ,trace,HBase
Found cell ,trace,HBase
Exception while getting cells to calculate covering permission,error,HBase
AccessController has been loaded with authorization checks DISABLED!,warn,HBase
A minimum HFile version of 3 is required to persist cell ACLs. Consider setting hfile.format.version accordingly.,info,HBase
Not adding owner permission for table  | .  |  is not yet created.  |  should be configured as the first Coprocessor,warn,HBase
 entry deleted in  |  table.,info,HBase
NULL region from RegionCoprocessorEnvironment in preOpen(),error,HBase
NULL region from RegionCoprocessorEnvironment in postOpen(),error,HBase
Carrying forward tag from  | : type  |  length ,trace,HBase
Carrying forward ACLs from  | : ,trace,HBase
Received request from * to grant access permission *,debug,HBase
Granted permission ,trace,HBase
Received request from * to revoke access permission *,debug,HBase
Revoked permission ,trace,HBase
Access * for user *; reason: *; remote address: *; request: *; context: *,trace,HBase
Error occurred while retrieving group for ,error,HBase
Obtained token  |  for user ,debug,HBase
Obtained token  |  for user  |  on cluster ,debug,HBase
Obtained token  |  for user  |  on cluster ,debug,HBase
ZooKeeper initialization failed,error,HBase
ZKWatcher is abort,error,HBase
Thread leaderElector[ | : | ] is stopped or not alive,warn,HBase
Thread leaderElector [ | : | ] is started,info,HBase
Sync token keys from zookeeper,debug,HBase
"Running as master, ignoring new key ",debug,HBase
Adding key ,debug,HBase
"Running as master, ignoring removed key ",debug,HBase
Removing key ,debug,HBase
Skipping removeExpiredKeys() because not running as master.,info,HBase
Removing expired key ,debug,HBase
Skipping rollCurrentKey() because not running as master.,info,HBase
"Stopping leader election, because: ",info,HBase
Interrupted waiting for next update,debug,HBase
Error reading data from zookeeper,error,HBase
Invalid znode name for key ID ' | ',error,HBase
Ignoring empty node ,debug,HBase
Error reading data from zookeeper,error,HBase
Error reading key writables,error,HBase
Error reading data from zookeeper,error,HBase
Ignoring empty node ,debug,HBase
Failed reading new secret key for id ' | ' from zk,error,HBase
Non-existent znode  |  for key ,error,HBase
Failed removing znode  |  for key ,error,HBase
Unable to synchronize master key  |  to znode ,error,HBase
Unable to update master key  |  in znode ,error,HBase
Error reading data from zookeeper,error,HBase
"Token generation denied for user= | , authMethod=",warn,HBase
Failed to get token for ,error,HBase
Use the existing token: ,info,HBase
Failed to cancel HDFS delegation token: ,warn,HBase
Error creating VisibilityLabelsCache,error,HBase
Adding the label ,debug,HBase
$$$Empty Message$$$,error,HBase
The auths for user  |  are ,trace,HBase
The auths for groups of user  |  are ,trace,HBase
Current active user name is ,trace,HBase
The identifier is ,trace,HBase
Error in isDeleted() check! Will treat cell as not deleted,error,HBase
Trying to use table specific value for config  | 'hbase.regionserver.visibility.label.service.class' which is not supported. |  Will use the cluster level VisibilityLabelService class ,warn,HBase
ZooKeeper initialization failed,error,HBase
$$$Empty Message$$$,warn,HBase
Error in isDeleted() check! Will treat cell as not deleted,error,HBase
Dropping authorizations requested by user  | : ,warn,HBase
Exception while reading the visibility labels from the cell. The replication  | would happen as per the existing format and not as  | string type for the cell  | .,error,HBase
Failed parsing data from labels table  from zk,error,HBase
Failed parsing data from labels table  from zk,error,HBase
Error setting watcher on node ,error,HBase
Error reading data from zookeeper for node ,error,HBase
Failed writing to ,error,HBase
The VisibilityController has been loaded with authorization checks disabled.,warn,HBase
Error while initializing VisibilityLabelService..,error,HBase
User is not having required permissions to add labels,error,HBase
$$$Empty Message$$$,error,HBase
User is not having required permissions to set authorization,error,HBase
$$$Empty Message$$$,error,HBase
Failed to get active system user.,warn,HBase
Details on failure to get active system user.,debug,HBase
Access  | allowed |  for user  | UNKNOWN | ; reason:  | ; remote address:  |  | ; request:  | ; user:  | null | ; labels:  | ; regex: ,trace,HBase
User is not having required permissions to clear authorization,error,HBase
$$$Empty Message$$$,error,HBase
starting restore table regions using snapshot=,info,HBase
Nothing to restore. Snapshot  |  looks empty,warn,HBase
region to restore: ,info,HBase
region to remove: ,info,HBase
region to add: ,info,HBase
finishing restore table regions using snapshot=,info,HBase
Skip update of unreferenced offline parent: ,warn,HBase
Update splits parent  |  -> ,debug,HBase
Removing hfile= |  from region= |  table=,trace,HBase
Adding HFileLink  |  to region= |  table=,debug,HBase
Removing family= |  from region= |  table=,trace,HBase
Adding HFileLink  |  to table=,trace,HBase
clone region= |  as ,info,HBase
Adding HFileLink  |  to table=,info,HBase
Restore reference  |  to ,debug,HBase
get table regions: ,debug,HBase
found  |  regions for table=,debug,HBase
Restored table dir:,debug,HBase
"Restore snapshot acl to table. snapshot:  | , table: ",info,HBase
"Creation time not specified, setting to: |  (current time: | ).",debug,HBase
$$$Empty Message$$$,error,HBase
"Snapshot is done, just moving the snapshot from  |  to ",debug,HBase
"can't write manifest without parent dir, maybe it has been deleted by master?",warn,HBase
No regions under directory:,debug,HBase
Storing region-info for snapshot.,debug,HBase
Creating references for hfiles,debug,HBase
No files under family: ,debug,HBase
Adding snapshot references for  |  hfiles,debug,HBase
Adding reference for file ( | / | ): ,debug,HBase
No manifest files present: ,debug,HBase
No manifest files present: ,debug,HBase
No manifest files present: ,debug,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
fs= |  root=,debug,HBase
Snapshot ' | ' not found in: ,warn,HBase
Storing mob region ' | ' region-info for snapshot.,debug,HBase
Creating references for mob files,debug,HBase
No mob files under family: ,debug,HBase
Storing ' | ' region-info for snapshot.,debug,HBase
Creating references for hfiles,debug,HBase
Adding snapshot references for  |  hfiles,debug,HBase
Adding reference for file ( | / | ): ,debug,HBase
Storing region-info for snapshot.,debug,HBase
Creating references for hfiles,debug,HBase
No files under family: ,debug,HBase
Adding snapshot references for %s %ss,debug,HBase
Adding reference for %s (%d/%d): %s,debug,HBase
Using old Snapshot Format,info,HBase
Convert to Single Snapshot Manifest,debug,HBase
Bulk load operation did not get any files to load,warn,HBase
"You are skipping HFiles validation, it might cause some data loss if files are not correct. If you fail to read data from your table after using this option, consider removing the files and bulkload again without this option. See HBASE-13985",warn,HBase
Bulk load operation did not find any files to load in directory *. Does it contain files in subdirectories that correspond to column family names?,warn,HBase
SecureBulkLoadEndpoint is deprecated. It will be removed in future releases.,warn,HBase
Secure bulk load has been integrated into HBase core.,warn,HBase
"Split occurred while grouping HFiles, retry attempt  |  with  |  files remaining to group or split",info,HBase
Unexpected execution exception during bulk load,error,HBase
Unexpected interrupted exception during bulk load,error,HBase
Going to connect to server  |  for row  |  with hfile group ,debug,HBase
Moved back file  |  from ,debug,HBase
Unable to move back file  |  from ,debug,HBase
Unable to move back file  |  from ,debug,HBase
Trying to load more than  |  hfiles to family  |  of region with start key ,error,HBase
IOException during splitting,error,HBase
Unexpected execution exception during splitting,error,HBase
Unexpected interrupted exception during splitting,error,HBase
HFile at  |  no longer fits inside a single  | region. Splitting...,info,HBase
Unable to delete temporary split file ,warn,HBase
Successfully split into new HFiles  |  and ,info,HBase
encountered,debug,HBase
Trying to load hfile= |  first= |  last=,info,HBase
"hfile  |  has no entries, skipping",info,HBase
Attempt to bulk load region containing  |  into table  |  with files  |  failed.  This is recoverable and they will be retried.,warn,HBase
"Encountered unrecoverable error from region server, additional details: ",error,HBase
Received a  |  from region server: ,warn,HBase
Will attempt to retry loading failed HFiles. Retry #,warn,HBase
hbase.bulkload.retries.retryOnIOException is disabled. Unable to recover,error,HBase
Setting compression  |  for family ,info,HBase
Trying to figure out region boundaries hfile= |  first= |  last=,info,HBase
Table  |  is available!!,info,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
Trying to bulk load hfile  |  with size:  |  bytes can be problematic as it may lead to oversplitting.,warn,HBase
Skipping non-directory ,warn,HBase
Skipping invalid ,warn,HBase
Skipping non-file ,warn,HBase
Skipping reference ,warn,HBase
Skipping HFileLink ,warn,HBase
the file  |  doesn't seems to be an hfile. skipping,warn,HBase
the file  |  was removed,warn,HBase
failed to close hfile reader for ,warn,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
Read from * on *,error,HBase
Read from * on * in *ms,info,HBase
Read from * on *,error,HBase
Read from * on * in *ms,info,HBase
Read from * on * failed,error,HBase
Read from * on * * failed,error,HBase
Read from * on * * in *ms,info,HBase
Write to * on * failed,error,HBase
Write to * on * * failed,error,HBase
Write to * on * * in *ms,info,HBase
Reading table descriptor for table *,debug,HBase
sniffRegion * of * failed,debug,HBase
Close table failed,error,HBase
rawScan * for *,debug,HBase
Reading from * * * *,debug,HBase
Close table failed,error,HBase
Writing to * * * *,debug,HBase
Reading from * * * *,debug,HBase
Table may be deleted,error,HBase
The targeted table was disabled.  Assuming success.,debug,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,error,HBase
Close table failed,error,HBase
The monitor is running too long ( | ) after timeout limit: |  will be killed itself !!,error,HBase
"Too many failures detected, treating failure as error, failing the Canary.",error,HBase
Initial HBaseAdmin failed...,error,HBase
HBaseAdmin aborted,error,HBase
-readTableTimeouts can only specify read timeouts for monitor targets passed via command line.,error,HBase
Check canary table distribution failed!,error,HBase
Sniff region failed!,error,HBase
Read operation for * took *ms (Configured read timeout *ms.,error,HBase
Read operation for * took *ms (Configured read timeout *ms.,info,HBase
Read operation for * failed!,error,HBase
Write operation for * took *ms. Configured write timeout *ms.,info,HBase
Write operation for * exceeded the configured write timeout.,error,HBase
Run regionMonitor failed,error,HBase
reading list of tables,debug,HBase
Communicate with admin failed,error,HBase
$$$Empty Message$$$,error,HBase
Reading list of tables,debug,HBase
"Number of live regionservers *, pre-splitting the canary table into * regions (current lower limit of regions per server is * and you can change it with config *).hbase.canary.write.perserver.regions.lowerLimit",info,HBase
Checking table is enabled and getting table descriptor for table *,debug,HBase
Table * is not enabled,warn,HBase
Reading list of regions for table *,debug,HBase
"Confirm allowable number of failed ZooKeeper nodes, as quorum will already be lost. Setting of * failures is unexpected for * ensemble size.",warn,HBase
Run ZooKeeperMonitor failed!,error,HBase
Sniff zookeeper failed!,error,HBase
Sniff zookeeper interrupted!,error,HBase
Run RegionServerMonitor failed!,error,HBase
Reading list of tables,debug,HBase
Get listTableNames failed,error,HBase
Regionserver not serving any regions - *,error,HBase
Sniff regionserver failed!,error,HBase
Successfully read * regions out of * on regionserver *,info,HBase
Sniff regionserver interrupted!,error,HBase
Reading list of tables and locations,debug,HBase
Get HTables info failed,error,HBase
"No RegionServerInfo found, regionServerPattern *",info,HBase
"No RegionServerInfo found, regionServerName *",info,HBase
Execution thread count=*,info,HBase
Error running command-line tool,error,HBase
Validating Data Block Encodings,info,HBase
"Incompatible DataBlockEncoding for table: *, cf: *, encoding: *",warn,HBase
There are * column families with incompatible Data Block Encodings. Do not upgrade until these encodings are converted to a supported one. Check https://s.apache.org/prefixtree for instructions.,warn,HBase
The used Data Block Encodings are compatible with HBase 2.0.,info,HBase
Validating HFile contents under *,info,HBase
Validating HFile contents under *,info,HBase
"Checked * HFiles, none of them are corrupted.",info,HBase
There are no incompatible HFiles.,info,HBase
"Checked * HFiles, * are corrupted.",info,HBase
Corrupted file: *,info,HBase
Change data block encodings before upgrading. Check https://s.apache.org/prefixtree for instructions.,info,HBase
Wrote  |  times in region ,info,HBase
Copying coprocessor jar '*' to '*'.,debug,HBase
Validating class '*'.,debug,HBase
Validating method '*'.,trace,HBase
Validating table *,debug,HBase
"Please give at least one -table, -class or -config parameter.",error,HBase
Classpath: *,debug,HBase
Warning in class '*': *.,warn,HBase
Warning in class '*': *.,warn,HBase
Error in class '*': *.,error,HBase
Error in class '*': *.,error,HBase
Moving region: |  from  |  to ,info,HBase
Retry  |  of maximum ,info,HBase
"Region:  |  stuck on  | ,newServer=",error,HBase
Moved Region  |  cost: | %.3f,info,HBase
Moving region: |  from  |  to ,info,HBase
Moved  |  from  |  to ,info,HBase
Error Moving Region:,error,HBase
Moving  |  regions to  |  using  |  threads.Ack mode:,info,HBase
Could not get server for Region: |  moving on,warn,HBase
Region  |  is already on target server=,info,HBase
No Regions to move....Quitting now,info,HBase
Moving  |  regions from  |  to  |  servers using  |  threads .Ack Mode:,info,HBase
Timed out before finishing the  |  operation. Timeout:  | sec,warn,HBase
Interrupted while  |  Regions on ,warn,HBase
Error while  |  regions on RegionServer ,error,HBase
Was Not able to move region....Exiting Now,error,HBase
Interrupted while waiting for Thread to Complete ,error,HBase
Got Exception From Thread While moving region ,error,HBase
Thread for moving region cancelled. Timeout for cancellation: | secs,error,HBase
"Server  | : |  is not up yet, waiting",warn,HBase
Could not get list of region servers,warn,HBase
Server  | : |  is not up. Giving up.,error,HBase
Error while reading regions from file:,error,HBase
ERROR: Was Not able to write regions moved to output file but moved  |  regions,error,HBase
"Exception while reading excludes file, continuing anyways",warn,HBase
Valid Region server targets are:,info,HBase
Excluded Servers are,info,HBase
Could not scan region:,error,HBase
Shutting down HBase Cluster,debug,HBase
Exception occurred while stopping master,error,HBase
Stopped backup Master * is stopped: *,info,HBase
"Found more than 1 active master, hash *",warn,HBase
"Found active master hash=*, stopped=*",debug,HBase
Exception occurred in HMaster.shutdown(),error,HBase
Got InterruptedException on shutdown - not waiting anymore on region server ends,info,HBase
"RegionServerThreads remaining, give one more chance before interrupting",warn,HBase
"RegionServerThreads taking too long to stop, interrupting; thread dump  | if > 3 attempts: i=",warn,HBase
Got InterruptedException on shutdown - not waiting anymore on master ends,info,HBase
Shutdown of  | 0 |  master(s) and  | 0 |  regionserver(s)  | interrupted,info,HBase
"Could not find scheme for uri  | , default to hdfs",warn,HBase
DFS Client does not support most favored nodes create; using default create,debug,HBase
Ignoring; use default create,trace,HBase
Ignoring (most likely Reflection related exception) ,debug,HBase
Ignoring (most likely Reflection related exception) ,debug,HBase
Ignoring (most likely Reflection related exception) ,debug,HBase
file system close failed: ,error,HBase
"Version file was empty, odd, will try to set it.",warn,HBase
Created version file at  |  with version=,info,HBase
"Unable to create version file at  | , retrying",debug,HBase
"Unable to check cluster ID file in  | , retrying in  | msec: ",warn,HBase
Cluster ID file  |  was empty,warn,HBase
Cluster ID file  |  was empty,warn,HBase
Cluster ID file does not exist at ,warn,HBase
Rewrote the hbase.id file as pb,debug,HBase
Created cluster ID file at  |  with ID: ,debug,HBase
"Unable to create cluster ID file in  | , retrying in  | msec: ",warn,HBase
Waiting for dfs to exit safe mode...,info,HBase
unable to verify if path= |  is a regular file,warn,HBase
An error occurred while verifying if [ | ] is a valid directory. Returning 'not valid' and continuing.,warn,HBase
INVALID NAME ,info,HBase
Skipping file  |  due to IOException,warn,HBase
Skipping file  |  due to IOException,warn,HBase
Skipping file  |  due to IOException,warn,HBase
Skipping file  |  due to IOException,warn,HBase
Skipping region because it no longer exists: ,warn,HBase
Skipping region because it has no family dirs: ,warn,HBase
Could not get region store file map for region: ,error,HBase
Unexpected exec exception!  Should've been caught already.  (Bug?),error,HBase
Cannot execute getTableStoreFilePathMap for ,error,HBase
Error Counting reference files.,warn,HBase
 doesn't exist,trace,HBase
Query Path:  |  ; # list of files: ,debug,HBase
Locality checking is underway: { Scanned Regions :  | / |  },info,HBase
$$$Empty Message$$$,info,HBase
"Configuration \ | be set to true. |  HBase checksum doesn't require  | it, see https://issues.apache.org/jira/browse/HBASE-6868.",warn,HBase
Failed find method  |  in dfsclient; no hedged read metrics: ,warn,HBase
Failed find method  |  in dfsclient; no hedged read metrics: ,warn,HBase
Failed invoking method  |  on dfsclient; no hedged read metrics: ,warn,HBase
Failed invoking method  |  on dfsclient; no hedged read metrics: ,warn,HBase
Failed invoking method  |  on dfsclient; no hedged read metrics: ,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,info,HBase
-D configuration override:  | =,debug,HBase
Creating table  |  with  |  column families.  Presplitting to  |  regions,debug,HBase
Table created!  Waiting for regions to show online in META...,debug,HBase
 of  |  regions online...,debug,HBase
Finished creating table with  |  regions,debug,HBase
Bucketing regions by regionserver...,debug,HBase
Done with bucketing.  Split time!,debug,HBase
 RS have regions to splt.,debug,HBase
Finding a region on ,debug,HBase
Region with  |  moved to  | . Relocating...,debug,HBase
Region already split on  | .  Skipping this region...,debug,HBase
Splitting at ,debug,HBase
Wait for outstanding splits ,debug,HBase
 outstanding splits finished,debug,HBase
STATUS UPDATE:  |  /  | . Avg Time / Split = ,debug,HBase
Finally Wait for outstanding splits ,debug,HBase
Finally  |  outstanding splits finished,debug,HBase
All regions have been successfully split!,debug,HBase
TOTAL TIME = ,debug,HBase
Splits = ,debug,HBase
Avg Time / Split = ,debug,HBase
$$$Empty Message$$$,info,HBase
No Server Exception thrown for: ,debug,HBase
Split Scan:  |  finished /  |  split wait /  |  reference wait,debug,HBase
No  |  file. Calculating splits ,debug,HBase
Table  |  has  |  regions that will be split.,debug,HBase
"Will Split [ |  ,  | ) at ",debug,HBase
_balancedSplit file found. Replay log to restore state...,debug,HBase
Adding: ,debug,HBase
Removing: ,debug,HBase
Done reading.  |  regions left.,debug,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,warn,HBase
attempted to add backwards edge:  |  ,debug,HBase
Bloom filters are disabled by configuration for  |  (configuration is null),trace,HBase
Bloom filter is turned off for the column family,trace,HBase
Delete Bloom filters are disabled by configuration for  |  (configuration is null),info,HBase
No regions under directory:,trace,HBase
No families under region directory:,trace,HBase
"No hfiles found for family:  | , skipping.",trace,HBase
Got exception in closing idle admin,info,HBase
Got exception in closing idle connection,info,HBase
"Unexpected: cached Connection is aborted/closed, removed from cache",info,HBase
Region replica replication peer id=region_replica_replication not exist,warn,HBase
Region replica replication peer id=region_replica_replication not exist. Creating...,info,HBase
DFSUtil.getNNServiceRpcAddresses failed. serviceName=,warn,HBase
Recover lease on dfs file ,info,HBase
isFileClosed not available,debug,HBase
"Cannot recoverLease after trying for  | hbase.lease.recovery.timeout | ms (hbase.lease.recovery.timeout); continuing, but may be DATALOSS!!!; ",warn,HBase
"Recovered lease, ",info,HBase
$$$Empty Message$$$,warn,HBase
No access,warn,HBase
Failed invocation for ,warn,HBase
"vmName= | , vmVendor= | , vmVersion=",info,HBase
vmInputArguments=,info,HBase
: ,info,HBase
env:,info,HBase
Failed to run,error,HBase
Exception during readTableDecriptor. Current table name = ,debug,HBase
Exception during readTableDecriptor. Current table name = ,debug,HBase
Fetching table descriptors from the filesystem.,trace,HBase
Trouble retrieving htd,warn,HBase
Trouble retrieving htd,warn,HBase
Failed cleanup of ,warn,HBase
Cleaned up old tableinfo file ,debug,HBase
Updated tableinfo=,info,HBase
Deleted ,debug,HBase
Failed to delete table descriptor at ,error,HBase
 exists; retrying up to  |  times,debug,HBase
Wrote into ,debug,HBase
Failed write and/or rename; retrying,debug,HBase
Failed cleanup of ,warn,HBase
Current path=,debug,HBase
TableInfo already exists.. Skipping creation,trace,HBase
None/Multiple table descriptors found for table ' | ' regions: ,error,HBase
Table region start key was not empty.  Created new empty region:  |  ,info,HBase
Table region end key was not empty.  Created new empty region:  |  ,info,HBase
Plugged hole by creating new empty region:  |  ,info,HBase
Not attempting to repair overlaps.,warn,HBase
"Overlap group has  |  overlapping  | regions which is greater than  | , the max number of regions to merge",warn,HBase
== [ | ] Attempting fix splits in overlap state.,info,HBase
"Too many overlaps were found on this group, falling back to regular merge.",info,HBase
"This group range is [ | ,  | ]",info,HBase
This is a parent for this group: ,info,HBase
Found parent: ,info,HBase
Found potential daughter a: ,info,HBase
Found potential daughter b: ,info,HBase
Trying to fix parent in overlap by removing the parent.,info,HBase
"Parent region could not be closed, continuing with regular merge...",warn,HBase
"Parent region could not be closed, continuing with regular merge...",warn,HBase
Unable to offline parent region:  | .  Just continuing with regular merge... ,warn,HBase
Unable to remove parent region in META:  | .  Just continuing with regular merge... ,warn,HBase
[ | ] Sidelined parent region dir  |  into ,info,HBase
Done fixing split.,info,HBase
"== [ | ] Merging regions into one region:  | ,",info,HBase
[ | ] Closing region before moving data around: ,debug,HBase
[ | ] Contained region dir before close,debug,HBase
[ | ] Closing region: ,info,HBase
[ | ] Was unable to close region  | .  Just continuing... ,warn,HBase
[ | ] Was unable to close region  | .  Just continuing... ,warn,HBase
[ | ] Offlining region: ,info,HBase
[ | ] Unable to offline region from master:  | .  Just continuing... ,warn,HBase
"[ | ] Created new empty container region:  |  to contain regions:  | ,",info,HBase
[ | ] Merging  |  into ,info,HBase
Closing region: ,info,HBase
Was unable to close region  | .  Just continuing... ,warn,HBase
Was unable to close region  | .  Just continuing... ,warn,HBase
Offlining region: ,info,HBase
Unable to offline region from master:  | .  Just continuing... ,warn,HBase
Before sideline big overlapped region: ,info,HBase
After sidelined big overlapped region:  |  to ,info,HBase
reached end of problem group: ,warn,HBase
Naming new problem group: ,warn,HBase
"this is a split, log to splits",info,HBase
reached end of problem group: ,warn,HBase
"Sidelined big overlapped regions, please bulk load them!",warn,HBase
Overlap merges were interrupted,error,HBase
Failed to merge overlap group,warn,HBase
Waiting for overlap merges was interrupted,error,HBase
Caught  |  during region creation,error,HBase
Got exception in closing connection,info,HBase
%s swept %d elements.,trace,HBase
"Failed to create lock file  | , try= |  of ",info,HBase
Failed to create lock file ,debug,HBase
Encountered exception when opening lock file,warn,HBase
Interrupted when opening lock file,warn,HBase
Took more than  |  seconds in obtaining lock,warn,HBase
Finishing hbck,info,HBase
"Failed to delete  | , try= |  of ",info,HBase
Failed to delete ,debug,HBase
Interrupted while deleting lock file,warn,HBase
"Another instance of hbck is fixing HBase, exiting this instance.  | [If you are sure no other instance is running, delete the lock file  |  and rerun the tool]",error,HBase
Launching hbck,info,HBase
Loading regioninfos HDFS,info,HBase
Exiting integrity repairs after max  |  iterations.  | Tables integrity may not be fully repaired!,warn,HBase
Successfully exiting integrity repairs after  |  iterations,info,HBase
Loading regionsinfo from the hbase:meta table,info,HBase
Loading region directories from HDFS,info,HBase
Loading region information from HDFS,info,HBase
Checking and fixing region consistency,info,HBase
"Fail to create znode  | , try= |  of ",warn,HBase
Delete HBCK znode  |  failed ,warn,HBase
"HBCK is running while master is not in maintenance mode, you might see transient error.  Please run HBCK multiple times to reduce the chance of transient error.",warn,HBase
$$$Empty Message$$$,warn,HBase
Region's boundaries not aligned between stores and META for:,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,error,HBase
Attempting to handle orphan hdfs dir: ,info,HBase
Attempt to adopt orphan hdfs region skipped because no files present in  | . This dir could probably be deleted.,warn,HBase
"Problem reading orphan file  | , skipping",warn,HBase
"Orphan file  |  is possibly corrupted HFile, skipping",warn,HBase
"No data in dir  | , sidelining data",warn,HBase
"Min max keys are : [ | ,  | )",info,HBase
Creating new region : ,info,HBase
Loading HBase regioninfo from HDFS...,info,HBase
No integrity errors.  We are done with this phase. Glorious.,info,HBase
Computing mapping of all store files,info,HBase
Validating mapping using HDFS state,info,HBase
Trying to sideline reference file  |  to ,info,HBase
Failed to sideline reference file ,error,HBase
Computing mapping of all link files,info,HBase
Validating mapping using HDFS state,info,HBase
Failed to sideline HFileLink file ,error,HBase
Failed to sideline HFileLink backreference file ,error,HBase
Failed to create path: ,error,HBase
Trying to sideline file  |  to ,info,HBase
Failed to read .regioninfo file for region ,warn,HBase
tableName was null for: ,warn,HBase
Unable to read .tableinfo from ,warn,HBase
Trying to fix empty REGIONINFO_QUALIFIER hbase:meta rows.,info,HBase
Trying to fix orphan table error: ,info,HBase
fixing orphan table:  |  from cache,info,HBase
fixing orphan table:  |  with a default .tableinfo file,warn,HBase
Strongly recommend to modify the TableDescriptor if necessary for: ,warn,HBase
Unable to create default .tableinfo for  |  while missing column family information,error,HBase
Strongly recommend to re-run manually hfsck after all orphanTableDirs being fixed,warn,HBase
Failed to fix  |  OrphanTables with default .tableinfo files,error,HBase
Handling overlap merges in parallel. set hbasefsck.overlap.merge.parallel to false to run serially.,info,HBase
Handling overlap merges serially.  set hbasefsck.overlap.merge.parallel to true to run in parallel.,info,HBase
Checking HBase region split map from HDFS data...,info,HBase
No previous  |  exists.  Continuing.,warn,HBase
Region dir is empty: ,info,HBase
$$$Empty Message$$$,error,HBase
Sidelining files from  |  into containing region ,info,HBase
$$$Empty Message$$$,error,HBase
Sideline directory contents:,debug,HBase
Removing old region dir: ,info,HBase
$$$Empty Message$$$,error,HBase
Trying to create a new hbase.version file.,info,HBase
Loading region dirs from ,debug,HBase
Could not completely load table dir ,warn,HBase
$$$Empty Message$$$,error,HBase
Could not process regionserver ,warn,HBase
Could not check region consistency ,warn,HBase
Unable to complete check or repair the region ' | '.,warn,HBase
Skip region ' | ',warn,HBase
Got AccessDeniedException when preCheckPermission ,warn,HBase
Deleted  |  from META,info,HBase
Reset split parent  |  in META,info,HBase
"Using unassign region  |  instead of using offline method, you should |  restart HMaster after these repairs",warn,HBase
Offlining region ,info,HBase
"Using unassign region  |  instead of using offline method, you should |  restart HMaster after these repairs",warn,HBase
Unable to close region  |  since meta does not have handle to reach it,warn,HBase
Unable to close region  |  because hbase:meta had invalid or missing  | : |  qualifier value.,warn,HBase
Undeploy region  |  from ,debug,HBase
Got exception when attempting to offline region ,warn,HBase
"Region  |  is in META, and in a disabled  | tabled that is not deployed",info,HBase
Region  |  was recently modified -- skipping,warn,HBase
"Region  |  got merge recently, its file(s) will be cleaned by CatalogJanitor later",info,HBase
Region  |  could have been repaired |  in table integrity repair phase if -fixHdfsOrphans was |  used.,error,HBase
 start and stop keys are in the range of  | . The region might not be cleaned up from hdfs when region  |  split failed. Hence deleting from hdfs.,warn,HBase
Patching hbase:meta with .regioninfo: ,info,HBase
This should have been repaired in table integrity repair phase,error,HBase
Patching hbase:meta with with .regioninfo: ,info,HBase
"Region  |  is a split parent in META, in HDFS,  | and not deployed on any region server. This may be transient.",info,HBase
There are  |  region info entries,debug,HBase
[ | ] Contained region dir after close and pause,debug,HBase
[ | ] HDFS region dir  |  is missing. Assuming already sidelined or moved.,warn,HBase
[ | ] HDFS region dir  |  already sidelined.,warn,HBase
[ | ] Moving files from  |  into containing region ,info,HBase
[ | ] Sideline directory contents:,debug,HBase
[ | ] Sidelined region dir  |  into ,info,HBase
getTableDescriptors == tableNames => ,info,HBase
Exception getting table descriptors,debug,HBase
Result=,error,HBase
Loading region info from hdfs:,debug,HBase
By the time we tried to process this region dir it was already gone: ,warn,HBase
Could not load region dir,error,HBase
Unexpected exec exception!  Should've been caught already.  (Bug?),error,HBase
Cannot execute WorkItemHdfsDir for ,error,HBase
Unable to read directory ,error,HBase
Checking all hfiles for corruption,info,HBase
Sleeping  | ms before re-checking after fix...,info,HBase
Interrupted while sleeping,warn,HBase
we may need to clean some erroneous data due to bugs,info,HBase
Problem scanning file system,warn,HBase
Problem scanning file system,warn,HBase
"Region still in transition, waiting for  | it to become assigned: ",info,HBase
"Exception when waiting for region to become assigned, retrying",warn,HBase
Entry  |  has no meta or hdfs region start key.,error,HBase
Entry  |  has no meta or hdfs region start key.,error,HBase
No HDFS region dir found:  |  meta=,warn,HBase
RegionInfo read: ,debug,HBase
 has no store files,info,HBase
Including store:  |  with:  |  files for compaction for region: ,info,HBase
Including store:  |  with:  |  files for compaction for region: ,info,HBase
 already compacted,info,HBase
Including store:  |  for compaction for region:   |  (reference store files),info,HBase
Waiting for servers to complete Compactions,debug,HBase
Server changed for region:  |  from:  |  to:  |  re-queuing request,info,HBase
"Firing off compaction request for server:  | ,  |  total queue size left: ",info,HBase
All compactions have completed,info,HBase
$$$Empty Message$$$,error,HBase
All regions major compacted successfully,info,HBase
"No family specified, will execute for all families",info,HBase
Initializing compaction queues for table:   |  with cf: ,info,HBase
"Region is invalid, requesting updated regions",warn,HBase
Error compacting:,warn,HBase
Waiting for compaction to complete for region: ,debug,HBase
"Not all store files were compacted, this may be due to the regionserver not  | being aware of all store files.  Will not reattempt compacting, ",error,HBase
Compaction failed for the following stores:  |  region: ,info,HBase
Compaction complete for region:  |  -> cf(s): ,info,HBase
"Undeleted replication queue for removed peer found: [removedPeerId=*, replicator=*, queueId=*]",debug,HBase
Undeleted replication hfile-refs queue for removed peer * found,debug,HBase
Found corrupt HFile ,warn,HBase
Quarantining corrupt HFile  |  into ,warn,HBase
HFile  |  was missing.  Likely removed due to compaction/split?,warn,HBase
hbase.hfile.quarantine.dir is deprecated. Default to ,warn,HBase
Colfam Directory  |  does not exist.  Likely due to concurrent split/compaction. Skipping.,warn,HBase
Colfam Directory  |  does not exist.  Likely due to concurrent split/compaction. Skipping.,warn,HBase
Mob colfam Directory  |  does not exist.  Likely the table is deleted. Skipping.,warn,HBase
Mob colfam Directory  |  does not exist.  Likely the table is deleted. Skipping.,warn,HBase
Found corrupt mob file ,warn,HBase
Quarantining corrupt mob file  |  into ,warn,HBase
Mob file  |  was missing.  Likely removed due to compaction?,warn,HBase
Mob directory  |  does not exist.  Likely the table is deleted. Skipping.,warn,HBase
Mob directory  |  does not exist.  Likely the table is deleted. Skipping.,warn,HBase
Region Directory  |  does not exist.  Likely due to concurrent split/compaction. Skipping.,warn,HBase
Region Directory  |  does not exist.  Likely due to concurrent split/compaction. Skipping.,warn,HBase
Table Directory  |  does not exist.  Likely due to concurrent delete. Skipping.,warn,HBase
Region dirs checking interrupted!,warn,HBase
Failed to quarantine an HFile in regiondir ,warn,HBase
Unexpected exception encountered,error,HBase
Region dirs check interrupted!,warn,HBase
"The RegionServer write ahead log provider for FileSystem implementations  | relies on the ability to call  |  for proper operation during  | component failures, but the current FileSystem does not support doing so. Please  | check the config value of ' | ' and ensure  | it points to a FileSystem mount that has suitable capabilities for output streams.",error,HBase
Error instantiating log writer.,debug,HBase
cannot close log writer,error,HBase
Call to makeQualified failed on  |  ,info,HBase
Cannot parse a server name from path= | ; ,warn,HBase
Invalid log file path=,warn,HBase
Couldn't locate log: ,error,HBase
Log  |  was moved to ,info,HBase
Couldn't locate log: ,error,HBase
Try to recover the WAL lease ,warn,HBase
"Got NPE opening reader, will retry.",warn,HBase
Still trying to recover WAL lease: ,debug,HBase
unable to recover lease for WAL: ,warn,HBase
hbase.regionserver.hlog.splitlog.corrupt.dir is deprecated. Default to *,warn,HBase
Unable to mkdir *,info,HBase
Unable to move corrupted log * to *,warn,HBase
Moved corrupted log * to *,warn,HBase
Unable to move * to *,warn,HBase
Archived processed log * to *,info,HBase
Found existing old file: *. It could be some leftover of an old installation. It should be a folder instead. So moving it to *,warn,HBase
Failed to sideline old file *,warn,HBase
mkdir failed on *,warn,HBase
Failed isFile check on *,warn,HBase
Rename failed from * to *,warn,HBase
Invalid SeqId File Name=*,warn,HBase
"Wrote file=*, newMaxSeqId=*, maxSeqId=*",debug,HBase
"Used * bytes of buffered edits, waiting for IO threads",debug,HBase
Got interrupted while waiting for EntryBuffers is drained,warn,HBase
Ignoring exception from listener.,debug,HBase
Ignoring exception from listener.,debug,HBase
Waiting for split writer threads to finish,debug,HBase
* split writers finished; closing.,info,HBase
Exiting thread,error,HBase
Writer thread starting,trace,HBase
Submitting writeThenClose of *,info,HBase
"The RegionServer async write ahead log provider  | relies on the ability to call  |  for proper operation during  | component failures, but the current FileSystem does not support doing so. Please  | check the config value of ' | ' and ensure  | it points to a FileSystem mount that has suitable capabilities for output streams.",error,HBase
Error instantiating log writer.,debug,HBase
"Got EOF when reading first WAL entry from *, an empty or broken WAL file?",debug,HBase
"Found existing old edits file. It could be the result of a previous failed |  split attempt or we have duplicated wal entries. Deleting  | , length=",warn,HBase
Failed deleting of old *,warn,HBase
"Found existing old edits file and we have less entries. Deleting  | , length=",warn,HBase
Failed deleting of *,warn,HBase
Submitting close of ,trace,HBase
Closing *,trace,HBase
Could not close log at *,error,HBase
"Closed wap  |  (wrote  |  edits, skipped  |  edits in  | ms",debug,HBase
Failed deleting empty *,warn,HBase
Rename * to *,info,HBase
Could not rename * to *,error,HBase
Couldn't close log at *,error,HBase
Closed log  |  (wrote  |  edits in  | ms),info,HBase
"Found old edits file. It could be the  | result of a previous failed split attempt. Deleting  | , length=",warn,HBase
Failed delete of old *,warn,HBase
Creating writer path=*,debug,HBase
"got an empty buffer, skipping",warn,HBase
getWriterAndPath decided we don't need to write edits for *,trace,HBase
Got while writing log entry to log,error,HBase
Instantiating RegionGroupingStrategy of type ,info,HBase
"couldn't set up region grouping strategy, check config key hbase.wal.regiongrouping.strategy",error,HBase
Exception details for failure to load region grouping strategy.,debug,HBase
Problem shutting down wal provider ' | ': ,error,HBase
Details of problem shutting down wal provider ' | ',debug,HBase
Problem closing wal provider ' | ': ,error,HBase
Details of problem closing wal provider ' | ',debug,HBase
"Failed to load AsyncFSWALProvider, falling back to FSHLogProvider",warn,HBase
Instantiating WALProvider of type ,info,HBase
"couldn't set up WALProvider, the configured class is ",error,HBase
Exception details for failure to load WALProvider.,debug,HBase
Running with WAL disabled.,warn,HBase
Could not close FSDataInputStream,warn,HBase
exception details,debug,HBase
Lease should have recovered. This is not expected. Will retry,warn,HBase
Can't open after  |  attempts and  | ms  |  for ,error,HBase
failed to close temporary singleton. ignoring.,debug,HBase
"Splitting WAL=*, length=*",info,HBase
Nothing to split in WAL=*,warn,HBase
DLS Last flushed sequenceid for  | : ,debug,HBase
"Could not parse, corrupted WAL=*",warn,HBase
Finishing writing output logs and closing down,debug,HBase
Could not close WAL reader,warn,HBase
$$$Empty Message$$$,info,HBase
"File * might be still open, length is 0",warn,HBase
Could not open * for reading. File is empty,warn,HBase
File * does not exist anymore,warn,HBase
EOF from wal *. Continuing.,info,HBase
Parse exception from wal *. Continuing,warn,HBase
Exception in run,error,HBase
Hook closing fs=,info,HBase
Need to fix these: ,debug,HBase
Running hook,warn,HBase
Error starting cluster,error,HBase
Killing ,info,HBase
Starting zookeeper nodes on mini cluster is not supported,warn,HBase
Aborting zookeeper nodes on mini cluster is not supported,warn,HBase
Stopping zookeeper nodes on mini cluster is not supported,warn,HBase
Waiting for zookeeper nodes to start on mini cluster is not supported,warn,HBase
Waiting for zookeeper nodes to stop on mini cluster is not supported,warn,HBase
Starting datanodes on mini cluster is not supported,warn,HBase
Aborting datanodes on mini cluster is not supported,warn,HBase
Stopping datanodes on mini cluster is not supported,warn,HBase
Waiting for datanodes to start on mini cluster is not supported,warn,HBase
Waiting for datanodes to stop on mini cluster is not supported,warn,HBase
Starting namenodes on mini cluster is not supported,warn,HBase
Aborting namenodes on mini cluster is not supported,warn,HBase
Stopping namenodes on mini cluster is not supported,warn,HBase
Waiting for namenodes to start on mini cluster is not supported,warn,HBase
Waiting for namenodes to stop on mini cluster is not supported,warn,HBase
Aborting ,info,HBase
Stopping ,info,HBase
Aborting ,info,HBase
Stopping ,info,HBase
 *************** Result Summary *************** ,info,HBase
$$$Empty Message$$$,info,HBase
Running  |  with codec[ | ]  | cipher[ | ] for  |  rows.,info,HBase
Running  |  with codec[ | ]  | cipher[ | ] for  |  rows took  | ms.,info,HBase
Processed  |  rows.,info,HBase
Not able to seekTo ,info,HBase
Nonexistent row: ,info,HBase
NOTHING FOLLOWS,info,HBase
NOTHING FOLLOWS,info,HBase
Shutting down due to request ' | ',info,HBase
Test took ,info,HBase
 encoded count= |  in  | ms for encoder ,info,HBase
 decoded count= |  in  | ms for decoder ,info,HBase
Found the KeyValue from WALEdit which should be ignored.,debug,HBase
Found the KeyValue from WALEdit which should be changed.,debug,HBase
About to delete a KeyValue from WALEdit.,debug,HBase
.isPreWALRestoreCalled is called.,debug,HBase
.isPostWALRestoreCalled is called.,debug,HBase
Calling ,info,HBase
Calling ,info,HBase
Calling ,info,HBase
Initialized: ,info,HBase
Started.,info,HBase
stop: ,info,HBase
Attempting to run a procedure.,info,HBase
Building procedure: ,info,HBase
Waiting for procedure to finish.,debug,HBase
Aborting because: ,warn,HBase
Constructing a SimpleSubprocedure.,info,HBase
Execute subprocedure on ,info,HBase
stop: ,info,HBase
$$$Empty Message$$$,error,HBase
Done waiting - exec procedure for ,info,HBase
$$$Empty Message$$$,error,HBase
Output directory is not specified,error,HBase
The number of keys/values not specified,error,HBase
Key size is not specified,error,HBase
Value size not specified,error,HBase
the parameter of bloom filter is not specified,error,HBase
Writing  |  key/value pairs,info,HBase
Writing  |  meta blocks,info,HBase
"Created *, * bytes, compression=*",info,HBase
$$$Empty Message$$$,error,HBase
"There is a bug in codec  |  it returned null KeyValue,",error,HBase
There is bug in codec  | \n on element  | \n codecKv.getKeyLength()  | \n codecKv.getValueLength()  | \n codecKv.getLength()  | \n currentKv.getKeyLength()  | \n currentKv.getValueLength()  | \n codecKv.getLength()  | \n currentKV rowLength  |  familyName  |  qualifier  | \n prefix  | \n codecKv   ' | ' diff ' | ' | \n currentKv ' | ' diff ' | ',error,HBase
Verification was successful!,info,HBase
Starting a throughput benchmark for data block encoding codecs,info,HBase
KV_LIMIT should not less than 1.,error,HBase
Please specify HFile name using the f option,error,HBase
The number of times to run each benchmark ( | ) must be greater than the number of benchmark runs to exclude  | from statistics ( | ),error,HBase
Running benchmark  |  times.  | Excluding the first  |  times from statistics.,info,HBase
"Principal or key tab file null for :  | , ",warn,HBase
$$$Empty Message$$$,error,HBase
Error while closing the table ,error,HBase
Error while closing the HTable ,error,HBase
"Failed to get the row for key = [ | ], column family = [ | ]",warn,HBase
"Failed to get the row for key = [ | ], column family = [ | ]",warn,HBase
Failed to mutate:  |  after  | ms; region information:  | ; errors: ,error,HBase
Inserted key tracker thread interrupted,info,HBase
Error in inserted/updaed key tracker,error,HBase
Number of keys = 0,info,HBase
"Keys= | , cols= | , time= |  Overall: [ | keys/s=  | , latency= | %.2f |  ms] |  Current: [ | keys/s= | , latency= | %.2f |  ms]",info,HBase
Could not close the connection: ,warn,HBase
"Error checking data for key [ | ], no data returned",error,HBase
"Error checking data for key [ | ], bad family count: ",error,HBase
"Error checking data for key [ | ], no data for family [ | ]]",error,HBase
"Error checking data for key [ | ], column family [ | ], column [ | ]; value is not found",error,HBase
"Error checking data for key [ | ], column family [ | ], column [ | ]; should be deleted",error,HBase
"Error checking data for key [ | ], column family [ | ], column [ | ]; value is not found",error,HBase
"Error checking data for key [ | ], column family [ | ], column [increment], extra [ | ], amount [ | ]",error,HBase
"Warning checking data for key [ | ], column family [ | ], column [increment], incremented [ | ] times",warn,HBase
"Error checking data for key [ | ], bad columns for family [ | ]: ",error,HBase
"Warning checking data for key [ | ], column family [ | ], column [ | ], appended [ | ] times",warn,HBase
"Error checking data for key [ | ], mutation checking failed for column family [ | ], column [ | ]; mutation [ | ], hashCode [ | ], verificationNeeded [ | ]",error,HBase
"Error checking data for key [ | ], column family [ | ], column [ | ], mutation [ | ]; value of length ",error,HBase
FAILED FOR null Result,info,HBase
FAILED FOR  |  Stale ,info,HBase
Couldn't get locations for row ,warn,HBase
LOCATION ,info,HBase
"Inserting keys [ | ,  | )",debug,HBase
"Preparing put for key = [ | ],  |  columns",debug,HBase
Failed to insert:  |  after  | ms; region information:  | ; errors: ,error,HBase
Error closing table,error,HBase
Abort why=,error,HBase
Stop why=,debug,HBase
Starting ZooKeeper on port ,info,HBase
Waiting for HBase startup by scanning META,info,HBase
Waiting for HBase to startup. Retries left: ,info,HBase
Process-based HBase Cluster with  |  region servers up and running... \n\n,info,HBase
Command : ,debug,HBase
Error running: ,error,HBase
Killing daemons using pid files,info,HBase
Could not read pid from file ,error,HBase
Killing pid  |  ( | ),info,HBase
Error writing to: ,error,HBase
Killing  | ; pid=,info,HBase
Creating directory ,debug,HBase
Could not install log4j.properties into ,error,HBase
Local  |  web UI is at http:// | :,info,HBase
$$$Empty Message$$$,error,HBase
Log tailer thread interrupted,error,HBase
Unrecognized log path format: ,error,HBase
Tailing ,debug,HBase
Tailer for  |  interrupted,error,HBase
Failed tailing ,error,HBase
Error in closing the table ,error,HBase
Failed to insert:  |  after  | ms; region information:  | ; errors: ,error,HBase
"Updating keys [ | ,  | )",debug,HBase
"Failed to modify the get from the load generator  = [ | ], column family = [ | ]",warn,HBase
Null result expected for the rowkey ,info,HBase
"Failed to update the row with key = [ | ], since we could not get the original row",error,HBase
"Preparing increment and append for key = [ | ],  |  columns",debug,HBase
Error closing table,error,HBase
"Failed to get the row for key = [ | ], column family = [ | ]",warn,HBase
"Detected nonce conflict, ignoring: ",info,HBase
Failed to mutate:  |  after  | ms; region information:  | ; errors: ,error,HBase
Failed to mutate:  |  after  | ms; region information:  | ; errors: ,error,HBase
"Reading keys [ | ,  | )",debug,HBase
Error closing table,error,HBase
Started thread # |  for reads...,info,HBase
"[ | ] FAILED read, key =  |  | , time from start:  |  ms",debug,HBase
$$$Empty Message$$$,warn,HBase
"[ | ] FAILED read, key =  |  | , time from start:  |  ms",debug,HBase
$$$Empty Message$$$,warn,HBase
"[ | ]  | Querying key  | , cfs ",info,HBase
"Key =  | , Region location: ",info,HBase
Null result obtained for the key =,debug,HBase
"At the time of failure, writer wrote  |  keys",error,HBase
Aborting readers -- found more than  |  errors,error,HBase
Error while closing the table ,error,HBase
"[ | ] FAILED read, key =  |  | ,  | time from start:  |  ms",debug,HBase
Tracing enabled but traceFreq=0.,warn,HBase
Full tracing of all iterations will produce a lot of data. Be sure your SpanReceiver can keep up.,warn,HBase
 Thread failed,error,HBase
Number of threads is less than the number of regions; some regions will sit idle.,warn,HBase
"FileSystem=*, rootDir=*",info,HBase
verifying written log entries.,info,HBase
shutting down log roller.,info,HBase
Read count= |  from ,debug,HBase
seqid=,info,HBase
%s took %.3fs %.3fops/s,info,HBase
Rolling after  |  edits,info,HBase
Using default thrift server type,info,HBase
Using thrift server type ,info,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
deleteTable: table=*,debug,HBase
$$$Empty Message$$$,warn,HBase
No column qualifier specified. Delete is the only mutation supported over the whole column family.,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
No column qualifier specified. Delete is the only mutation supported over the whole column family.,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
scannerClose: id=*,debug,HBase
scanner ID is invalid,warn,HBase
scannerGetList: id=*,debug,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,error,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
$$$Empty Message$$$,warn,HBase
Read configuration selectorThreads: |  workerThreads: |  stopTimeoutVal: | sec |  acceptQueueSizePerThread: |  acceptPolicy:,info,HBase
Kerberos Authentication failed,error,HBase
Failed to authenticate with * kerberos principal,info,HBase
Error while disposing GSS Context,warn,HBase
Elements drained: ,info,HBase
Error occurred during listening.,error,HBase
Transport error when accepting message,warn,HBase
 from ,warn,HBase
"Queue is full, closing connection",warn,HBase
Waiting for up to  |  ms to finish processing |  pending requests,info,HBase
Interrupting all worker threads and waiting for 5000 ms longer,info,HBase
Thrift server shutdown complete,info,HBase
Thrift error occurred during processing of message.,error,HBase
Error occurred during processing of message.,error,HBase
Fail to enable the doAs feature. hbase.regionserver.thrift.http is not configured,warn,HBase
Starting Thrift HTTP Server on *,info,HBase
Using framed transport,debug,HBase
Effective user: *,info,HBase
Server types * don't support IP address binding at the moment. See https://issues.apache.org/jira/browse/HBASE-2155 for details.,error,HBase
starting HBase * server on *,info,HBase
starting HBase Nonblocking Thrift server on ,info,HBase
starting HBase HsHA Thrift server on ,info,HBase
starting HBase ThreadedSelector Thrift server on ,info,HBase
starting HBase ThreadPool Thrift server on ,info,HBase
Using compact protocol,debug,HBase
Using binary protocol,debug,HBase
Invalid filter specification  |  - skipping,warn,HBase
Could not parse the value provided for the port option,error,HBase
Web UI port set to ,debug,HBase
Could not parse the value provided for the infoport option,error,HBase
Stopping infoServer,info,HBase
Failed to stop infoServer,error,HBase
Problem encountered in shutting down HTTP server,error,HBase
Set configuration key: |  value:,info,HBase
***** STARTING service ' | ' *****,info,HBase
***** STOPPING service ' | ' *****,info,HBase
"FAILED_ICV:  | ,  | ,  | ,  | , ",error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
scannerClose: id=,debug,HBase
$$$Empty Message$$$,warn,HBase
Couldn't close the locator.,warn,HBase
Couldn't close the locator.,warn,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException writing to internal frame buffer,error,HBase
Exception writing to internal frame buffer,error,HBase
TTransportException inside handler,error,HBase
TApplicationException inside handler,error,HBase
Exception inside handler,error,HBase
Exception writing to internal frame buffer,error,HBase
Failed binding ZK Server to client port: ,debug,HBase
Started MiniZooKeeperCluster and ran successful 'stat'  | on client port=,info,HBase
Shutdown MiniZK cluster with all ZK servers,info,HBase
Kill the current active ZK servers in the cluster  | on client port: ,info,HBase
Activate a backup zk server in the cluster  | on client port: ,info,HBase
Kill one backup ZK servers in the cluster  | on client port: ,info,HBase
server localhost: |  not up ,info,HBase
 opening connection to ZooKeeper ensemble=,trace,HBase
no keytab specified for: ,warn,HBase
JaasConfiguration loginContextName= |  principal= |  useTicketCache= |  keytabFile=,info,HBase
Set watcher on existing znode=,debug,HBase
"Set watcher on znode that does not yet exist, ",debug,HBase
Unable to set watcher on znode ,warn,HBase
Unable to set watcher on znode ,warn,HBase
Unable to set watcher on znode ,warn,HBase
Unable to set watcher on znode ( | ),warn,HBase
Unable to set watcher on znode ( | ),warn,HBase
Unable to list children of znode  |   | because node does not exist (not an error),debug,HBase
Unable to list children of znode  |  ,warn,HBase
Unable to list children of znode  |  ,warn,HBase
Unable to list children of znode  |  because node does not exist (not an error),debug,HBase
Unable to list children of znode ,warn,HBase
Unable to list children of znode ,warn,HBase
Unable to get children of node ,warn,HBase
Unable to get data of znode  |   | because node does not exist (not an error),debug,HBase
Unable to get data of znode ,warn,HBase
Unable to get data of znode  |   | because node does not exist (not an error),trace,HBase
Unable to get data of znode ,warn,HBase
Unable to get data of znode ,warn,HBase
Unable to get data of znode  |   | because node does not exist (not necessarily an error),debug,HBase
Unable to get data of znode ,warn,HBase
Unable to get data of znode ,warn,HBase
Could not acquire current User.,debug,HBase
"Znode ACL setting for group  |  is skipped, ZooKeeper doesn't support this feature presently.",warn,HBase
Interrupted,info,HBase
Given path is not valid!,warn,HBase
Given path is not valid!,warn,HBase
hbase.zookeeper.useMulti is deprecated. Default to true always.,warn,HBase
"On call to ZK.multi, received exception:  | . |   Attempting to run operations sequentially because |  runSequentialOnMultiFailure is:  | .",info,HBase
Couldn't get the replication znode dump,warn,HBase
Got Exception while parsing peer: ,warn,HBase
Got Exception while parsing peer: ,warn,HBase
Retrieved  |  byte(s) of data from znode  |  and set watcher;  | null,trace,HBase
Waiting until the base znode is available,info,HBase
Parent znode exists: ,info,HBase
Current zk system:,debug,HBase
$$$Empty Message$$$,debug,HBase
$$$Empty Message$$$,debug,HBase
Could not flag a log file as corrupted. Failed to create ,warn,HBase
Error when re-setting the watch on ,error,HBase
Processing delete on ,debug,HBase
$$$Empty Message$$$,error,HBase
Tried to set null ServerName in hbase:meta; skipping -- ServerName required,warn,HBase
Setting hbase:meta (replicaId= | ) location in ZooKeeper as ,info,HBase
"META region location doesn't exist, create it",debug,HBase
"META region location doesn't exist for replicaId= | , create it",debug,HBase
Deleting hbase:meta region location in ZooKeeper,info,HBase
Deleting hbase:meta for  |  region location in ZooKeeper,info,HBase
Got ZK exception ,warn,HBase
Try starting again because there is no data from ,debug,HBase
Unexpected exception handling blockUntilAvailable,warn,HBase
"Got exception while trying to check existence in  ZooKeeper |  of the node:  | , retrying if timeout not reached",warn,HBase
"Node  |  now exists, resetting a watcher",debug,HBase
Unexpected exception handling blockUntilAvailable,warn,HBase
 - erase ACLs for ,info,HBase
 - set ACLs for ,info,HBase
Erase |  HBase ACLs for  |  ,info,HBase
ZK state for LoadBalancer could not be parsed ,error,HBase
ZK state for RegionNormalizer could not be parsed ,error,HBase
Found new leader for znode: ,info,HBase
"Leader change, but no new leader found",info,HBase
Claimed the leader znode as ' | ',debug,HBase
"Found existing leader with our ID ( | ), removing",info,HBase
Found existing leader with ID: ,info,HBase
Interrupted waiting on leader,debug,HBase
Stepping down as leader,info,HBase
"Not current leader, no need to step down",info,HBase
"Attempted to set cluster as down but already down, cluster  | state node ( | ) not found",warn,HBase
Process identifier= |  connecting to ZooKeeper ensemble=,info,HBase
Unable to create ZooKeeper Connection,warn,HBase
"Closing dead ZooKeeper connection, session |  was: 0x",info,HBase
"Recreated a ZooKeeper, session |  is: 0x",info,HBase
Node  |  already deleted. Assuming a  | previous attempt succeeded.,debug,HBase
"Node  |  already deleted, retry=",debug,HBase
ZooKeeper  |  failed after  |  attempts,error,HBase
"Retry, connectivity issue (JVM Pause?); quorum= | , | exception=",debug,HBase
"Node  |  already exists with  | , could not write ",error,HBase
Node * already exists,trace,HBase
Encountered InterruptedException when closing ,debug,HBase
"not a secure deployment, proceeding",info,HBase
setting znode ACLs,info,HBase
Received exception while checking and setting zookeeper ACLs,warn,HBase
"Setting ACLs for znode: |  , acl:",info,HBase
Checking znode ACLs,debug,HBase
ACL is empty,debug,HBase
"permissions for '%s' are not correct: have 0x%x, want 0x%x",debug,HBase
"permissions for '%s' are not correct: have 0x%x, want 0x%x",debug,HBase
"permissions for '%s' are not correct: have 0x%x, want 0x%x",debug,HBase
Unexpected shortname in SASL ACL: ,debug,HBase
unexpected ACL id ' | ',debug,HBase
"superuser '%s' does not have correct permissions: have 0x%x, want 0x%x",debug,HBase
"Received ZooKeeper Event,  | type= | ,  | state= | ,  | path=",debug,HBase
 connected,debug,HBase
"Received Disconnected from ZooKeeper, ignoring",debug,HBase
"Received unexpected KeeperException, re-throwing exception",error,HBase
"Received InterruptedException, will interrupt current thread |  and rethrow a SystemErrorException",debug,HBase
Failed parse master zk node data,warn,HBase
Failed to get backup master:  | 's info port.,warn,HBase
Failed parse,warn,HBase
Can't get or delete the master znode,warn,HBase
Can't get or delete the master znode,warn,HBase
Bolt connection already exists,error,JMeter
$$$Empty Message$$$,debug,JMeter
Assertion failed,debug,JMeter
"Assertion failed, as expected",debug,JMeter
HTMLAssertion(): called,debug,JMeter
HTMLAssertions.getResult() called,debug,JMeter
HTMLAssertions.getResult(): start parsing with tidy ...,debug,JMeter
Parsing with tidy starting...,debug,JMeter
"Parsing with tidy done! node: *, output: *",debug,JMeter
Errors/warnings detected while parsing with tidy: *,debug,JMeter
HTMLAssertions.getResult(): there were errors/warnings but threshold to high,debug,JMeter
HTMLAssertions.getResult(): no errors/warnings detected:,debug,JMeter
Cannot parse result content,warn,JMeter
"Setting up tidy... doctype: *, errors only: *, error threshold: *,warning threshold: *, html mode: *, xhtml mode: *, xml mode: *.",debug,JMeter
"Tidy instance created... err file: *, tidy parser: *",debug,JMeter
Unable to instantiate tidy parser,error,JMeter
writeOutput() -> output successfully written to file: *,debug,JMeter
writeOutput() -> could not write output to file: *,warn,JMeter
"Test Type Info: contains=*, notTest=*, orTest=*",debug,JMeter
Not checking empty response field in: *,debug,JMeter
Failed: *,debug,JMeter
Failed: *,debug,JMeter
Passed: *,debug,JMeter
"Validation is set to *, Whitespace is set to *, Tolerant is set to *",debug,JMeter
Caught sax exception.,debug,JMeter
Cannot parse result content.,warn,JMeter
Cannot parse result content.,warn,JMeter
Problem in BSF script,warn,JMeter
Message digestion failed.,error,JMeter
Problem in JSR223 script: *,error,JMeter
Error initializing XMLReader in XMLAssertion,error,JMeter
BeanShell Jar missing?,error,JMeter
Error in BeanShellAssertion,warn,JMeter
"Exception parsing document, message:*",warn,JMeter
"Exception parsing document, message:*",error,JMeter
"Fatal Exception parsing document, message:*",error,JMeter
"xmlString: *, xsdFileName: *",debug,JMeter
$$$Empty Message$$$,warn,JMeter
IO error,warn,JMeter
Problem with Parser Config,warn,JMeter
$$$Empty Message$$$,debug,JMeter
$$$Empty Message$$$,debug,JMeter
$$$Empty Message$$$,debug,JMeter
Getting message number: * of *,debug,JMeter
Getting message number: *,debug,JMeter
Content-type: *,debug,JMeter
Found signature,debug,JMeter
Did not find signature,debug,JMeter
$$$Empty Message$$$,warn,JMeter
Cannot read mime message content: *,error,JMeter
Can't create a provider.,error,JMeter
DN from cert: *,debug,JMeter
DN from assertion: *,debug,JMeter
IssuerDN from cert: *,debug,JMeter
IssuerDN from assertion: *,debug,JMeter
Could not read cert file *,debug,JMeter
SMIME message contains multiple signers! Checking multiple signers is not supported.,warn,JMeter
$$$Empty Message$$$,error,JMeter
"Bytes: *, Content Type: *",debug,JMeter
msg.getSize() = *,debug,JMeter
Add email from RDN: *,debug,JMeter
Add email from subjectAlternativeName: *,debug,JMeter
HTMLAssertionGui.modifyTestElement() called,debug,JMeter
Exception while validating XPath.,warn,JMeter
XMLSchemaAssertionGui.createTestElement() called,debug,JMeter
XMLSchemaAssertionGui.modifyTestElement() called,debug,JMeter
Exception while validating XPath.,warn,JMeter
JMESPath query * invoked on response *. Query result is *. ,debug,JMeter
maximum(*) must be >= minimum(*),error,JMeter
maximum(*) - minimum(*) must be <= *2147483647,warn,JMeter
"Exception formatting value: * at format: *, using default",warn,JMeter
Cannot parse random seed: '*' in element *,warn,JMeter
Destroying Keystore,info,JMeter
https.use.cached.ssl.context property must be set to false to ensure Multiple Certificates are used,warn,JMeter
"Failed parsing startIndex: *, will default to: *, error message: *",warn,JMeter
"Failed parsing endIndex: *, will default to: *, error message: *",warn,JMeter
"Configuring Keystore with (preload: '*', startIndex: *, endIndex: *, clientCertAliasVarName: '*')",info,JMeter
Converted *=* to * using Locale: *,debug,JMeter
Could not translate *=* using Locale: *,warn,JMeter
Could not find BeanInfo; cannot translate shareMode entries,error,JMeter
"Empty delimiter, will use ','",debug,JMeter
$$$Empty Message$$$,error,JMeter
loadIncludedElements -- try to load included module: *,info,JMeter
loadIncludedElements -failed for: *,info,JMeter
loadIncludedElements -Attempting to read it from: *,info,JMeter
Include Controller '*' can't load '*' - see log for details,error,JMeter
$$$Empty Message$$$,warn,JMeter
$$$Empty Message$$$,warn,JMeter
$$$Empty Message$$$,warn,JMeter
"No Test Fragment was found in included Test Plan, returning empty HashTree",warn,JMeter
Error parsing '*',warn,JMeter
Error parsing '*',warn,JMeter
"* : Found in vars:*, isDone:*",debug,JMeter
"* : Found in vars:*, not end of Arguments",debug,JMeter
"* : Did not find in vars:*, End of Arguments reached",debug,JMeter
* No entries found - null first entry: *,debug,JMeter
Empty lock name in Critical Section Controller: *,warn,JMeter
Thread ('*') acquired lock: '*' in Critical Section Controller *  in: * ms,debug,JMeter
"Lock '*' not released in: *, releasing in threadFinished",warn,JMeter
"No variable '*' found to process by XPathExtractor '*', skipping processing",warn,JMeter
"Exception while processing '*', message:*",warn,JMeter
Boundary Extractor *: processing result,debug,JMeter
*: Error while generating result. *,warn,JMeter
*: Could not parse number: '*'.,warn,JMeter
"No variable '*' found to process by Boundary Extractor '*', skipping processing",warn,JMeter
Input = '*',debug,JMeter
HtmlExtractor *: processing result,debug,JMeter
*: Could not parse number: '*'.,warn,JMeter
*: Error while generating result. *,warn,JMeter
"No variable '*' found to process by CSS Selector Extractor '*', skipping processing",warn,JMeter
Problem in BSF script: *,warn,JMeter
"No variable '*' found to process by XPathExtractor '*', skipping processing",warn,JMeter
IOException on (*),error,JMeter
$$$Empty Message$$$,error,JMeter
SAXException while processing (*). *,warn,JMeter
TransformerException while processing (*). *,warn,JMeter
BeanShell not found,error,JMeter
Problem in BeanShell script: *,warn,JMeter
"Problem in JSR223 script, *",error,JMeter
RegexExtractor processing result,debug,JMeter
Could not parse number: '*',warn,JMeter
Error while generating result,warn,JMeter
Error in pattern: '*',error,JMeter
Input = '*',debug,JMeter
Regex = '*',debug,JMeter
"No variable '*' found to process by RegexExtractor '*', skipping processing",warn,JMeter
RegexExtractor: Match found!,debug,JMeter
Could not parse number: '*'.,warn,JMeter
RegexExtractor: Template piece * (*),debug,JMeter
Regex Extractor result = '*',debug,JMeter
"Pattern = '*', template = '*'",debug,JMeter
Template item count: *,debug,JMeter
Template item-*: * '*',debug,JMeter
"Error processing JSON content in *, message: *",error,JMeter
"Error processing JSON content in *, message: *",error,JMeter
"matchNumber(*) exceeds number of items found(*), default value will be used",debug,JMeter
"No value extracted, storing empty in: *",debug,JMeter
Response or source variable is null or empty for *,debug,JMeter
"JMESExtractor is using variable: *, which content is: *",debug,JMeter
JMESExtractor * working on Response: *,debug,JMeter
"Error processing JSON content in *, message: *",error,JMeter
"Error processing JSON content in *, message: *",error,JMeter
"Number of JSON Path variables must match number of default values and json-path expressions, check you use separator ';' if you have many values",error,JMeter
"matchNumber(*) exceeds number of items found(*), default value will be used",debug,JMeter
"No value extracted, storing empty in: **_ALL",debug,JMeter
Response or source variable is null or empty for *,debug,JMeter
"JSON Extractor is using variable: *, which content is: *",debug,JMeter
JSON Extractor * working on Response: *,debug,JMeter
Could not find JSON Path * in [*]: *,debug,JMeter
Exception extracting from '*' with expression '*',debug,JMeter
Exception extracting from '*' with expression '*',debug,JMeter
"No transaction exported using regexp '*', modify property '*' to fix this problemreport_transactions_pattern",warn,JMeter
Exported transactions: jmeter.reportgenerator.exporter.html.series_filter=^(*)(-success|-failure)?$,info,JMeter
InterruptTimer(),debug,JMeter
sampleStarting(),debug,JMeter
sampleEnded(),debug,JMeter
Scheduled timer: @* *,debug,JMeter
threadStarted(),debug,JMeter
threadFinished(),debug,JMeter
Cancelled timer: @*  with result *,debug,JMeter
Problem in BSF script. *,warn,JMeter
BeanShell not found,error,JMeter
Problem in BeanShell script. *,warn,JMeter
"Problem in JSR223 script, *",error,JMeter
"Error formatting * at format *, using default",warn,JMeter
* process *,debug,JMeter
* Running up named: *,debug,JMeter
* saving variable: *=*,debug,JMeter
* iteration start *,debug,JMeter
making threadlists from gui,debug,JMeter
Adding column to threadlist: *,debug,JMeter
Threadlists now = *,debug,JMeter
"In the end, threadlists = *",debug,JMeter
Ignored unexpected e-mail address: *,warn,JMeter
Problem sending mail: ,error,JMeter
Problem sending mail,error,JMeter
$$$Empty Message$$$,info,JMeter
Test mail sent successfully!!,info,JMeter
Script did not return a value,warn,JMeter
Problem in BSF script. *,warn,JMeter
BeanShell not found,error,JMeter
Problem in BeanShell script. *,warn,JMeter
Number format exception while decoding number: '*',warn,JMeter
Script did not return a value,warn,JMeter
"Problem in JSR223 script, *",error,JMeter
SyncTimer * timeouted waiting for users after: *ms,warn,JMeter
Test started - reset throughput calculation.,debug,JMeter
Converted *=* to mode=* using Locale: *,debug,JMeter
Could not convert *=* using Locale: *,warn,JMeter
Could not find BeanInfo,error,JMeter
Calculated delay is *,debug,JMeter
"Spent * ms while generating sequence of delays for * samples, * throughput, * duration",warn,JMeter
"Generated * events (* required, rate *) in * ms",debug,JMeter
$$$Empty Message$$$,info,JMeter
An error occurred rendering html code,warn,JMeter
Problem creating BSF manager,error,JMeter
Problem in BSF script. *,warn,JMeter
$$$Empty Message$$$,error,JMeter
"Problem in JSR223 script, *",error,JMeter
Error in load result render: *,warn,JMeter
Expanded: *,debug,JMeter
Elements: *,debug,JMeter
updateGui1 : child sample result - *,debug,JMeter
init() - pass,debug,JMeter
Add JavaFX to your Java installation if you want to use renderer: *,info,JMeter
Error loading result renderer: *,warn,JMeter
Error loading result renderer: *,warn,JMeter
selectedTab=*,debug,JMeter
Error while rendering axis chart. *,error,JMeter
"Exception converting to XML: *, message: *",error,JMeter
Chart property exception occurred.,warn,JMeter
Exception occurred while rendering chart.,warn,JMeter
Error inserting text,error,JMeter
"Exception converting to XML: *, message: *",error,JMeter
Exception while setting Y axis properties.,warn,JMeter
Exception while rendering axis chart.,warn,JMeter
Invalid mail address ,error,JMeter
Couldn't send mail...,error,JMeter
Error extracting data from tree node using searcher:*,error,JMeter
Error while rendering document.,error,JMeter
Constructor only intended for use in testing,warn,JMeter
Error trying to parse document,warn,JMeter
lastPosition=*,debug,JMeter
Location exception in text find,error,JMeter
BeanShell not found,error,JMeter
Problem in BeanShell script. *,warn,JMeter
Error saving to file,error,JMeter
Drawing a sample at *,debug,JMeter
"Drawing coords = *, *",debug,JMeter
*: setupTest,debug,JMeter
*: teardownTest,debug,JMeter
Exception getting interfaces.,debug,JMeter
Error getting argument list for *,error,JMeter
BackendListenerClient doesn't implement getDefaultParameters.  Default parameters won't be shown.  Please update your client class: *,warn,JMeter
"Error setting class: '*' in BackendListener: *, check for a missing jar in your jmeter 'search_paths' and 'plugin_dependency_paths' properties",error,JMeter
*	Exception initialising: *,error,JMeter
* => Dropping SampleResult: *,debug,JMeter
"sampleOccurred, failed to queue the sample",error,JMeter
Thread: * taking SampleResult from queue: *,debug,JMeter
"Thread: * took SampleResult: *, isFinal: *",debug,JMeter
Thread: * polling from queue: *,debug,JMeter
"Thread: * took from queue: *, isFinal: *",debug,JMeter
"Thread: * exiting with FINAL EVENT: *, null: *",debug,JMeter
Worker ended,info,JMeter
Exception creating: *,error,JMeter
*	testStarted(*),debug,JMeter
Invalid queue size '*' defaulting to *5000,warn,JMeter
*: Starting worker with class: * and queue capacity: *,info,JMeter
*: Started  worker with class: *,info,JMeter
testEnded called on instance *#*,debug,JMeter
No listener client data found for BackendListener *,error,JMeter
testEnded() with exception: *,warn,JMeter
"QueueWaits: *; QueueWaitTime: * (nanoseconds), you may need to increase queue capacity, see property 'backend_queue_capacity'",warn,JMeter
"ErrorBackendListenerClient#handleSampleResult called, noop",warn,JMeter
Value for parameter '*' not an integer: '*'.  Using default: '*'.,warn,JMeter
Value for parameter '*' not a long: '*'.  Using default: '*'.,warn,JMeter
"Created TextGraphiteMetricsSender with host: *, port: *, prefix: *",info,JMeter
Wrote * metrics,debug,JMeter
"IO Errors writing to Graphite, some data will be lost",error,JMeter
Exception invalidating socketOutputStream connected to graphite server *:*,warn,JMeter
Error writing to Graphite: *,error,JMeter
Error parsing percentile: '*',error,JMeter
Canceled state: *,debug,JMeter
Error waiting for end of scheduler,error,JMeter
"Created PickleGraphiteMetricsSender with host: *, port: *, prefix: *",info,JMeter
Exception invalidating socketOutputStream connected to graphite server *:*,warn,JMeter
Error writing to Graphite: *,error,JMeter
Wrote * metrics,debug,JMeter
Setting up with url:*,debug,JMeter
Cannot open udp port!,error,JMeter
Error in transferring udp package,error,JMeter
Created InfluxDBMetricsSender with url: *,debug,JMeter
"Success, number of metrics written: *",debug,JMeter
"Error writing metrics to influxDB Url: *, responseCode: *, responseBody: *",error,JMeter
failed to send data to influxDB server.,error,JMeter
Request to influxDB server was cancelled,warn,JMeter
$$$Empty Message$$$,error,JMeter
Destroying ,info,JMeter
Error waiting for last request to be send to InfluxDB,error,JMeter
Error parsing percentile: '*',error,JMeter
Canceled state: *,debug,JMeter
Error waiting for end of scheduler,error,JMeter
Sending last metrics,info,JMeter
Could not find order list,warn,JMeter
"Error in colors.properties, current property=*",warn,JMeter
Setting LAF to: *,info,JMeter
Could not set LAF to: *,warn,JMeter
Loading file: *,info,JMeter
Failure loading test file,error,JMeter
Failure loading test file,error,JMeter
$$$Empty Message$$$,info,JMeter
Version *,info,JMeter
java.version=*,info,JMeter
java.vm.name=*,info,JMeter
os.name=*,info,JMeter
os.arch=*,info,JMeter
os.version=*,info,JMeter
file.encoding=*,info,JMeter
java.awt.headless=*,info,JMeter
Max memory     =*,info,JMeter
Available Processors =*,info,JMeter
Default Locale=*,info,JMeter
JMeter  Locale=*,info,JMeter
JMeterHome=*,info,JMeter
user.dir  =*,info,JMeter
PWD       =*,info,JMeter
IP: * Name: * FullName: *,info,JMeter
ClassPath,debug,JMeter
$$$Empty Message$$$,debug,JMeter
"Giving up, as server failed with:",error,JMeter
An error occurred: ,error,JMeter
Setting property '*' to:'*'jmeter.reportgenerator.outputdir,info,JMeter
*=*,info,JMeter
Can't read *,warn,JMeter
Adding to classpath and loader: *,info,JMeter
Adding to loader: *,info,JMeter
"Starting Beanshell server (*,*)",info,JMeter
Starting Mirror server (*),info,JMeter
Could not start Mirror server,warn,JMeter
Running Beanshell on file: *,info,JMeter
Could not process Beanshell file: *,warn,JMeter
Running JSR-223 init script in file: *,info,JMeter
No script engine found for [*]. Will try to use Groovy. Possible engines and their extensions are: *,warn,JMeter
Error running init script * with engine for *: *,error,JMeter
Script * referenced by property * is not readable or does not existjsr223.init.file,error,JMeter
Set Proxy login: */*,info,JMeter
Set Proxy login: *,info,JMeter
"Set proxy Host: *, Port: *, Scheme: *",info,JMeter
Set http[s].nonProxyHosts: *,info,JMeter
Loading user properties from: *,info,JMeter
Error loading user property file: *,warn,JMeter
Loading system properties from: *,info,JMeter
Error loading system property file: *,warn,JMeter
Loading additional properties from: *,info,JMeter
Can't find additional property file: *,warn,JMeter
Error loading additional property file: *,warn,JMeter
Setting System properties from file: *,info,JMeter
Cannot find system property file. *,warn,JMeter
Setting System property: *=*,info,JMeter
Removing System property: *,warn,JMeter
Setting JMeter property: *=*,info,JMeter
Removing JMeter property: *,warn,JMeter
Setting Global property: *=*,info,JMeter
Setting Global properties from the file *,info,JMeter
Could not find properties file: *,warn,JMeter
Could not load properties file: *,warn,JMeter
LogLevel: *=*,info,JMeter
"Invalid log level, '*' for '*'.",warn,JMeter
LogLevel: *,warn,JMeter
"Invalid log level, '*', for the root logger.",warn,JMeter
Creating summariser <*>,info,JMeter
Error in NonGUIDriver,error,JMeter
Finished remote host: * (*),info,JMeter
"All remote engines have ended test, starting RemoteTestStopper thread",info,JMeter
Started remote host:  * (*),info,JMeter
* (*),info,JMeter
Generating Dashboard,info,JMeter
Dashboard generated,info,JMeter
Error generating the report: *,error,JMeter
"jmeter.exit.check.pause is <= 0, JMeter won't check for unterminated non-daemon threads",debug,JMeter
* not found - using *org/apache/jmeter/images/icon.properties,info,JMeter
* not found - using inbuilt icon set,info,JMeter
Loaded icon properties from *,info,JMeter
Command: * received from *,info,JMeter
Unable to find logo ,warn,JMeter
iterationStart called on * with source * and iteration *,debug,JMeter
*: error while processing [*],error,JMeter
*: error while processing [*],error,JMeter
    getCondition() : [*],debug,JMeter
    >> evaluate Condition -  [*] results is  [*],debug,JMeter
Condition string: '*',debug,JMeter
Condition value: '*',debug,JMeter
setCondition(*),debug,JMeter
End of transaction *,debug,JMeter
Start of transaction *,debug,JMeter
Could not fetch SamplePackage,warn,JMeter
Calling next on: *,debug,JMeter
Notifying test listeners of end of test,info,JMeter
Error encountered during shutdown of ,warn,JMeter
Test has ended on host * ,info,JMeter
stopping_test_failed,error,JMeter
Exiting,error,JMeter
Running the test!,info,JMeter
Error occurred compiling the tree:,error,JMeter
Starting setUp thread groups,info,JMeter
Starting setUp ThreadGroup: * : * ,info,JMeter
Waiting for setup thread group: * to finish before starting next setup group,info,JMeter
Waiting for all setup thread groups to exit,info,JMeter
All Setup Threads have ended,info,JMeter
Starting ThreadGroup: * : *,info,JMeter
Waiting for thread group: * to finish before starting next group,info,JMeter
No enabled thread groups found,info,JMeter
All thread groups have been started,info,JMeter
Test stopped - no more thread groups will be started,info,JMeter
Starting tearDown thread groups,info,JMeter
Starting tearDown ThreadGroup: * : *,info,JMeter
Waiting for post thread group: * to finish before starting next post group,info,JMeter
Forced JVM shutdown requested at end of test,info,JMeter
Starting * threads for group *.,info,JMeter
Test will stop on error,info,JMeter
Test will stop abruptly on error,info,JMeter
Thread will stop on error,info,JMeter
Thread will start next loop on error,info,JMeter
Thread will continue on error,info,JMeter
About to run System.exit(0) on *,warn,JMeter
Bye from *,info,JMeter
Applying properties *,info,JMeter
Starting backing engine on *,info,JMeter
IP address is a site-local address; this may cause problems with remote access. 	Can be overridden by defining the system property 'java.rmi.server.hostname' - see jmeter-server script file,info,JMeter
This = *,debug,JMeter
Creating RMI registry (server.rmi.create=true),info,JMeter
Created registry: *,debug,JMeter
$$$Empty Message$$$,warn,JMeter
Locating registry,debug,JMeter
About to rebind registry: *,debug,JMeter
Bound to RMI registry on port *,info,JMeter
rmiregistry needs to be running to start JMeter in server mode. *,error,JMeter
Creating JMeter engine on host * base '*',info,JMeter
Remote client host: *,info,JMeter
Engine is busy - cannot create JMeter engine,warn,JMeter
Running test,info,JMeter
Reset,info,JMeter
"Backing engine is null, ignoring reset",warn,JMeter
Stopping test ...,info,JMeter
Shutting test ...,info,JMeter
... stopped,info,JMeter
Exiting,info,JMeter
* is not boundJMeterEngine,warn,JMeter
Unbound from registry,info,JMeter
Cleaning previously set properties: *,info,JMeter
$$$Empty Message$$$,warn,JMeter
About to * remote test on *,info,JMeter
$$$Empty Message$$$,error,JMeter
Retry reset after: *,info,JMeter
Failed to reset remote engine,error,JMeter
running clientengine run method,info,JMeter
sent test to * basedir='*',info,JMeter
Sending properties *,info,JMeter
"Could not set properties: *, error:*",warn,JMeter
sent run command to *,info,JMeter
Error in * method ,error,JMeter
Error in * method,error,JMeter
Interrupting *,info,JMeter
about to exit remote server on *,info,JMeter
Could not perform remote exit: ,warn,JMeter
Ignoring timer node: *,debug,JMeter
Host not found in list of active engines: *,warn,JMeter
Host not found in list of active engines: *,warn,JMeter
Host not found in list of active engines: *,warn,JMeter
Host not found in list of active engines: *,warn,JMeter
Failed to create engine at *,error,JMeter
$$$Empty Message$$$,info,JMeter
$$$Empty Message$$$,error,JMeter
$$$Empty Message$$$,error,JMeter
invalid variables in node *,error,JMeter
invalid variables in node *,error,JMeter
num threads = *,debug,JMeter
Error replacing * by wrapper: *,error,JMeter
Cannot handle ThreadListener Remotable item: *,error,JMeter
Could not replace Remotable item: *,warn,JMeter
RemoteException occurred while replacing Remotable item.,error,JMeter
About to replace in property of type: *: *,debug,JMeter
Replacement result: *,debug,JMeter
Replacement result: *,debug,JMeter
Replacement result: *,debug,JMeter
Won't replace *,debug,JMeter
Malformed pattern: *,warn,JMeter
Error parsing function: *,error,JMeter
Error parsing function: *,error,JMeter
Probably an invalid function string: *,warn,JMeter
Error parsing function: *,error,JMeter
Probably an invalid function string: *,warn,JMeter
Invalid variable: *,debug,JMeter
Invalid variable: *,debug,JMeter
Exception occurred while instantiating a function: *,error,JMeter
Exception during stateChanged,info,JMeter
Error calling function *,error,JMeter
Can't escape commata in input string: *,warn,JMeter
Error initializing parameter panel,error,JMeter
Event *: *,debug,JMeter
No component set through property: *,warn,JMeter
Cannot add element on very top level,debug,JMeter
Failed to perform quick component add: *,warn,JMeter
No keycode could be found for this actionEvent *,debug,JMeter
Dnd failed,warn,JMeter
"Importing file, *, from DnD failed because file extension does not end with .jmx",warn,JMeter
Error awt title: *,warn,JMeter
Could not get GUI for ,error,JMeter
Gui retrieved = *,debug,JMeter
Problem retrieving gui,error,JMeter
No Component found for *.,debug,JMeter
Updating gui to new node,debug,JMeter
Problem retrieving current gui,error,JMeter
Problem retrieving gui,error,JMeter
Problem retrieving gui for ,error,JMeter
Problem retrieving gui for ,error,JMeter
No component found for *,debug,JMeter
Updating current node *,debug,JMeter
No component found for *,debug,JMeter
Problem retrieving gui,error,JMeter
"Showing pop up for * at x,y = *,*",debug,JMeter
Failure setting file server's base dir,error,JMeter
obj.getStringValue() returned null for test element: |  at property:,debug,JMeter
"Failed to create configured naming policy: | , will use default one",error,JMeter
Error during html report generation: *,error,JMeter
Error during html report generation: *,error,JMeter
CSV file path * user.properties file path: * Output directory file path: *,debug,JMeter
Clearing undo history,debug,JMeter
Clearing undo history with * unfinished transactions,warn,JMeter
"undo.history.size is set to 0, undo/redo feature is disabled",debug,JMeter
Not adding history because of noop,debug,JMeter
Not adding history because of no children,debug,JMeter
Adding history element *: *,debug,JMeter
"Can't undo, we're already on the last record",warn,JMeter
"Can't redo, we're already on the first record",warn,JMeter
Failed to load from history,error,JMeter
Nodes changed *,debug,JMeter
Nodes inserted *,debug,JMeter
Nodes removed: *,debug,JMeter
Nodes struct changed,debug,JMeter
Skipping undo since there is no previous known state,debug,JMeter
Undo transaction ended without beginning,error,JMeter
Constructor only intended for use in testing,warn,JMeter
SampleSaveConfiguration = *,debug,JMeter
grid panel is * by *3,debug,JMeter
Problem creating save config dialog,warn,JMeter
Setting enabled: *,debug,JMeter
setting element to enabled: *,debug,JMeter
Exception while adding a TestElement.,error,JMeter
Will use file * for Schematic View generation,info,JMeter
Clipboard node read error: *,error,JMeter
Clipboard node read error: *,error,JMeter
Error generating output file * from template *,error,JMeter
Could not delete generated output file * from template *,warn,JMeter
Error opening URL in browser: *,error,JMeter
Exception while adding a component to tree.,error,JMeter
Setting root log level: *,info,JMeter
Error trying to restart: *,error,JMeter
Error calling restart command *,error,JMeter
performAction(*) updateCurrentGui() on* caused,error,JMeter
Error processing *,error,JMeter
performAction(*) * caused,error,JMeter
Could not add Command,error,JMeter
Can't get location for class sources,debug,JMeter
Using fallback search path,info,JMeter
"!!!!!Uh-oh, didn't find any action handlers!!!!!",error,JMeter
AWT headless exception occurred. *,warn,JMeter
exception finding action handlers,error,JMeter
Failed to change parent,error,JMeter
"Applying naming policy, selected node * is not a Controller, will ignore it",warn,JMeter
Failed to apply naming policy,error,JMeter
Changing locale to *,debug,JMeter
Can't clear: * *,error,JMeter
Restoring dirty after undo/redo,debug,JMeter
Node is class: *,debug,JMeter
Running report generation,debug,JMeter
The HTML report generation failed and returned: *,info,JMeter
Error during HTML report generation:,error,JMeter
SystemCommand ran: *  returned: *,debug,JMeter
Action * not handled by this class,warn,JMeter
"OpenLinkAction: User default browser is not found, or it fails to be launched, or the default handler application failed to be launched on *",error,JMeter
OpenLinkAction: Current platform does not support the Desktop.Action.BROWSE action on *,error,JMeter
OpenLinkAction: Security problem on *,error,JMeter
OpenLinkAction on *,error,JMeter
Error occurred searching for word:* in node:*,error,JMeter
Replaced * in element:*,info,JMeter
Error occurred replacing data in node:*,error,JMeter
Merging file: *,info,JMeter
Loading file: *,info,JMeter
Could not convert file. *,warn,JMeter
$$$Empty Message$$$,warn,JMeter
$$$Empty Message$$$,warn,JMeter
Failed to add think times,error,JMeter
"TestElement: *, guiClassName: *",info,JMeter
Log level set to DEBUG for *,info,JMeter
Log level set to INFO for *,info,JMeter
"Test plan has changed, make backup of *",debug,JMeter
Failed to create a backup for *,error,JMeter
Error converting subtree. *,warn,JMeter
Error saving tree.,error,JMeter
"Could not backup file! Backup directory does not exist, is not a directory or could not be created ! <*>",error,JMeter
Failed to backup file: *,error,JMeter
"Error setting page for url, *",error,JMeter
Illegal user action while adding a tree node.,error,JMeter
Stopping test,info,JMeter
Shutting test down,info,JMeter
No thread group selected the test will not be started,warn,JMeter
test plan before cloning is running version: *,debug,JMeter
test plan after cloning and running test is running version: *,debug,JMeter
Error instantiating class:'*' defined in property:'*'testplan_validation.tree_cloner_class,error,JMeter
popupShouldSave,debug,JMeter
Could not delete existing file *,error,JMeter
Could not delete existing file *,error,JMeter
enabling currently selected gui objects,debug,JMeter
disabling currently selected gui objects,debug,JMeter
toggling currently selected gui objects,debug,JMeter
Reading templates from: *,info,JMeter
Ignoring template file:'*' as it does not exist or is not readable,warn,JMeter
"Ignoring template file:'*', an error occurred parsing the file",warn,JMeter
Warning parsing file *,warn,JMeter
No name provided for GuiLogEventAppender,error,JMeter
"value changed, updating currentPath",debug,JMeter
"ClosestPathForLocation is not found for x=*, y=*",debug,JMeter
"Mouse click was outside of node *. bounds=*, event.x=*, event.y=*",debug,JMeter
About to display pop-up,debug,JMeter
Class Not Found,error,JMeter
Drop file failed,error,JMeter
Unsupported Flavor in Transferable,error,JMeter
getIcon(): Can't obtain GUI class from *,warn,JMeter
Can't obtain icon for class *,error,JMeter
Can't get icon for class *,warn,JMeter
Can't get popup menu for gui,error,JMeter
Can't get popup menu for gui,error,JMeter
* participates in no menus.,debug,JMeter
*ms total menu initialization time,debug,JMeter
IO Exception while initializing menus.,error,JMeter
"Configuration error, probably corrupt or missing third party library(jar)? Could not create class: *.",warn,JMeter
Could not instantiate class: *,warn,JMeter
Could not instantiate class: *,warn,JMeter
Skipping *,info,JMeter
Unable to parse * as width x height for icon *. Will default to 22x22,info,JMeter
"Toolbar icon Action names error: *, use unknown action.",warn,JMeter
remove row: *,debug,JMeter
Calling remove row on Data,debug,JMeter
No valid initial directory found for: *,info,JMeter
Exception while adding button item to toolbar. *,warn,JMeter
Could not find toolbar definition list,warn,JMeter
Toolbar icon key: *,debug,JMeter
No definition for toolbar entry: *,warn,JMeter
Font is set to: *,debug,JMeter
Error reading  |  for JSyntaxTextArea,error,JMeter
Loading menu creator class: *,debug,JMeter
Instantiating: *,debug,JMeter
Exception registering * with implementation: *,error,JMeter
Exception finding implementations of *,error,JMeter
"setRunning(*, *)",info,JMeter
Found start host: *,debug,JMeter
Found stop  host: *,debug,JMeter
Found exit  host: *,debug,JMeter
Found shut  host: *,debug,JMeter
Can't find icon for * - *,warn,JMeter
Can't find disabled icon for * - *,info,JMeter
Load configuration for exporter '*',debug,JMeter
Using class:'*' for exporter:'*',debug,JMeter
Load configuration for graph '*',debug,JMeter
Using class:'*' for graph:'*' with id:'*',debug,JMeter
"Property '*' not found, using default value '*' instead.",info,JMeter
Use '*' value for optional property '*',debug,JMeter
Use '*' value for required property '*',debug,JMeter
"Invalid property '*', skip it.",warn,JMeter
Report generator properties loading,debug,JMeter
Loading properties:*,debug,JMeter
Error parsing property * with value: * using format: *jmeter.reportgenerator.start_date,error,JMeter
Error parsing property * with value: * using format: *jmeter.reportgenerator.end_date,error,JMeter
"Will use date range start date: *, end date: *",info,JMeter
No graph configuration found.,info,JMeter
No export configuration found. No report will be generated.,warn,JMeter
End of report generator properties loading,debug,JMeter
"apdex_per_transaction is empty, not APDEX per transaction customization",info,JMeter
"error parsing property apdex_per_transaction around chunk *. Wrong format, should have been: 'sample:satisfiedMs|toleratedMS', ignoring",error,JMeter
Unsupported CHARSET: *,warn,JMeter
"File '*' does not contain the field names header, ensure the jmeter.save.saveservice.* properties are the same as when the CSV file was created or the file may be read incorrectly when generating report",warn,JMeter
Short CSV read around line * of file '*'. Could only read * elements of * expected. Data is [*],warn,JMeter
"Copying folder from '*' to '*', got message: *, found non empty folder with following content *, will be ignored",info,JMeter
* is set while the graph * excludes controllers.show_controllers_only,warn,JMeter
"name:* matches pattern:*, supportsControllerDiscrimination:*, isController:*, showControllerSeriesOnly:*",debug,JMeter
"name:* does not match pattern:*, filtersOnlySampleSeries:*, supportsControllerDiscrimination:*",debug,JMeter
No series matches the series_filter: * in graph: *series_filter,warn,JMeter
Start template processing,debug,JMeter
$$$Empty Message$$$,error,JMeter
Will generate dashboard in folder: *,info,JMeter
"Invalid series filter: '*', *",error,JMeter
"Report will be generated in: *, creating folder structure",info,JMeter
End of template processing,debug,JMeter
ReportGenerator will use for Parsing the separator: '*',info,JMeter
Will only generate report from results file: *,info,JMeter
Will generate report at end of test from  results file: *,info,JMeter
Reading report generator properties from: *,info,JMeter
Merging with JMeter properties,info,JMeter
Problem loading properties from file.,error,JMeter
Flushing result collector before report Generation,info,JMeter
Start report generation,debug,JMeter
Start samples processing,debug,JMeter
End of samples processing,debug,JMeter
Start data exporting,debug,JMeter
Exporting data using exporter:'*' of className:'*',info,JMeter
End of data exporting,debug,JMeter
End of report generation,debug,JMeter
"Cannot delete created temporary directory, '*'.",warn,JMeter
$$$Empty Message$$$,error,JMeter
"Unable to add class:* as consumer for HTML report generation, check class name or that the plugin that contains it is on classpath",warn,JMeter
"'*' is not a valid property for class '*', skip it",warn,JMeter
$$$Empty Message$$$,error,JMeter
Found data for consumer * in contextstatisticsSummary,info,JMeter
Creating statistics for overall,info,JMeter
Creating statistics for other transactions,info,JMeter
Checking output folder,info,JMeter
Writing statistics JSON to *,info,JMeter
Creating statistics for result data:*,debug,JMeter
#stopProducing():  |  produced  |  samples,info,JMeter
"sort():  |  samples read from input,  |  samples written to chunk files",debug,JMeter
Failure! Number of samples read from input and written to chunk files differ,error,JMeter
dumping of samples chunk succeeded.,info,JMeter
Was not able to delete folder *,warn,JMeter
sortAndDump(): Sorting  |  samples...,debug,JMeter
sortAndDump(): in  |  s. Sorted   |  samples.,debug,JMeter
sortAndDump(): Dumping chunk ,debug,JMeter
sortAndDump(): in  |  s : Dumped chunk ,debug,JMeter
produce(): * samples produced in * on channel *,info,JMeter
"Using format, '*', to parse timeStamp field",info,JMeter
"startConsuming(): No output file set, writing to work directory :",info,JMeter
Was not able to delete folder *,warn,JMeter
$$$Empty Message$$$,error,JMeter
$$$Empty Message$$$,error,JMeter
Could not delete intermediate file *,warn,JMeter
"Cannot delete created temporary directory, '*'",warn,JMeter
Shutdown hook started,info,JMeter
Shutdown hook ended,info,JMeter
"Should not happen: shutdownHook==null, instanceCount=*",warn,JMeter
Exception occurred while initializing file output.,error,JMeter
* is empty,warn,JMeter
Failed to load * using XStream. Error was: *,warn,JMeter
Problem reading JTL file: *,warn,JMeter
Getting file: * in thread *,debug,JMeter
Folder at * was created,info,JMeter
Error creating directories for *,warn,JMeter
Opened file: * in thread *,debug,JMeter
Writing header to file: *,debug,JMeter
Unexpected EOF trying to find XML end marker in *,warn,JMeter
Error trying to find XML terminator. *,warn,JMeter
Error trying to record a sample,error,JMeter
forced flush through ResultCollector#flushFile,info,JMeter
Closing: *,debug,JMeter
Problem detected during use of *,warn,JMeter
Error closing file *,error,JMeter
$$$Empty Message$$$,info,JMeter
ResultStatusHandler * for * OK? *,debug,JMeter
Ignoring SampleResult from Sampler *,debug,JMeter
Saving * in *,debug,JMeter
Error creating sample file for *,error,JMeter
Error saving sample *,error,JMeter
Creating path hierarchy for folder *,debug,JMeter
Folder * already exists,debug,JMeter
Disabling SSL for RMI as server.rmi.ssl.disable is set to 'true',info,JMeter
Disabling SSL for RMI as server.rmi.ssl.disable is set to 'true',info,JMeter
"System property 'java.rmi.server.hostname' is not defined, using localHost address",info,JMeter
Resolving by name the value of System property 'java.rmi.server.hostname': *,info,JMeter
Local IP address=*,info,JMeter
Created SSLSocket: *,info,JMeter
"Could not convert string, using default encoding. ",warn,JMeter
"Could not convert string using ' | ', using default encoding: ",warn,JMeter
Using platform default as  |  caused ,warn,JMeter
setEndTime must be called after setStartTime,error,JMeter
sampleStart called twice,error,JMeter
sampleEnd called twice,error,JMeter
samplePause called twice,error,JMeter
sampleResume without samplePause,error,JMeter
Constructor only intended for use in testing,warn,JMeter
"Using StatisticalSampleSender (client settings) for this run. Thresholds: num=*, time=*. Key uses ThreadName: *",info,JMeter
Using StatisticalSampleSender (server settings) for this run.,info,JMeter
Test Ended on *,info,JMeter
testEnded(hostname),warn,JMeter
Firing sample,debug,JMeter
sampleOccurred,warn,JMeter
"Using StatisticalSampleSender for this run. * config: Thresholds: num=*, time=*. Key uses ThreadName: *",info,JMeter
Constructor only intended for use in testing,warn,JMeter
Using DataStrippingSampleSender for this run,info,JMeter
Using DataStrippingSampleSender for this run,info,JMeter
Test Ended on *,info,JMeter
Error sending sample result over network,error,JMeter
Using DataStrippingSampleSender for this run with stripAlsoOnError: *,info,JMeter
Constructor only intended for use in testing,warn,JMeter
"Using HoldSampleSender for this test run, ensure you have configured enough memory (-Xmx) for your test",warn,JMeter
Test Ended on *,info,JMeter
testEnded(host),error,JMeter
testEnded(host),error,JMeter
"Using HoldSampleSender for this test run, ensure you have configured enough memory (-Xmx) for your test",warn,JMeter
Constructor only intended for use in testing,warn,JMeter
"Using Asynch Remote Sampler for this test run, queue size: *",info,JMeter
Using batch queue size (asynch.batch.queue.size): *,info,JMeter
Test Ended on *,debug,JMeter
testEnded(host),warn,JMeter
QueueWaits: *; QueueWaitTime: * (nanoseconds),info,JMeter
sampleOccurred; failed to queue the sample,error,JMeter
Failed to return sample,error,JMeter
Worker ended,debug,JMeter
"Unable to create a sample sender from class:'*', search for mode property in jmeter.properties for correct configuration options",error,JMeter
Constructor only intended for use in testing,warn,JMeter
"Using batching (client settings) for this run. Thresholds: num=*, time=*",info,JMeter
Using batching (server settings) for this run.,info,JMeter
Test Ended on *,info,JMeter
testEnded(host),error,JMeter
Firing sample,debug,JMeter
sampleOccurred,error,JMeter
"Using batching for this run. Thresholds: num=*, time=*",info,JMeter
RemoteException while handling sample occurred event.,error,JMeter
RemoteException while handling sample started event.,error,JMeter
RemoteException while handling sample stopped event.,error,JMeter
List of sample_variables: *,info,JMeter
Successfully validated pattern value * for property *jmeter.save.saveservice.timestamp_format,debug,JMeter
Invalid pattern value * for property *jmeter.save.saveservice.timestamp_format,error,JMeter
Test Started(),debug,JMeter
testStarted(),error,JMeter
testStarted(),error,JMeter
Test Started on *,debug,JMeter
testStarted(host) on *,error,JMeter
testStarted(host) on *,error,JMeter
Sample started,debug,JMeter
sampleStarted,error,JMeter
Sample stopped,debug,JMeter
sampleStopped,error,JMeter
Constructor only intended for use in testing,warn,JMeter
Using DiskStoreSampleSender for this test run,info,JMeter
Test Ended on *,info,JMeter
Executor did not terminate in a timely fashion,error,JMeter
Executor did not terminate in a timely fashion,error,JMeter
returning sample,error,JMeter
Unexpected object type found in data file. *,error,JMeter
returning sample,error,JMeter
returning sample,error,JMeter
Could not delete file: *,warn,JMeter
Using DiskStoreSampleSender for this test run,info,JMeter
Failed to create output file,error,JMeter
Constructor only intended for use in testing,warn,JMeter
Using StandardSampleSender for this test run,info,JMeter
Test Ended on *,info,JMeter
testEnded(host),warn,JMeter
sampleOccurred,error,JMeter
Using StandardSampleSender for this test run,info,JMeter
* does not appear to have a valid header. Using default configuration.,info,JMeter
"Cannot parse timestamp: '*', will try following formats *",warn,JMeter
Setting date format to: *,warn,JMeter
"* did not match *, trying next date format",info,JMeter
Unknown timestamp format,warn,JMeter
"Line: *. Found * fields, expected *. Extra fields have been ignored.",warn,JMeter
Error parsing field '*' at line *. *,warn,JMeter
Insufficient columns to parse field '*' at line *,warn,JMeter
Default delimiter '*' did not work; using alternate '*' for reading *,warn,JMeter
Unknown column name *,warn,JMeter
Column header number * name * is out of order.,warn,JMeter
Duplicate class detected for *: * & *,error,JMeter
Duplicate alias detected for *: * & *,error,JMeter
Can't compute checksum for saveservice properties file,error,JMeter
Using SaveService properties version *,info,JMeter
"SaveService properties file version is now computed by a checksum,the property _file_version is not used anymore and can be removed.",info,JMeter
Using SaveService properties file encoding *,info,JMeter
Bad saveservice properties file,error,JMeter
Can't register a converter: *,warn,JMeter
Unexpected entry in saveservice.properties; class does not exist and is not upgraded: *,error,JMeter
"Bad _version - expected *, found *.5.0",warn,JMeter
Loading file: *,info,JMeter
Problem loading XML: see above.,error,JMeter
fileEncoding not defined - using JRE default,info,JMeter
System doesn't support *,warn,JMeter
System doesn't support *,warn,JMeter
Failed to read result file.,warn,JMeter
Default base='*',info,JMeter
Reset base to '*',info,JMeter
Set new base='*',info,JMeter
Set new base='*',info,JMeter
Stored: *,info,JMeter
Stored: * Alias: *,info,JMeter
Read:*,debug,JMeter
Write:*,debug,JMeter
Close: *,info,JMeter
Loading class: *,debug,JMeter
Instantiating: *,debug,JMeter
Exception registering * with implementation: *,error,JMeter
Exception finding implementations of *,error,JMeter
Starting thread group... number=* threads=* ramp-up=* delayedStart=*,info,JMeter
Computed delayForNextThreadInMillis:* for thread:*,debug,JMeter
Started thread group number *,info,JMeter
Started new thread in group *,info,JMeter
Ending thread *,debug,JMeter
Exception occurred interrupting ThreadStarter,warn,JMeter
Exception occurred interrupting ThreadStarter,warn,JMeter
Thread won't exit: *,warn,JMeter
An error occurred scheduling delay start of threads for Thread Group: *,error,JMeter
Detected problem in Listener.,error,JMeter
Continuing to process further listeners,info,JMeter
Stopping because end time detected by thread: *,info,JMeter
"Start Next Thread Loop option is on, Last sample failed, starting next thread loop",debug,JMeter
Thread is done: *,info,JMeter
Stopping Test: *,info,JMeter
Stopping Test Now: *,info,JMeter
"Stop Thread seen for thread *, reason: *",info,JMeter
Test failed!,error,JMeter
Thread finished: *,info,JMeter
Stopping Test: *,info,JMeter
Stopping Test with interruption of current samplers: *,info,JMeter
Stopping Thread: *,info,JMeter
Error while processing sampler: '*'.,error,JMeter
Error while processing sampler.,error,JMeter
Thread started: *,info,JMeter
Error calling threadStarted,error,JMeter
Error calling threadFinished,error,JMeter
Stopping: *,info,JMeter
Interrupting: * sampler: *,warn,JMeter
No operation pending,warn,JMeter
Caught Exception interrupting sampler: *,warn,JMeter
Sampler is not Interruptible: *,warn,JMeter
Shutdown Test detected by thread: *,info,JMeter
Stop Test Now detected by thread: *,info,JMeter
Stop Thread detected by thread: *,info,JMeter
Error processing Assertion.,debug,JMeter
Error processing Assertion.,error,JMeter
Exception processing Assertion.,error,JMeter
Running preprocessor: *,debug,JMeter
Applying TIMER_FACTOR:* on timer:* for thread:*,debug,JMeter
"The delay would be longer than the scheduled period, so stop thread now.",debug,JMeter
The delay timer was interrupted - probably did not wait as long as intended.,warn,JMeter
* delay for * was interrupted. Waited * milli-seconds out of *,warn,JMeter
Exception invoking listener on threadStarted.,error,JMeter
Exception invoking listener on threadFinished.,error,JMeter
Could not set protocol list: *.,warn,JMeter
Valid protocols are: *,warn,JMeter
Could not set cipher list: *.,warn,JMeter
Valid ciphers are: *,warn,JMeter
Cannot find *,warn,JMeter
Cannot open *,warn,JMeter
Error reading * *,warn,JMeter
Setting Locale to *,info,JMeter
Resource bundles will be ignored,warn,JMeter
"Could not find resources for '*', using '*'",info,JMeter
Could not find resources for '*',error,JMeter
ERROR! Resource string not found: [*],warn,JMeter
"Resource string not found: [*], using default value *",debug,JMeter
ERROR! Resource string not found: [*],warn,JMeter
"Resource string not found: [*], using default value *",debug,JMeter
Could not resolve ResourceBundle for Locale [*],warn,JMeter
no icon for *,warn,JMeter
no icon for * *,info,JMeter
"Exception '*' occurred when fetching int property:'*', defaulting to: *",warn,JMeter
"Exception '*' occurred when fetching boolean property:'*', defaulting to: *",warn,JMeter
"Exception '*' occurred when fetching long property:'*', defaulting to: *",warn,JMeter
"Exception '*' occurred when fetching float property:'*', defaulting to: *",warn,JMeter
"Exception '*' occurred when fetching double property:'*', defaulting to: *",warn,JMeter
"Exception '*' occurred when fetching String property:'*', defaulting to: *",warn,JMeter
Exception '*' occurred when fetching String property:'*',warn,JMeter
Unknown error,warn,JMeter
$$$Empty Message$$$,error,JMeter
$$$Empty Message$$$,error,JMeter
"reportErrorToUser(""*"") caused",warn,JMeter
$$$Empty Message$$$,info,JMeter
"reportInfoToUser(""*"") caused",warn,JMeter
Unable to get local host IP address.,error,JMeter
Interrupted in thread *,warn,JMeter
Parsed namespaces:* into list of namespaces:*,debug,JMeter
"Declared namespaces:*, now compiling xPathQuery:*",debug,JMeter
Can't instantiate BeanShell,error,JMeter
Can't set logger variable,warn,JMeter
Cannot find init file: *,warn,JMeter
Cannot read init file: *,warn,JMeter
Cannot source init file: *,warn,JMeter
$$$Empty Message$$$,error,JMeter
$$$Empty Message$$$,error,JMeter
JmeterKeyStore Location: * type *,info,JMeter
KeyStore created OK,info,JMeter
Total of * aliases loaded OK from PKCS11,info,JMeter
Total of * aliases loaded OK from keystore,info,JMeter
"Keystore file not found, loading empty keystore",warn,JMeter
Problem loading keystore: *,error,JMeter
JmeterKeyStore type: *,debug,JMeter
"No password provided, and no GUI present so cannot prompt",warn,JMeter
TrustStore Location: *,info,JMeter
"TrustStore created OK, Type: JKS",info,JMeter
Truststore loaded OK from file,info,JMeter
"Truststore file not found, loading empty truststore",warn,JMeter
TidyException: *,error,JMeter
Tidy errors: *,warn,JMeter
Type=*. *,info,JMeter
Type=*. *,warn,JMeter
Type=*. *,error,JMeter
Unexpected object type: * returned for: *,warn,JMeter
Error : *,warn,JMeter
Error : **,warn,JMeter
nodeList length *,debug,JMeter
nodeList is null or empty. No match by xpath expression: *,debug,JMeter
nodeList[*]: *,debug,JMeter
Error : *,warn,JMeter
Error document parsing.,warn,JMeter
$$$Empty Message$$$,warn,JMeter
$$$Empty Message$$$,warn,JMeter
Error closing document stream,warn,JMeter
Probably: *,warn,JMeter
ssl Provider = *,debug,JMeter
Creating shared context,debug,JMeter
SSL stuff all set,debug,JMeter
Could not set up SSLContext,error,JMeter
JsseSSLManager installed,debug,JMeter
Unexpected HttpURLConnection class: *,warn,JMeter
Using shared SSL context for: *,debug,JMeter
Creating threadLocal SSL context for: *,debug,JMeter
Using threadLocal SSL context for: *,debug,JMeter
Clearing session context for current thread,debug,JMeter
JmeterKeyStore type: *,debug,JMeter
Default Cipher: *,debug,JMeter
Supported Cipher: *,debug,JMeter
WrappedX509Manager: getClientAliases: ,debug,JMeter
WrappedX509Manager: getServerAliases: ,debug,JMeter
WrappedX509Manager: getCertificateChain(*),debug,JMeter
WrappedX509Manager: getPrivateKey: *,debug,JMeter
keyType: *,debug,JMeter
Client alias: '*',debug,JMeter
"Could not source, *. *",warn,JMeter
Beanshell Interpreter not found,error,JMeter
Problem starting BeanShell server,error,JMeter
 Client certificate *:   Subject DN: *   Signature Algorithm: *   Valid from: *   Valid until: *   Issuer: *,debug,JMeter
 Server certificate *:   Subject DN: *   Signature Algorithm: *   Valid from: *   Valid until: *   Issuer: *,debug,JMeter
Upgrading class * to *,info,JMeter
Upgrading * to *,info,JMeter
Upgrading property * to *,info,JMeter
Upgrading value * to *,info,JMeter
"Did not find as much aliases as configured in indexes Start=*, end=*, found=*",warn,JMeter
No var called '*' found,error,JMeter
getting new collector,debug,JMeter
$$$Empty Message$$$,trace,JMeter
$$$Empty Message$$$,trace,JMeter
$$$Empty Message$$$,trace,JMeter
$$$Empty Message$$$,trace,JMeter
$$$Empty Message$$$,trace,JMeter
$$$Empty Message$$$,trace,JMeter
$$$Empty Message$$$,trace,JMeter
$$$Empty Message$$$,trace,JMeter
$$$Empty Message$$$,trace,JMeter
$$$Empty Message$$$,trace,JMeter
$$$Empty Message$$$,debug,JMeter
$$$Empty Message$$$,debug,JMeter
$$$Empty Message$$$,debug,JMeter
$$$Empty Message$$$,debug,JMeter
$$$Empty Message$$$,debug,JMeter
$$$Empty Message$$$,debug,JMeter
$$$Empty Message$$$,debug,JMeter
$$$Empty Message$$$,debug,JMeter
$$$Empty Message$$$,debug,JMeter
$$$Empty Message$$$,debug,JMeter
$$$Empty Message$$$,info,JMeter
$$$Empty Message$$$,info,JMeter
$$$Empty Message$$$,info,JMeter
$$$Empty Message$$$,info,JMeter
$$$Empty Message$$$,info,JMeter
$$$Empty Message$$$,info,JMeter
$$$Empty Message$$$,info,JMeter
$$$Empty Message$$$,info,JMeter
$$$Empty Message$$$,info,JMeter
$$$Empty Message$$$,info,JMeter
$$$Empty Message$$$,warn,JMeter
$$$Empty Message$$$,warn,JMeter
$$$Empty Message$$$,warn,JMeter
$$$Empty Message$$$,warn,JMeter
$$$Empty Message$$$,warn,JMeter
$$$Empty Message$$$,warn,JMeter
$$$Empty Message$$$,warn,JMeter
$$$Empty Message$$$,warn,JMeter
$$$Empty Message$$$,warn,JMeter
$$$Empty Message$$$,warn,JMeter
$$$Empty Message$$$,error,JMeter
$$$Empty Message$$$,error,JMeter
$$$Empty Message$$$,error,JMeter
$$$Empty Message$$$,error,JMeter
$$$Empty Message$$$,error,JMeter
$$$Empty Message$$$,error,JMeter
$$$Empty Message$$$,error,JMeter
$$$Empty Message$$$,error,JMeter
$$$Empty Message$$$,error,JMeter
$$$Empty Message$$$,error,JMeter
$$$Empty Message$$$,debug,JMeter
* (*) * * *,debug,JMeter
Cannot set URL: ,warn,JMeter
Split * using * into *,debug,JMeter
$$$Empty Message$$$,debug,JMeter
Format date pattern '*' is invalid (see https://docs.oracle.com/javase/8/docs/api/java/time/format/DateTimeFormatter.html),error,JMeter
Failed to parse the date '*' to shift with formatter '*',error,JMeter
Failed to parse the amount duration '*' to shift (see https://docs.oracle.com/javase/8/docs/api/java/time/Duration.html#parse-java.lang.CharSequence-) ,error,JMeter
Create a new instance of DateTimeFormatter for format '*' in the cache,debug,JMeter
*: Opening *,info,JMeter
$$$Empty Message$$$,warn,JMeter
XPathFileContainer is null!,error,JMeter
XPathFileContainer has no nodes: * *,warn,JMeter
getting match number *,debug,JMeter
clearAll(),debug,JMeter
*: clearing container,info,JMeter
Error running BSH script,warn,JMeter
"__Beanshell(*,*)=*",debug,JMeter
$$$Empty Message$$$,info,JMeter
An error occurred while evaluating the expression \ | \,error,JMeter
"Error calling * function with value *, digest algorithm *, salt *, __digest",error,JMeter
$$$Empty Message$$$,debug,JMeter
* closing file *,info,JMeter
closeFile() error: *,error,JMeter
closeFile() error: *,error,JMeter
"Exception parsing * as int, value will not be considered as Start Number sequence",warn,JMeter
"Exception parsing * as int, value will not be considered as End Number sequence",warn,JMeter
* Start = * Current = * End = *,info,JMeter
"* No more files to process, * > *",info,JMeter
* using format *,info,JMeter
Bad file name format ,warn,JMeter
* opening file *,info,JMeter
openFile() error: *,error,JMeter
* EOF on  file *,info,JMeter
* Detected end of sequence.,info,JMeter
* error reading file *,error,JMeter
* Detected end of sequence.,info,JMeter
* name:* value:*,debug,JMeter
*::StringFromFile.setParameters(),debug,JMeter
*,info,JMeter
* * *,error,JMeter
* * *,warn,JMeter
* * *,info,JMeter
* * *,debug,JMeter
* * *,trace,JMeter
Could not read open: * ,warn,JMeter
Could not read file: * *,warn,JMeter
* name: * value: *,debug,JMeter
Using default: *,warn,JMeter
Cannot determine default file name,error,JMeter
Opening * as *,info,JMeter
Alias cannot be empty,error,JMeter
Stored * as *,info,JMeter
Saved * as * delimiter=<*>,info,JMeter
endRow(): no entry for *,warn,JMeter
endRow() called twice in succession,warn,JMeter
Cannot perform initial open using alias *,warn,JMeter
Attaching *,info,JMeter
clearAll(),debug,JMeter
Removing *,info,JMeter
Malformed cache pattern:*,error,JMeter
"FRCC(*,*)",debug,JMeter
FRCC(*)[*],debug,JMeter
$$$Empty Message$$$,warn,JMeter
"*(*,*):*",debug,JMeter
Row: *,debug,JMeter
XPath(*) xpath *,debug,JMeter
found *,debug,JMeter
$$$Empty Message$$$,warn,JMeter
Row: *,debug,JMeter
"An error occurred while evaluating the expression ""*"" ",error,JMeter
"execute (*, *)   ",debug,JMeter
* - can't parse column number: * *,warn,JMeter
* - invalid column number: * at row * *,warn,JMeter
execute value: *,debug,JMeter
setParameter - Collection.size=*,debug,JMeter
i: *,debug,JMeter
Error running groovy script,warn,JMeter
"__groovy(*,*)=*",debug,JMeter
Format date pattern '*' is invalid (see https://docs.oracle.com/javase/8/docs/api/java/time/format/DateTimeFormatter.html),error,JMeter
Format date pattern '*' is invalid (see https://docs.oracle.com/javase/8/docs/api/java/time/format/DateTimeFormatter.html),error,JMeter
Failed to parse Start Date '*',error,JMeter
Failed to create current date '*',error,JMeter
Failed to parse End date '*',error,JMeter
End Date '*' must be greater than Start Date '*',error,JMeter
Failed to generate random date '*',error,JMeter
Create a new instance of DateTimeFormatter for format '*' in the cache,debug,JMeter
* name:* value:*,debug,JMeter
File name '*' is empty,error,JMeter
Writing * to file * with charset * and append *,debug,JMeter
The parent file of * doesn't exist or is not writable,error,JMeter
The encoding of file is not supported,error,JMeter
The encoding of file contains illegal characters,error,JMeter
IOException occurred,error,JMeter
"RandomFromMultiResult didn't find <var>_matchNr in variables :'*' using separator:'*', will return empty value",debug,JMeter
* name:* value:*,debug,JMeter
"Error calling * function with value *, source format *, target format *, __dateTimeConvert",error,JMeter
"Unknown mode *, returning * unchanged",error,JMeter
execute (* *),debug,JMeter
execute value: *,debug,JMeter
setParameter - Collection.size=*,debug,JMeter
i:*,debug,JMeter
Error processing Javascript: [*],error,JMeter
Error processing Javascript: [*],error,JMeter
Could not parse * : *,warn,JMeter
Variables have not yet been defined,error,JMeter
Creating HttpMirror ... on port *,info,JMeter
HttpMirror up and running!,info,JMeter
Starting new Mirror thread,debug,JMeter
Server not running,warn,JMeter
HttpMirror Server stopped,info,JMeter
Could not bind HttpMirror to port *. Maybe there is already a HttpMirror running?,warn,JMeter
HttpMirror Server stopped,warn,JMeter
Invalid log level '*'.,warn,JMeter
Setting root log level to '*',info,JMeter
Setting log level to '*' for '*'.,info,JMeter
Received Cookie: * From: *,debug,JMeter
Unable to add the cookie,error,JMeter
Not storing invalid cookie: <*> for URL * (*),info,JMeter
Dropping expired Cookie: *,info,JMeter
$$$Empty Message$$$,warn,JMeter
Found * cookies for *,debug,JMeter
Dropping cookie with null value *,debug,JMeter
Add cookie to store *,debug,JMeter
Clear all cookies from store,debug,JMeter
New Cookie = * removing matching Cookie *,debug,JMeter
Unable to load or invoke class: *,error,JMeter
Policy: * Clear: *,debug,JMeter
Initialise cookies from pre-defined list,debug,JMeter
Subject cached: |  before:,debug,JMeter
Interrupted while getting subject for ,warn,JMeter
Execution of getting subject for  |  failed,warn,JMeter
Found vary value * for * in response,debug,JMeter
"setCache(*, *, *, *, *, *, *)",debug,JMeter
Set entry into cache for url * and vary * (*),debug,JMeter
Entry for * already in cache.,debug,JMeter
Set entry * into cache for url *,debug,JMeter
"Unable to parse Expires: '*', exception: *",debug,JMeter
"Failed computing expiration date with following info: | , | , | , | , | ,",warn,JMeter
setHeaders for HTTP Method:*(OAH) URL:* Entry:*,debug,JMeter
setHeaders HTTP Method*(Java) url:* entry:*,debug,JMeter
Check if entry * is still valid for url *,debug,JMeter
Expires= * (Valid) for url *,debug,JMeter
Expires= * (Expired) for url *,debug,JMeter
expiresDate is null for url *,debug,JMeter
getEntry url:* entry:* header:*,debug,JMeter
No entry found for url *,debug,JMeter
Entry * with no vary found for url *,debug,JMeter
"Entry * found, but it should depend on vary * for url *",debug,JMeter
Looking again for * because of * with vary: * (*),debug,JMeter
Clear cache,debug,JMeter
Use DelegatingSPNegoScheme,debug,JMeter
Use SPNegoScheme,debug,JMeter
Use DelegatingKerberosScheme,debug,JMeter
Use KerberosScheme,debug,JMeter
Starting thread,debug,JMeter
Write body,debug,JMeter
Invalid request received:'*',error,JMeter
Received => '*',debug,JMeter
$$$Empty Message$$$,warn,JMeter
$$$Empty Message$$$,info,JMeter
Write headers,debug,JMeter
$$$Empty Message$$$,info,JMeter
"Transfer-Encoding header set, the value is not supported : *",error,JMeter
"Reading, * < *",debug,JMeter
Read bytes: *,debug,JMeter
totalReadBytes: *,debug,JMeter
Chunked,debug,JMeter
Other,debug,JMeter
Read bytes: *,debug,JMeter
Flush,debug,JMeter
$$$Empty Message$$$,error,JMeter
End of Thread,debug,JMeter
Internal error!,error,JMeter
Target URL strings to match against: * and *,debug,JMeter
Checking match against auth'n entry: *,debug,JMeter
Matched against auth'n entry: *,debug,JMeter
Did not match against auth'n entry: *,debug,JMeter
Found the same Authorization object:*,debug,JMeter
Error parsing auth line: '*',error,JMeter
* > D=* R=* M=*,debug,JMeter
Using DNS Resolvers: *,debug,JMeter
Failed to create Extended resolver: *,warn,JMeter
Cache  |  thread#*: * => *,debug,JMeter
Look for * at *: *,debug,JMeter
Found static host: * => *,debug,JMeter
No static host found for *,debug,JMeter
Couldn't resolve static address * for host *,warn,JMeter
Couldn't convert * as literal address to InetAddress,info,JMeter
"Failed to create Lookup object for host:*, error message:*",debug,JMeter
Clear all servers from store,debug,JMeter
Clear all hosts from store,debug,JMeter
Creating HttpMirrorControlGui,debug,JMeter
creating/configuring model = *,debug,JMeter
Configuring gui with *,debug,JMeter
Error while removing recorded samples,error,JMeter
Unhandled option *,warn,JMeter
Failed to read from File *,error,JMeter
Could not load headers,error,JMeter
$$$Empty Message$$$,error,JMeter
Adding entry *,debug,JMeter
Error loading auth data,error,JMeter
Setting auth value: *,debug,JMeter
Failed to read from File *,error,JMeter
File * doesn't exist,error,JMeter
"No AbstractThreadGroup found, potentially empty plan, creating a new plan",info,JMeter
Newly created element will be placed under current selected node *,info,JMeter
Newly created element will be placed under first AbstractThreadGroup node *,info,JMeter
"Error creating test plan from cURL command:*, error:*",error,JMeter
Error creating test plan from cURL command list:*,error,JMeter
Parsed CURL command * into *,info,JMeter
"Error creating test plan from line * of file, command:*, error:*",error,JMeter
"Error creating test plan from cURL command:*, error:*",error,JMeter
 Running up named: ,debug,JMeter
"RegExUserParameters element: * => Referenced RegExp was not found, no parameter will be changed",info,JMeter
"RegExUserParameters element: * => changed parameter: * = *, was: *",debug,JMeter
Can't apply HTML Link Parser when the previous sampler run is not an HTTP Request.,info,JMeter
Check for matches against: ,debug,JMeter
Selected: ,debug,JMeter
No matches found,debug,JMeter
Modifying argument: ,debug,JMeter
Problem adding Argument,error,JMeter
Just set argument to values:  |  = ,debug,JMeter
Potential Form match: ,debug,JMeter
Matched!,debug,JMeter
Potential <a href> match: ,debug,JMeter
Matched!,debug,JMeter
Bad URL ,warn,JMeter
Potential <frame src> match: ,debug,JMeter
Matched!,debug,JMeter
Bad URL ,warn,JMeter
Constructor only intended for use in testing,warn,JMeter
$$$Empty Message$$$,warn,JMeter
"Error occurred building relative url for: *, message: *",debug,JMeter
Start : getParser,debug,JMeter
getParser : tidy parser created - ,debug,JMeter
End   : getParser,debug,JMeter
Start : getDOM,debug,JMeter
node : ,debug,JMeter
End   : getDOM,debug,JMeter
UTF-8 encoding not supported!,error,JMeter
Start : getParser1,debug,JMeter
getParser1 : tidy parser created - ,debug,JMeter
End : getParser1,debug,JMeter
Start : getDOM1,debug,JMeter
node : ,debug,JMeter
End : getDOM1,debug,JMeter
"Creating URL from Anchor:  | , base: ",debug,JMeter
Some bad HTML ,warn,JMeter
"Error extracting embedded resource URLs from:' | ', probably not text content, message:",debug,JMeter
"Parsed: *, got: *",debug,JMeter
"Failed parsing CSS: *, got null CascadingStyleSheet",warn,JMeter
userAgent is null,info,JMeter
Fetched *,debug,JMeter
Created *,info,JMeter
match groups * *,debug,JMeter
new baseUrl: * - *,debug,JMeter
Can't build base URL from URL * in page *,debug,JMeter
group * - *,debug,JMeter
getSampler: sampler path = *,debug,JMeter
sampler path = *,debug,JMeter
Using encoding * for request body,debug,JMeter
"No encoding found, using JRE default encoding for request body",debug,JMeter
Could not create binary file: *,warn,JMeter
Sampler name naming mode not recognized,debug,JMeter
Sampler name naming mode not recognized,debug,JMeter
Proxy: setting path: *,debug,JMeter
Computed encoding:* for url:*,debug,JMeter
Computed encoding:* for url:*,debug,JMeter
Defaulting to encoding:* for url:*,debug,JMeter
Proxy: setting port: *,debug,JMeter
Proxy: setting method: *,debug,JMeter
Proxy: setting server: *,debug,JMeter
Loading class: *,debug,JMeter
Instantiating: *,debug,JMeter
Registering samplerCreator * for content type:*,debug,JMeter
"A sampler creator was already registered for:*, class:*, it will be replaced",warn,JMeter
Exception registering * with implementation:*,error,JMeter
Exception finding implementations of *,error,JMeter
Could not initialise key store,error,JMeter
Could not initialise key store,error,JMeter
Could not create HTTP(S) Test Script Recorder Proxy daemon,error,JMeter
Sample excluded based on url or content-type: * - *,debug,JMeter
Sample not delivered to Child Sampler Listener based on url or content-type: * - *,debug,JMeter
"Error filling url on authorization, message: *",error,JMeter
"Error parsing BASIC Auth authorization header:'*', decoded value:'*'",error,JMeter
Problem reading root CA from keystore,error,JMeter
No Content-type found for : *,debug,JMeter
Content-type to filter : *,debug,JMeter
"Testing Expression : * on sampleContentType: *, expected to match: *",debug,JMeter
Skipped invalid content pattern: *,warn,JMeter
Creating HTTP Authentication manager for authorization: *,debug,JMeter
Failed to add Authorization Manager to target node: *,error,JMeter
Program error adding timers,error,JMeter
Program error: test script recording target not found.,error,JMeter
Applicable: *,debug,JMeter
Add sample * into controller *,info,JMeter
Error placing sampler,error,JMeter
Error placing sampler,error,JMeter
Cannot add element that lacks the * property as testElement: *TestElement.gui_class,error,JMeter
Skipped invalid pattern: *,warn,JMeter
Invalid variables included for replacement into recorded sample,warn,JMeter
HTTP(S) Test Script Recorder will use the keystore '*' with the alias: '*',info,JMeter
Could not find key with alias *,error,JMeter
Could not open keystore or certificate is not valid * *,error,JMeter
Valid alias found for *,info,JMeter
"Could not read key store *; cause: *, a new one will be created, ensure you install it in browser",warn,JMeter
"Could not open/read key store *, a new one will be created, ensure you install it in browser",warn,JMeter
"Existing ROOT Certificate has expired, a new one will be created, ensure you install it in browser, message: *",warn,JMeter
"Existing ROOT Certificate is not yet valid, a new one will be created, ensure you install it in browser, message: *",warn,JMeter
"Problem reading key store, a new one will be created, ensure you install it in browser, message: *",warn,JMeter
"Creating HTTP(S) Test Script Recorder Root CA in *, ensure you install certificate in your Browser for recording",info,JMeter
Created keystore in *,info,JMeter
Creating entry * in *,info,JMeter
Attempt to create an invalid domain certificate: *,warn,JMeter
* Creating entry * in *,info,JMeter
Could not open expected file or certificate is not valid * *,warn,JMeter
Generating standard keypair in *,info,JMeter
"Could not delete *, this could create issues, stop jmeter, ensure file is deleted and restart again",warn,JMeter
Opened Keystore file: *,debug,JMeter
Loaded Keystore file: *,debug,JMeter
Creating Daemon Socket on port: *,info,JMeter
Test Script Recorder up and running!,info,JMeter
HTTP(S) Test Script Recorder stopped,info,JMeter
HTTP(S) Test Script Recorder stopped,warn,JMeter
* ====================================================================,debug,JMeter
"* Empty request, ignored",debug,JMeter
* Initial request: *,debug,JMeter
* Method CONNECT => SSL,debug,JMeter
"* Start to negotiate SSL connection, host: *",debug,JMeter
"In SSL request, unable to find host and port in CONNECT request: *",error,JMeter
* Problem with SSL certificate for url *? Ensure browser is set to accept the JMeter proxy cert: *,warn,JMeter
* Reparse: *,debug,JMeter
* Empty response to http over SSL. Probably waiting for user to authorize the certificate for *,warn,JMeter
* Execute sample: * and url *,debug,JMeter
* Server Not Found.,warn,JMeter
* Not implemented (probably used https),error,JMeter
* Exception when processing sample,error,JMeter
* Will deliver sample *,debug,JMeter
* Failed to close client socket,error,JMeter
"* No keystore available, cannot record SSL",error,JMeter
* Problem with keystore,error,JMeter
"* Good, already in map, host=* using alias *",debug,JMeter
* KeyStore for SSL loaded OK and put host '*' in map with key (*),info,JMeter
* Problem with SSL certificate,error,JMeter
* Problem with keystore,error,JMeter
* SSL transaction ok with cipher: *,debug,JMeter
* Error in SSL socket negotiation: ,error,JMeter
"* Unable to negotiate SSL transaction, no keystore?",warn,JMeter
* Done writing to client,debug,JMeter
$$$Empty Message$$$,error,JMeter
* Error while closing socket,warn,JMeter
* Exception while writing error,warn,JMeter
"Unsupported charset detected in contentType:'*', will continue processing with default charset",warn,JMeter
Will not guess encoding of url:* as it's binary,debug,JMeter
"* Unable to parse response, could not find any form character set encodings for url:*",debug,JMeter
Client Request Line: '*',debug,JMeter
"rawPostData in default JRE encoding: *, Request: '*'",debug,JMeter
browser request: *,debug,JMeter
"parsed method: *, url/host: *, version: *",debug,JMeter
First Line url: *,debug,JMeter
Successfully built URI from url:* => *,debug,JMeter
"Url ' | ' contains unsafe characters, will escape it, message:",warn,JMeter
Successfully escaped url:'*' to:'*',debug,JMeter
"Error escaping URL:' | ', message:",error,JMeter
First Line url: *,debug,JMeter
Proxy: setting protocol to : *,debug,JMeter
Proxy: setting protocol to https,debug,JMeter
Proxy setting default protocol to: http,debug,JMeter
Parsing html of: *,debug,JMeter
Creating ProxyControlGui,debug,JMeter
creating/configuring model = *,debug,JMeter
Configuring gui with *,debug,JMeter
Change target * in model *,debug,JMeter
Using port * for recording,debug,JMeter
Reinitializing target combo,debug,JMeter
Selecting item * for model * in *,debug,JMeter
Reinitialization complete,debug,JMeter
File * is invalid as no path is defined,warn,JMeter
adding argument: name: * value: * metaData: * contentEncoding: *,debug,JMeter
Unable to get encoded value using encoding *,warn,JMeter
Unexpected protocol: *,warn,JMeter
Existing AuthManager * superseded by *,warn,JMeter
Existing HeaderManager '*' merged with '*',debug,JMeter
    *=*,debug,JMeter
Existing CookieManager * superseded by *,warn,JMeter
Existing KeystoreConfig * superseded by *,warn,JMeter
Existing CacheManager * superseded by *,warn,JMeter
Existing DNSCacheManager * superseded by *,warn,JMeter
Unexpected argument type: * cannot be cast to HTTPArgument,warn,JMeter
"Unable to encode parameter in encoding *, parameter value not included in query string",warn,JMeter
Arg: *,debug,JMeter
Name: * Value: * Metadata: *,debug,JMeter
Ignoring embedded URL match string: *,warn,JMeter
"Concurrent download resources selected, but pool size value is bad. Use default value",warn,JMeter
"Number of parallel downloads set to 1, (sampler name=*)",warn,JMeter
Null URL detected (should not happen),warn,JMeter
Interrupted fetching embedded resources,warn,JMeter
Execution issue when fetching embedded resources,warn,JMeter
Parser for * is *,info,JMeter
"Error escaping URL:'*', message:*",error,JMeter
No user agent extracted from requestHeaders:*,info,JMeter
Initial location: *,debug,JMeter
Location after /. and space transforms: *,debug,JMeter
Location as URL: *,debug,JMeter
Location set to - *,debug,JMeter
Should not happen - could not find MD5 digest,error,JMeter
"Big response, truncating it to * bytes",debug,JMeter
Unknown stream type *,warn,JMeter
Trying httpclient parameters from ,info,JMeter
" httpclient parameters does not exist, trying ",info,JMeter
Cannot read parameters file for HttpClient: ,error,JMeter
Reading httpclient parameters from ,info,JMeter
Defining  |  as  |  ( | ),info,JMeter
Unexpected type:  |  for name ,warn,JMeter
Defining  |  as ,info,JMeter
Error in property:  | = |  ,error,JMeter
Problem loading properties ,error,JMeter
Could not find log parsers.,warn,JMeter
Entered access log sampler bean info,debug,JMeter
found parsers: *,debug,JMeter
couldn't find classes and set up properties,warn,JMeter
Got to end of access log sampler bean info init,debug,JMeter
Store creds * for *,debug,JMeter
Get creds for *,info,JMeter
Invalid URL * in authManager,debug,JMeter
clear creds,debug,JMeter
Setting keepalive to *,debug,JMeter
Sent * bytes,debug,JMeter
Start : sample * method * followingRedirect * depth *,debug,JMeter
Headers in request before:*,debug,JMeter
"Headers in request after:*, in localContext#request:*",debug,JMeter
ResponseHeadersSize=* Content-Length=* Total=*,debug,JMeter
IOException,debug,JMeter
Overwriting request old headers: *,debug,JMeter
RuntimeException,debug,JMeter
Extracted from HttpContext user token:* storing it as JMeter variable:*__jmeter.U_T__,debug,JMeter
"Found user token:* as JMeter variable:*, storing it in HttpContext__jmeter.U_T__",debug,JMeter
Storing in HttpContext the user token: *,debug,JMeter
Can't execute httpRequest with subject: *,error,JMeter
Created new HttpClient: @* *,debug,JMeter
Reusing the HttpClient: @* *,debug,JMeter
"Building multipart with:getDoBrowserCompatibleMultipart(): *, with charset:*, haveContentEncoding:*",debug,JMeter
notifyFirstSampleAfterLoopRestart called with config(httpclient.reset_state_on_thread_group_iteration=*),debug,JMeter
"Thread Group is configured to simulate a returning visitor on each iteration, ignoring property value *",debug,JMeter
"Thread Group is configured to simulate a new visitor on each iteration, using property value *",debug,JMeter
Thread state will be reset ?: *,debug,JMeter
Thread Finished,debug,JMeter
Could not abort pending request,warn,JMeter
Problem creating the SSLManager: ,warn,JMeter
Problem setting the SSLManager for the connection: ,warn,JMeter
"Content-Length: 0, not reading http-body",info,JMeter
readResponse: *,error,JMeter
Cause: *,error,JMeter
"Error Response Code: *, Server sent no Errorpage",info,JMeter
Error Response Code: *,info,JMeter
readResponse: *,error,JMeter
Cause: *,error,JMeter
"Start : sample *, method *, followingRedirect *, depth *",debug,JMeter
"Can't connect after * retries, message: *",error,JMeter
"Bind exception, try again",debug,JMeter
"Connection failed, giving up",debug,JMeter
ResponseCode==-1; parsed * as *,warn,JMeter
ResponseCode==-1; could not parse * hdr: *,warn,JMeter
ResponseCode==-1 & null ResponseMessage. Header(0)= * ,warn,JMeter
"Response headersSize=*, bodySize=*, Total=*",debug,JMeter
End : sample,debug,JMeter
Error closing channel,debug,JMeter
Creating ResourcesDownloader with keepalive_inseconds : *,info,JMeter
the pool executor workqueue is not empty size=*,warn,JMeter
Content of workqueue is not an instance of Future,warn,JMeter
PoolSize=* LargestPoolSize=*,debug,JMeter
Interrupted while waiting for resource downloads : cancelling remaining tasks,debug,JMeter
Stopping current thread,info,JMeter
Sampling failure,warn,JMeter
No log file specified,error,JMeter
$$$Empty Message$$$,error,JMeter
Couldn't instantiate filter '*',warn,JMeter
Could not clone cloneable filter,warn,JMeter
Setting up HTTPS TrustAll Socket Factory,info,JMeter
"Decoding name, calling URLDecoder.decode with '*' and contentEncoding: '*'",debug,JMeter
"Decoding value, calling URLDecoder.decode with '*' and contentEncoding: '*'",debug,JMeter
* encoding not supported!,error,JMeter
Problem creating samples,error,JMeter
Error reading log file,error,JMeter
Problem with pattern: ,error,JMeter
SessionFilter wait interrupted,info,JMeter
$$$Empty Message$$$,error,JMeter
Problem creating samples,error,JMeter
Error reading log file,error,JMeter
parsing line: ,debug,JMeter
filter is not null,debug,JMeter
line was not filtered,debug,JMeter
Line was filtered,debug,JMeter
filter was null,debug,JMeter
$$$Empty Message$$$,warn,JMeter
"Error decoding query, maybe your request parameters should be encoded:",warn,JMeter
Exception getting interfaces.,debug,JMeter
JavaSamplerClient doesn't implement  | getDefaultParameters.  Default parameters won't  | be shown.  Please update your client class: ,warn,JMeter
Error getting argument list for ,error,JMeter
"Error creating class:' | ' in JavaSampler  | , check for a missing jar in your jmeter 'search_paths' and 'plugin_dependency_paths' properties",error,JMeter
"Problem in JSR223 script *, message: *",error,JMeter
BeanShell Jar missing? *,error,JMeter
Exception executing script. *,warn,JMeter
* : *,debug,JMeter
Value for parameter ' | ' not an integer: ' | '.  Using default: ' | '.,warn,JMeter
Value for parameter ' | ' not a long: ' | '.  Using default: ' | '.,warn,JMeter
: setupTest,debug,JMeter
: teardownTest,debug,JMeter
* *,debug,JMeter
BSF error,warn,JMeter
Problem evaluating the script,warn,JMeter
Created class: *. Uses tearDownTest: ,info,JMeter
*	Exception initialising: ,error,JMeter
*	Creating Java Client,debug,JMeter
*	Created:	*@*,debug,JMeter
*	Exception creating: *,error,JMeter
*	testStarted,debug,JMeter
*	testStarted(*),debug,JMeter
*	testEnded,debug,JMeter
*	runTest,debug,JMeter
Error closing pool: *,error,JMeter
Closing pool: *@*,debug,JMeter
Error closing pool:*,error,JMeter
JDBC data source already defined for: *,error,JMeter
$$$Empty Message$$$,error,JMeter
$$$Empty Message$$$,debug,JMeter
$$$Empty Message$$$,debug,JMeter
$$$Empty Message$$$,debug,JMeter
Preinitializing the connection pool: *@*,debug,JMeter
Error preinitializing the connection pool: *@*,error,JMeter
PoolConfiguration:*,debug,JMeter
Setting transaction isolation: *@*,debug,JMeter
Could not set transaction isolation: *@*,error,JMeter
Storing pool: *@*,debug,JMeter
Illegal transaction isolation configuration ' | ',warn,JMeter
SQL Problem in *: *,warn,JMeter
IO Problem in *: *,warn,JMeter
Execution Problem in *: *,warn,JMeter
Error during close: ,error,JMeter
Error during close: ,error,JMeter
Error during close: ,error,JMeter
Error during close: ,error,JMeter
context.getEnvironment() returned null (should not happen according to javadoc but non compliant implementation can return this),warn,JMeter
context.getEnvironment() not supported by implementation ,warn,JMeter
Adding property [ | = | ],debug,JMeter
<init> complete,debug,JMeter
start(),debug,JMeter
stop(),debug,JMeter
close(),debug,JMeter
"Stopping connection throws exception, message: *",warn,JMeter
Could not add message to queue,warn,JMeter
authentication properties set,info,JMeter
$$$Empty Message$$$,error,JMeter
InitialContextFactory.close() called and Context instances cleaned up,info,JMeter
Setting jms property value: *,debug,JMeter
Can't extract message headers,warn,JMeter
SubscriberSampler.initListenerClient called,debug,JMeter
SubscriberSampler.initReceiveClient called,debug,JMeter
Problem starting subscriber,warn,JMeter
Error [*] *,warn,JMeter
Problem stopping subscriber,warn,JMeter
Interrupted *,warn,JMeter
$$$Empty Message$$$,error,JMeter
Could not initialise client,error,JMeter
Point-to-point mode: *,debug,JMeter
$$$Empty Message$$$,warn,JMeter
isBrowseOnly,debug,JMeter
isClearQueue,debug,JMeter
isOneWay,debug,JMeter
isRead,debug,JMeter
NO TEMP QUEUE,debug,JMeter
Create temp message,debug,JMeter
Message: *,debug,JMeter
Error browsing queue * with selector * and configured timeout *,error,JMeter
Error extracting content from message,error,JMeter
Error browsing messages on the queue *,error,JMeter
Error clearing queue *,error,JMeter
$$$Empty Message$$$,error,JMeter
Session created,debug,JMeter
Starting connection,debug,JMeter
Connection started,debug,JMeter
$$$Empty Message$$$,error,JMeter
Using InitialContext [*],debug,JMeter
Using Provider [*],debug,JMeter
Empty JNDI properties,debug,JMeter
Number of JNDI properties: *,debug,JMeter
Initial Context Properties,debug,JMeter
*=*,debug,JMeter
context.getEnvironment() returned null (should not happen according to javadoc but non compliant implementation can return this),warn,JMeter
context.getEnvironment() not supported by implementation ,warn,JMeter
Thread started *,debug,JMeter
"JMSSampler: [*], hashCode=[*]",debug,JMeter
"QCF: [*], sendQueue=[*]",debug,JMeter
Timeout = [*],debug,JMeter
Use temporary queue =[*],debug,JMeter
Reply queue         = [*],debug,JMeter
Thread ended *,debug,JMeter
Error closing executor *,error,JMeter
Failed parsing number of samples to aggregate,debug,JMeter
Error closing sender,error,JMeter
Error closing receiver,error,JMeter
Error deleting tempQueue *,error,JMeter
* will wait for reply * started on *,debug,JMeter
Waiting infinitely for message,debug,JMeter
Timeout * ms reached before getting a reply message,debug,JMeter
* done waiting for * on * ended on *,debug,JMeter
Interrupt exception caught,warn,JMeter
PublisherSampler.testEnded called,debug,JMeter
PublisherSampler.initClient called,debug,JMeter
REQ_ID [*],debug,JMeter
RPL_ID [*] for holder *,debug,JMeter
* releasing latch : *,debug,JMeter
* released latch : *,debug,JMeter
Failed to match reply: *,debug,JMeter
GET_ID [*] for *,debug,JMeter
Message with * not found.,debug,JMeter
creating receiver WITH authorisation credentials. UseResMsgId=*,info,JMeter
creating receiver without authorisation credentials. UseResMsgId=*,info,JMeter
Receiver - ctor. Creating consumer with JMS Selector:*,debug,JMeter
Receiver - ctor. Starting connection now,debug,JMeter
Receiver - ctor. Connection to messaging system established,info,JMeter
Received message with correlation id null. Discarding message ...,warn,JMeter
Error handling receive,error,JMeter
Sending message and waiting for response in Temporary queue with timeout * ms (0==infinite),debug,JMeter
"removing row, size = ",debug,JMeter
got to here,debug,JMeter
Removing row: ,debug,JMeter
Setting currentpos to ,debug,JMeter
Problem deleting the keystore ' | ',warn,JMeter
Problem deleting the certificate file ' | ',warn,JMeter
Problem deleting the certificate file ' | ',warn,JMeter
"If problems occur when recording SSL, delete the files manually and retry.",warn,JMeter
"Failed creating  | , check 'keytool' utility in path is available and points to a JDK >= 7",warn,JMeter
checkKeyTool:status=,debug,JMeter
$$$Empty Message$$$,debug,JMeter
"Exception checking for keytool existence, will return false, try another way.",info,JMeter
Exception is: ,debug,JMeter
Command was interrupted\n,error,JMeter
"Timeout reached while checking for keytool existence, will return false, try another way.",info,JMeter
Error writing stream,warn,JMeter
Applying font scale factor: *,info,JMeter
Header count=* but classes count=*,warn,JMeter
Header count=* but writeFunctor count=*,warn,JMeter
Header count=* but readFunctor count=*,warn,JMeter
Adding row value: *,debug,JMeter
Getting row value,debug,JMeter
Cannot create instance of class *,error,JMeter
* is attempting to use nonexistent *,warn,JMeter
* is attempting to use nonexistent *,warn,JMeter
$$$Empty Message$$$,error,JMeter
Failed to getText,error,JMeter
$$$Empty Message$$$,debug,JMeter
$$$Empty Message$$$,debug,JMeter
$$$Empty Message$$$,info,JMeter
$$$Empty Message$$$,info,JMeter
$$$Empty Message$$$,warn,JMeter
$$$Empty Message$$$,warn,JMeter
$$$Empty Message$$$,error,JMeter
$$$Empty Message$$$,error,JMeter
$$$Empty Message$$$,error,JMeter
$$$Empty Message$$$,error,JMeter
$$$Empty Message$$$,error,JMeter
$$$Empty Message$$$,error,JMeter
$$$Empty Message$$$,warn,JMeter
$$$Empty Message$$$,info,JMeter
$$$Empty Message$$$,debug,JMeter
$$$Empty Message$$$,error,JMeter
$$$Empty Message$$$,error,JMeter
$$$Empty Message$$$,warn,JMeter
$$$Empty Message$$$,info,JMeter
$$$Empty Message$$$,debug,JMeter
$$$Empty Message$$$,error,JMeter
$$$Empty Message$$$,warn,JMeter
doCreateMethod() using  | class= |  types: ,debug,JMeter
$$$Empty Message$$$,debug,JMeter
$$$Empty Message$$$,debug,JMeter
"findClassesThatExtend with searchPathsOrJars : *, superclass : * innerClasses : * annotations: * contains: *, notContains: *",debug,JMeter
findClasses with searchPathsOrJars : * and classFilter : *,debug,JMeter
listClasses.size()=*,debug,JMeter
listClasses : *,debug,JMeter
"Can not open the jar *, message: *",warn,JMeter
* is not a folder,warn,JMeter
"Error filtering class *, it will be ignored",error,JMeter
caught exception,info,JMeter
caught exception,info,JMeter
ClassNotFoundException:: *,warn,JMeter
Trying to find constructor with one String parameter returned error: *,info,JMeter
Trying to find empty constructor returned error: *,info,JMeter
No empty constructor nor string constructor found for class:*,error,JMeter
Error instantiating class:*:*,error,JMeter
$$$Empty Message$$$,warn,JMeter
Using secure connection with trustAll,debug,JMeter
prov_url= *,info,JMeter
Cannot disconnect null context,info,JMeter
Ldap client disconnect - ,warn,JMeter
"searchBase=*, scope=*, countlim=*, timelim=*, attrs=*, retobj=*, deref=*, filter=*",debug,JMeter
ddn and newDn= *@@@@*,debug,JMeter
Ldap client - ,error,JMeter
Ldap client - ,error,JMeter
Invalid opCode: *,warn,JMeter
Closing previous context for thread: *,warn,JMeter
context and LdapExtClients removed,info,JMeter
performing test: *,debug,JMeter
Tidying old Context for thread: *,warn,JMeter
load local truststore - try to load truststore from: ,info,JMeter
load local truststore -Failed to load truststore from: ,info,JMeter
load local truststore -Attempting to read truststore from:  ,info,JMeter
"load local truststore -Failed to load truststore from:  | . Local truststore not available, aborting execution.",info,JMeter
$$$Empty Message$$$,debug,JMeter
$$$Empty Message$$$,debug,JMeter
Error while preparing message,warn,JMeter
Error occurred trying to save request info,warn,JMeter
Failed to set result response data,warn,JMeter
$$$Empty Message$$$,warn,JMeter
$$$Empty Message$$$,warn,JMeter
loading file with relative path: ,debug,JMeter
file path set to: ,debug,JMeter
load local truststore - try to load truststore from: *,info,JMeter
load local truststore -Failed to load truststore from: *,info,JMeter
load local truststore -Attempting to read truststore from: *,info,JMeter
"load local truststore -Failed to load truststore from: *. Local truststore not available, aborting execution.",info,JMeter
Problem setting ssl/tls protocols for mail,error,JMeter
Using ssl/tls protocols for mail: *,info,JMeter
transport closed,debug,JMeter
message sent,debug,JMeter
Message delivered,debug,JMeter
Message not delivered,debug,JMeter
Message partially delivered,debug,JMeter
 testStarted,debug,JMeter
options : ,debug,JMeter
 has already been defined.,warn,JMeter
  is being defined.,debug,JMeter
 testEnded,debug,JMeter
$$$Empty Message$$$,debug,JMeter
$$$Empty Message$$$,debug,JMeter
"username:  | , password:  | , database: ",debug,JMeter
authenticated: ,debug,JMeter
clearing,debug,JMeter
$$$Empty Message$$$,debug,JMeter
$$$Empty Message$$$,debug,JMeter
"database:  | , script: ",debug,JMeter
Result : ,debug,JMeter
 ( |   |  ,debug,JMeter
Using default directory:,debug,JMeter
Using configured directory:,debug,JMeter
Will run :  |  using working directory: |  with environment: ,debug,JMeter
Ran :  |  using working directory:  |  with execution environment:  |  => ,debug,JMeter
Error parsing timeout field value:,error,JMeter
Using eomByte=*,info,JMeter
Wrote: ,debug,JMeter
"Deprecated method, use read(is, sampleResult) instead",warn,JMeter
Read:  | \n,debug,JMeter
Wrote:  |  bytes,debug,JMeter
"Deprecated method, use read(is, sampleResult) instead",warn,JMeter
"Incomplete message read, expected: * got: *",warn,JMeter
Read:  | \n,debug,JMeter
Created *,debug,JMeter
* Reusing connection *,debug,JMeter
Created new connection *,debug,JMeter
Unknown host for *,warn,JMeter
Could not create socket for *,warn,JMeter
"* Timeout=*, NoDelay=*",debug,JMeter
Could not set timeout or nodelay for *,warn,JMeter
Could not find protocol class '*',error,JMeter
Using eolByte=*,info,JMeter
* Created: *@*,debug,JMeter
* Exception creating: * ,error,JMeter
  |   |  ,debug,JMeter
$$$Empty Message$$$,error,JMeter
$$$Empty Message$$$,error,JMeter
Thread Started,debug,JMeter
Using Protocol Handler: *,debug,JMeter
* Closing connection *,debug,JMeter
Error closing socket *,warn,JMeter
Thread Finished,debug,JMeter
Using eolByte=*,info,JMeter
Using platform default charset:*,info,JMeter
Using charset:*,info,JMeter
WriteS: *,debug,JMeter
WriteIS: *,debug,JMeter
Read: * *,debug,JMeter
Conversation * has expired for *,info,wicket
Activating conversation *,debug,wicket
Unable to restore conversation with id *,info,wicket
Unable to restore conversation,debug,wicket
Propagating non-transient conversation * via page parameters of handler *,debug,wicket
Detaching transient conversation * via meta of page instance *,debug,wicket
Propagating non-transient conversation * via meta of page instance *,debug,wicket
Propagating non-transient conversation * via url,debug,wicket
Deactivating conversation *,debug,wicket
Auto-began conversation * for page *,debug,wicket
Auto-ended conversation * for page *,debug,wicket
Firing Detach event *,debug,wicket
Conversation * has expired for *,info,wicket
Activating conversation *,debug,wicket
There is no active context for the requested scope!,debug,wicket
Propagating non-transient conversation * via url,debug,wicket
$$$Empty Message$$$,debug,wicket
Auto-began conversation '*' for page '*',debug,wicket
Auto-ended conversation '*' for page '*',debug,wicket
Firing Detach event *,debug,wicket
Conversation * has expired for *,info,wicket
Rendered *,debug,wicket
"Page ' | ' is not stateless because it is not bookmarkable,  | but the stateless hint is set to true!",warn,wicket
Page '*' is not stateless because of component with path '*'.,debug,wicket
Component * wasn't rendered but might have a transparent parent.,debug,wicket
Page not allowed to render: ,debug,wicket
"ending request for page  | , request ",debug,wicket
Tried to retrieve a localized string for a component that has not yet been added to the page. This can sometimes lead to an invalid or no localized resource returned. Make sure you are not calling Component#getString() inside your Component's constructor. Offending component: *,warn,wicket
Property found in cache: ' | '; Component: ' | '; value: ',debug,wicket
Locate property: key: ' | '; Component: ',debug,wicket
Property not found; key: ' | '; Component: ',debug,wicket
Exception getting size for component ,error,wicket
Begin render *,debug,wicket
End render *,debug,wicket
Error while cleaning up after exception,error,wicket
$$$Empty Message$$$,warn,wicket
$$$Empty Message$$$,warn,wicket
Component is not connected to a Page. Cannot register the component as being rendered. Component: ,error,wicket
internalRenderHead: *,debug,wicket
Error while building toString(),warn,wicket
$$$Empty Message$$$,warn,wicket
$$$Empty Message$$$,warn,wicket
Replacing parent  |  with ,debug,wicket
[*] destroy: *,info,wicket
[*] init: *,info,wicket
[*] init: *,info,wicket
"PageAccessSynchronizer created outside of application thread, using default timeout: *",warn,wicket
An error occurred while handling a previous error: ,error,wicket
unexpected exception when handling another exception: ,error,wicket
"Connection lost, give up responding.",debug,wicket
$$$Empty Message$$$,debug,wicket
Unexpected error occurred,error,wicket
component not enabled or visible; ignoring call. Component: ,info,wicket
behavior not enabled; ignore call. Behavior * at component *,warn,wicket
registered listener interface ,info,wicket
Add  |  to ,debug,wicket
internalAdd  |  to ,debug,wicket
Replacing  |  in ,debug,wicket
$$$Empty Message$$$,error,wicket
"AjaxFormComponentUpdatingBehavior is not supposed to be added in the form component at path: \ | Use the AjaxFormChoiceComponentUpdatingBehavior instead, that is meant for choices/groups that are not one component in the html but many",warn,wicket
unexpected invocation of #onError() on *,warn,wicket
unexpected invocation of #onSubmit() on *,warn,wicket
unexpected invocation of #onAfterSubmit() on *,warn,wicket
unexpected invocation of #onSubmit() on *,warn,wicket
unexpected invocation of #onAfterSubmit() on *,warn,wicket
unexpected invocation of #onError() on *,warn,wicket
ClassResolver '*' cannot find class: '*',debug,wicket
clzLocation=,debug,wicket
Watching changes of class ,info,wicket
"Class file  |  has changed, reloading",info,wicket
Could not notify listener,error,wicket
Class file does not exist: ,debug,wicket
Could not locate class ,debug,wicket
"Error decrypting login cookie: *. The cookie will be deleted. Possible cause is that a session-relative encryption key was used to encrypt this cookie while this decryption attempt is happening in a different session, eg user coming back to the application after session expiration",info,wicket
An IRequestListener was called but its page/component(*) couldn't be resolved. Scheduling re-create of the page and ignoring the listener interface...,debug,wicket
component not enabled or visible; ignoring call. Component: ,info,wicket
behavior not enabled; ignore call. Behavior * at component *,warn,wicket
Url '*' has been decrypted to '*',debug,wicket
Error decrypting URL,error,wicket
Error decrypting encrypted request listener query parameter,error,wicket
Cannot set new value  |  at index  |  for array holding elements of class ,warn,wicket
Can't find setter method corresponding to ,debug,wicket
Null setMethod,warn,wicket
Cannot set new value  |  at index ,warn,wicket
Cannot find setter corresponding to ,debug,wicket
Cannot find setter corresponding to ,debug,wicket
Null setMethod,warn,wicket
Cannot set new value ,warn,wicket
Cannot set field  |  to ,warn,wicket
Cannot find field  | .,debug,wicket
Cannot find getter  | .,debug,wicket
Cannot find method  | .,debug,wicket
Could not resolve class [ | ],warn,wicket
"Class not found by using objects own classloader, trying the IClassResolver",debug,wicket
using  |  for calculating object sizes,info,wicket
"Error delegating to Externalizable : *, path: *",warn,wicket
"error delegating to writeObject : *, path: *",warn,wicket
Object with type '*' wont be checked because its type is excluded (*),debug,wicket
getLastModified() for '*' failed: *,warn,wicket
failed to retrieve last modified timestamp,warn,wicket
Attempting to locate resource '*' using finder'*',debug,wicket
Component '*' with a parent '*' is passed for standalone rendering. It is recommended to render only orphan components because they are not cleaned up/detached after the rendering.,warn,wicket
Cannot register folder ' | ' to be watched.,warn,wicket
Registering folder '*' to the watching service with kinds: *,debug,wicket
Adding feedback message '*',debug,wicket
Removing from cache: ,debug,wicket
Removed from cache: ,debug,wicket
Removed from watcher: ,debug,wicket
Removed derived markup from cache: ,debug,wicket
Load markup: cacheKey=,debug,wicket
Markup not found: ,debug,wicket
Remove markup from watcher: ,debug,wicket
Loading markup from ,debug,wicket
Merge markup: derived markup:  | ; base markup: ,debug,wicket
Merge markup: ,debug,wicket
Please use component.setMarkupId(String) to change the tag's 'id' attribute.,warn,wicket
You are using a non-standard namespace name: '*',debug,wicket
: | . It is safer to use it,debug,wicket
"Markup file not loaded, since the markup type is not yet available: *",debug,wicket
Markup not found: ,error,wicket
Markup not found: ,error,wicket
Error while reading the markup ,error,wicket
Error while reading the markup ,error,wicket
Error while reading the markup ,error,wicket
IE CSS engine doesn't support dynamically injected links in conditional comments. See the javadoc of IHeaderResponse for alternative solution.,warn,wicket
"A HeaderItem '*' was rendered to the filtering header response, but did not match any filters, so it put in the <head>.",debug,wicket
Access denied to shared (static) resource because it is a Wicket markup file: ,warn,wicket
Access denied to shared (static) resource because of the file extension: ,warn,wicket
Access denied to shared (static) resource because of the file name: ,warn,wicket
Access to parent directories via '..' is by default disabled for shared resources: ,warn,wicket
Access to root directory is by default disabled for shared resources: ,warn,wicket
Access denied to shared (static) resource: ,warn,wicket
header/body check throws exception,error,wicket
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^,error,wicket
You probably forgot to add a <body> or <head> tag to your markup since no Header Container was \n | found but components were found which want to write to the <head> section.\n,error,wicket
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^,error,wicket
$$$Empty Message$$$,warn,wicket
Form with id '*' is multipart. It should use method 'POST'!,warn,wicket
IFormValidator in form ` | ` depends on a component that has been removed from the page or is no longer visible.  | Offending component id ` | `.,warn,wicket
Component: * is referenced via a wicket:for attribute but does not have its outputMarkupId property set to true,warn,wicket
$$$Empty Message$$$,warn,wicket
An error occurred while trying to modify the collection attached to ,debug,wicket
An error occurred while trying to set the collection attached to ,debug,wicket
"tag:  | , stack: ",debug,wicket
"wicket:container with id '*' has attribute '*' in markup, which will be ignored in deployment mode",warn,wicket
$$$Empty Message$$$,warn,wicket
$$$Empty Message$$$,error,wicket
Repeater '*' has multiple children with the same component id: '*',warn,wicket
No value found for wicket:message tag with key: *,warn,wicket
$$$Empty Message$$$,warn,wicket
$$$Empty Message$$$,warn,wicket
Did not find corresponding java class: ,warn,wicket
Did not find corresponding java class: ,warn,wicket
Added autolink ,debug,wicket
It is not a good idea to reference the Session instance in models directly as it may lead to serialization problems. If you need to access a property of the session via the model use the page instance as the model object and 'session.attribute' as the path.,warn,wicket
It is not a good idea to reference non-serializable * in a model directly as it may lead to serialization problems.,warn,wicket
removed transient object for '*',debug,wicket
loaded transient object '*' for '*',debug,wicket
Component '*' not rendered because it was already removed from page,warn,wicket
Component '*' not cannot be updated because it was already removed from page,warn,wicket
Only methods that can be called on IHeaderResponse outside renderHead() are #render(OnLoadHeaderItem) and #render(OnDomReadyHeaderItem),debug,wicket
'*' attempting to acquire lock to page with id '*',debug,wicket
* acquired lock to page *,debug,wicket
"Thread '*' failed to acquire lock to page with id '*', attempted for * out of allowed *. The thread that holds the lock has name '*'.",warn,wicket
'*' released lock to page with id '*',debug,wicket
"lock for page with id * no longer locked by *, falling through",debug,wicket
* waiting for lock to page * for *,debug,wicket
'*' notifying blocked threads,debug,wicket
An error occurred while checking whether a page is stateless. Assuming it is stateful.,warn,wicket
Page * cannot be serialized. See previous logs for possible reasons.,warn,wicket
$$$Empty Message$$$,error,wicket
Returning the data of a non-stored entry with sessionId '*' and pageId '*',debug,wicket
Returning the data of a stored entry with sessionId '*' and pageId '*',debug,wicket
Storing synchronously page with id '*' in session '*',debug,wicket
$$$Empty Message$$$,error,wicket
PageSavingRunnable:: Interrupted...,debug,wicket
PageSavingRunnable:: Saving asynchronously: *...,debug,wicket
Cannot create file store folder for some reason.,warn,wicket
Destroying...,debug,wicket
Destroyed.,debug,wicket
Returning data* for page with id '*' in session with id '*',debug,wicket
Removing data for page with id '*' in session with id '*',debug,wicket
Removing data for pages in session with id '*',debug,wicket
Storing data for page with id '*' in session with id '*',debug,wicket
Couldn't load DiskDataStore index from file  | .,error,wicket
Couldn't write DiskDataStore index to file  | .,error,wicket
Error writing to a channel ,error,wicket
Cannot save page with id '*' because the data file cannot be opened.,warn,wicket
Error reading from file channel ,error,wicket
$$$Empty Message$$$,error,wicket
Page * cannot be serialized. See previous logs for possible reasons.,warn,wicket
PageSavingRunnable:: Interrupted...,debug,wicket
PageSavingRunnable:: Saving asynchronously: *...,debug,wicket
$$$Empty Message$$$,error,wicket
Returning the page of a non-stored entry with session id '*' and page id '*',debug,wicket
Returning the page of a stored entry with session id '*' and page id '*',debug,wicket
Offered for storing asynchronously page with id '*' in session '*',debug,wicket
Storing synchronously page with id '*' in session '*',debug,wicket
$$$Empty Message$$$,error,wicket
Loaded '*' bytes for page with id '*' in session '*',debug,wicket
Removed page '*' in session '*',debug,wicket
Removed all pages in session '*',debug,wicket
Stored '*' bytes for page '*' in session '*',debug,wicket
Cannot store the data for page with id '*' in session with id '*',error,wicket
Evicted page with id '*' from the HttpSessionDataStore,debug,wicket
Exception while determining the size of the session in the request logger: ,error,wicket
Request Source URI: *,debug,wicket
"CSRF listener is disabled, no checks performed",trace,wicket
"Targeted page * was opted out of the CSRF origin checks, allowed",debug,wicket
"Resolved handler * doesn't target an action on a page, no CSRF check performed",trace,wicket
"Source URI not present in request, *",debug,wicket
"Source URI conflicts with request origin, *",debug,wicket
"Origin * matched whitelisted origin *, request accepted",trace,wicket
Origin: * not parseable as an URI. Whitelisted-origin check skipped.,debug,wicket
"Invalid URI provided: *, marked conflicting",debug,wicket
"CSRF Origin * was whitelisted, allowed for page *",debug,wicket
"CSRF Origin * matched requested resource, allowed for page *",debug,wicket
"Possible CSRF attack, request URL: *, Origin: *, action: allowed",info,wicket
"Possible CSRF attack, request URL: *, Origin: *, action: suppressed",info,wicket
"Possible CSRF attack, request URL: *, Origin: *, action: aborted with error * *",info,wicket
SecurityManager doesn't allow to read the configuration type from the system properties. The configuration type will be read from the web.xml.,warn,wicket
$$$Empty Message$$$,info,wicket
"storeBufferedResponse needs a valid session id to store the response, but a null one was found. Please report the problem to dev team and try to reproduce it in a quickstart project.",error,wicket
$$$Empty Message$$$,info,wicket
Ignoring request *,debug,wicket
"Unable to determine filter path from filter init-param, web.xml, or servlet 3.0 annotations. Assuming user will set filter path manually by calling setFilterPath(String)",warn,wicket
The initialization of an application with name '%s' has failed.,error,wicket
Unable to destroy after initialization failure,error,wicket
"Multiple url patterns defined for Wicket filter/servlet, using the first: *",warn,wicket
Unexpected markup found:  | ...,error,wicket
Found tag < | /> was expected to have  |  child elements,error,wicket
Found closing tag </ | > when there are no  | tags currently open,error,wicket
Found closing tag </ | > when we expecting  | the closing tag </ | > instead,error,wicket
Found closing tag </ | > but we were  | expecting to find another child element: ,error,wicket
Unexpected parsing error,error,wicket
Found comment ' | ' does not match  | expected comment ' | ',error,wicket
Found comment ' | ' was not expected.  | We were expecting: ,error,wicket
Found comment ' | ' was not expected.  | We were not expecting any more elements within the current tag,error,wicket
Found tag < | > does not match  | expected tag < | >,error,wicket
Tag < | > was expected to have a ' | ' attribute  | but this was not present,error,wicket
Attribute  |  was expected but not found,error,wicket
The value ' | ' of attribute ' | ' of tag < | > was expected to match the pattern ' | ' but it does not,error,wicket
Tag < | > should not have an attributed named ' | ',error,wicket
Found tag < | > was not expected.  | We were expecting: ,error,wicket
Found tag < | > was not expected.  | We were not expecting any more elements within the current tag,error,wicket
Found text ' | ' does not match  | expected text ' | ',error,wicket
Found text ' | ' was not expected.  | We were expecting: ,error,wicket
Found text ' | ' was not expected.  | We were not expecting any more elements within the current tag,error,wicket
WARNING: The webapp root directory is invalid: ,warn,wicket
$$$Empty Message$$$,error,wicket
$$$Empty Message$$$,error,wicket
$$$Empty Message$$$,info,wicket
$$$Empty Message$$$,error,wicket
determined user agent: *,debug,wicket
"Incoming request uri= |  with originalSecure=' | ', remoteAddr=' | ' will be seen with newSecure=' | '",debug,wicket
filterName/application key set to *,debug,wicket
"could not set Wicket session: key  |  not found in http session for  | , | , or http session does not exist",debug,wicket
will use * as the session key to get the Wicket session,debug,wicket
Skip XForwardedFilter for request  |  with remote address ,debug,wicket
"Incoming request  |  with originalRemoteAddr ' | ', originalRemoteHost=' | ', originalSecure=' | ', originalScheme=' | ', original[ | ]=' | , original[ | ]=' | ' will be seen as newRemoteAddr=' | ', newRemoteHost=' | ', newScheme=' | ', newSecure=' | ', new[ | ]=' | , new[ | ]=' | '",debug,wicket
"Calculating context relative path from: context path '*', filterPrefix '*', uri '*'",debug,wicket
"No suitable handler found for URL *, falling back to container to process this request",debug,wicket
Error during request processing. URL=,error,wicket
Exception retry count exceeded,error,wicket
********************************,warn,wicket
Handling the following exception,warn,wicket
********************************,warn,wicket
Exception occurred during onEndRequest,error,wicket
Error detaching RequestCycle,error,wicket
"* exception handlers available for exception *, using the first handler",debug,wicket
Falling back to Redirect_To_Buffer render strategy because none of the conditions  | matched. Details: ,debug,wicket
$$$Empty Message$$$,debug,wicket
$$$Empty Message$$$,debug,wicket
Unable to close the resource stream,warn,wicket
Error while compressing the content,error,wicket
$$$Empty Message$$$,warn,wicket
Error accessing object property,warn,wicket
Couldn't close ResourceStream,error,wicket
* cannot be added to the registry.,warn,wicket
A ResourceReference wont be created for a resource with key [*] because it cannot be located.,warn,wicket
A resource with name '*' contains the version prefix '*' so the un-decoration will not work. Either use a different version prefix or rename this resource.,error,wicket
unable to compute hash for ,warn,wicket
unable to locate resource for ,warn,wicket
Loading properties files from '*' with loader '*',debug,wicket
Unable to find resource ,warn,wicket
A properties files has changed. Removing all entries  | from the cache. Resource: ,info,wicket
PropertiesReloadListener has thrown an exception: ,error,wicket
$$$Empty Message$$$,debug,wicket
$$$Empty Message$$$,debug,wicket
$$$Empty Message$$$,warn,wicket
$$$Empty Message$$$,warn,wicket
key: ' | '; class: ' | '; locale: ' | '; Style: ' | '; Variation: ',debug,wicket
component: ' | '; key: ',debug,wicket
ms server time taken for request  |  response size: ,info,wicket
ms server time taken for request  |  response size: ,info,wicket
Empty src attribute found in response:,warn,wicket
[...] | [...],warn,wicket
An invalid character '*' found at position '*' in '*',debug,wicket
Dropping character for codePoint '0x%X' at position '%d',debug,wicket
Error serializing object  |  [object= | ],error,wicket
"Class not found by the object outputstream itself, trying the IClassResolver",debug,wicket
"Proxy Class not found by the object outputstream itself, trying the IClassResolver",debug,wicket
error writing object  | : ,error,wicket
Session unbound: *,debug,wicket
Wicket application with name '*' not found.,debug,wicket
Found constructor for Page of type '*' and argument of type '*'.,debug,wicket
Page of type '*' has not visible constructor with an argument of type '*'.,debug,wicket
Removed Cookie: ,debug,wicket
Found Cookie with name= |  and request URI=,debug,wicket
Unable to find Cookie with name= |  and request URI=,debug,wicket
Cookie saved:  | ; request URI=,debug,wicket
$$$Empty Message$$$,error,wicket
.onSubmit,info,wicket
.onError,info,wicket
rendered '*' for *ms,debug,wicket
Detaching conversational counter,info,wicket
Detaching application counter,info,wicket
Attempting to locate resource '*' using classloader the servlet context,debug,wicket
Unable to read resource stream for:  | ; Page=,error,wicket
Can't construct the uri as a file: ,debug,wicket
trying the filename:  |  to load as a zip/jar.,debug,wicket
key: * is null.,error,wicket
user is trying to access class: * which is not in the scope of org.apache.wicket.examples,error,wicket
Error loading image,error,wicket
Error loading image,error,wicket
$$$Empty Message$$$,info,wicket
File 'charset.properties' not found,debug,wicket
This PushBuilder does nothing. Please use one of the other implementations - Jetty9 or Tomcat8.5+,warn,wicket
Attempted to use HTTP2 Push but it is not supported for the current request: *!,warn,wicket
Attempted to use HTTP2 Push but it is not supported for the current request: *!,warn,wicket
Attempted to use HTTP2 Push but it is not supported for the current request: *!,warn,wicket
Attempted to use HTTP2 Push but it is not supported for the current request: *!,warn,wicket
$$$Empty Message$$$,error,wicket
not allowed to read property wicket.mbean.server.agentid due to security settings; ignoring,warn,wicket
unable to find mbean server with agent id ,error,wicket
not allowed to read property wicket.mbean.server.class due to security settings; ignoring,warn,wicket
unable to find mbean server of type '*',error,wicket
registering Wicket mbeans with server '*',info,wicket
Page with id '*' has been expired. No message will be broadcast!,debug,wicket
An error occurred during processing of a WebSocket message,error,wicket
Either there is no connection(*) or it is closed.,debug,wicket
An error occurred while pushing text message.,error,wicket
The websocket connection is already closed. Cannot push the text message '*',warn,wicket
An error occurred while pushing binary message.,error,wicket
The websocket connection is already closed. Cannot push the binary message '*',warn,wicket
An error occurred while writing response to WebSocket client.,error,wicket
An error occurred while resetting the binary content,error,wicket
An HTTP error response in WebSocket communication would not be processed by the browser! If you need to send the error code and message to the client then configure custom WebSocketResponse via WebSocketSettings#newWebSocketResponse() factory method and override #sendError() method to write them in an appropriate format for your application. The ignored error code is '*' and the message: '*'.,warn,wicket
httpSession: *,trace,wicket
headers: *,trace,wicket
parameterMap: *,trace,wicket
queryString: *,trace,wicket
requestURI: *,trace,wicket
userPrincipal: *,trace,wicket
An error occurred while closing WebSocket session,error,wicket
Web Socket connection with id '*' has been closed with code '*' and reason: *,debug,wicket
An error occurred in web socket connection with id : ,error,wicket
An error occurred while calculating the size of object: ,error,wicket
request handler is still active.,warn,wicket
Error detaching RequestHandler,error,wicket
Segments '*' do not start with common prefix '*',debug,wicket
No compatible mapper found for URL '*',debug,wicket
One compatible mapper found for URL '*' -> '*',debug,wicket
Multiple compatible mappers found for URL '*',debug,wicket
 * *,debug,wicket
Error decoding text: ,debug,wicket
Unable to encrypt text ' | ',error,wicket
Unable to encrypt text ' | ',error,wicket
using encryption/decryption object *,info,wicket
************************** WARNING **************************,warn,wicket
As the instantiation of encryption/decryption class:,warn,wicket
\t,warn,wicket
"failed, Wicket will fallback on a dummy implementation",warn,wicket
\t( | ),warn,wicket
This is NOT recommended for production systems.,warn,wicket
Please override method org.apache.wicket.util.crypt.ICryptFactory.newCrypt(),warn,wicket
to provide a custom encryption/decryption implementation.,warn,wicket
The cause of the instantiation failure: ,warn,wicket
\t,warn,wicket
exception: ,debug,wicket
Set log level to DEBUG to display the stack trace.,warn,wicket
*************************************************************,warn,wicket
Incomplete trailing escape (%) pattern in '%s'. The escape character (%) will be ignored.,info,wicket
Illegal hex characters in escape (%) pattern in '*'. The escape character (%) will be ignored. NumberFormatException: * ,info,wicket
Error reading servlet/filter path from web.xml,error,wicket
Couldn't read web.xml to automatically pick up servlet/filter path: ,info,wicket
web.xml: No url-pattern found for '*' with name '*',warn,wicket
$$$Empty Message$$$,info,wicket
Failed to create directory: ,error,wicket
closing resource failed: ,debug,wicket
$$$Empty Message$$$,warn,wicket
$$$Empty Message$$$,warn,wicket
'*' has no minimum value. Falling back to Double.,debug,wicket
'*' has no maximum value. Falling back to Double.MAX_VALUE.,debug,wicket
Error invoking listener: ,error,wicket
Error invoking listener: ,error,wicket
Adding: '*',debug,wicket
An error occurred while converting '%s' to a boolean: %s,debug,wicket
An error occurred while converting '%s' to a character: %s,debug,wicket
An error occurred while converting '%s' to a double: %s,debug,wicket
An error occurred while converting '%s' to a Duration: %s,debug,wicket
An error occurred while converting '%s' to an integer: %s,debug,wicket
An error occurred while converting '%s' to a long: %s,debug,wicket
An error occurred while converting '%s' to a Time: %s,debug,wicket
An error occurred while converting '%s' to a %s: %s,debug,wicket
Run the job: '*',trace,wicket
Unhandled exception thrown by user code in task ,error,wicket
Finished with job: '*',trace,wicket
Task '*' terminated,error,wicket
Cannot track modifications to resource '*',info,wicket
Initialized Velocity successfully,info,wicket
$$$Empty Message$$$,error,wicket
$$$Empty Message$$$,error,wicket
(Re)initializing * (validity period/update interval/max entries) (*/*/*),info,cassandra
CassandraAuthorizer failed to authorize * for *,warn,cassandra
CassandraAuthorizer failed to revoke all permissions of *: *,warn,cassandra
CassandraAuthorizer failed to revoke all permissions on *: *,warn,cassandra
Converting legacy permissions data,info,cassandra
Completed conversion of legacy permissions,info,cassandra
Unable to complete conversion of legacy permissions data (perhaps not enough nodes are upgraded yet). Conversion should not be considered complete,info,cassandra
Conversion error,trace,cassandra
No CallbackHandler available for authentication,info,cassandra
Unexpected exception processing authentication callbacks,info,cassandra
"An invalid value has been detected in the * table for role *. If you are unable to login, you may need to disable authentication and confirm that values in that table are accurateroles",warn,cassandra
Created default superuser role '*'cassandra,info,cassandra
CassandraRoleManager skipped default role setup: some nodes were not ready,warn,cassandra
"Not all nodes are upgraded to a version that supports Roles yet, rescheduling setup task",trace,cassandra
"Setup task failed with error, rescheduling",info,cassandra
Converting legacy users,info,cassandra
Completed conversion of legacy users,info,cassandra
Migrating legacy credentials data to new system table,info,cassandra
Completed conversion of legacy credentials,info,cassandra
Unable to complete conversion of legacy auth data (perhaps not enough nodes are upgraded yet). Conversion should not be considered complete,info,cassandra
Conversion error,trace,cassandra
"Configuration options credentials_update_interval_in_ms, credentials_validity_in_ms and credentials_cache_max_entries may not be applicable for the configured authenticator (*)",info,cassandra
"Error: invalid password hash encountered, rejecting user",warn,cassandra
Error performing internal authentication,trace,cassandra
Error performing internal authentication,trace,cassandra
Decoding credentials from client token,trace,cassandra
Authorizing JMX method invocation * for *,trace,cassandra
"Auth setup is not complete, refusing access",trace,cassandra
Access denied to blacklisted method *,trace,cassandra
JMX invocation of * on * requires permission *,trace,cassandra
Permissions for JMX resource contains invalid ObjectName *,warn,cassandra
Subject does not have sufficient permissions on all MBeans matching the target pattern *,trace,cassandra
Permissions for JMX resource contains invalid ObjectName *,warn,cassandra
Subject does not have sufficient permissions on target MBean *,trace,cassandra
"Access denied, method name * does not map to any defined permission",debug,cassandra
Authentication exception,trace,cassandra
Started replayFailedBatches,trace,cassandra
Replay cancelled as there are no peers in the ring.,trace,cassandra
Finished replayFailedBatches,trace,cassandra
Skipped batch replay of * due to *,warn,cassandra
Replaying batch *,trace,cassandra
"Failed replaying a batched mutation to a node, will write a hint",trace,cassandra
Failure was : *,trace,cassandra
Migrating legacy batchlog to new storage,info,cassandra
Applying legacy batchlog mutation *,trace,cassandra
Converting mutation at *,trace,cassandra
Failed to convert mutation * at timestamp *,error,cassandra
Sending legacy batchlog store request * to * for * mutations,trace,cassandra
Sending legacy batchlog remove request * to *,trace,cassandra
reading saved cache *,info,cassandra
completed reading (* ms; * keys) saved cache *,trace,cassandra
Unable to rename * to *,error,cassandra
Unable to rename * to *,error,cassandra
"Cannot fetch in memory data, we will fallback to read from disk ",trace,cassandra
Error contacting seed list * *,trace,cassandra
Error in ThreadPoolExecutor,error,cassandra
Task cancelled,trace,cassandra
"Failed to execute task, unexpected exception killed worker: *",error,cassandra
Unexpected exception killed worker: *,error,cassandra
ScheduledThreadPoolExecutor has shut down as part of C* shutdown,debug,cassandra
"Interrupted while executing *, but not shutdown; continuing with loop",error,cassandra
"Exception thrown by runnable, continuing with loop",error,cassandra
Uncaught exception on thread *: *,warn,cassandra
Node configuration:[*],info,cassandra
Configuration location: *,info,cassandra
Loading settings from *,debug,cassandra
applying * to *,debug,cassandra
application result is *,debug,cassandra
Syncing log with a batch window of *,debug,cassandra
Syncing log with a period of *,debug,cassandra
concurrent_replicates has been deprecated and should be removed from cassandra.yaml,warn,cassandra
Global memtable on-heap threshold is enabled at *MB,info,cassandra
"Global memtable off-heap threshold is disabled, HeapAllocator will be used instead",info,cassandra
Global memtable off-heap threshold is enabled at *MB,info,cassandra
Error checking disk space,debug,cassandra
Small commitlog volume detected at *; setting commitlog_total_space_in_mb to *.  You can override this in cassandra.yaml,warn,cassandra
Error checking disk space,debug,cassandra
Small cdc volume detected at *; setting cdc_total_space_in_mb to *.  You can override this in cassandra.yaml,warn,cassandra
cdc_enabled is true. Starting casssandra node with Change-Data-Capture enabled.,info,cassandra
Error checking disk space,debug,cassandra
Only * free across all data volumes. Consider adding more capacity to your cluster or removing obsolete snapshots,warn,cassandra
memtable_cleanup_threshold has been deprecated and should be removed from cassandra.yaml,warn,cassandra
"memtable_cleanup_threshold is set very low [*], which may cause performance degradation",warn,cassandra
index_interval has been deprecated and should be removed from cassandra.yaml,warn,cassandra
Please rename encryption_options as server_encryption_options in the yaml,warn,cassandra
Back-pressure is * with strategy *.,info,cassandra
"rpc_max_threads setting of * may be too high for the hsha server and cause unnecessary thread contention, reducing performance",warn,cassandra
Adding * to cfIdMap,debug,cassandra
Adding * to cfIdMap,debug,cassandra
prepared statement recreation error: *,warn,cassandra
Preloaded * prepared statements,info,cassandra
Process * @CL.*,trace,cassandra
[*] '*',trace,cassandra
"Column definitions for *.* changed, invalidating related prepared statements",trace,cassandra
"Keyspace * was dropped, invalidating related prepared statements",trace,cassandra
"Table *.* was dropped, invalidating related prepared statements",trace,cassandra
Failed to compile function '*' for language *: ,info,cassandra
Compiling Java source UDF '*' as class '*' using source: *,trace,cassandra
The function 'dateof' is deprecated. Use the function 'toTimestamp' instead.,warn,cassandra
The function 'unixtimestampof' is deprecated. Use the function 'toUnixTimestamp' instead.,warn,cassandra
access denied: resource *,trace,cassandra
access denied: resource *,trace,cassandra
Invocation of user-defined function '*' failed,trace,cassandra
Invocation of user-defined function '*' failed,debug,cassandra
$$$Empty Message$$$,warn,cassandra
$$$Empty Message$$$,warn,cassandra
Creating materialized view * for *.*. Materialized views are experimental and are not recommended for production use.,warn,cassandra
Dropping trigger with name *,info,cassandra
Ignoring obsolete property *,warn,cassandra
Adding trigger with name * and class *,info,cassandra
dclocal_read_repair_chance and read_repair_chance table options have been deprecated and will be removed in version 4.0,warn,cassandra
Updating index definition for *,trace,cassandra
 (see batch_size_fail_threshold_in_kb),error,cassandra
$$$Empty Message$$$,warn,cassandra
Received migration request from *.,trace,cassandra
Received schema check request.,trace,cassandra
Applying forwarded *,trace,cassandra
Refreshing disk boundary cache for *.*,debug,cassandra
Updating boundaries from * to * for *.*,debug,cassandra
Got local ranges * (ringVersion = *),debug,cassandra
Using stored Gossip Generation * as it is greater than current system time *.  See CASSANDRA-3654 if you experience problems,warn,cassandra
"No host ID found, created * (Note: This should happen exactly once per node).",warn,cassandra
"Detected version upgrade from * to *, snapshotting system keyspace",info,cassandra
Found unreadable versions info in pre 1.2 system.Versions table,trace,cassandra
stored prepared statement for logged keyspace '*': '*',debug,cassandra
Blacklisting * for reads,warn,cassandra
Blacklisting * for writes,warn,cassandra
Node is not part of the ring; not recording size estimates,debug,cassandra
Recording size estimates,trace,cassandra
Spent * milliseconds on estimating *.* size,trace,cassandra
$$$Empty Message$$$,warn,cassandra
"Couldn't find a defined index on *.* with the id *. If an index was just created, this is likely due to the schema not being fully propagated. Local read will proceed without using the index. Please wait for schema agreement after index creation.",info,cassandra
Error in truncation,error,cassandra
* applied.  Enqueuing response to *@* ,trace,cassandra
New replication settings for keyspace * - invalidating disk boundary caches,debug,cassandra
Could not acquire lock for * and table *,trace,cassandra
Attempting to mutate non-existant table * (*.*),error,cassandra
Operation not allowed on secondary Index table (*),warn,cassandra
adding secondary index table * to operation,info,cassandra
Not a directory *,error,cassandra
Doesn't have execute permissions for * directory,error,cassandra
Doesn't have read permissions for * directory,error,cassandra
Doesn't have write permissions for * directory,error,cassandra
Failed to create * directory,error,cassandra
Moving index file * to *,trace,cassandra
Removing temporary directory *,debug,cassandra
removing blacklisted candidate *,trace,cassandra
"removing candidate *, usable=*, requested=*",trace,cassandra
Removing snapshot directory *,trace,cassandra
Could not calculate the size of *. *,error,cassandra
Received schema mutation push from *,trace,cassandra
scheduling flush in * ms,trace,cassandra
Could not set new local compaction strategy,error,cassandra
Failed unregistering mbean: *,warn,cassandra
Loading new SSTables for */*...,info,cassandra
"Cannot read sstable *; other IO error, skipping table",error,cassandra
Renaming new SSTable * to *,info,cassandra
Corrupt sstable *; skipping table,error,cassandra
"Cannot read sstable *; file system error, skipping table",error,cassandra
"Cannot read sstable *; other IO error, skipping table",error,cassandra
No new SSTables were found for */*,info,cassandra
Loading new SSTables and building secondary indexes for */*: *,info,cassandra
Done loading load new SSTables for */*,info,cassandra
User Requested secondary index re-build for */* indexes: *,info,cassandra
"Flushed to * (* sstables, *), biggest *, smallest *",debug,cassandra
"Flushing largest * to free up room. Used total: *, live: *, flushing: *, this: *",debug,cassandra
Checking for sstables overlapping *,trace,cassandra
Snapshot for * keyspace data file * created in *,trace,cassandra
Created ephemeral snapshot marker file on *.,trace,cassandra
Clearing ephemeral snapshot * leftover from previous session.,trace,cassandra
using snapshot sstable *,trace,cassandra
using active sstable *,trace,cassandra
Truncating *.*,info,cassandra
Discarding sstable data for truncated CF + indexes,debug,cassandra
cleaning out row cache,trace,cassandra
Truncate of *.* is complete,info,cassandra
Cancelling in-progress compactions for *,trace,cassandra
"Unable to cancel in-progress compactions for *.  Perhaps there is an unusually large row in progress somewhere, or the system is simply overloaded.",warn,cassandra
Compactions successfully cancelled,trace,cassandra
"Writing *, flushed range = (*, *]",debug,cassandra
Completed flushing * (*) for commitlog position *,debug,cassandra
High update contention in */* partitions of * ,trace,cassandra
Skipping invalid directory found in .toDelete: *. Only %TEMP% or data file subdirectories are valid.,warn,cassandra
Discovered obsolete snapshot. Deleting directory [*],warn,cassandra
Failed to open *. Obsolete snapshots from previous runs will not be deleted.,warn,cassandra
Restore point in time is before latest truncation of table *.*. Clearing truncation record.,info,cassandra
Global replay position is * from columnfamilies *,debug,cassandra
Skipped * mutations from unknown (probably removed) CF with id *,warn,cassandra
Finished waiting on mutations from recovery,trace,cassandra
Ignoring commit log replay error likely due to incomplete flush to disk,error,cassandra
Ignoring commit log replay error,error,cassandra
"Replay stopped. If you wish to override this error and continue starting the node ignoring commit log replay problems, specify -Dcassandra.commitlog.ignorereplayerrors=true on the command line",error,cassandra
Failed to force-recycle all segments; at least one segment is still in use with dirty CFs.,error,cassandra
Failed waiting for a forced recycle of in-use commit log segments,error,cassandra
Segment * is no longer active and will be deleted *,debug,cassandra
Total active commitlog segment space used is * out of *,trace,cassandra
Marking clean CF * that doesn't exist anymore,trace,cassandra
CLSM closing and clearing existing commit log segments...,debug,cassandra
CLSM done with closing and clearing existing commit log segments.,trace,cassandra
(Unopened) segment * is no longer needed and will be deleted now,trace,cassandra
"discard completed log segments for *-*, table *",trace,cassandra
Commit log segment * is unused,debug,cassandra
Not safe to delete* commit log segment *; dirty is *,trace,cassandra
$$$Empty Message$$$,error,cassandra
No commitlog_archiving properties found; archive + pitr will be disabled,trace,cassandra
"Archiving file * failed, file may have already been archived.",warn,cassandra
"Looks like the archiving of file * failed earlier, cassandra is going to ignore this segment for now.",error,cassandra
Skipping restore of archive * as the segment already exists in the restore location *,trace,cassandra
created a new encrypted commit log segment: *,debug,cassandra
Skipping playback of empty log: *,info,cassandra
Finished reading *,debug,cassandra
"Reading * (CL version *, messaging version *, compression *)",debug,cassandra
Skipping read of fully-flushed *,trace,cassandra
Reading mutation at *,trace,cassandra
"Not enough bytes left for another mutation in this CommitLog segment, continuing",trace,cassandra
Encountered end of segment marker at *,trace,cassandra
Read mutation for *.*: *,trace,cassandra
Moving (Unopened) segment * to cdc_raw directory after replay,trace,cassandra
not refreshing overlaps - running with -D*=truecassandra.never_purge_tombstones,debug,cassandra
not refreshing overlaps - running with ignoreOverlaps activated,debug,cassandra
Checking droppable sstables in *,trace,cassandra
"Dropping overlap ignored expired SSTable * (maxLocalDeletionTime=*, gcBefore=*)",trace,cassandra
"Dropping expired SSTable * (maxLocalDeletionTime=*, gcBefore=*)",trace,cassandra
"At level *, * [*, *] overlaps * [*, *].  This could be caused by a bug in Cassandra 1.1.0 .. 1.1.3 or due to the fact that you have dropped sstables from another node into the data directory. Sending back to L0.  If you didn't drop in sstables, and have not yet run scrub, you should do so since you may also have rows out-of-order within an sstable",warn,cassandra
Bootstrapping - doing STCS in L0,info,cassandra
Compaction score for level * is *,trace,cassandra
Compaction candidates for L* are *,trace,cassandra
No compaction candidates for L*,trace,cassandra
"L0 is too far behind, performing size-tiering there first",debug,cassandra
CompactionCounter: *: *,trace,cassandra
Adding high-level (L*) * to candidates,info,cassandra
L* contains * SSTables (*) in *,trace,cassandra
Estimating * compactions to do for *.*,trace,cassandra
Compaction buckets are *,trace,cassandra
"Could not acquire references for compacting SSTables * which is not a problem per se,unless it happens frequently, in which case it must be reported. Will retry later.",warn,cassandra
"You are running with sstables overlapping checks disabled, it can result in loss of data",warn,cassandra
Using a non-default timestamp_resolution * - are you really doing inserts with USING TIMESTAMP <non_microsecond_timestamp> (or driver equivalent)?,warn,cassandra
Autocompaction is disabled,trace,cassandra
Background compaction is still running for *.* (* remaining). Skipping,trace,cassandra
Scheduling a background task check for *.* with *,trace,cassandra
Failed to wait for compaction executors shutdown,warn,cassandra
Interrupted while waiting for tasks to be terminated,error,cassandra
Checking *.*,trace,cassandra
Aborting compaction for dropped CF,trace,cassandra
No tasks available,trace,cassandra
Partitioner does not support splitting,info,cassandra
Relocate cannot run before a node has joined the ring,info,cassandra
Relocating *,debug,cassandra
Major compaction will not result in a single sstable - repaired and unrepaired data is kept separate and compaction runs per data_file_directory.,info,cassandra
"Compaction executor has shut down, not submitting task",info,cassandra
Schema does not exist for file *. Skipping.,warn,cassandra
Schema does not exist for file *. Skipping.,warn,cassandra
Cleanup cannot run before a node has joined the ring,error,cassandra
"Will not clean *, it is not an active sstable",warn,cassandra
forceUserDefinedCleanup failed: *,error,cassandra
Will not compact *: it is not an active sstable,info,cassandra
No files to compact for user defined compaction,info,cassandra
"Validation finished in * msec, for *",debug,cassandra
"Created * merkle trees with merkle trees size *, * partitions, * bytes",debug,cassandra
Could not reference sstables,error,cassandra
Performing anticompaction on * sstables,info,cassandra
$$$Empty Message$$$,info,cassandra
"No valid anticompactions for this group, All sstables were compacted and are no longer available",info,cassandra
Anticompacting *,info,cassandra
Repaired * keys out of * for */* in *,trace,cassandra
Error anticompacting ,error,cassandra
Cache flushing was already in progress: skipping *,trace,cassandra
"Compaction executor has shut down, not submitting index build",info,cassandra
$$$Empty Message$$$,info,cassandra
Interruption of compaction encountered exceptions:,warn,cassandra
Full interruption stack trace:,trace,cassandra
"Executor has been shut down, not submitting *",info,cassandra
"Executor has shut down, could not submit *",info,cassandra
Failed to submit *,error,cassandra
Max sstable size of *MB is configured for *.*; having a unit of compaction this large is probably a bad idea,warn,cassandra
Max sstable size of *MB is configured for *.*.  Testing done for CASSANDRA-5727 indicates that performance improves up to 160MB,warn,cassandra
Created *,trace,cassandra
No compaction necessary for *,trace,cassandra
"Could not acquire references for compacting SSTables * which is not a problem per se,unless it happens frequently, in which case it must be reported. Will retry later.",warn,cassandra
Unable to mark * for compaction; probably a background compaction got to it first.  You can disable background compactions temporarily if this is a problem,trace,cassandra
"Live sstable * from level * is not on corresponding level in the leveled manifest. This is not a problem per se, but may indicate an orphaned sstable due to a failed compaction not cleaned up properly.",warn,cassandra
"insufficient space to compact all requested files. *MB required, *",warn,cassandra
Compaction space check is disabled,info,cassandra
$$$Empty Message$$$,warn,cassandra
"Not enough space for compaction, *MB estimated.  Reducing scope.",warn,cassandra
Disabling tombstone compactions for DTCS,trace,cassandra
Enabling tombstone compactions for DTCS,trace,cassandra
"Could not acquire references for compacting SSTables * which is not a problem per se,unless it happens frequently, in which case it must be reported. Will retry later.",warn,cassandra
Including expired sstables: *,trace,cassandra
Compaction buckets are *,debug,cassandra
Got sstables * for STCS from *,debug,cassandra
* subscribed to the data tracker.,trace,cassandra
Recreating compaction strategy - compaction parameters changed for *.*,debug,cassandra
Recreating compaction strategy - disk boundaries are out of date for *.*.,debug,cassandra
Switching local compaction strategy from * to *},info,cassandra
Using a non-default timestamp_resolution * - are you really doing inserts with USING TIMESTAMP <non_microsecond_timestamp> (or driver equivalent)?,warn,cassandra
Disabling tombstone compactions for TWCS,debug,cassandra
Enabling tombstone compactions for TWCS,debug,cassandra
"Could not acquire references for compacting SSTables * which is not a problem per se,unless it happens frequently, in which case it must be reported. Will retry later.",warn,cassandra
"TWCS expired check sufficiently far in the past, checking for fully expired SSTables",debug,cassandra
TWCS skipping check for fully expired SSTables,debug,cassandra
Including expired sstables: *,debug,cassandra
"Key *, now *",trace,cassandra
"Using STCS compaction for first window of bucket: data files * , options *",debug,cassandra
"bucket size * >= 2 and not in current bucket, compacting what's here: *",debug,cassandra
"No compaction necessary for bucket size * , key *, now *",trace,cassandra
Switching write location from * to *,debug,cassandra
All sstables not from the same disk - putting results in *,trace,cassandra
putting compaction results in *,trace,cassandra
"Switching writer, currentBytesToWrite = *",debug,cassandra
"Switching writer, currentPartitionsToWrite = *",trace,cassandra
"invalid global counter shard detected; (*, *, *) and (*, *, *) differ only in count; will pick highest to self-heal on compaction",warn,cassandra
"invalid remote counter shard detected; (*, *, *) and (*, *, *) differ only in count; will pick highest to self-heal on compaction",warn,cassandra
Registered user defined expression type * and serializer * with identifier *,debug,cassandra
Failed to read records for transaction log *,error,cassandra
"Aborting transaction over * staged: *, logged: *",trace,cassandra
Obsoleting *,trace,cassandra
Checkpointing staged *,trace,cassandra
Created new file replica *,trace,cassandra
"Mismatched line in file *: got '*' expected '*', giving up",error,cassandra
Mismatched last line in file *: '*' not the same as '*',warn,cassandra
"Mismatched line in file *: got '*' expected '*', giving up",error,cassandra
Failed to add record '*' to some replicas '*',error,cassandra
adding * to list of files tracked for *.*,trace,cassandra
removing * from list of files tracked for *.*,trace,cassandra
Created transaction logs with id *,trace,cassandra
Deleting *,trace,cassandra
"Unable to delete * as it does not exist, see debug log file for stack trace",error,cassandra
"Unable to delete * as it does not exist, stack trace:  *",debug,cassandra
Unable to delete *,error,cassandra
Removing files for transaction log *,trace,cassandra
"Transaction log * indicates txn was not completed, trying to abort it now",error,cassandra
Failed to abort transaction log *,error,cassandra
"Failed deleting files for transaction log *, we'll retry after GC and on on server restart",info,cassandra
Closing transaction log *,trace,cassandra
SSTableTidier ran with no existing data file for an sstable that was not new,error,cassandra
"Failed deletion for *, we'll retry after GC and on server restart",error,cassandra
Failed to complete file transaction id *,error,cassandra
Failed to remove unfinished transaction leftovers for transaction log *,error,cassandra
Unexpected disk state: failed to read transaction log *,error,cassandra
"Changing from DateType to TimestampType is allowed, but be wary that they sort differently for pre-unix-epoch timestamps (negative timestamp values) and thus this change will corrupt your data if you have such negative timestamp. So unless you know that you don't have *any* pre-unix-epoch timestamp you should change back to DateType",warn,cassandra
Failed with [*] when decoding the byte buffer in ByteBufferUtil.string(),error,cassandra
"Failed to parse value string ""*"" with exception: [*]",error,cassandra
"Changing from TimestampType to DateType is allowed, but be wary that they sort differently for pre-unix-epoch timestamps (negative timestamp values) and thus this change will corrupt your data if you have such negative timestamp. There is no reason to switch from DateType to TimestampType except if you were using DateType in the first place and switched to TimestampType by mistake.",warn,cassandra
"Scheduling monitoring task with report interval of * ms, max operations *",info,cassandra
"Some operations timed out, details available at debug level (debug.log)",warn,cassandra
* operations timed out in the last * msecs:**,debug,cassandra
"Some operations were slow, details available at debug level (debug.log)",info,cassandra
* operations were slow in the last * msecs:**,debug,cassandra
"[*] Logging iterator on *.*, partition key=*, reversed=*",info,cassandra
[*] *,info,cassandra
[*] *,info,cassandra
"[*] Logging iterator on *.*, partition key=*, reversed=*, deletion=*",info,cassandra
[*] *,info,cassandra
[*] *,info,cassandra
[*] *,info,cassandra
View query: *,trace,cassandra
Stopping current view builder due to schema change,debug,cassandra
Not submitting build tasks for views in keyspace * as storage service is not initialized,info,cassandra
Not adding view * because the base table * is unknown,warn,cassandra
"Skipping *, view query filters",trace,cassandra
Starting view builder for *.*,debug,cassandra
Running view builder for *.*,trace,cassandra
View already marked built for *.*,debug,cassandra
Starting new view build. flushing base table *.*,debug,cassandra
Resuming view build from token *. flushing base table *.*,debug,cassandra
Marking view(*.*) as built covered * keys ,debug,cassandra
Stopped build for view(*.*) after covering * keys,debug,cassandra
"Materialized View failed to complete, sleeping 5 minutes before restarting",warn,cassandra
"Failed to updated the distributed status of view, sleeping 5 minutes before retrying",warn,cassandra
Beginning bootstrap process,trace,cassandra
manually specified tokens override automatic allocation,warn,cassandra
Picking random token for a single vnode.  You should probably add more vnodes and/or use the automatic token allocation mechanism.,warn,cassandra
tokens manually specified as *,info,cassandra
Generated random tokens. tokens are *,info,cassandra
*: range * exists on *,trace,cassandra
*: range * from source * for keyspace *,trace,cassandra
Unable to find sufficient sources for streaming range * in keyspace * with RF=1. Keyspace might be missing data.,warn,cassandra
Some ranges of * are already available. Skipping streaming those ranges.,info,cassandra
*ing from * ranges *,trace,cassandra
Selected tokens *,warn,cassandra
Replicated node load in datacentre before allocation *,warn,cassandra
Replicated node load in datacentre after allocation *,warn,cassandra
Unexpected growth in standard deviation after allocation.,warn,cassandra
Using NoReplicationTokenAllocator.,info,cassandra
Using ReplicationAwareTokenAllocator.,info,cassandra
Received a GossipDigestSynMessage from *,trace,cassandra
Ignoring GossipDigestSynMessage because gossip is disabled,trace,cassandra
ClusterName mismatch from * *!=*,warn,cassandra
Partitioner mismatch from * *!=*,warn,cassandra
Ignoring non-empty GossipDigestSynMessage because currently in gossip shadow round,debug,cassandra
"Received a shadow round syn from *. Gossip is disabled but currently also in shadow round, responding with a minimal ack",debug,cassandra
Gossip syn digests are : *,trace,cassandra
sending * digests and * deltas,trace,cassandra
Sending a GossipDigestAckMessage to *,trace,cassandra
My heartbeat is now *,trace,cassandra
Gossip error,error,cassandra
Convicting * with status * - alive *,debug,cassandra
evicting * from gossip,debug,cassandra
"removed * from seeds, updated seeds list = *",info,cassandra
removing endpoint *,debug,cassandra
$$$Empty Message$$$,debug,cassandra
Gossip Digests are : *,trace,cassandra
Removing host: *,info,cassandra
Sleeping for *ms to ensure * does not change,info,cassandra
Advertising removal for *,info,cassandra
Completing removal of *,info,cassandra
Gossiper.unsafeAssassinateEndpoint is deprecated and will be removed in the next release; use assassinateEndpoint instead,warn,cassandra
Assassinating * via gossip,warn,cassandra
Sleeping for *ms to ensure * does not change,info,cassandra
"Endpoint * disappeared while trying to assassinate, continuing anyway",warn,cassandra
Unable to calculate tokens for *.  Will use a random one,warn,cassandra
Finished assassinating *,warn,cassandra
Sending a GossipDigestSyn to * ...,trace,cassandra
Performing status check ...,trace,cassandra
Gossip stage has * pending tasks; skipping status check (no nodes will be marked down),warn,cassandra
"FatClient * has been silent for *ms, removing from gossip",info,cassandra
time is expiring for endpoint : * (*),debug,cassandra
"* elapsed, * gossip quarantine over",debug,cassandra
local heartbeat version * greater than * for *,trace,cassandra
Adding state *: *,trace,cassandra
Clearing interval times for * due to generation change,debug,cassandra
Sending a EchoMessage to *,trace,cassandra
marking as alive *,trace,cassandra
removing expire time for endpoint : *,debug,cassandra
InetAddress * is now UP,info,cassandra
Notified *,trace,cassandra
marking as down *,trace,cassandra
InetAddress * is now DOWN,info,cassandra
Notified *,trace,cassandra
"Node * has restarted, now UP",info,cassandra
Node * is now part of the cluster,info,cassandra
Adding endpoint state for *,trace,cassandra
Not marking * alive due to dead state,debug,cassandra
Ignoring gossip for * because it is quarantined,trace,cassandra
"* local generation *, remote generation *",trace,cassandra
"received an invalid gossip generation for peer *; local time = *, received generation = *",warn,cassandra
Updating heartbeat state generation to * from * for *,trace,cassandra
Ignoring remote version * <= * for *,trace,cassandra
Ignoring remote generation * < *,trace,cassandra
There is at least one 3.0 node in the cluster - will store and announce compatible schema version,info,cassandra
requestAll for *,trace,cassandra
"Shadow request received, adding all states",debug,cassandra
gossip started with generation *,trace,cassandra
Sending shadow round GOSSIP DIGEST SYN to seeds *,trace,cassandra
Sending shadow round GOSSIP DIGEST SYN to known peers *,trace,cassandra
Attempt to add self as saved endpoint,debug,cassandra
"not replacing a previous epState for *, but reusing it: *",debug,cassandra
Adding saved endpoint * *,trace,cassandra
Announcing shutdown,info,cassandra
"No local state, state is in silent shutdown, or node hasn't joined, not announcing shutdown",warn,cassandra
"Received an ack from *, who isn't a seed. Ensure your seed list includes a live node. Exiting shadow round",warn,cassandra
"Received a regular ack from *, can now exit shadow round",debug,cassandra
Received an ack from * indicating it is also in shadow round,debug,cassandra
"All seeds are in a shadow round, clearing this node to exit its own",debug,cassandra
adding expire time for endpoint : * (*),debug,cassandra
Waiting for gossip to settle...,info,cassandra
Gossip looks settled.,debug,cassandra
Gossip not settled after * polls.,info,cassandra
Gossip not settled but startup forced by cassandra.skip_wait_for_gossip_to_settle. Gossip total polls: *,warn,cassandra
Gossip settled after * extra polls; proceeding,info,cassandra
No gossip backlog; proceeding,info,cassandra
Received a GossipDigestAckMessage from *,trace,cassandra
Ignoring GossipDigestAckMessage because gossip is disabled,trace,cassandra
Received ack with * digests and * states,trace,cassandra
"Received an ack from *, which may trigger exit from shadow round",debug,cassandra
Ignoring unrequested GossipDigestAck from *,trace,cassandra
Sending a GossipDigestAck2Message to *,trace,cassandra
Ignoring shutdown message from * because gossip is disabled,debug,cassandra
Received a GossipDigestAck2Message from *,trace,cassandra
Ignoring GossipDigestAck2Message because gossip is disabled,trace,cassandra
Overriding max local pause time to *ms,warn,cassandra
Overriding FD INITIAL_VALUE to *ms,info,cassandra
Unknown endpoint:  | ,error,cassandra
Average for * is *,trace,cassandra
Not marking nodes down due to local pause of * > *,warn,cassandra
Still not marking nodes down due to local pause,debug,cassandra
PHI for * : *,trace,cassandra
Node * phi * > *; intervals: * mean: *,trace,cassandra
PHI for * : *,debug,cassandra
PHI for * : *,trace,cassandra
mean for * : *,trace,cassandra
Forcing conviction of *,debug,cassandra
Overriding FD MAX_INTERVAL to *ms,info,cassandra
Reading token of *,trace,cassandra
failed to connect to any initial addresses,error,cassandra
$$$Empty Message$$$,error,cassandra
"Invalid replica host name: *, skipping it",warn,cassandra
Created instance with the following replicas: *,trace,cassandra
Initialized with replica hosts: *,trace,cassandra
Using the following hosts order for the new query plan: * | *,trace,cassandra
Added a new host *,trace,cassandra
The host * is now up,trace,cassandra
The host * is now down,trace,cassandra
Removed the host *,trace,cassandra
Could not retrieve local network interfaces.,warn,cassandra
cqlQuery *,trace,cassandra
created *,trace,cassandra
Finished scanning * rows (estimate was: *),trace,cassandra
Error closing connection,warn,cassandra
Some hosts failed: *,warn,cassandra
adding *,trace,cassandra
Deleted hint file *,info,cassandra
Failed to delete hint file *,error,cassandra
Transferring all hints to *: *,info,cassandra
Failed to transfer all hints to *: *; will retry in * seconds10,warn,cassandra
Transferring all hints to *: *,info,cassandra
Failed to transfer all hints to *: *,error,cassandra
Failed to dispatch hints file *: file is corrupted (*),error,cassandra
Dispatching hints file *,trace,cassandra
Finished hinted handoff of file * to endpoint *: *,info,cassandra
"Finished hinted handoff of file * to endpoint *: *, partially",info,cassandra
Finished converting hints file *,info,cassandra
Hint dispatch was interrupted,warn,cassandra
Failed to decode and apply a hint for *: * - table with id * is unknown,trace,cassandra
Failed to validate a hint for *: * - skipped,warn,cassandra
failed to create encyption context for hints file. ignoring encryption for hints.,warn,cassandra
Failed to deserialize hints descriptor *,error,cassandra
Paused hints dispatch,info,cassandra
Resumed hints dispatch,info,cassandra
Migrating legacy hints to new storage,info,cassandra
Forcing a major compaction of *.* tablesystemhints,info,cassandra
Writing legacy hints to the new storage,info,cassandra
Truncating *.* tablesystemhints,info,cassandra
Failed to migrate a hint for * from legacy *.* tablesystemhints,error,cassandra
Failed to validate a hint for * from legacy *.* table - skippingsystemhints,warn,cassandra
"Unexpected EOF replaying hints (*), likely due to unflushed hint file on shutdown; continuing",warn,cassandra
Failed to read a hint for *: * - table with id * is unknown in file *,warn,cassandra
Failed to read a hint for *: * - digest mismatch for hint at position * in file *,warn,cassandra
"Unexpected EOF replaying hints (*), likely due to unflushed hint file on shutdown; continuing",warn,cassandra
Failed to read a hint for * - digest mismatch for hint at position * in file *,warn,cassandra
No defined indexes with the supplied names: *,info,cassandra
Index build of * complete,info,cassandra
Executing pre-join* tasks for: *,info,cassandra
Calculated page size * for indexing *.* (*/*/*/*),trace,cassandra
"Command contains a custom index expression, using target index *",trace,cassandra
No applicable indexes found,trace,cassandra
Registered index *,trace,cassandra
Index * was not registered,trace,cassandra
failed to flush indexes: * because flush task is missing.,error,cassandra
Removed index entry for stale value *,trace,cassandra
Inserted entry into index for value *,trace,cassandra
Removed index entry for value *,trace,cassandra
"No SSTable data for *.* to build index * from, marking empty index as built",info,cassandra
Submitting index build of * for data in *,info,cassandra
Index build of * complete,info,cassandra
"Non-composite index was used on the table '*' during the query. Starting from Cassandra 4.0, only composite indexes will be supported. If compact flags were dropped for this table, drop and re-create the index.",warn,cassandra
Search Concurrency Factor is set to * for *,info,cassandra
Failed to deserialize value with ,error,cassandra
Failed to get stemmer constructor,error,cassandra
Failed to create new SnowballStemmer instance for language [*],debug,cassandra
An unhandled exception to occurred while processing pipeline [*],info,cassandra
Failed to populate Stop Words Cache for language [*],error,cassandra
Failed to retrieve Stop Terms resource for language [*],error,cassandra
Failed to create new instance of analyzer with class [*],error,cassandra
Failed to find specified analyzer class [*]. Falling back to default analyzer,error,cassandra
"failed to parse * option, defaulting to 'false'.is_literal",error,cassandra
"SSTableIndex.open(column: *, minTerm: *, maxTerm: *, minKey: *, maxKey: *, sstable: *)",info,cassandra
"Can't open index file at  | , skipping.",error,cassandra
"Rejecting value (size *, maximum *) for column * (analyzed *) at * SSTable.",info,cassandra
"(*) Failed to add * to index for key: *, value size was *, validator is *.",info,cassandra
Scheduling index flush to *,info,cassandra
"Rejecting value (value size *, maximum size *).",error,cassandra
"Can't add column * to index for key: *, value size *, validator: *.",error,cassandra
"Can't add term of column * to index for key: *, term size *, max allowed size *, use analyzed = true (if not yet set) for that column.",info,cassandra
"Can't cast value for * to size accepted by *, value size is *.",error,cassandra
'*' parameter is ignored when '*' is '*'lz4_high_compressor_levellz4_compressor_typefast,warn,cassandra
Redistributing index summaries,info,cassandra
SSTable * cannot be re-sampled due to old sstable format,trace,cassandra
Beginning redistribution of index summaries for * sstables with memory pool size * MB; current spaced used is * MB,trace,cassandra
Total reads/sec across all sstables in index summary resize process: *,trace,cassandra
Index summaries for compacting SSTables are using * MB of space,trace,cassandra
Completed resizing of index summaries; current approximate memory used: *,trace,cassandra
"min_index_interval changed from * to *, so the current sampling level for * is effectively now * (was *)",trace,cassandra
"* has * reads/sec; ideal space for index summary: * (* entries); considering moving from level * (* entries, *) to level * (* entries, *)",trace,cassandra
Forcing resample of * because the current index interval (*) is below min_index_interval (*),trace,cassandra
Forcing upsample of * because the current index interval (*) is above max_index_interval (*),trace,cassandra
SSTable * is within thresholds of ideal sampling,trace,cassandra
Re-sampling index summary for * from */* to */* of the original number of entries128128,trace,cassandra
Using leftover space to keep * at the current sampling level (*),trace,cassandra
Initializing index summary manager with a memory pool size of * MB and a resize interval of * minutes,info,cassandra
Deleting sstable: *,debug,cassandra
Missing component: *,error,cassandra
Failed to delete snapshot [*]. Will retry after further sstable deletions. Folder will be deleted on JVM shutdown or next node restart on crash.,warn,cassandra
Successfully deleted snapshot *.,info,cassandra
"Memory capacity of index summary exceeded (2GB), index summary will not cover full sstable, you should increase min_sampling_level",error,cassandra
Reading cardinality from Statistics.db failed for *,warn,cassandra
Reading cardinality from Statistics.db failed.,warn,cassandra
Cardinality merge failed.,warn,cassandra
Got a null cardinality estimator in: *,trace,cassandra
Could not read up compaction metadata for *,warn,cassandra
Estimated compaction gain: */*=*,trace,cassandra
Could not merge cardinalities,warn,cassandra
Missing sstable component in *; skipped because of *,error,cassandra
Corrupt sstable *; skipped,error,cassandra
Corrupt sstable *; skipping table,error,cassandra
"Cannot read sstable *; file system error, skipping table",error,cassandra
"Cannot read sstable *; other IO error, skipping table",error,cassandra
Cannot deserialize SSTable Summary File *: *,trace,cassandra
Cannot save SSTable Summary: ,trace,cassandra
Cannot save SSTable bloomfilter: ,trace,cassandra
Adding cache entry for * -> *,trace,cassandra
Marking * as a suspect for blacklisting.,trace,cassandra
Running instance tidier for * with setup *,trace,cassandra
"Async instance tidier for *, before barrier",trace,cassandra
"Async instance tidier for *, after barrier",trace,cassandra
"Async instance tidier for *, completed",trace,cassandra
wrote * at *,trace,cassandra
"Key size * exceeds maximum of *, skipping row65535",error,cassandra
Writing large partition */*:* (*) to sstable *,warn,cassandra
wrote index entry: * at *,trace,cassandra
Load metadata for *,trace,cassandra
No sstable stats for *,trace,cassandra
Mutating * to level *,trace,cassandra
Mutating * to repairedAt time *,trace,cassandra
Could not move file  |  to ,trace,cassandra
Could not do an atomic move,trace,cassandra
Failed closing *,warn,cassandra
Failed closing *,warn,cassandra
Failed closing stream *,warn,cassandra
Failed closing *,warn,cassandra
Received null list of files to delete,debug,cassandra
Failed to list files in * with exception: *,error,cassandra
Scheduling deferred deletion of file: *,trace,cassandra
Error while getting * folder size. *,error,cassandra
Error while closing mmapped regions,error,cassandra
Failed to close mapped regions,error,cassandra
"EC2Snitch using region: *, zone: *.",info,cassandra
Configured datacenter replicas are *,trace,cassandra
Updating topology for all endpoints that have changed,info,cassandra
"No bootstrapping, leaving or moving nodes -> empty pending ranges for *",trace,cassandra
Starting pending range calculation for *,debug,cassandra
Pending range calculation for * completed (took: *ms),debug,cassandra
Calculated pending ranges for *: *,trace,cassandra
Unable to read *,warn,cassandra
Seed provider couldn't lookup host *,warn,cassandra
Error in getting the IP address resolved: ,error,cassandra
Initiated reconnect to an Internal IP * for the *,debug,cassandra
"* found, but does not look like a plain file. Will not watch it for changescassandra-topology.properties",error,cassandra
"Could not find end point information for *, will use default",trace,cassandra
Loaded network topology from property file: *,trace,cassandra
"Cannot update data center or rack from * to * for live host *, property file NOT RELOADED",error,cassandra
"GCESnitch using region: *, zone: *.",info,cassandra
EC2Snitch using publicIP as identifier: *,info,cassandra
"broadcast_rpc_address unset, broadcasting public IP as rpc_address: *",info,cassandra
Loaded * for compatibilitycassandra-topology.properties,info,cassandra
Unable to load *; compatibility mode disabledcassandra-topology.properties,info,cassandra
clearing cached endpoints,trace,cassandra
Ignoring *,warn,cassandra
"* has * dropped hints, because node is down past configured hint window.",warn,cassandra
Error while reading from socket from *.,error,cassandra
Error closing socket,debug,cassandra
$$$Empty Message$$$,trace,cassandra
"Initialized back-pressure with high ratio: *, factor: *, flow: *, window size: *.",info,cassandra
"Back-pressure state for *: incoming rate *, outgoing rate *, ratio *, rate limiting *",trace,cassandra
* currently applied for remote replicas: *,info,cassandra
"Cannot apply * due to exceeding write timeout, pausing * nanoseconds instead.",info,cassandra
Failed to set receive buffer size on internode socket.,warn,cassandra
eof reading from socket; closing,trace,cassandra
UnknownColumnFamilyException reading from socket; closing,warn,cassandra
IOException reading from socket; closing,trace,cassandra
Closing socket * - isclosed: *,trace,cassandra
Error closing socket,trace,cassandra
Received connection from newer protocol version *. Ignoring message,trace,cassandra
$$$Empty Message$$$,error,cassandra
Enqueuing socket close for *,debug,cassandra
error processing a message intended for *,error,cassandra
Error writing to *,debug,cassandra
error writing to *,error,cassandra
Socket to * closed,debug,cassandra
Exception closing connection to *,debug,cassandra
Attempting to connect to *,debug,cassandra
Failed to set send buffer size on internode socket.,warn,cassandra
"Target max version is *; no version information yet, will retry",trace,cassandra
Target max version is *; will reconnect with that version,trace,cassandra
Seed gossip version is *; will not connect with that version,warn,cassandra
Configuration error prevented outbound connection: *,warn,cassandra
Detected higher max version * (using *); will reconnect when queued messages are done,trace,cassandra
Upgrading OutputStream to * to be compressed,trace,cassandra
Done connecting to *,debug,cassandra
SSL handshake error for outbound connection to ,error,cassandra
Unable to connect to *,debug,cassandra
Expiration of * took *μs,trace,cassandra
Resetting pool for *,trace,cassandra
Starting Encrypted Messaging Service on SSL port *,info,cassandra
await interrupted,trace,cassandra
Message-to-self * going over MessagingService,trace,cassandra
Setting version * for *,trace,cassandra
Resetting version for *,trace,cassandra
Assuming current protocol version for *,trace,cassandra
$$$Empty Message$$$,info,cassandra
remote failed to authenticate,trace,cassandra
Connection version * from *,trace,cassandra
Asynchronous close seen by server thread,trace,cassandra
MessagingService server thread already closed,trace,cassandra
SSL handshake error for inbound connection from ,error,cassandra
Error reading the socket *,trace,cassandra
MessagingService has terminated the accept() thread,info,cassandra
Closing accept() thread,trace,cassandra
[repair #*] *,info,cassandra
[repair #*] *,info,cassandra
[repair #*] *,info,cassandra
[repair #*] Repair completed between * and * on *,debug,cassandra
[repair #*] new session: will sync * on range * for *.*,info,cassandra
[repair #*] *,info,cassandra
[repair #*] *,error,cassandra
[repair #*] *Session completed successfully,info,cassandra
Validated * partitions for *.  Partitions per leaf are:,debug,cassandra
Validated * partitions for *.  Partition sizes are:,debug,cassandra
"Failed creating a merkle tree for *, * (see log for details)",error,cassandra
[repair #*] Sending completed merkle tree to * for *.*,info,cassandra
Repair failed:,error,cassandra
$$$Empty Message$$$,info,cassandra
Repair failed:,error,cassandra
$$$Empty Message$$$,info,cassandra
$$$Empty Message$$$,error,cassandra
$$$Empty Message$$$,info,cassandra
[repair #*] *,info,cassandra
[streaming task #*] Performing streaming repair of * ranges with *,info,cassandra
"[repair #*] streaming task succeed, returning response to *",info,cassandra
Error executing query ,error,cassandra
"Preparing, *",debug,cassandra
Snapshotting *,debug,cassandra
Enqueuing response to snapshot request * to *,debug,cassandra
Validating *,debug,cassandra
Table *.* was dropped during snapshot phase of repair,error,cassandra
Syncing *,debug,cassandra
Got anticompaction request *,debug,cassandra
cleaning up repair,debug,cassandra
"Got error, removing parent repair session",error,cassandra
$$$Empty Message$$$,error,cassandra
[repair #*] Endpoint * died during anti-compaction,error,cassandra
[repair #*] * is fully synced,info,cassandra
[repair #*] * sync failed,warn,cassandra
[repair #*] *,info,cassandra
[repair #*] *,info,cassandra
Validating *,info,cassandra
Validating *,info,cassandra
[repair #*] *,info,cassandra
Validating *,info,cassandra
Validating *,info,cassandra
Incremental repair can't be requested with subrange repair because each subrange repair would generate an anti-compacted table. The repair will occur but without anti-compaction.,warn,cassandra
Sequential repair disabled when memory-mapped I/O is configured on Windows. Reverting to parallel.,warn,cassandra
Started the RoundRobin Request Scheduler,info,cassandra
$$$Empty Message$$$,error,cassandra
restart cassandra with -Dcassandra.ignore_corrupted_schema_tables=true and ,error,cassandra
Skipping duplicate compilation of already existing UDF *,trace,cassandra
The option crc_check_chance was deprecated as a compression option. You should specify it as a top-level table option instead,warn,cassandra
The * option has been deprecated. You should use * insteadchunk_length_kbchunk_length_in_kb,warn,cassandra
The * option has been deprecated. You should use * insteadsstable_compressionclass,warn,cassandra
Moving * keyspaces from legacy schema tables to the new schema keyspace (*)system_schema,info,cassandra
Truncating legacy schema tables,info,cassandra
Completed migration of legacy schema tables,info,cassandra
Migrating keyspace *,info,cassandra
Failed to find index name for legacy migration of index on *.*,error,cassandra
Compaction strategy * does not have a static validateOptions method. Validation ignored,warn,cassandra
Indexer * does not have a static validateOptions method. Validation ignored,info,cassandra
initializing keystore from file *,info,cassandra
Certificate for * expired on *,warn,cassandra
Filtering out * as it isn't supported by the socket,warn,cassandra
initializing CipherFactory,info,cassandra
key * removed from cipher key cache,info,cassandra
loading secret key for alias *,info,cassandra
could not build cipher,error,cassandra
$$$Empty Message$$$,warn,cassandra
$$$Empty Message$$$,info,cassandra
$$$Empty Message$$$,trace,cassandra
Error accessing field of java.nio.Bits,trace,cassandra
Cannot start multiple repair sessions over the same sstables,error,cassandra
Cannot start multiple repair sessions over the same sstables,error,cassandra
Removing * in parent repair sessions,debug,cassandra
Initializing key cache with capacity of * MBs.,info,cassandra
Initializing row cache with capacity of * MBs,info,cassandra
Initializing counter cache with capacity of * MBs,info,cassandra
submitting cache saves,debug,cassandra
cache saves completed,debug,cassandra
JMX settings in cassandra-env.sh have been bypassed as the JMX connector server is already initialized. Please refer to cassandra-env.(sh|ps1) for JMX configuration info,warn,cassandra
Exception in thread ,error,cassandra
Exception in thread ,error,cassandra
Exception in thread ,error,cassandra
opening keyspace *,debug,cassandra
Error loading key or row cache,warn,cassandra
Unable to start GCInspector (currently only supported on the Sun JVM),warn,cassandra
Trying to load metrics-reporter-config from file: *,info,cassandra
"Failed to load metrics-reporter-config, file does not exist: *",warn,cassandra
"Failed to load metrics-reporter-config, metric sinks will not be activated",warn,cassandra
Hostname: *,info,cassandra
Could not resolve local host,info,cassandra
JVM vendor/version: */*,info,cassandra
Heap size: */*,info,cassandra
* *: *,info,cassandra
Classpath: *,info,cassandra
JVM Arguments: *,info,cassandra
Not starting client transports in write_survey mode as it's bootstrapping or auth is enabled,info,cassandra
Not starting client transports as bootstrap has not completed,info,cassandra
Not starting native transport as requested. Use JMX (StorageService->startNativeTransport()) or nodetool (enablebinary) to start it,info,cassandra
Not starting RPC server as requested. Use JMX (StorageService->startRPCServer()) or nodetool (enablethrift) to start it,info,cassandra
Cassandra shutting down...,info,cassandra
Error shutting down local JMX server: ,error,cassandra
Exception encountered during startup,error,cassandra
Exception encountered during startup: *,error,cassandra
$$$Empty Message$$$,error,cassandra
Sending a EchoMessage reply *,trace,cassandra
Enqueuing response to snapshot request * to *,debug,cassandra
Can't send schema pull request: node * is down.,warn,cassandra
Skipped sending a migration request: node * has a higher major version now.,info,cassandra
Configuration exception merging remote schema,error,cassandra
Disseminating load info ...,trace,cassandra
Got failure from *,trace,cassandra
resolving * responses,trace,cassandra
resolve: * ms.,trace,cassandra
Finished PendingRangeTask for * keyspaces in *ms,trace,cassandra
Overriding RING_DELAY to *ms,info,cassandra
Stopping gossip by operator request,warn,cassandra
Stopping gossiper,error,cassandra
Stopping RPC server,error,cassandra
Stopping native transport,error,cassandra
Gathering node replacement information for *,info,cassandra
Skipping endpoint collision check as cassandra.allow_unsafe_join=true,warn,cassandra
Starting shadow gossip round to check for endpoint collision,debug,cassandra
Unable to gossip with any peers but continuing anyway since node is in its own seed list,info,cassandra
Populating token metadata from system tables,info,cassandra
Token metadata: *,info,cassandra
Cassandra version: *,info,cassandra
Thrift API version: *20.1.0,info,cassandra
CQL supported versions: * (default: *),info,cassandra
Not starting gossip as requested.,info,cassandra
Error loading counter cache,warn,cassandra
Not joining ring as requested. Use JMX (StorageService->joinRing()) to initiate ring joining,info,cassandra
Loading persisted ring state,info,cassandra
Replace address on first boot requested; this node is already bootstrapped,info,cassandra
"This node was decommissioned, but overriding by operator request.",warn,cassandra
"Writes will not be forwarded to this node during replacement because it has the same address as the node to be replaced (*). If the previous node has been down for longer than max_hint_window_in_ms, repair must be run after the replacement process in order to make this node consistent.",warn,cassandra
Starting up server gossip,info,cassandra
got schema: *,debug,cassandra
Bootstrap variables: * * * *,debug,cassandra
This node will not auto bootstrap because it is configured to be a seed node.,info,cassandra
Detected previous bootstrap failure; retrying,warn,cassandra
... got ring + schema info,debug,cassandra
Using saved tokens *,info,cassandra
"Some data streaming failed. Use nodetool to check bootstrap state and resume. For more, see `nodetool help bootstrap`. *",warn,cassandra
"Startup complete, but write survey mode is active, not becoming an active ring member. Use JMX (StorageService->joinRing()) to finalize ring joining.",info,cassandra
"Some data streaming failed. Use nodetool to check bootstrap state and resume. For more, see `nodetool help bootstrap`. *",warn,cassandra
Joining ring by operator request,info,cassandra
Leaving write survey mode and joining ring at operator request,info,cassandra
Can't join the ring because in write_survey mode and bootstrap hasn't completed,warn,cassandra
Can't join the ring because bootstrap hasn't completed.,warn,cassandra
"Attempted to create new keyspace *, but it already exists",debug,cassandra
"rebuild from dc: *, *, *",info,cassandra
"adding range: (*,*]",info,cassandra
Error while rebuilding node,error,cassandra
set rpc timeout to * ms,info,cassandra
set read rpc timeout to * ms,info,cassandra
set range rpc timeout to * ms,info,cassandra
set write rpc timeout to * ms,info,cassandra
set counter write rpc timeout to * ms,info,cassandra
set cas contention rpc timeout to * ms,info,cassandra
set truncate rpc timeout to * ms,info,cassandra
set streaming socket timeout to * ms,info,cassandra
setstreamthroughput: throttle set to *,info,cassandra
setinterdcstreamthroughput: throttle set to *,info,cassandra
$$$Empty Message$$$,info,cassandra
$$$Empty Message$$$,debug,cassandra
Resetting bootstrap progress to start fresh,info,cassandra
Bootstrap completed! for the tokens *,info,cassandra
Error during bootstrap.,warn,cassandra
Error while waiting on bootstrap to complete. Bootstrap will have to be restarted.,error,cassandra
Resuming bootstrap...,info,cassandra
"Startup complete, but write survey mode is active, not becoming an active ring member. Use JMX (StorageService->joinRing()) to finalize ring joining.",info,cassandra
Resume complete,info,cassandra
$$$Empty Message$$$,error,cassandra
"Resuming bootstrap is requested, but the node is already bootstrapped.",info,cassandra
Ignoring state change for dead or unknown endpoint: *,debug,cassandra
"Node * state bootstrapping, token *",debug,cassandra
Node * state jump to bootstrap,info,cassandra
Node * tried to replace malformed endpoint *.,error,cassandra
"Node * is replacing *, tokens *",debug,cassandra
"Node * state leaving, tokens *",debug,cassandra
Node * state jump to leaving,info,cassandra
Node * 'leaving' token mismatch. Long network partition?,warn,cassandra
Received removenode gossip about myself. Is this node rejoining after an explicit removenode?,info,cassandra
Tokens * removed manually (endpoint was *),debug,cassandra
Removing tokens * for *,info,cassandra
Notifying * of replication completion ,debug,cassandra
Requesting from * ranges *,debug,cassandra
Streaming to restore replica count failed,warn,cassandra
Node * ranges [*],debug,cassandra
Range * already in all replicas,debug,cassandra
Range * will be responsibility of *,debug,cassandra
Cleared out snapshot directories,debug,cassandra
"Forcing flush on keyspace *, CF *",debug,cassandra
Snapshot-based repair is not yet supported on Windows.  Reverting to parallel repair.,warn,cassandra
Snapshot-based repair is not yet supported on Windows.  Reverting to parallel repair.,warn,cassandra
Incremental repair can't be requested with subrange repair because each subrange repair would generate an anti-compacted table. The repair will occur but without anti-compaction.,warn,cassandra
starting user-requested repair of range * for keyspace * and column families *,info,cassandra
computing ranges for *,trace,cassandra
DECOMMISSIONING,debug,cassandra
failed to shutdown message service: *,info,cassandra
Error while decommissioning node ,error,cassandra
Announcing that I have left the ring for *ms,info,cassandra
Ranges needing transfer are [*],debug,cassandra
waiting for batch log processing.,debug,cassandra
waiting for stream acks.,debug,cassandra
stream acks all received.,debug,cassandra
Unable to stream hints since no live endpoints seen,warn,cassandra
Invalid request to move(Token); This node has more than one token and cannot be moved thusly.,error,cassandra
Successfully moved to new token *,debug,cassandra
Removal not confirmed for for *,warn,cassandra
"No nodes to force removal on, call 'removenode' first",warn,cassandra
"Node * is already being removed, continuing removal anyway",warn,cassandra
Endpoint * is down and will not receive data for re-replication of *,warn,cassandra
Received unexpected REPLICATION_FINISHED message from *. Was this node recently a removal coordinator?,info,cassandra
"Created new dynamic snitch * with update-interval=*, reset-interval=*, badness-threshold=*",info,cassandra
Created new non-dynamic snitch *,info,cassandra
"Applying config change to dynamic snitch * with update-interval=*, reset-interval=*, badness-threshold=*",info,cassandra
"Skipping transferred range * of keyspace *, endpoint *",debug,cassandra
Updated hinted_handoff_throttle_in_kb to *,info,cassandra
"Not pulling schema because release version in Gossip is not major version *, it is *",debug,cassandra
"Not pulling schema from *, because local schama version is not known yet",debug,cassandra
"Not pulling schema from *, because schema versions match: local/real=*, local/compatible=*, remote=*",debug,cassandra
Not pulling schema because versions match or shouldPullSchemaFrom returned false,debug,cassandra
"Immediately submitting migration task for *, schema versions: local/real=*, local/compatible=*, remote=*",debug,cassandra
Migration task failed to complete,error,cassandra
Migration task was interrupted,error,cassandra
Create new Keyspace: *,info,cassandra
Create new table: *,info,cassandra
Create new view: *,info,cassandra
Create scalar function '*',info,cassandra
Create aggregate function '*',info,cassandra
Update Keyspace '*' From * To *,info,cassandra
Update table '*/*' From * To *,info,cassandra
Update view '*/*' From * To *,info,cassandra
Update type '*.*' to *,info,cassandra
Drop Keyspace '*',info,cassandra
Drop table '*/*',info,cassandra
Drop table '*/*',info,cassandra
Drop scalar function overload '*' args '*',info,cassandra
Drop aggregate function overload '*' args '*',info,cassandra
Gossiping my * schema version *,debug,cassandra
Starting local schema reset...,info,cassandra
Truncating schema tables...,debug,cassandra
Clearing local schema keyspace definitions...,debug,cassandra
Requesting schema from *,debug,cassandra
Local schema reset is complete.,info,cassandra
jemalloc shared library could not be preloaded to speed up memory allocations,warn,cassandra
jemalloc preload explicitly disabled,info,cassandra
jemalloc seems to be preloaded from *,info,cassandra
JMX is not enabled to receive remote connections. Please see cassandra-env.sh for more info.,warn,cassandra
"cassandra.jmx.local.port missing from cassandra-env.sh, unable to start local JMX service.",error,cassandra
JMX is enabled to receive remote connections on port: *,info,cassandra
Use of com.sun.management.jmxremote.port at startup is deprecated. Please use cassandra.jmx.remote.port instead.,warn,cassandra
32bit JVM detected.  It is recommended to run Cassandra on a 64bit JVM for better performance.,warn,cassandra
"Non-Oracle JVM detected.  Some features, such as immediate unmap of compacted SSTables, may not work as intended",warn,cassandra
"The JVM is not configured to stop on OutOfMemoryError which can cause data corruption. Use one of the following JVM options to configure the behavior on OutOfMemoryError:  -XX:+ExitOnOutOfMemoryError, -XX:+CrashOnOutOfMemoryError, or -XX:OnOutOfMemoryError=""<cmd args>;<cmd args>""",warn,cassandra
"The JVM is not configured to stop on OutOfMemoryError which can cause data corruption. Either upgrade your JRE to a version greater or equal to 8u92 and use -XX:+ExitOnOutOfMemoryError/-XX:+CrashOnOutOfMemoryError or use -XX:OnOutOfMemoryError=""<cmd args>;<cmd args>"" on your current JRE.",warn,cassandra
Unable to parse *.,warn,cassandra
IO exception while reading file *.,warn,cassandra
"Maximum number of memory map areas per process (vm.max_map_count) * is too low, recommended value: *, you can change it with sysctl.1048575",warn,cassandra
Failed to apply paxos commit locally : *,error,cassandra
"Received base materialized view mutation for key * that does not belong to this node. There is probably a range movement happening (move or decommission),but this node hasn't updated its ring metadata yet. Adding mutation to local batchlog to be replayed later.",warn,cassandra
Error applying local view update to keyspace *: *,error,cassandra
Sending batchlog store request * to * for * mutations,trace,cassandra
Sending batchlog remove request * to *,trace,cassandra
Adding FWD message to *@*,trace,cassandra
Sending message to *@*,trace,cassandra
Failed to apply mutation locally : *,error,cassandra
Failed to apply mutation locally : *,error,cassandra
Timed out waiting on digest mismatch repair requests,trace,cassandra
$$$Empty Message$$$,error,cassandra
"Didn't get enough response rows; actual rows per range: *; remaining rows: *, new concurrent requests: *",trace,cassandra
"Estimated result rows per range: *; requested rows: *, ranges.size(): *; concurrent range requests: *",trace,cassandra
Hosts not in agreement. Didn't get a response from everybody: *,debug,cassandra
* disagrees (*),debug,cassandra
Schemas are in agreement.,debug,cassandra
"Starting a blocking truncate operation on keyspace *, CF *",debug,cassandra
"Cannot perform truncate, some hosts are down",info,cassandra
"Some hints were not written before shutdown.  This is not supposed to happen.  You should (a) run repair, and (b) file a bug report",warn,cassandra
Discarding hint for endpoint not part of ring: *,debug,cassandra
Adding hints for *,trace,cassandra
Netty using native Epoll event loop,info,cassandra
Netty using Java NIO event loop,info,cassandra
Timeout while read-repairing after receiving all * data and digest responses,debug,cassandra
"Encountered an oversized (*/*) read repair mutation for table *.*, key *, node *",debug,cassandra
"Encountered an oversized (*/*) read repair mutation for table *.*, key *, node *",warn,cassandra
*; received * of * responses*,debug,cassandra
Read: * ms.,trace,cassandra
reading * from *,trace,cassandra
reading * locally,trace,cassandra
speculating read retry on *,trace,cassandra
Prepare response * from *,trace,cassandra
Propose response * from *,trace,cassandra
Failed attempt * to connect to *. Retrying in * ms. (*),warn,cassandra
Connecting next session * with *.,debug,cassandra
Finished connecting all sessions,debug,cassandra
"[Stream #*, ID#*] Beginning stream session with *",info,cassandra
"[Stream #*] Start receiving file #* from *, repairedAt = *, size = *, ks = '*', table = '*'.",debug,cassandra
"[Stream #*] Finished receiving file #* from * readBytes = *, totalSize = *",debug,cassandra
[Stream *] Error while reading partition * from stream on ks='*' and table='*'.,warn,cassandra
"Initializing rewindable input stream for reading legacy sstable with * bytes with following parameters: initial_mem_buffer_size=*, max_mem_buffer_size=*, max_spill_file_size=*.",trace,cassandra
Error while closing RewindableDataInputStreamPlus.,warn,cassandra
"[Stream #*] Start streaming file * to *, repairedAt = *, totalSize = *",debug,cassandra
"[Stream #*] Finished streaming file * to *, bytesTransferred = *, totalSize = *",debug,cassandra
Peer * does not support keep-alive.,debug,cassandra
[Stream #*] Session does not have any tasks.,info,cassandra
[Stream #*] Starting streaming to **,info,cassandra
[Stream #*] Finishing keep-alive task.,debug,cassandra
"[Stream #*] Did not receive response from peer ** for * secs. Is peer down? If not, maybe try increasing streaming_keep_alive_period_in_secs.",error,cassandra
[Stream #*] Streaming socket timed out. This means the session peer stopped responding or is still processing received data. If there is no sign of failure in the other end or a very dense table is being transferred you may want to increase streaming_socket_timeout_in_ms property. Current value is *ms.,error,cassandra
[Stream #*] Streaming error occurred on session with peer **,error,cassandra
[Stream #*] Scheduling keep-alive task with *s period.,debug,cassandra
[Stream #*] Remote peer * failed stream session.,error,cassandra
[Stream #*] Session failed because remote peer * has left.,error,cassandra
[Stream #*] Session failed because remote peer * was restarted.,error,cassandra
[Stream #*] Sending keep-alive to *.,trace,cassandra
[Stream #*] Could not send keep-alive message (perhaps stream session is finished?).,debug,cassandra
[Stream #*] Skip sending keep-alive to * (previous was not yet sent).,trace,cassandra
[Stream #*] Sending stream init for incoming stream,debug,cassandra
[Stream #*] Sending stream init for outgoing stream,debug,cassandra
[Stream #*] Closing stream connection handler on *,debug,cassandra
Unexpected error while closing streaming connection,debug,cassandra
Could not set incoming socket timeout to *,warn,cassandra
[Stream #*] Received *,debug,cassandra
[Stream #*] Sending *,debug,cassandra
[Stream #*] Received * sstables from * (*),debug,cassandra
[Stream #*] Invalidated * row cache entries on table *.* after stream receive task completed.,debug,cassandra
[Stream #*] Invalidated * counter cache entries on table *.* after stream receive task completed.,debug,cassandra
[Stream #*] Executing streaming plan for *,info,cassandra
[Stream #* ID#*] Creating new streaming plan for *,info,cassandra
"[Stream #*, ID#*] Received streaming plan for *",info,cassandra
"[Stream #* ID#*] Prepare completed. Receiving * files(*), sending * files(*)",info,cassandra
[Stream #*] Session with * is complete,info,cassandra
[Stream #*] Stream failed,warn,cassandra
[Stream #*] All sessions completed,info,cassandra
Replying to *@*,debug,cassandra
Error while reading compressed input stream.,warn,cassandra
"[Stream #*] Start streaming file * to *, repairedAt = *, totalSize = *",debug,cassandra
[Stream #*] Writing section * with length * to stream.,trace,cassandra
"[Stream #*] Finished streaming file * to *, bytesTransferred = *, totalSize = *",debug,cassandra
Interrupted while waiting thrift server to stop,error,cassandra
Binding thrift service to *:*,info,cassandra
Listening for thrift clients...,info,cassandra
Stop listening to thrift clients,info,cassandra
Failed to set keep-alive on Thrift socket.,warn,cassandra
Failed to set send buffer size on Thrift socket.,warn,cassandra
Failed to set receive buffer size on Thrift socket.,warn,cassandra
Could not set socket timeout.,error,cassandra
Could not close server socket.,warn,cassandra
Failed to set keep-alive on Thrift socket.,warn,cassandra
Failed to set send buffer size on Thrift socket.,warn,cassandra
Failed to set receive buffer size on Thrift socket.,warn,cassandra
get_slice,trace,cassandra
multiget_slice,trace,cassandra
get_count,trace,cassandra
average row column size is *; using pageSize of *,trace,cassandra
multiget_count,trace,cassandra
insert,trace,cassandra
cas,trace,cassandra
batch_mutate,trace,cassandra
atomic_batch_mutate,trace,cassandra
remove,trace,cassandra
get_paged_slice,trace,cassandra
scan,trace,cassandra
Failed to find metadata for keyspace '*'. Continuing... ,info,cassandra
add_column_family,trace,cassandra
drop_column_family,trace,cassandra
add_keyspace,trace,cassandra
drop_keyspace,trace,cassandra
update_keyspace,trace,cassandra
update_column_family,trace,cassandra
truncating *.*,trace,cassandra
checking schema agreement,trace,cassandra
add,trace,cassandra
remove_counter,trace,cassandra
execute_cql3_query,trace,cassandra
prepare_cql3_query,trace,cassandra
execute_prepared_cql3_query,trace,cassandra
Retrieved prepared statement #* with * bind markers,trace,cassandra
get_multi_slice,trace,cassandra
Could not configure socket.,warn,cassandra
Could not configure socket.,error,cassandra
Could not set socket timeout.,warn,cassandra
Could not close socket.,warn,cassandra
Using non-blocking/asynchronous thrift server on * : *,info,cassandra
Using custom half-sync/half-async thrift server on * : *,info,cassandra
Using custom thrift server * on * : *,info,cassandra
rejecting invalid value *,trace,cassandra
Starting up *,info,cassandra
Error occurred during listening.,error,cassandra
Transport error occurred during acceptance of message.,warn,cassandra
Dropping client connection because our limit of * has been reached,trace,cassandra
Maximum number of clients * reached,warn,cassandra
Thrift transport error occurred during processing of message.,trace,cassandra
Thrift error occurred during processing of message.,error,cassandra
Error occurred during processing of message.,error,cassandra
enabling encrypted thrift connections between client and server,info,cassandra
Fatal error parsing partition: *,error,cassandra
Fatal error parsing row.,error,cassandra
Failure parsing ColumnData.,error,cassandra
Failure parsing cell.,error,cassandra
Adding <*> to trace events,trace,cassandra
Waiting for up to * seconds for * trace events to complete,trace,cassandra
Failed to wait for tracing events to complete in * seconds,trace,cassandra
Got exception whilst waiting for tracing events to complete,error,cassandra
"Failed to insert pending future, tracing synchronization may not work",warn,cassandra
Too many nodes are overloaded to save trace events,warn,cassandra
request complete,trace,cassandra
Exceeded maximum native connection limit of * by using * connections,warn,cassandra
Exceeded maximum native connection limit per ip of * by using * connections,warn,cassandra
$$$Empty Message$$$,trace,cassandra
$$$Empty Message$$$,info,cassandra
$$$Empty Message$$$,error,cassandra
Enabling optionally encrypted CQL connections between client and server,info,cassandra
Enabling encrypted CQL connections between client and server,info,cassandra
Using Netty Version: *,info,cassandra
Starting listening for CQL clients on * (*)...,info,cassandra
Stop listening for CQL clients,info,cassandra
Problem retrieving RPC address for *,error,cassandra
"Sending event for endpoint *, rpc address *",trace,cassandra
"Topology changed event : *, *",trace,cassandra
"Status changed event : *, *",trace,cassandra
Exception in response,error,cassandra
Unexpected error during query,error,cassandra
Unexpected exception during request,error,cassandra
Loading new jar *,info,cassandra
"Class not found using parent class loader,",trace,cassandra
Configured JMX server at: *,info,cassandra
"JMX SSL configuration. { protocols: [*], cipher_suites: [*], require_client_auth: * }",debug,cassandra
Expired * entries,trace,cassandra
"Will try to load mx4j now, if it's in the classpath",trace,cassandra
mx4j successfuly loaded,info,cassandra
"Will not load MX4J, mx4j-tools.jar is not in the classpath",trace,cassandra
Could not start register mbean in JMX,warn,cassandra
JNA mlockall successful,info,cassandra
"Unable to lock JVM memory (ENOMEM). This can result in part of the JVM being swapped out, especially with mmapped I/O enabled. Increase RLIMIT_MEMLOCK or run Cassandra as root.",warn,cassandra
Unknown mlockall error *,warn,cassandra
Could not skip cache,warn,cassandra
"posix_fadvise(*, *) failed, errno (*).",warn,cassandra
"fcntl(*, *, *) failed, errno (*).",warn,cassandra
"open(*, O_RDONLY) failed, errno (*).",warn,cassandra
"fsync(*) failed, errorno (*) *",warn,cassandra
"close(*) failed, errno (*).",warn,cassandra
Unable to read fd field from FileChannel,warn,cassandra
Unable to read fd field from FileDescriptor,warn,cassandra
Failed to get PID from JNA,info,cassandra
"Digest mismatch detected among leaf nodes *, *",debug,cassandra
"Digest mismatch detected, traversing trees [*, *]",debug,cassandra
Range * fully inconsistent,debug,cassandra
"(*) No sane midpoint (*) for range * , marking whole range as inconsistent",debug,cassandra
"(*) Hashing sub-ranges [*, *] for * divided by midpoint *",debug,cassandra
"(*) Inconsistent digest on left sub-range *: [*, *]",debug,cassandra
(*) Left sub-range fully inconsistent *,debug,cassandra
"(*) Inconsistent digest on right sub-range *: [*, *]",debug,cassandra
(*) Right sub-range fully inconsistent *,debug,cassandra
"(*) Fully inconsistent range [*, *]",debug,cassandra
(*) Adding left sub-range to diff as fully inconsistent *,debug,cassandra
(*) Adding right sub-range to diff as fully inconsistent *,debug,cassandra
(*) Range * partially inconstent,debug,cassandra
"Trigger directory doesn't exist, please create it and try again.",warn,cassandra
Unable to load version.properties,warn,cassandra
$$$Empty Message$$$,info,cassandra
$$$Empty Message$$$,warn,cassandra
$$$Empty Message$$$,error,cassandra
$$$Empty Message$$$,info,cassandra
$$$Empty Message$$$,warn,cassandra
$$$Empty Message$$$,error,cassandra
Failed to set timer to : *. Performance will be degraded.,warn,cassandra
Failed to end accelerated timer period. System timer will remain set to: * ms.,warn,cassandra
$$$Empty Message$$$,info,cassandra
$$$Empty Message$$$,trace,cassandra
$$$Empty Message$$$,warn,cassandra
$$$Empty Message$$$,warn,cassandra
Unable to create output file for debugging coalescing,error,cassandra
* gap *μs,info,cassandra
Underlying string constructor threw an error: *,error,cassandra
Some JRE information could not be retrieved for the JRE version: ,error,cassandra
Cannot provide an optimal BloomFilter for * elements (*/* buckets per element).,warn,cassandra
Initializing SIGAR library,info,cassandra
Could not initialize SIGAR library * ,info,cassandra
Could not initialize SIGAR library * ,info,cassandra
Could not determine if max processes was acceptable. Error message: *,warn,cassandra
Could not determine if max open file handle limit is correctly configured. Error message: *,warn,cassandra
Could not determine if VirtualMemoryMax was acceptable. Error message: *,warn,cassandra
Could not determine if swap configuration is acceptable. Error message: *,warn,cassandra
"Cassandra server running in degraded mode. Is swap disabled? : *,  Address space adequate? : *,  nofile limit adequate? : *, nproc limit adequate? : * ",warn,cassandra
Checked OS settings and found them configured for optimal performance.,info,cassandra
"Sigar could not be initialized, test for checking degraded mode omitted.",info,cassandra
Trying to log the heap histogram using jcmd,info,cassandra
The process ID could not be retrieved. Skipping heap histogram generation.,error,cassandra
The heap histogram could not be generated due to the following error: ,error,cassandra
$$$Empty Message$$$,info,cassandra
OutOfMemory error letting the JVM handle the error:,error,cassandra
Exiting due to error while processing commit log during initialization.,error,cassandra
$$$Empty Message$$$,error,cassandra
JVM state determined to be unstable.  Exiting forcefully due to:,error,cassandra
Failure to offer sample,trace,cassandra
BAD RELEASE: attempted to release a reference (*) that has already been released,error,cassandra
LEAK DETECTED: a reference (*) to * was not released before the reference was garbage collected,error,cassandra
Error when closing *,error,cassandra
Allocate trace *: *,error,cassandra
Deallocate trace *: *,error,cassandra
Strong reference leak candidates detected: *,warn,cassandra
You are using Cassandra with an unsupported deployment. The intended logging implementation library logback is not used by slf4j. Detected slf4j logger factory: *. You will not be able to dynamically manage log levels via JMX and may have performance or other issues.,warn,cassandra
"The log level was not changed, because you are using an unsupported slf4j logging implementation for which this functionality was not implemented.",warn,cassandra
"An empty map of logger names and their logging levels was returned, because you are using an unsupported slf4j logging implementation for which this functionality was not implemented.",warn,cassandra
set log level to * for classes under '*' (if the level doesn't look like '*' then the logger couldn't parse '*'),info,cassandra
* regions now allocated in *,trace,cassandra
Requested buffer size * has been allocated directly due to lack of capacity,trace,cassandra
"Requested buffer size * is bigger than *, allocating directly",trace,cassandra
"Maximum memory usage reached (*), cannot allocate chunk of *1048576",info,cassandra
"Buffer pool failed to allocate chunk of *, current size * (*). Attempting to continue; buffers will be allocated in on-heap memory which can degrade performance. Make sure direct memory size (-XX:MaxDirectMemorySize) is large enough to accommodate off-heap memtables and caches.1048576",error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Exception writing to internal frame buffer,error,cassandra
Test failed. *,info,cassandra
Re-running * times to verify it isn't failing more often than it should.,info,cassandra
"Test failed again, total num failures: *",debug,cassandra
Test failed in * of the * reruns.,error,cassandra
All reruns succeeded. Failure treated as flake.,info,cassandra
Encountered non-info status in logger setup; aborting stdout capture: ',warn,cassandra
$$$Empty Message$$$,error,cassandra
$$$Empty Message$$$,info,cassandra
Removed index entry for stale value *,debug,cassandra
Inserted entry into index for value *,debug,cassandra
Removed index entry for value *,debug,cassandra
"No SSTable data for *.* to build index * from, marking empty index as built",info,cassandra
Submitting index build of * for data in *,info,cassandra
Index build of * complete,info,cassandra
Received matching message: *,trace,cassandra
Responding to intercepted message: *,trace,cassandra
Error publishing StatisticsMXBean,warn,karaf
Client  |  request received on ,info,karaf
Datasource * ,debug,karaf
Error creating table ,error,karaf
Tables does not exist,info,karaf
Schema and tables has been created,info,karaf
Can't create tables,error,karaf
Tables already exist,info,karaf
Can't verify tables existence,error,karaf
Can't retreive the bookings,error,karaf
Error getting connection ,error,karaf
Can't find booking with id *,error,karaf
Error getting connection ,error,karaf
Booking created with id = *,debug,karaf
Can't insert booking with customer *,error,karaf
Error getting connection ,error,karaf
Service deleted with id = *,debug,karaf
Can't delete service with id *,error,karaf
Error getting connection ,error,karaf
Using repositories:,info,karaf
   ,info,karaf
Creating work directory: ,info,karaf
Loading direct KAR and features XML dependencies,info,karaf
   Standard startup Karaf KAR found: ,info,karaf
   Custom startup KAR found: ,info,karaf
   Standard startup KAR implied from framework ( | ): ,info,karaf
   Feature  |  will be added as a startup feature,info,karaf
"Your project should use the ""kar"" packaging or configure a ""classifier"" for kar attachment",warn,karaf
Artifact was not resolved,error,karaf
Artifact was not found,error,karaf
$$$Empty Message$$$,error,karaf
"Feature artifact is a SNAPSHOT, handling the maven-metadata-local.xml",debug,karaf
Looking for ,debug,karaf
" doesn't exist, create it",debug,karaf
Could not create maven-metadata-local.xml,warn,karaf
It means that this SNAPSHOT could be overwritten by an older one present on remote repositories,warn,karaf
Adding file  |  in the jar path  | /maven-metadata-local.xml,debug,karaf
Could not create maven-metadata-local.xml,warn,karaf
It means that this SNAPSHOT could be overwritten by an older one present on remote repositories,warn,karaf
Cannot delete temporary created file.,warn,karaf
Using Karaf container located ,info,karaf
Extracting Karaf container,info,karaf
Starting Karaf container,info,karaf
Artifact was not resolved,error,karaf
Artifact was not found,error,karaf
$$$Empty Message$$$,error,karaf
Creating Dockerfile,info,karaf
Using repositories: ,info,karaf
Verification of feature  |  skipped,info,karaf
Verification of feature  |  succeeded,info,karaf
: ,warn,karaf
$$$Empty Message$$$,warn,karaf
$$$Empty Message$$$,warn,karaf
Verification of feature  |  succeeded,info,karaf
Feature resolution failed for  | \nMessage: ,warn,karaf
$$$Empty Message$$$,warn,karaf
$$$Empty Message$$$,warn,karaf
"Features verified:  | , failures:  | , ignored:  | , skipped: ",info,karaf
"Failures:  | , ",info,karaf
$$$Empty Message$$$,debug,karaf
$$$Empty Message$$$,info,karaf
$$$Empty Message$$$,warn,karaf
$$$Empty Message$$$,error,karaf
Creating Docker image,info,karaf
Docker PID  |  running,info,karaf
Docker image  |  created,info,karaf
Client execution is skipped,info,karaf
No command specified,warn,karaf
$$$Empty Message$$$,info,karaf
Error starting ssh agent for: ,error,karaf
retrying (attempt  | ) ...,info,karaf
Error starting ssh agent for: ,error,karaf
retrying (attempt  | ) ...,info,karaf
Found command:  | :,info,karaf
Unable to write help for ,warn,karaf
Ignoring jar without BundleSymbolicName: ,warn,karaf
Copying artifact: ,info,karaf
Error copying artifact ,warn,karaf
Generation not enabled,info,karaf
Attaching artifact,info,karaf
Attaching features XML,info,karaf
$$$Empty Message$$$,error,karaf
Generating feature descriptor file ,info,karaf
...done!,info,karaf
Error while reading artifact from directory,warn,karaf
Manifest not present in the module directory ,warn,karaf
Error while opening artifact,warn,karaf
Manifest not present in the first entry of the zip - ,warn,karaf
Error while reading artifact,warn,karaf
"dependencies.contains:  | , dependencies.remove(test): ",warn,karaf
"dependencies.contains:  | , size before:  | , size after: ",warn,karaf
"dependencies.contains:  | , dependencies.remove(test): ",warn,karaf
"dependencies.contains:  | , size before:  | , size after: ",warn,karaf
$$$Empty Message$$$,info,karaf
$$$Empty Message$$$,warn,karaf
"File encoding has not been set, using platform encoding  | , i.e. build is platform dependent!",warn,karaf
Can't add  |  in the descriptors set,warn,karaf
$$$Empty Message$$$,debug,karaf
Can't resolve artifact ,warn,karaf
$$$Empty Message$$$,debug,karaf
Using local repository at: ,info,karaf
Resolving artifact  |  from ,debug,karaf
Cound not resolve ,warn,karaf
Resolved artifact  |  to  |  from ,debug,karaf
Resolving artifact  |  from ,debug,karaf
Could not resolve ,warn,karaf
Resolved artifact  |  to  |  from ,debug,karaf
Ignoring ,info,karaf
Activator ,info,karaf
Service ,info,karaf
Use artifact  |  ,debug,karaf
Ignore artifact ,debug,karaf
Unknown queue type:  | ,warn,karaf
Error creating layout:  | . Using a simple layout.,error,karaf
Error waiting for audit runner buffer stop,debug,karaf
Error closing audit logger,debug,karaf
Interrupted while putting event in queue,debug,karaf
Error writing audit log,warn,karaf
Blueprint app state changed to  |  for bundle ,debug,karaf
Dependency tree calculated in %d ms,debug,karaf
Skipping %s (already exists in the current branch),debug,karaf
Adding %s as a dependency for %s,debug,karaf
Skipping children of %s (already exists in another branch),debug,karaf
Updating %s with URL %s,debug,karaf
No additional packages have been wired since dynamic import was enabled,debug,karaf
Additional packages wired since dynamic import was enabled,debug,karaf
- ,debug,karaf
Error retrieving maven configuration,error,karaf
Error retrieving maven configuration,error,karaf
Bundle watcher thread started,debug,karaf
Error watching bundle.,error,karaf
Error updating bundle.,error,karaf
"[Watch] Bundle * is a fragment, so it's not started",info,karaf
[Watch] Error starting bundle,warn,karaf
Bundle watcher thread stopped,debug,karaf
[Watch] Updating watched bundle: * (*),info,karaf
"[Watch] Bundle * is a fragment, so it's not stopped",info,karaf
Could not parse artifact path for bundle,error,karaf
$$$Empty Message$$$,error,karaf
Spring app state changed to  |  for bundle ,debug,karaf
config:meta disabled because the org.osgi.service.metatype package is not wired,warn,karaf
config:meta disabled because the org.osgi.service.metatype package is not wired (enable debug logging for full stack trace).,warn,karaf
Updating configuration *,trace,karaf
Deleting configuration *,trace,karaf
Blueprint xml URL is: [ | ],debug,karaf
Error opening blueprint xml url,error,karaf
Unable to parse deployed file ,error,karaf
Unable to build blueprint application bundle,error,karaf
Unable to get FeatureDeploymentListener.cfg,debug,karaf
unknown features uri,error,karaf
Unable to parse deployed file ,error,karaf
Unable to build feature bundle,error,karaf
Unable to update deployed features for bundle:  |  - ,error,karaf
Features xml URL is: [ | ],debug,karaf
Error opening features xml url,error,karaf
Deployment finished. Registering FeatureDeploymentListener,info,karaf
$$$Empty Message$$$,error,karaf
KAR * is already installed. Please uninstall it first.,info,karaf
Installing KAR file *,info,karaf
Uninstalling KAR *,info,karaf
Karaf archive *' has been updated; redeploying.,warn,karaf
Found a .kar file to deploy.,info,karaf
Found a .zip file to deploy; checking contents to see if it's a Karaf archive.,debug,karaf
Found a Karaf archive with .zip prefix; will deploy.,info,karaf
Problem extracting zip file '*'; ignoring.,warn,karaf
Problem closing zip file '*'; ignoring.,warn,karaf
Unable to parse deployed file ,error,karaf
Unable to build spring application bundle,error,karaf
Spring xml URL is: [ | ],debug,karaf
Error opening Spring xml url,error,karaf
Created dump ,info,karaf
$$$Empty Message$$$,debug,karaf
$$$Empty Message$$$,debug,karaf
Can't parse \ | \,debug,karaf
Matched URI can't use version ranges: ,warn,karaf
Downloading [ | ],trace,karaf
Error downloading  | :  | .  |  in approx  |  ms.,debug,karaf
Old style feature file without namespace found (URI: *). This format is deprecated and support for it will soon be removed,warn,karaf
Can't parse blacklisted repository location pattern:  | . Ignoring.,warn,karaf
Can't override bundle in maven mode without explicit original URL. Switching to osgi mode.,warn,karaf
Can't parse override URL location pattern:  | . Ignoring.,warn,karaf
Override URI \ | \,warn,karaf
Can't parse override URL location pattern:  | . Ignoring.,warn,karaf
Problem parsing override URI \ | \ | . Version ranges are not handled. Ignoring.,warn,karaf
Problem parsing override URI \ | \ | . Ignoring.,warn,karaf
Error reading configuration file ,warn,karaf
Unrecognized resource repository: ,warn,karaf
Ignoring failure: ,warn,karaf
Ignoring failure: ,warn,karaf
$$$Empty Message$$$,error,karaf
$$$Empty Message$$$,warn,karaf
$$$Empty Message$$$,info,karaf
$$$Empty Message$$$,debug,karaf
$$$Empty Message$$$,warn,karaf
"Value * has unresolved properties, please check configuration.",warn,karaf
Unable to load blacklist bundles list *,debug,karaf
Unable to load blacklist bundles list,debug,karaf
Repository blacklist URI is empty. Ignoring.,warn,karaf
Problem parsing repository blacklist URI \ | \ | . Ignoring.,warn,karaf
Problem parsing blacklisted feature identifier \ | \ | . Ignoring.,warn,karaf
Bundle blacklist URI is empty. Ignoring.,warn,karaf
Problem parsing bundle blacklist URI \ | \ | . Ignoring.,warn,karaf
$$$Empty Message$$$,info,karaf
Unable to load overrides bundles list *,debug,karaf
Unable to load overrides bundles list,debug,karaf
Unable to post event to EventAdmin,warn,karaf
Unable to post event to EventAdmin,warn,karaf
Can't update cfg file,warn,karaf
Skipping configuration * - file already exists,info,karaf
Can't update cfg file,warn,karaf
Substitution failed. Skip substitution of variables of configuration final name (*).,info,karaf
"Configuration file * already exist, don't override it",debug,karaf
"Configuration file * already exist, overriding it",info,karaf
Creating configuration file *,info,karaf
$$$Empty Message$$$,error,karaf
Update *,trace,karaf
Error installing boot features,error,karaf
Error installing boot feature repository ,error,karaf
Converted path to unix separators: *,debug,karaf
Update snapshot for ,debug,karaf
Error calculating checksum for bundle: *,debug,karaf
New snapshot available for ,debug,karaf
Usage for bundle * is *,debug,karaf
Selected bundles * for destroy (no services in use),debug,karaf
Currently selecting bundle * for destroy (with reference *),debug,karaf
Selected bundle * for destroy (lowest ranking service),debug,karaf
"Can't find feature processing file ( | ), skipping",debug,karaf
Can't initialize feature processor: ,warn,karaf
Overriding bundle location \ | \ | \,debug,karaf
Error reading resolution request,warn,karaf
Error updating state,warn,karaf
Error loading FeaturesService state,warn,karaf
Error saving FeaturesService state,warn,karaf
Error notifying listener about the current state,error,karaf
DeploymentListener * failed to process event *,warn,karaf
Can't load features repository *,warn,karaf
The specified feature: '*' version '*' *,info,karaf
$$$Empty Message$$$,info,karaf
Can't load proxies,error,karaf
removing proxy *,debug,karaf
update proxies,debug,karaf
Adding * proxy to * (*),debug,karaf
Adding * proxy to *,debug,karaf
Can't add * proxy to *,error,karaf
unable to update http proxy from configuration,error,karaf
Proxy to * (host *),debug,karaf
Could not read port start value from the root instance configuration.,debug,karaf
$$$Empty Message$$$,info,karaf
$$$Empty Message$$$,debug,karaf
Starting instance  |  with command: ,debug,karaf
Unable to cleanly shutdown root instance ,debug,karaf
Unable to cleanly shutdown instance ,debug,karaf
Keystore * not found,info,karaf
Keystore * locked,info,karaf
Keystore's key * locked,info,karaf
Truststore * not found,info,karaf
Truststore * locked,info,karaf
Unable to retrieve default configuration,warn,karaf
Unable to read certificate from keystore,error,karaf
Unable to read retrieve alias for given certificate from keystore,error,karaf
Unable to read certificate chain from keystore,error,karaf
Unable to read private key from keystore,error,karaf
Unable to read private key from keystore,error,karaf
Unable to read private key from keystore,error,karaf
Unable to open keystore with provided password,error,karaf
Unable to open keystore with provided password,error,karaf
Unable to open keystore with provided password,error,karaf
Unable to open keystore with provided password,error,karaf
abort,debug,karaf
logout,debug,karaf
Unable to send security auditing EventAdmin events: ,warn,karaf
* - * - *,debug,karaf
* - * - *,trace,karaf
* - * - *,warn,karaf
* - * - *,error,karaf
* - * - *,info,karaf
Encryption is disabled.,debug,karaf
Encryption is enabled. Using service  |  with options ,debug,karaf
Encryption is enabled. Using options ,debug,karaf
Initialization failed. Digest algorithm  |  is not available.,error,karaf
Initialization failed. Digest encoding  |  is not supported.,error,karaf
Error executing statement,error,karaf
Error executing statement,error,karaf
"Executing [%s], params=%s. %d rows affected.",debug,karaf
Error creating JDBCBackingEngine.,error,karaf
No datasource was specified ,error,karaf
Invalid datasource lookup protocol,error,karaf
No roleQuery specified so no roles have been retrieved for the authenticated user,debug,karaf
Changing from authentication = none to simple since user or password was specified.,debug,karaf
Get the user DN.,debug,karaf
Can't connect to the LDAP server: *,warn,karaf
Bind user (authentication).,debug,karaf
"Set the security principal for  | ,",debug,karaf
Binding the user.,debug,karaf
User  |  successfully bound.,debug,karaf
User  |  authentication failed.,warn,karaf
Looking for user * in LDAP with,debug,karaf
   base DN: *,debug,karaf
   filter: *,debug,karaf
Looking for the users in LDAP with ,debug,karaf
  base DN: ,debug,karaf
  filter: ,debug,karaf
Parse role mapping *,debug,karaf
Setting up SSL,debug,karaf
No LDAP URL specified.,error,karaf
Invalid LDAP URL: ,error,karaf
Get the user DN.,debug,karaf
Can't connect to the LDAP server: *,warn,karaf
Can't connect to the LDAP server: *,warn,karaf
Public key authentication failed for user *: *,warn,karaf
Looking for the user in LDAP with ,debug,karaf
  base DN: ,debug,karaf
  filter: ,debug,karaf
User  |  not found in LDAP.,warn,karaf
Found the user DN.,debug,karaf
LDAP role * is mapped to Karaf role *,debug,karaf
Looking for the user roles in LDAP with ,debug,karaf
  base DN: *,debug,karaf
  filter: *,debug,karaf
User * is a member of role *,debug,karaf
PartialResultException encountered and ignored,debug,karaf
The user role filter is null so no roles are retrieved,debug,karaf
Looking for public keys of user * in attribute *,debug,karaf
The user public key attribute is null so no keys were retrieved,debug,karaf
gssapiRealm is not set,warn,karaf
error with delegated authentication,error,karaf
error with callback handler,error,karaf
error with callback handler,error,karaf
Get the user DN.,debug,karaf
Can't connect to the LDAP server: *,warn,karaf
Initialized debug=* usersFile=*,debug,karaf
$$$Empty Message$$$,debug,karaf
$$$Empty Message$$$,debug,karaf
Successfully logged in *,debug,karaf
"Cannot update users file,",error,karaf
"Cannot remove users file,",error,karaf
"Cannot update users file,",error,karaf
"Cannot update users file,",error,karaf
$$$Empty Message$$$,warn,karaf
$$$Empty Message$$$,warn,karaf
"The password isn't flagged as encrypted, encrypt it.",debug,karaf
Cannot open users file: *,warn,karaf
$$$Empty Message$$$,info,karaf
$$$Empty Message$$$,debug,karaf
Initialized debug=* usersFile=*,debug,karaf
Successfully logged in *,debug,karaf
Cannot open keys file:,warn,karaf
Initialized debug= |  usersFile=,debug,karaf
Successfully logged in ,debug,karaf
"Cannot update users file,",error,karaf
"Cannot remove users file,",error,karaf
"Cannot update users file,",error,karaf
"Cannot update users file,",error,karaf
Authenticate user * on Syncope located *,debug,karaf
Syncope HTTP response status code: *,debug,karaf
User * not authenticated,warn,karaf
User * authenticated,debug,karaf
Populating principals with user,debug,karaf
Retrieving user * roles,debug,karaf
User * authentication failed,error,karaf
Populating principals with roles,debug,karaf
Can't add user *,error,karaf
Can't add user *,error,karaf
Can't delete user *,error,karaf
Error creating the Syncope backing engine,error,karaf
Can't get information about datasource *,error,karaf
Multiple JDBC datasources found with the same service ranking for ,warn,karaf
File '*' is not a features file.,debug,karaf
Uncompress the KAR file * into directory *,debug,karaf
"kar entry * contains a .. relative path. For security reasons, it's not allowed.",warn,karaf
Creating directory *,debug,karaf
Error closing stream,warn,karaf
Installing KAR * from *,debug,karaf
Feature dependency * is not available. Kar deployment postponed to see if it is about to be deployed,warn,karaf
Dependencies of kar * are now satisfied. Installing,info,karaf
Error closing reader for file ,warn,karaf
Added feature repository '*',info,karaf
Unable to add repository '*',warn,karaf
noAutoRefreshBundles is *,debug,karaf
noAutoStartBundles is * (default *),debug,karaf
Unable to install Kar feature *,warn,karaf
Feature  | / |  has install flag set to \,warn,karaf
Can't get features for KAR *,warn,karaf
Error closing stream,warn,karaf
Error adding ,error,karaf
Unable to uninstall Kar feature *,warn,karaf
Can't get features for KAR *,warn,karaf
Delayed deployment of kar  |  failed,error,karaf
Installing and starting initial bundles,info,karaf
All initial bundles installed and set to start,info,karaf
"Data directory does not exist anymore, halting",info,karaf
Lock lost. Setting startlevel to ,warn,karaf
Lock acquired. Setting startlevel to ,info,karaf
Shutdown socket thread is listening on  | :,info,karaf
$$$Empty Message$$$,info,karaf
Executing statement: ,info,karaf
Trying to lock ,info,karaf
Lock acquired,info,karaf
Lock failed,info,karaf
Releasing lock ,info,karaf
Executing statement: ,info,karaf
INSTANCE unique id: ,info,karaf
Failed to acquire database lock. Missing database lock record.,warn,karaf
Failed to acquire database lock: ,warn,karaf
Attribute  |  can not be found for MBean ,debug,karaf
"The current roles are \' | \', however the expected roles are \' | \'. To make the call pass RBAC check, please add current role into entry \' | \' of file  | .cfg",debug,karaf
Can't init JMXConnectorServer: ,error,karaf
Can't re-init JMXConnectorServer with SSL enabled when register a keystore:,error,karaf
Can't re-init JMXConnectorServer with SSL enabled when unregister a keystore: ,error,karaf
Error destroying ConnectorServerFactory,warn,karaf
Error destroying MBeanServerFactory,warn,karaf
"* (objectName = ""*"", method = ""*"")",warn,karaf
$$$Empty Message$$$,error,karaf
$$$Empty Message$$$,error,karaf
$$$Empty Message$$$,error,karaf
Can't decrypt ,warn,karaf
Problem with segment  |  in ,warn,karaf
Problem with segment  |  in ,warn,karaf
Problem with segment  |  in ,warn,karaf
Problem with segment  |  in ,warn,karaf
Problem with segment  |  in ,warn,karaf
Problem with segment  |  in ,warn,karaf
Problem with segment  |  in ,warn,karaf
$$$Empty Message$$$,warn,karaf
Adding CompositeDataSupport *,debug,karaf
$$$Empty Message$$$,error,karaf
$$$Empty Message$$$,error,karaf
$$$Empty Message$$$,error,karaf
$$$Empty Message$$$,error,karaf
      skipping blacklisted maven artifact: ,info,karaf
      adding overriden maven artifact:  |  (original location:  | ),info,karaf
      adding maven artifact: ,info,karaf
Ignoring non maven artifact ,warn,karaf
      adding maven artifact: ,info,karaf
Ignoring non maven artifact ,warn,karaf
Generating Karaf assembly: ,info,karaf
Unzipping kars,info,karaf
   processing KAR: ,info,karaf
      found repository: ,info,karaf
Loading profiles from:,info,karaf
"   Found profiles:  | , ",info,karaf
Found existing features processor configuration: *,info,karaf
Explicitly configured * will be used for features processor configuration.,warn,karaf
Found features processor configuration: *,info,karaf
Loading repositories,info,karaf
   adding all non-blacklisted features from repository:  |  (stage:  | ),info,karaf
      feature */* is blacklisted - skipping.,info,karaf
Adding profiles to *,info,karaf
Configuring etc/config.properties and etc/system.properties,info,karaf
Downloading libraries for generated profiles,info,karaf
Downloading additional libraries,info,karaf
Writing configurations,info,karaf
   not changing existing config file: *,info,karaf
   adding config file: *,info,karaf
Generating features processor configuration: *,info,karaf
Copying features processor configuration: * -> *,info,karaf
Can't generate consistency report into * - it's not a directory,warn,karaf
Writing bundle report,info,karaf
"Found * which is deprecated, please use new feature processor configuration.",warn,karaf
"Found * which is deprecated, please use new feature processor configuration.",warn,karaf
"Blacklisted features XML repository URI is invalid: *, ignoring",warn,karaf
"Blacklisted bundle URI is invalid: *, ignoring",warn,karaf
   blacklisting profile * from *,info,karaf
Ignoring library  |  of type  |  which is only supported for Java 1.8.,warn,karaf
Install stage,info,karaf
   Loading installed repositories,info,karaf
"   Feature  |  is blacklisted, ignoring",info,karaf
   Feature * is defined as an installed feature,info,karaf
"   Conditionial  |  is blacklisted, ignoring",info,karaf
Boot stage,info,karaf
   Loading boot repositories,info,karaf
bundle start-level: ,debug,karaf
new bundle location after strip start-level: ,debug,karaf
"   Feature  |  is blacklisted, ignoring",info,karaf
   Feature  |  is defined as a boot feature,info,karaf
"   Conditionial  |  is blacklisted, ignoring",info,karaf
Feature  |  is a prerequisite and should be installed as a startup feature.,warn,karaf
Startup stage,info,karaf
   Loading startup repositories,info,karaf
   Resolving startup features and bundles,info,karaf
"      Features:  | , ",info,karaf
"      Bundles:  | , ",info,karaf
   feature repository  |  is blacklisted,info,karaf
      adding feature repository: ,info,karaf
   referenced feature repository  |  is blacklisted,info,karaf
Generating * profile,info,karaf
Generating * profile with parents: *,info,karaf
      not changing existing config file: *,info,karaf
      appending to config file: *,info,karaf
      adding config file: *,info,karaf
      adding maven artifact: ,info,karaf
      skipping blacklisted bundle: *,info,karaf
      not changing existing config file: *,info,karaf
      appending to config file: *,info,karaf
      adding config file: *,info,karaf
$$$Empty Message$$$,error,karaf
$$$Empty Message$$$,warn,karaf
$$$Empty Message$$$,info,karaf
$$$Empty Message$$$,debug,karaf
Error while importing configuration * to profile.,warn,karaf
Could not find a scheduled job with name ,warn,karaf
Failed to trigger job *,error,karaf
Error executing script,warn,karaf
Error executing scheduled command *,warn,karaf
Executing job * with name *,debug,karaf
Scheduled job * is neither a job nor a runnable.,error,karaf
Exception during job execution of  |  : ,error,karaf
Ignoring service * : scheduler period is less than 1.,debug,karaf
Ignoring service * : scheduler times is defined but is less than -1.,debug,karaf
Ignoring service * : no scheduling property found.,debug,karaf
Error scheduling job,warn,karaf
Exception during shutdown of scheduler.,debug,karaf
Apache Karaf Quartz Scheduler stopped.,debug,karaf
Unscheduling job with name *,debug,karaf
Scheduling job * with name * and trigger *,debug,karaf
Update job scheduling * with name * and trigger *,debug,karaf
Unscheduling job with name *,debug,karaf
Activating the *Greeter Service Factory Manager,info,karaf
Deactivating the *Greeter Service Factory Manager,info,karaf
Activating the *Greeter Service Component Factory,info,karaf
Deactivating the *Greeter Service Component Factory,info,karaf
Message *: salutation *,info,karaf
Thread shutting down,info,karaf
Activating the *Managed Greeter Component,info,karaf
Deactivating the *Managed Greeter Component,info,karaf
Activating the *Managed Greeter Service,info,karaf
Deactivating the *Managed Greeter Service,info,karaf
Modifying the *Managed Greeter Service,info,karaf
Message *: * *,info,karaf
Thread shutting down,info,karaf
Activating the *Greeter Service Component,info,karaf
Deactivating the *Greeter Service Component,info,karaf
* *,info,karaf
Activating the Apache Karaf ServiceComponentRuntime MBean,info,karaf
Exception registering the SCR Management MBean: ,error,karaf
Deactivating the Apache Karaf ServiceComponentRuntime MBean,info,karaf
No role-based security for services as its system property is not set: *karaf.secured.services,info,karaf
Adding role-based security to services with filter: *,info,karaf
Starting GuardProxyCatalog,trace,karaf
No compulsory roles for a karaf command without the ACL as its system property is not set: *karaf.secured.command.compulsory.roles,info,karaf
Creating Config Admin Tracker using filter *,trace,karaf
Creating Proxy Manager Tracker using filter *,trace,karaf
Stopping GuardProxyCatalog,trace,karaf
Unregistering proxy service of * with properties *,info,karaf
Will create proxy of service *(*),trace,karaf
Created proxy of service * under * with properties *,debug,karaf
Problem scheduling a proxy creator for service *(*),warn,karaf
"Service * has role mapping, but assigned no roles to method *",info,karaf
Allow user with role * to invoke service * method *,trace,karaf
Current user does not have required roles (*) for service * method * and/or arguments,info,karaf
Printing URL: ,info,karaf
Printing file: ,info,karaf
Disconnecting from current session...,info,karaf
Executing: *,debug,karaf
Waiting for process to exit...,debug,karaf
Process exited w/status: *,debug,karaf
Using type: ,info,karaf
Using method: ,info,karaf
Invoking w/arguments: *,info,karaf
Result: ,info,karaf
Ignore incorrect info * provided by bundle *,debug,karaf
Ignore property * without value,debug,karaf
Duplicate @Argument annotations on class  |  for index:  |  see: ,warn,karaf
Could not use value  |  as set of completions!,warn,karaf
Index out of range on @CompleterValues on class  |  for index:  |  see: ,warn,karaf
Duplicate @CompleterMethod annotations on class  |  for index:  |  see: ,warn,karaf
Could not invoke @CompleterMethod on  | . ,warn,karaf
Could not invoke @CompleterMethod on  | . ,warn,karaf
Failed to release action:  | . ,warn,karaf
Duplicate @Argument annotations on class  |  for index:  |  see: ,warn,karaf
Index out of range on @CompleterValues on class  |  for index:  |  see: ,warn,karaf
Duplicate @CompleterMethod annotations on class  |  for index:  |  see: ,warn,karaf
Could not use value  |  as set of completions!,warn,karaf
Could not invoke @CompleterMethod on  | . ,warn,karaf
Could not invoke @CompleterMethod on  | . ,warn,karaf
Failed to release action:  | . ,warn,karaf
Duplicate @Argument annotations on class  |  for index:  |  see: ,warn,karaf
Could not use value  |  as set of completions!,warn,karaf
Index out of range on @CompleterValues on class  |  for index:  |  see: ,warn,karaf
Duplicate @CompleterMethod annotations on class  |  for index:  |  see: ,warn,karaf
Could not invoke @CompleterMethod on  | . ,warn,karaf
Could not invoke @CompleterMethod on  | . ,warn,karaf
Failed to release action:  | . ,warn,karaf
Unable to create completers for command ' | ',debug,karaf
Unable to create completers for command ' | ',debug,karaf
Duplicate @Argument annotations on class  |  for index:  |  see: ,warn,karaf
Index out of range on @CompleterValues on class  |  for index:  |  see: ,warn,karaf
Duplicate @CompleterMethod annotations on class  |  for index:  |  see: ,warn,karaf
Could not use value  |  as set of completions!,warn,karaf
Could not invoke @CompleterMethod on  | . ,warn,karaf
Could not invoke @CompleterMethod on  | . ,warn,karaf
Failed to release action:  | . ,warn,karaf
Generating command ACL config * into service ACL configs *,info,karaf
Config ACL deleted: *. Deleting generated service ACL configs *,info,karaf
Problem processing Configuration Event *,error,karaf
can't find the command bundle for scope ,error,karaf
the refreshed bundle is ,debug,karaf
PackageAdmin service is unavailable.,error,karaf
PackageAdmin service is unavailable.,error,karaf
Problem refresh the affected shell command bundle,error,karaf
Problem load the scope bundle map,error,karaf
Unknown command entered,debug,karaf
"Command exception (Undefined option, ...)",debug,karaf
Exception caught while executing command,error,karaf
Duplicate @Argument annotations on class  |  for index:  |  see: ,warn,karaf
$$$Empty Message$$$,debug,karaf
$$$Empty Message$$$,warn,karaf
$$$Empty Message$$$,error,karaf
Inspection of class * failed.,info,karaf
Command registration delayed for bundle */*. Missing service: *,info,karaf
The wait for bundle  |  being started before destruction has been interrupted.,warn,karaf
* commands for bundle */*,info,karaf
unsupported operation,debug,karaf
Console session is closed,debug,karaf
completionMode property is not defined in etc/org.apache.karaf.shell.cfg file. Using default completion mode.,debug,karaf
Can't read */org.apache.karaf.shell.cfg file. The completion is set to default.,warn,karaf
Error in initialization script *,debug,karaf
Exception caught while masking command line,debug,karaf
Could not load branding.,trace,karaf
Could not load branding.,trace,karaf
Not starting local console. To activate set karaf.startLocalConsole=true,info,karaf
Executing command: ' | ',debug,karaf
Command: ' | ' failed,debug,karaf
Command: ' | ' failed: ,debug,karaf
Command: ' | ' returned ' | ',debug,karaf
Problem processing Configuration Event *,error,karaf
Unknown command entered,debug,karaf
"Command exception (Undefined option, ...)",debug,karaf
Exception caught while executing command,error,karaf
Error closing: ,warn,karaf
Unable to start shell,error,karaf
Error in initialization script *,debug,karaf
Exception caught while starting SSH server,warn,karaf
Exception caught while stopping SSH server,warn,karaf
Configured  |  ' | ' not available,warn,karaf
Prompting user for login,debug,karaf
Created client: *,debug,karaf
Error starting ssh agent for local console,warn,karaf
Error stopping ssh agent for local console,warn,karaf
Created server: *,debug,karaf
Waiting for server to shutdown,debug,karaf
User authentication failed with ,debug,karaf
Failed to parse keypair in *. Attempting to parse it 'directly',warn,karaf
Successfully loaded key pair,info,karaf
Failed to parse keypair in *. Attempting to parse it as a legacy 'simple' key,warn,karaf
Successfully loaded legacy simple key. Converted to PEM format,info,karaf
 is not a 'simple' key either,warn,karaf
Creating ssh server private key at ,info,karaf
generateKeyPair( | ) generating host key - size=,info,karaf
$$$Empty Message$$$,info,karaf
XSL transformer implementation doesn't support * featurehttp://javax.xml.XMLConstants/property/accessExternalDTD,warn,karaf
XSL transformer implementation doesn't support * featurehttp://javax.xml.XMLConstants/property/accessExternalStylesheet,warn,karaf
XSL transformer implementation doesn't support * featurehttp://javax.xml.XMLConstants/property/accessExternalDTD,warn,karaf
XSL transformer implementation doesn't support * featurehttp://javax.xml.XMLConstants/property/accessExternalStylesheet,warn,karaf
Error generating filenames,warn,karaf
Error starting activator,warn,karaf
Error starting activator,warn,karaf
Bundle ID * is invalid,warn,karaf
Bundle ID * is invalid,warn,karaf
Bundle ID * is invalid,warn,karaf
Login failed,debug,karaf
Account failure,warn,karaf
General Security Exception,error,karaf
Error during authentication,warn,karaf
Error flushing after sending auth required,debug,karaf
Features plugin activated,info,karaf
Features plugin deactivated,info,karaf
failed to open ,error,karaf
$$$Empty Message$$$,error,karaf
$$$Empty Message$$$,error,karaf
Features service is not available,error,karaf
Can't install feature */*,error,karaf
Features service is not available,error,karaf
Can't uninstall feature */*,error,karaf
Features service is not available,error,karaf
Can't remove features repository *,error,karaf
Features service is not available,error,karaf
Can't refresh features repository *,error,karaf
Features service is not available,error,karaf
Can't add features repository *,error,karaf
Features service is not available,error,karaf
$$$Empty Message$$$,error,karaf
Features service is not available,error,karaf
$$$Empty Message$$$,error,karaf
Gogo plugin activated,info,karaf
Gogo plugin deactivated,info,karaf
failed to open ,error,karaf
$$$Empty Message$$$,error,karaf
$$$Empty Message$$$,error,karaf
Http plugin activated,info,karaf
Http plugin deactivated,info,karaf
failed to open ,error,karaf
$$$Empty Message$$$,error,karaf
$$$Empty Message$$$,error,karaf
Instance plugin activated,info,karaf
Instance plugin deactivated,info,karaf
failed to open ,error,karaf
$$$Empty Message$$$,error,karaf
$$$Empty Message$$$,error,karaf
Creating missing directory: *,info,karaf
Creating file: *,info,karaf
writing: *,info,karaf
File already exists. Move it out of the way if you wish to recreate it: *,warn,karaf
Creating file: *,info,karaf
File already exists. Move it out of the way if you wish to recreate it: *,warn,karaf
Creating file: *,info,karaf
Opening split *,info,flink
Loaded SCHEMA: *,debug,flink
Could not extract schema from Avro-generated SpecificRecord class *: *.,warn,flink
Trying to load and instantiate Azure File System,info,flink
Running 'run' command.,info,flink
Building program from JAR file,info,flink
Could not properly shut down the client.,info,flink
*,debug,flink
User parallelism is set to *,debug,flink
Could not properly terminate the Flink cluster.,info,flink
Could not properly shut down the client.,info,flink
Could not properly close the cluster descriptor.,info,flink
Running 'info' command.,info,flink
Building program from JAR file,info,flink
Creating program plan dump,info,flink
Running 'list' command.,info,flink
Successfully retrieved list of jobs,info,flink
Running 'stop-with-savepoint' command.,info,flink
Running 'cancel' command.,info,flink
Running 'savepoint' command.,info,flink
Invalid command line arguments.,error,flink
Program has not been parametrized properly.,error,flink
Error while running the command.,error,flink
$$$Empty Message$$$,info,flink
Could not properly shut down the cluster client.,info,flink
Could not properly close the cluster descriptor.,info,flink
Fatal error while running command line interface.,error,flink
Could not load CLI class *.org.apache.flink.yarn.cli.FlinkYarnSessionCli,warn,flink
"Job was executed in detached mode, the results will be available on completion.",warn,flink
Changing plan default parallelism from * to *,debug,flink
"Set parallelism *, plan default parallelism *",debug,flink
Starting program (detached: *),info,flink
An error occurred during stopping the WebMonitorRetrievalService,error,flink
An error occurred during stopping the ClientHighAvailabilityServices,error,flink
Error while closing the Cluster Client,error,flink
Submitting job * (detached: *).,info,flink
Error while shutting down cluster,error,flink
Could not retrieve the web interface URL for the cluster.,warn,flink
Error while closing session.,error,flink
Error while closing cluster.,error,flink
Error while closing session.,error,flink
Error while closing cluster.,error,flink
Error while closing session.,error,flink
Error while closing cluster.,error,flink
Error while closing session.,error,flink
Error while closing cluster.,error,flink
Error while sending value.,error,flink
Sending a value failed.,warn,flink
Error while sending value.,error,flink
Error while closing session.,error,flink
Error while closing cluster.,error,flink
Error while closing session.,error,flink
Error while closing cluster.,error,flink
Error while closing session.,error,flink
Error while closing cluster.,error,flink
Error while closing session.,error,flink
Error while closing cluster.,error,flink
Error while sending value.,error,flink
Sending a value failed.,warn,flink
Failed Elasticsearch item request: *,error,flink
Failed Elasticsearch bulk request: *,error,flink
Created Elasticsearch TransportClient with connected nodes *,info,flink
Created Elasticsearch TransportClient with connected nodes *,info,flink
Pinging Elasticsearch cluster via hosts * ...,info,flink
Created Elasticsearch RestHighLevelClient connected to *,info,flink
Error while creating FileSystem when initializing the state of the BucketingSink.,error,flink
Restoring state for the * (taskIdx=*).,info,flink
* idx * restored *,debug,flink
No state to restore for the * (taskIdx=*).,info,flink
BucketingSink * starting new bucket.,debug,flink
BucketingSink * starting new bucket because file position * is above batch size *.,debug,flink
BucketingSink * starting new bucket because file is older than roll over interval *.,debug,flink
BucketingSink * closing bucket due to inactivity of over * ms.,debug,flink
Created new bucket directory: *,debug,flink
Next part path is *,debug,flink
Moving in-progress bucket * to pending file *,debug,flink
Truncate not found. Will write a file with suffix '*'  and prefix '*' to specify how many bytes in a bucket are valid.,debug,flink
Could not create file for checking if truncate works.,error,flink
Truncate is not supported.,debug,flink
Could not delete truncate test file.,error,flink
Moving pending files to final location for checkpoint *,debug,flink
Moving pending file * to final location having completed checkpoint *.,debug,flink
* idx * checkpointed *.,debug,flink
"In-progress file * has been moved to pending after checkpoint, moving to final location.",debug,flink
"In-progress file * is still in-progress, moving to final location.",debug,flink
In-Progress file * was already moved to final location *.,debug,flink
"In-Progress file * was neither moved to pending nor is still in progress. Possibly, it was moved to final location by a previous snapshot restore",debug,flink
Truncating * to valid length *,debug,flink
Trying to recover file lease *,debug,flink
"Truncate did not immediately complete for *, waiting...",debug,flink
Writing valid-length file for * to specify valid length *,debug,flink
Error while restoring BucketingSink state.,error,flink
Could not invoke truncate.,error,flink
Moving pending files to final location on restore.,debug,flink
Restoring BucketingSink State: Moving pending file * to final location after complete checkpoint *.,debug,flink
Restoring BucketingSink State: Error while renaming pending file * to final path *: *,error,flink
Shutting down Publisher failed.,info,flink
Shutting down TransportChannel failed.,info,flink
Shutting down ManagedChannel failed.,info,flink
Interrupted when waiting for futures to complete,info,flink
Successfully published message with id: *,debug,flink
CreateTopic *,info,flink
DeleteTopic * first delete old subscriptions.,info,flink
DeleteTopic *,info,flink
CreateSubscription *,info,flink
DeleteSubscription *,info,flink
$$$Empty Message$$$,info,flink
/===========================================,info,flink
| GCloud Emulator,info,flink
"| - Getting docker image ""*""google/cloud-sdk:latest",info,flink
| - Creating new container,info,flink
| - Starting it up ....,warn,flink
| Waiting for the emulators to be running,info,flink
\===========================================,info,flink
$$$Empty Message$$$,info,flink
|,error,flink
| ==================== ,error,flink
| YOUR TESTS WILL FAIL ,error,flink
| ==================== ,error,flink
|,error,flink
| - * Emulator is running at *:*,info,flink
| - PubSub Emulator at *:* FAILED to return an Ok status within * ms 10000,error,flink
| * Emulator * --> NOTHING CONNECTED TO *,info,flink
$$$Empty Message$$$,info,flink
/===========================================,info,flink
|    >>> FOUND OLD EMULATOR INSTANCE RUNNING <<< ,warn,flink
| Destroying that one to keep tests running smoothly.,warn,flink
| Cleanup of GCloud Emulator,info,flink
| - Killed,info,flink
| - Removed,info,flink
\===========================================,info,flink
$$$Empty Message$$$,info,flink
Error happens when converting hive data type to flink data type.,error,flink
Successfully loaded Hive udf '*' with class '*',info,flink
Transforming Hive function '*' into a HiveSimpleUDF,info,flink
Transforming Hive function '*' into a HiveGenericUDF,info,flink
Transforming Hive function '*' into a HiveGenericUDTF,info,flink
Transforming Hive function '*' into a HiveGenericUDAF with no UDAF bridging and Hive version %s,info,flink
Transforming Hive function '*' into a HiveGenericUDAF with UDAF bridging and Hive version %s,info,flink
Created HiveCatalog '*',info,flink
Setting hive conf dir as *,info,flink
Connected to Hive metastore,info,flink
Close connection to Hive metastore,info,flink
Flink does not support converting ColumnStatisticsData '*' for Hive column type '*' yet.,warn,flink
Creating HiveSimpleUDF from '*',info,flink
Opening HiveSimpleUDF as '*',info,flink
Creating HiveGenericUDF from '*',info,flink
Open HiveGenericUDF as *,info,flink
Getting result type of HiveGenericUDF from *,info,flink
Getting result type of HiveGenericUDTF with *,info,flink
Setting up * in *,info,flink
Tearing down *,info,flink
Tear down failed: ,warn,flink
HMS started at port *,info,flink
Waiting for HMS to start...,info,flink
$$$Empty Message$$$,error,flink
Ignoring configured key DeSerializer (*)key.deserializer,warn,flink
Ignoring configured value DeSerializer (*)value.deserializer,warn,flink
Overwriting the '*' is not recommendedkey.serializer,warn,flink
Overwriting the '*' is not recommendedvalue.serializer,warn,flink
Property [*] not specified. Setting it to *transaction.timeout.ms,warn,flink
Error while sending record to Kafka: ,error,flink
Encountered error * while recovering transaction *. Presumably this transaction has been already committed before,warn,flink
"Using * semantic, but checkpointing is not enabled. Switching to * semantic.",warn,flink
Generated new transactionalIds *,info,flink
Recovered transactionalIds *,info,flink
Starting FlinkKafkaInternalProducer (*/*) to produce into default topic *,info,flink
Producer implementation does not support metrics,info,flink
Consumer implementation does not support metrics,info,flink
Sending async offset commit request to Kafka broker,debug,flink
Error while closing Kafka consumer,warn,flink
Committing offsets to Kafka takes longer than the checkpoint interval. Skipping commit of previous offsets because newer complete checkpoint offsets are available. This does not compromise Flink's checkpoint integrity.,warn,flink
Committing offsets to Kafka failed. This does not compromise Flink's checkpoints.,warn,flink
Attempting to resume transaction * with producerId * and epoch *,info,flink
Flushing new partitions,info,flink
Overwriting the '*' is not recommendedkey.serializer,warn,flink
Overwriting the '*' is not recommendedvalue.serializer,warn,flink
Property [*] not specified. Setting it to *transaction.timeout.ms,warn,flink
Error while sending record to Kafka: ,error,flink
Encountered error * while recovering transaction *. Presumably this transaction has been already committed before,warn,flink
"Using * semantic, but checkpointing is not enabled. Switching to * semantic.",warn,flink
Generated new transactionalIds *,info,flink
Recovered transactionalIds *,info,flink
Starting FlinkKafkaProducer (*/*) to produce into default topic *,info,flink
Producer implementation does not support metrics,info,flink
Attempting to resume transaction * with producerId * and epoch *,info,flink
Flushing new partitions,info,flink
Starting to fetch from *,info,flink
Starting to consume * partitions with consumer thread *,info,flink
Adding * new partitions to consumer thread *,info,flink
Partitions list: *,debug,flink
Consumer thread * does not have any partitions assigned anymore. Stopping thread.,info,flink
Issuing fetch request *,debug,flink
Fetch failed because of ClosedChannelException.,warn,flink
Full exception,debug,flink
Unable to reach broker after * retries. Returning all current partitions,warn,flink
Error while closing consumer connection,warn,flink
* is not the leader of *. Reassigning leader for partition,warn,flink
Error code = *,debug,flink
The following partitions had an invalid offset: *,warn,flink
The new partition offsets are *,warn,flink
Skipping message with offset  |  because we have seen messages until (including)  |  from topic/partition  |  already,info,flink
This fetch contained * messages (* deleted messages),debug,flink
Error while closing the Kafka simple consumer,error,flink
Unable to get last offset for partitions: Exception(s): *,warn,flink
Trying to get topic metadata from broker * in try */*,info,flink
Error while getting metadata from broker * to find partitions for *. Error: *.,warn,flink
Error communicating with broker * to find partitions for *. * Message: *,warn,flink
Detailed trace,debug,flink
Trying to get topic metadata from broker * in try */*,info,flink
Error while getting metadata from broker * to find partitions for *. Error: *.,warn,flink
Received metadata from topic  |  even though it was not requested. Skipping ...,warn,flink
Error communicating with broker * to find partitions for *. * Message: *,warn,flink
Detailed trace,debug,flink
No group offset can be found for partition * in Zookeeper; resetting starting offset to 'auto.offset.reset',warn,flink
"Starting periodic offset committer, with commit interval of *ms",info,flink
Assigning * partitions to broker threads,info,flink
Removing stopped consumer thread *,info,flink
"All consumer threads are finished, there are no more unassigned partitions. Stopping fetcher",info,flink
Exception while shutting down consumer threads,error,flink
Exception while shutting down ZookeeperOffsetHandler,error,flink
Starting thread *,info,flink
Refreshing leader information for partitions *,info,flink
Partitions with assigned leaders *,debug,flink
"The offset in ZooKeeper for group '*', topic '*', partition * is a malformed string: *",error,flink
Ignoring configured key DeSerializer (*)key.deserializer,warn,flink
Ignoring configured value DeSerializer (*)value.deserializer,warn,flink
Consumer implementation does not support metrics,info,flink
Sending async offset commit request to Kafka broker,debug,flink
Error while closing Kafka consumer,warn,flink
Committing offsets to Kafka takes longer than the checkpoint interval. Skipping commit of previous offsets because newer complete checkpoint offsets are available. This does not compromise Flink's checkpoint integrity.,warn,flink
Committing offsets to Kafka failed. This does not compromise Flink's checkpoints.,warn,flink
Consumer subtask * will start reading * partitions with offsets in restored state: *,info,flink
Consumer subtask * will start reading the following * partitions from the earliest offsets: *,info,flink
Consumer subtask * will start reading the following * partitions from the latest offsets: *,info,flink
Consumer subtask * will start reading the following * partitions from timestamp *: *,info,flink
Consumer subtask * will start reading the following * partitions from the specified startup offsets *: *,info,flink
Consumer subtask * cannot find offsets for the following * partitions in the specified startup offsets: *; their startup offsets will be defaulted to their committed group offsets in Kafka.,warn,flink
Consumer subtask * will start reading the following * partitions from the committed group offsets in Kafka: *,info,flink
Consumer subtask * initially has no partitions to read from.,info,flink
Consumer subtask %d failed async Kafka commit.,warn,flink
Consumer subtask * creating fetcher with offsets *.,info,flink
Consumer subtask * restored state: *.,info,flink
Consumer subtask * has no restore state.,info,flink
snapshotState() called on closed source,debug,flink
notifyCheckpointComplete() called on closed source,debug,flink
notifyCheckpointComplete() called on uninitialized source,debug,flink
Consumer subtask * committing offsets to Kafka/ZooKeeper for checkpoint *.,debug,flink
Consumer subtask * received confirmation for unknown checkpoint id *,warn,flink
Consumer subtask * has empty checkpoint state.,debug,flink
Overwriting the '*' is not recommendedkey.serializer,warn,flink
Overwriting the '*' is not recommendedvalue.serializer,warn,flink
Starting FlinkKafkaProducer (*/*) to produce into default topic *,info,flink
Producer implementation does not support metrics,info,flink
"Flushing on checkpoint is enabled, but checkpointing is not enabled. Disabling flushing.",warn,flink
Error while sending record to Kafka: ,error,flink
Record was not sent successful,warn,flink
An exception occurred while processing a record,warn,flink
Started Kinesis producer instance for region '*',info,flink
No target stream set. Skipping record,warn,flink
Closing producer,info,flink
Flushing outstanding * records,info,flink
Flushing done. Destroying producer instance.,info,flink
An exception was thrown while processing a record: *,warn,flink
"Waiting for the queue length to drop below the limit takes unusually long, still not done after * attempts.",warn,flink
Flushing was interrupted.,warn,flink
Flushing was interrupted.,warn,flink
Flink Kinesis Consumer is going to read the following streams: *,info,flink
"Subtask * is seeding the fetcher with restored shard *, starting state set to the restored sequence number *",info,flink
"Subtask * is seeding the fetcher with new discovered shard *, starting state set to the SENTINEL_EARLIEST_SEQUENCE_NUM",info,flink
"Subtask * will be seeded with initial shard *, starting state set as sequence number *",info,flink
Error while closing Kinesis data fetcher,warn,flink
Setting restore state in the FlinkKinesisConsumer. Using the following offsets: *,info,flink
No restore state for FlinkKinesisConsumer.,info,flink
snapshotState() called on closed source; returning null.,debug,flink
Snapshotting state ...,debug,flink
"Snapshotted state, last processed sequence numbers: *, checkpoint id: *, timestamp: *",debug,flink
Encountered an unexpected expired iterator * for shard *; refreshing the iterator ...,warn,flink
Subtask * has failed to find any shards for the following subscribed streams: *,warn,flink
Subtask * will start consuming seeded shard * from sequence number * with ShardConsumer *,info,flink
Starting periodic watermark emitter with interval *,info,flink
Subtask * has no active shards to read on startup; marking the subtask as temporarily idle ...,info,flink
Subtask * is trying to discover new shards that were created due to resharding ...,debug,flink
"Subtask * has discovered a new shard * due to resharding, and will start consuming the shard from sequence number * with ShardConsumer *",info,flink
Shutting down the shard consumer threads of subtask * ...,info,flink
Skipping non-deserializable record at sequence number * of shard *.,warn,flink
Subtask * has reached the end of subscribed shard: *,info,flink
Subtask * has reached the end of all currently subscribed shards; marking the subtask as temporarily idle ...,info,flink
Evaluating watermark for subtask * time *,debug,flink
"No active shard for subtask *, marking the source idle.",info,flink
Emitting watermark * from subtask *,debug,flink
registering periodic watermark timer with interval *,debug,flink
Registering watermark tracker with interval *,info,flink
WatermarkSyncCallback subtask: * is idle,info,flink
"WatermarkSyncCallback subtask: * local watermark: *, global watermark: *, delta: * timeouts: *, emitter: *",info,flink
stalled watermark * key * next watermark * next timestamp *,info,flink
Got recoverable SdkClientException. Backing off for  |  millis ( | :  | ),warn,flink
Got recoverable AmazonServiceException. Backing off for  |  millis ( | :  | ),warn,flink
Got LimitExceededException when listing shards from stream  | . Backing off for  |  millis.,warn,flink
The stream is currently not in active state. Reusing the older state for the time being,info,flink
List Shards has an expired token. Reusing the previous state.,warn,flink
Got SdkClientException when listing shards from stream *. Backing off for * millis.,warn,flink
Got LimitExceededException when describing stream %s.  | Backing off for %d millis.,warn,flink
The status of stream %s is %s ; result of the current  | describeStream operation will not contain any shard information.,warn,flink
[setMaxLookaheadMillis] Max lookahead millis set to *,info,flink
"[setCurrentWatermark] Current watermark set to *, maxEmitTimestamp = *",info,flink
Starting emitter with maxLookaheadMillis: *,info,flink
"WatermarkAggregateFunction added: *, timeout: *, map: *",info,flink
"A transaction could not be created, waiting and will try again...",warn,flink
"No data available to pull, waiting and will try again...",debug,flink
Cannot send RMQ message * at *,error,flink
Both channel and connection closing failed. Logging channel exception and failing with connection exception,warn,flink
Starting RabbitMQ source with autoAck status: ,debug,flink
Failed to parse uri,error,flink
Failed to initialize ssl context.,error,flink
Failed to setup ssl factory.,error,flink
Initializing Twitter Streaming API connection,info,flink
Twitter Streaming API connection established successfully,info,flink
Closing source,info,flink
Cancelling Twitter source,info,flink
[*] *: *.,debug,flink
"Dropping message, because of full queue.",debug,flink
Connected.,debug,flink
Disconnected.,debug,flink
Error: '*'.,error,flink
Error #*: '*'.,error,flink
[*]: * invites *.,debug,flink
[*]: * joins.,debug,flink
[*]: * kicks *.,debug,flink
[*]: mode '*'.,debug,flink
* sets modes * (*).,debug,flink
* is now known as *.,debug,flink
[*] * (notice): *.,debug,flink
[*] * parts.,debug,flink
Quit: *.,debug,flink
Reply #*: * *.,debug,flink
[*] * changes topic into *.,debug,flink
UNKNOWN:  |   |   |  ,warn,flink
Scanning class path for job JAR,info,flink
Using * as job jar,info,flink
Could not parse command line arguments *.,error,flink
In file \ | \ | )  |  invalid line(s) were skipped.,warn,flink
In file \ | \ | )  |  comment line(s) were skipped.,info,flink
No more input splits available,debug,flink
Assigning split  |  to ,debug,flink
Invalid default maximum number of line samples:  | . Using default value of ,error,flink
Invalid default minimum number of line samples:  | . Using default value of ,error,flink
"Default minimum number of line samples cannot be greater the default maximum number  | of line samples: min= | , max= | . Defaulting minimum to maximum.",error,flink
Invalid value for the maximum sample record length. Using default value of ,error,flink
Increasing maximum sample record length to size of the read buffer ( | ).,warn,flink
Invalid value for number of samples to take:  | . Skipping sampling.,warn,flink
Could not determine statistics for files ' | '  | due to an io error: ,warn,flink
Unexpected problem while getting the file statistics for files ' | ': ,error,flink
"Opening stream for output ( | / | ). WriteMode= | , OutputDirectoryMode=",debug,flink
Could not properly close FileOutputFormat.,error,flink
Could not remove the incomplete file ,error,flink
Invalid timeout value for filesystem stream opening:  | . Using default value of ,error,flink
"Overwriting an existing decompression algorithm for ""*"" files.",warn,flink
Could not determine statistics for paths ' | ' due to an io error: ,warn,flink
Unexpected problem while getting the file statistics for paths ' | ': ,error,flink
Minimal split size of  |  is larger than the block size of  | . Decreasing minimal split size to block size.,warn,flink
Directory  |  did not pass the file-filter and is excluded.,debug,flink
Directory  |  did not pass the file-filter and is excluded.,debug,flink
"Opening input split  |  [ | , | ]",debug,flink
Assigning split to null host (random assignment).,info,flink
No more unassigned input splits remaining.,debug,flink
Assigning local split to host ,info,flink
Assigning remote split to host ,info,flink
No more input splits remaining.,debug,flink
"With the given block size %d, the files %s cannot be split into %d blocks. Filling up with empty splits...",warn,flink
Could not determine complete statistics for files '%s' due to an I/O error,warn,flink
Unexpected problem while getting the file statistics for files '%s',error,flink
Termination criterion stats in iteration [ | ]: ,info,flink
Someone else beat us at initializing the serializer.,debug,flink
Could not read a requested serializer. Replaced with a UnloadableDummyTypeSerializer.,warn,flink
Unable to handle type  |  as POJO. Message: ,debug,flink
 does not contain a getter for field ,info,flink
 does not contain a setter for field ,info,flink
Class  |  is not public so it cannot be used as a POJO type  | and must be processed as GenericType. Please read the Flink documentation  | on \,info,flink
No fields were detected for  |  so it cannot be used as a POJO type  | and must be processed as GenericType. Please read the Flink documentation  | on \,info,flink
"Class  |  cannot be used as a POJO type because not all fields are valid POJO fields,  | and must be processed as GenericType. Please read the Flink documentation  | on \",info,flink
"Class  |  contains custom serialization methods we do not call, so it cannot be used as a POJO type  | and must be processed as GenericType. Please read the Flink documentation  | on \",info,flink
" is abstract or an interface, having a concrete  | type can increase performance.",info,flink
 is missing a default constructor so it cannot be used as a POJO type  | and must be processed as GenericType. Please read the Flink documentation  | on \,info,flink
The default constructor of  |  is not Public so it cannot be used as a POJO type  | and must be processed as GenericType. Please read the Flink documentation  | on \,info,flink
"Cannot extract type of Row field, because of Row field[ | ] is null.  | Should define RowTypeInfo explicitly.",warn,flink
Cannot find registered class  |  for Kryo serialization in classpath; |  using a dummy class as a placeholder.,warn,flink
Cannot find registered Kryo serializer class for class  |  in classpath; using a dummy Kryo serializer that should be replaced as soon as |  a new Kryo serializer for the class is present,warn,flink
Cannot find registered Kryo serializer class for class  |  in classpath; using a dummy Kryo serializer that should be replaced as soon as |  a new Kryo serializer for the class is present,warn,flink
The registered Kryo serializer class for class  |  has changed and is no longer valid; using a dummy Kryo serializer that should be replaced |  as soon as a new Kryo serializer for the class is present.,warn,flink
$$$Empty Message$$$,error,flink
$$$Empty Message$$$,warn,flink
$$$Empty Message$$$,info,flink
$$$Empty Message$$$,debug,flink
$$$Empty Message$$$,trace,flink
Cannot find registered class  |  for Kryo serialization in classpath; |  using a dummy class as a placeholder.,warn,flink
Cannot find registered Kryo serializer class for class  |  in classpath; using a dummy Kryo serializer that should be replaced as soon as |  a new Kryo serializer for the class is present,warn,flink
Cannot find registered Kryo serializer class for class  |  in classpath; using a dummy Kryo serializer that should be replaced as soon as |  a new Kryo serializer for the class is present,warn,flink
The registered Kryo serializer class for class  |  has changed and is no longer valid; using a dummy Kryo serializer that should be replaced |  as soon as a new Kryo serializer for the class is present.,warn,flink
Cannot find registered class  |  for Kryo serialization in classpath.,warn,flink
Cannot deserialize a previously serialized kryo serializer for the type ,warn,flink
Falling back to default Kryo serializer because Chill serializer couldn't be found.,warn,flink
Configuration cannot evaluate value  |  as a class name,warn,flink
Configuration cannot evaluate value * as a byte[] value,warn,flink
Config uses deprecated configuration key '*' instead of proper key '*',warn,flink
Config uses fallback configuration key '*' instead of key '*',info,flink
Configuration value * overflows/underflows the integer type.,warn,flink
Configuration cannot evaluate value * as an integer number,warn,flink
Configuration cannot evaluate value  |  as a long integer number,warn,flink
Configuration value * overflows/underflows the float type.,warn,flink
Configuration cannot evaluate value * as a float value,warn,flink
Configuration cannot evaluate value * as a double value,warn,flink
Error while trying to split key and value in configuration file  | : | : \ | \,warn,flink
Error after splitting key and value in configuration file  | : | : \ | \,warn,flink
"Loading configuration property: *, *",info,flink
Could not check for stream progress to determine inactivity,debug,flink
Closing unclosed resource via safety-net: *,warn,flink
Error while closing resource via safety-net,debug,flink
Loading extension file systems via services,debug,flink
Failed to load additional file systems via services,error,flink
Added file system *:*,debug,flink
Failed to load a file system via services,error,flink
No Flink runtime dependency present. The extended set of supported File Systems via Hadoop is not available.,info,flink
Flink's Hadoop file system factory could not be loaded,warn,flink
Hadoop is not in the classpath/dependencies. The extended set of supported File Systems via Hadoop is not available.,info,flink
Flink's Hadoop file system factory could not be created,warn,flink
Could not resolve local host,error,flink
Releasing serialization buffer of  |  bytes.,debug,flink
Environment variable [*] is not setFLINK_PLUGINS_DIR,info,flink
Environment variable [*] is set to [*] but the directory doesn't existFLINK_PLUGINS_DIR,warn,flink
$$$Empty Message$$$,warn,flink
Exception in closing ,debug,flink
ExecutorService did not terminate in time. Shutting it down now.,warn,flink
Interrupted while shutting down executor services. Shutting all remaining ExecutorServices down now.,warn,flink
Cannot register shutdown hook that cleanly terminates *.,error,flink
"Unable to remove shutdown hook for *, shutdown already in progress",debug,flink
Exception while un-registering *'s shutdown hook.,warn,flink
"Ignoring serialVersionUID mismatch for class *; was *, now *.",warn,flink
Trying to open socket on port *,debug,flink
Unable to allocate socket on port,debug,flink
"Unable to allocate on port *, due to error: *",info,flink
Failed to generate message schema for class *.,error,flink
Failed to write message schema for class *.,error,flink
Initializing copy tasks,info,flink
Copy task initialization took  | ms,info,flink
Processing task: ,info,flink
== COUNTERS ==,info,flink
: ,info,flink
Getting copy task for task: ,info,flink
$$$Empty Message$$$,info,flink
Processed message with payload: ,info,flink
Handling deprecation for all properties in config...,debug,flink
Handling deprecation for ,debug,flink
Reloading  |  existing configurations,debug,flink
Unexpected SecurityException in Configuration,warn,flink
$$$Empty Message$$$,info,flink
$$$Empty Message$$$,info,flink
Regular expression ' | ' for property ' | ' not valid. Using default,warn,flink
Could not make  |  in local directories from ,warn,flink
[ | ]=,warn,flink
 not found,info,flink
found resource  |  at ,info,flink
 not found,info,flink
found resource  |  at ,info,flink
parsing URL ,debug,flink
parsing input stream ,debug,flink
parsing File ,debug,flink
error parsing conf ,error,flink
error parsing conf ,error,flink
:an attempt to override final parameter:  | ;  Ignoring.,warn,flink
Could not determine statistics due to an io error: ,warn,flink
Unexpected problem while getting the file statistics: ,error,flink
Cannot find hdfs-default configuration file,debug,flink
Cannot find hdfs-site configuration file,debug,flink
Adding  | /core-site.xml to hadoop configuration,debug,flink
Adding  | /hdfs-site.xml to hadoop configuration,debug,flink
Could not determine statistics due to an io error: ,warn,flink
Unexpected problem while getting the file statistics: ,error,flink
Hadoop configuration has not been explicitly initialized prior to loading a Hadoop file system. Using configuration from the classpath.,warn,flink
Instantiating for file system scheme * Hadoop File System *,debug,flink
"URI * does not specify file system authority, trying to load default authority (fs.defaultFS)",debug,flink
Hadoop's 'fs.defaultFS' is set to *,debug,flink
Using hdfs-default configuration-file path form Flink config: *,debug,flink
Cannot find hdfs-default configuration-file path in Flink config.,debug,flink
Using hdfs-site configuration-file path form Flink config: *,debug,flink
Cannot find hdfs-site configuration-file path in Flink config.,debug,flink
Adding  | /core-site.xml to hadoop configuration,debug,flink
Adding  | /hdfs-site.xml to hadoop configuration,debug,flink
"Could not find Hadoop configuration via any of the supported methods (Flink configuration, environment variables).",debug,flink
Flink configuration is not set prior to loading this configuration. Cannot forward configuration keys from Flink configuration.,warn,flink
Adding Flink config entry for * as * to Hadoop config,debug,flink
Initializing HBaseConfiguration,info,flink
Error instantiating a new HTable instance,error,flink
Error after scan of  |  rows. Retry with a new scanner...,warn,flink
* split (this=*)[*|*|*|*],info,flink
Closing split (scanned * rows),info,flink
Created  |  splits,info,flink
can not connect to HBase without * configurationhbase.zookeeper.quorum,error,flink
start open ...,info,flink
Table '*' not found ,error,flink
Exception while creating connection to HBase.,error,flink
end open.,info,flink
start close ...,info,flink
exception when close table,warn,flink
exception when close connection,warn,flink
end close.,info,flink
Initializing HBase configuration.,info,flink
The table  |  not found ,error,flink
Exception while creating connection to HBase.,error,flink
start open ...,info,flink
The table  |  not found ,error,flink
Exception while creating connection to HBase.,error,flink
end open.,info,flink
Can not connect to HBase without * configurationhbase.zookeeper.quorum,error,flink
Exception occurs while closing HBase BufferedMutator.,warn,flink
Exception occurs while closing HBase Connection.,warn,flink
Dig to clean the *,debug,flink
 is accessed: ,debug,flink
The job has * registered types and * default Kryo serializers,info,flink
"In the ExecutionConfig, both Avro and Kryo are enforced. Using Kryo serializer",warn,flink
Using KryoSerializer for serializing POJOs,info,flink
Using AvroSerializer for serializing POJOs,info,flink
Registered Kryo types: *,debug,flink
Registered Kryo with Serializers types: *,debug,flink
Registered Kryo with Serializer Classes types: *,debug,flink
Registered Kryo default Serializers: *,debug,flink
Registered Kryo default Serializers Classes *,debug,flink
Registered POJO types: *,debug,flink
Static code analysis mode: *,debug,flink
GroupCombineFunction cannot be used as combiner for GroupReduceFunction. Generic types are incompatible.,warn,flink
Cannot check generic types of GroupReduceFunction. Enabling combiner but combine function might fail at runtime.,warn,flink
Cannot check generic types of GroupCombineFunction. Enabling combiner but combine function might fail at runtime.,warn,flink
JDBC connection could not be closed: ,warn,flink
Inputformat Statement couldn't be closed - ,info,flink
Inputformat couldn't be closed - ,info,flink
Executing '%s' with parameters %s,debug,flink
Inputformat ResultSet couldn't be closed - ,info,flink
Username was not supplied separately.,info,flink
Password was not supplied separately.,info,flink
No input splitting configured (data will be read with parallelism 1).,debug,flink
"JDBC executeBatch error, retry times = *",error,flink
Close JDBC writer failed.,warn,flink
"JDBC executeBatch error, retry times = %d",error,flink
JDBC statement could not be closed: ,info,flink
JDBC connection could not be closed: ,info,flink
JDBC statement could not be closed: ,info,flink
Username was not supplied.,info,flink
Password was not supplied.,info,flink
Column SQL types array doesn't match arity of passed Row! Check the passed array...,warn,flink
Unknown column type for column *. Best effort approach to set its value: *.,warn,flink
Unmanaged sql type (*) for column *. Best effort approach to set its value: *.,warn,flink
Unmanaged sql type (*) for column *. Best effort approach to get its value: *.,warn,flink
Trying to load and instantiate MapR File System,info,flink
Trying to retrieve MapR cluster configuration from %s,debug,flink
Could not parse the command-line options.,error,flink
TaskManagers will be created with * task slots,info,flink
"TaskManagers will be started with container size * MB, JVM heap size * MB, JVM direct memory limit * MB, * cpus, * gpus, disk space * MB",info,flink
Mesos dynamic properties: *,debug,flink
Failed to load the TaskManager configuration and dynamic properties.,error,flink
ResourceID assigned for this container: *,info,flink
Error while starting the TaskManager,error,flink
Could not parse the command-line options.,error,flink
Registering as new framework.,info,flink
Recovery scenario: re-registering using framework ID *.,info,flink
Retrieved * TaskManagers from previous attempt,info,flink
Shutting down and unregistering as a Mesos framework.,info,flink
Starting a new worker.,info,flink
"Scheduling Mesos task * with (* MB, * cpus).",info,flink
Stopping worker *.,info,flink
Ignoring request to stop worker * because it is already being stopped.,info,flink
Unrecognized worker *.,warn,flink
Launching Mesos task * on host *.,info,flink
Received a termination notice for an unrecognized worker: *,info,flink
Worker * finished successfully with message: *,info,flink
"Worker * failed with status: *, reason: *, message: *.",info,flink
LaunchableMesosWorker parameters: *,debug,flink
unrecognized message: ,error,flink
Added * in ZooKeeper.,debug,flink
Updated * in ZooKeeper.,debug,flink
No such worker * in ZooKeeper.,debug,flink
Removed worker * from ZooKeeper.,debug,flink
"Unknown resource type  |  for resource  |  in offer, hostname= | , offerId=",debug,flink
Enabling ssl for the artifact server,info,flink
"Mesos Artifact Server Base URL: *, listening at *:*",info,flink
Cannot access local server port,error,flink
* request for file '*',debug,flink
unable to stat file,error,flink
Caught exception,error,flink
Allocating * *,debug,flink
Taking * from *,debug,flink
"Allocated: *, unsatisfied: *",debug,flink
Allocating * *,debug,flink
Taking * from *,debug,flink
"Allocated: *, unsatisfied: *",debug,flink
--------------------------------------------------------------------------------,info,flink
 Mesos Info:,info,flink
    Master URL: *,info,flink
 Framework Info:,info,flink
    ID: *,info,flink
    Name: *,info,flink
    Failover Timeout (secs): *,info,flink
    Role: *,info,flink
    Capabilities: *,info,flink
    Principal: *,info,flink
    Host: *,info,flink
    LIBPROCESS_IP: *,info,flink
    LIBPROCESS_PORT: *,info,flink
    Web UI: *,info,flink
--------------------------------------------------------------------------------,info,flink
Cannot add unknown metric type *. This indicates that the reporter does not support this metric type.,warn,flink
Cannot remove unknown metric type *. This indicates that the reporter does not support this metric type.,warn,flink
Cannot add * because Datadog HTTP API doesn't support Histogram,warn,flink
Cannot add unknown metric type *. This indicates that the reporter does not support this metric type.,warn,flink
Cannot remove unknown metric type *. This indicates that the reporter does not support this metric type.,warn,flink
Configured DatadogHttpReporter,info,flink
Shut down DatadogHttpReporter,info,flink
The metric * will not be reported because only number types are supported by this reporter.,info,flink
The metric * will not be reported because it threw an exception.,debug,flink
The metric * will not be reported because it threw an exception.,info,flink
Reported series with size *.,debug,flink
Failed reporting metrics to Datadog because of socket timeout.,warn,flink
Failed reporting metrics to Datadog.,warn,flink
Failed sending request to Datadog,warn,flink
Failed to send request to Datadog (response was *),warn,flink
Cannot add metric of type *. This indicates that the reporter does not support this metric type.,warn,flink
"Invalid protocol configuration:  |  Expected: TCP or UDP, defaulting to TCP.",warn,flink
"Configured GraphiteReporter with {host:*, port:*, protocol:*}",info,flink
Cannot add unknown metric type *. This indicates that the reporter does not support this metric type.,warn,flink
Cannot remove unknown metric type *. This indicates that the reporter does not support this metric type.,warn,flink
"Configured InfluxDBReporter with {host:*, port:*, db:*, and retentionPolicy:*}",info,flink
Started JMX server on port  | .,info,flink
Could not start JMX server on port  | .,debug,flink
Could not stop JMX server.,debug,flink
Configured JMXReporter with {port:*},info,flink
Failed to stop JMX server.,error,flink
Implementation error. The domain or table does not conform to JMX rules.,debug,flink
Cannot add unknown metric type: *. This indicates that the metric type is not supported by this reporter.,error,flink
Metric did not comply with JMX MBean rules.,debug,flink
A metric with the name  |  was already registered.,warn,flink
Failed to register metric,warn,flink
Un-registering metric failed,error,flink
JMXServer is already running.,debug,flink
There was a problem registering metric *.,warn,flink
Cannot create collector for unknown metric type: *. This indicates that the metric type is not supported by this reporter.,warn,flink
Cannot add unknown metric type: *. This indicates that the metric type is not supported by this reporter.,warn,flink
Cannot remove unknown metric type: *. This indicates that the metric type is not supported by this reporter.,warn,flink
There was a problem unregistering metric *.,warn,flink
"Gauge * is null-valued, defaulting to 0.",debug,flink
"Invalid type for Gauge *: *, only number types and booleans are supported by this reporter.",debug,flink
"Configured PrometheusPushGatewayReporter with {host:*, port:*, jobName:*, randomJobNameSuffix:*, deleteOnShutdown:*, groupingKey:*}",info,flink
"Invalid prometheusPushGateway groupingKey:*, will be ignored",warn,flink
"Invalid groupingKey {labelKey:*, labelValue:*} must not be empty",warn,flink
"Failed to push metrics to PushGateway with jobName *, groupingKey *.",warn,flink
"Failed to delete metrics from PushGateway with jobName *, groupingKey *.",warn,flink
Started PrometheusReporter HTTP server on port *.,info,flink
Could not start PrometheusReporter HTTP server on port *.,debug,flink
$$$Empty Message$$$,info,flink
"Configured StatsDReporter with {host:*, port:*}",info,flink
unable to send packet to statsd at '*:*',error,flink
"Failed to extract param info *, ignore it",warn,flink
Config value * for option * is invalid. Ignoring and using a value of *.,warn,flink
Beginning compilation of program ',debug,flink
Using a default parallelism of *,debug,flink
Using default data exchange mode *,debug,flink
"Strategy hint for GroupReduce ' | ' requires combinable reduce, but user function is not marked combinable.",warn,flink
Could not instantiate InputFormat to obtain statistics. Limited statistics will be available.,warn,flink
Error obtaining statistics from input format: ,warn,flink
Compiler could not determine the size of input ' | '. Using default estimates.,info,flink
Found that a field is forwarded to more than one target field in semantic forwarded field information. Will only use the field with the lowest index.,warn,flink
Found that a field is forwarded to more than one target field in semantic forwarded field information. Will only use the field with the lowest index.,warn,flink
Found that a field is forwarded to more than one target field in semantic forwarded field information. Will only use the field with the lowest index.,warn,flink
Found that a field is forwarded to more than one target field in semantic forwarded field information. Will only use the field with the lowest index.,warn,flink
Found that a field is forwarded to more than one target field in semantic forwarded field information. Will only use the field with the lowest index.,warn,flink
Found that a field is forwarded to more than one target field in semantic forwarded field information. Will only use the field with the lowest index.,warn,flink
Cannot automatically inject combiner for GroupReduceFunction. Please add an explicit combiner with combineGroup() in front of the partition operator.,warn,flink
Cannot automatically inject combiner for ReduceFunction. Please add an explicit combiner with combineGroup() in front of the partition operator.,warn,flink
Could not determine whether * denotes a local path.,warn,flink
The parallelism of nested dataflows (such as step functions in iterations) is currently fixed to the parallelism of the surrounding operator (the iteration).,warn,flink
Assigned  |  of total memory to each subtask of  | .,debug,flink
Assigned  |  of total memory to each local strategy  | instance of  | .,debug,flink
Assigned  |  of total memory to each instance of the temp  | table for  | .,debug,flink
Opening ORC file *,debug,flink
Predicate [*] converted into OrcPredicate [*] and pushed into OrcTableSource for path *.,info,flink
Predicate [*] could not be pushed into OrcTableSource for path *.,info,flink
Unsupported predicate [*] cannot be pushed into OrcTableSource.,debug,flink
Unsupported predicate [*] cannot be pushed into OrcTableSource.,debug,flink
Encountered a non-serializable literal of type *. Cannot push predicate [*] into OrcTableSource. This is a bug and should be reported.,warn,flink
Unsupported predicate [*] cannot be pushed into OrcTableSource.,debug,flink
Unsupported predicate [*] cannot be pushed into OrcTableSource.,debug,flink
Unsupported predicate [*] cannot be pushed into OrcTableSource.,debug,flink
Unsupported predicate [*] cannot be pushed into OrcTableSource.,debug,flink
Unsupported predicate [*] cannot be pushed into OrcTableSource.,debug,flink
Adding Flink config entry for * as * to Hadoop config,debug,flink
Fields number is %d,error,flink
Escaped the file split [%s] due to mismatch of file schema to expected result schema,warn,flink
Open ParquetInputFormat with FileInputSplit [%s],debug,flink
Unsupported predict [*] cannot be pushed to ParquetTableSource.,debug,flink
Unsupported predicate [*] cannot be pushed into ParquetTableSource.,debug,flink
All of the predicates should be in CNF. Found an AND expression.,debug,flink
Unsupported predicate [*] cannot be pushed into ParquetTableSource.,debug,flink
Encountered a non-comparable literal of type *.Cannot push predicate [*] into ParquetTablesource.This is a bug and should be reported.,warn,flink
Parquet field * in schema type * can not be converted to Flink Internal Type,error,flink
$$$Empty Message$$$,error,flink
$$$Empty Message$$$,warn,flink
filtered record reader reached end of block,debug,flink
read value: *,debug,flink
Can not read value at %d in block %d in file %s,error,flink
"Required at least two arguments, only python file or python module is available.",error,flink
Could not parse command line arguments *.,error,flink
Run python process failed,error,flink
The gateway server thread join failed.,error,flink
Gets pyflink dependent libs failed.,error,flink
Create symbol link for pyflink lib failed.,error,flink
Try to copy pyflink lib to working directory,info,flink
The Queryable State Client was shutdown successfully.,info,flink
The Queryable State Client shutdown failed: ,warn,flink
Sending State Request to *.,debug,flink
Unable to send KVStateRequest: ,error,flink
Failed to notify callback about failure,error,flink
Failed to notify callback about failure,error,flink
Failed to notify callback about failure,error,flink
Started * @ *.,info,flink
Unable to start *. All ports in provided range (*) are occupied.,info,flink
Attempting to start * on port *.,debug,flink
Failed to start * on port *: *.,debug,flink
Problem while shutting down *: *,warn,flink
Shutting down * @ *,info,flink
$$$Empty Message$$$,debug,flink
$$$Empty Message$$$,debug,flink
$$$Empty Message$$$,debug,flink
Request * was successfully answered after * ms.,debug,flink
Request * failed after * ms due to: *,debug,flink
* was shutdown successfully.,info,flink
* shutdown failed: *,warn,flink
Retrieving location for state=* of job=* from the cache.,debug,flink
Retrieving location for state=* of job=* from the key-value state location oracle.,debug,flink
* was shutdown successfully.,info,flink
* shutdown failed: *,warn,flink
Failed to stringify accumulator [ | ],error,flink
Failed to serialize accumulators for task.,warn,flink
Failed to delete local blob ,error,flink
Using ssl connection to the blob server,info,flink
Downloading */* from *,info,flink
 Retrying...,error,flink
 Retrying...,error,flink
 No retries left.,error,flink
Downloading */* from * (retry *),info,flink
GET BLOB */* from *.,debug,flink
PUT BLOB buffer ( |  bytes) to  | .,debug,flink
PUT BLOB stream to *.,debug,flink
Failed to delete locally cached BLOB * at *,warn,flink
Failed to offload value * for job * to BLOB store.,warn,flink
Created BLOB server storage directory *,info,flink
Invalid value for maximum connections in BLOB server: *. Using default value of *,warn,flink
Invalid value for BLOB connection backlog: *. Using default value of *,warn,flink
Started BLOB server at *:* - max concurrent requests: * - max backlog: *,info,flink
BLOB server stopped working. Shutting down,error,flink
Could not properly close the BlobServer.,error,flink
Error while waiting for this thread to die.,debug,flink
Shutting down connection *.,debug,flink
Stopped BLOB server at *:*,info,flink
Could not delete the staging file * for blob key * and job *.,warn,flink
Received PUT call for BLOB of job *.,debug,flink
Could not delete the staging file * for job *.,warn,flink
Could not delete the staging file * for blob key * and job *.,warn,flink
Received PUT call for BLOB of job *.,debug,flink
Could not delete the staging file * for blob key * and job *.,warn,flink
 No retries left.,error,flink
"Trying to find a unique key for BLOB of job * (retry *, last tried *)",debug,flink
Failed to locally delete BLOB  |  at ,warn,flink
Failed to locally delete BLOB storage directory at ,warn,flink
Creating highly available BLOB storage directory at *,info,flink
Created highly available BLOB storage directory at *,debug,flink
Copying from * to *.,debug,flink
Copying from * to *.,debug,flink
Deleting *.,debug,flink
Failed to delete blob at ,warn,flink
Cleaning up *.,debug,flink
Failed to clean up recovery directory.,error,flink
Created BLOB cache storage directory ,info,flink
Invalid value for *. System will attempt no retries on failed fetch operations of BLOBs.,warn,flink
Failed to copy from blob store. Downloading from BLOB server instead.,info,flink
Could not delete the staging file * for blob key * and job *.,warn,flink
Shutting down BLOB cache,info,flink
Socket connection closed,debug,flink
Error while executing BLOB connection.,error,flink
Received GET request for BLOB */* from *.,debug,flink
GET operation from * failed.,error,flink
GET operation failed for BLOB */* from *.,error,flink
DELETE operation failed for BLOB */* from *.,warn,flink
Socket connection closed,debug,flink
GET operation failed,error,flink
Received PUT request for BLOB of job * with from *.,debug,flink
Socket connection closed,debug,flink
PUT operation failed,error,flink
Cannot delete BLOB server staging file ,warn,flink
improper use of releaseJob() without a matching number of registerJob() calls for jobId ,warn,flink
Failed to locally delete job directory ,warn,flink
Exception while closing BLOB server connection socket.,debug,flink
Detected concurrent file modifications. This should only happen if multipleBlobServer use the same storage directory.,warn,flink
File upload for an existing file with key * for job *. This may indicate a duplicate upload or a hash collision. Ignoring newest upload.,warn,flink
Could not delete the storage file *.,warn,flink
Could not delete the staging file * for blob key * and job *.,warn,flink
"Getting Broadcast Variable ( | ) - First access, materializing.",debug,flink
Materialization of Broadcast Variable ( | ) finished.,debug,flink
Getting Broadcast Variable ( | ) - shared access.,debug,flink
Stopping checkpoint coordinator for job *.,info,flink
Trying to trigger another checkpoint for job * while one was queued already.,warn,flink
Checkpoint triggering task * of job * is not being executed at the moment. Aborting checkpoint.,info,flink
Checkpoint triggering task * of job * is not in state * but * instead. Aborting checkpoint.,info,flink
Checkpoint acknowledging task * of job * is not being executed at the moment. Aborting checkpoint.,info,flink
Failed to trigger checkpoint for job * (* consecutive failed attempts so far).,warn,flink
Trying to trigger another checkpoint for job * while one was queued already.,warn,flink
Triggering checkpoint * @ * for job *.,info,flink
Failed to trigger checkpoint * for job *. (* consecutive failed attempts so far),warn,flink
Cannot dispose failed checkpoint storage location *,warn,flink
Decline checkpoint * by task * of job * at *.,info,flink
Received another decline message for now expired checkpoint attempt * from task * of job * at * : *,debug,flink
Received decline message for unknown (too old?) checkpoint attempt * from task * of job * at * : *,debug,flink
Received wrong AcknowledgeCheckpoint message for job * from * : *,error,flink
Received acknowledge message for checkpoint * from task * of job * at *.,debug,flink
"Received a duplicate acknowledge message for checkpoint *, task *, job *, location *.",debug,flink
"Could not acknowledge the checkpoint * for task * of job * at *, because the task's execution attempt id was unknown. Discarding the state handle to avoid lingering state.",warn,flink
"Could not acknowledge the checkpoint * for task * of job * at *, because the pending checkpoint had been discarded. Discarding the state handle tp avoid lingering state.",warn,flink
Received late message for now expired checkpoint attempt * from task * of job * at *.,warn,flink
Received message for an unknown checkpoint * from task * of job * at *.,debug,flink
Could not properly discard completed checkpoint *.,warn,flink
Completed checkpoint * for job * (* bytes in * ms).,info,flink
$$$Empty Message$$$,debug,flink
Status of the shared state registry of job * after restore: *.,debug,flink
Resetting the master hooks.,debug,flink
Restoring job * from latest valid checkpoint: *.,info,flink
Starting job * from savepoint * (*),info,flink
Reset the checkpoint ID of job * to *.,info,flink
Exception while triggering checkpoint for job *.,error,flink
Discarding checkpoint * of job *.,info,flink
Could not properly discard state object of checkpoint * belonging to task * of job *.,warn,flink
"Found a completed checkpoint before the latest savepoint, will use it to recover!",info,flink
Method getAllCheckpoints caused exception : ,error,flink
Overriding maximum parallelism for JobVertex * from * to *,debug,flink
Skipped checkpoint state for operator *.,info,flink
Fail to subsume the old checkpoint.,warn,flink
Shutting down,info,flink
Could not find ExecutionJobVertex. Including user-defined OperatorIDs in search.,info,flink
Skipping savepoint state for operator *.,info,flink
Skipping empty savepoint state for operator *.,info,flink
Attempting to load configured state backend for savepoint disposal,info,flink
"No state backend configured, attempting to dispose savepoint with default backend (file system based)",info,flink
Could not load configured state backend.,info,flink
Detailed exception:,debug,flink
Error while discarding operator states.,warn,flink
Recovering checkpoints from ZooKeeper.,info,flink
Concurrent modification while reading from ZooKeeper. Retrying.,warn,flink
Found * checkpoints in ZooKeeper.,info,flink
Trying to fetch * checkpoints from storage.,info,flink
"Could not retrieve checkpoint, not adding to list of recovered checkpoints.",warn,flink
Could only fetch * of * checkpoints from storage.,warn,flink
Added * to *.,debug,flink
Failed to subsume the old checkpoint,warn,flink
Shutting down,info,flink
Suspending,info,flink
Could not parse checkpoint id from *. This indicates that the checkpoint id to path conversion has changed.,warn,flink
Trying to retrieve checkpoint *.,info,flink
$$$Empty Message$$$,warn,flink
Checkpoint with ID * at '*' not discarded.,info,flink
Executing discard procedure for *.,trace,flink
Error while discarding operator states.,warn,flink
Could not properly dispose the private states in the pending checkpoint * of job *.,warn,flink
Error while cancelling checkpoint timeout task,warn,flink
Shutting down.,info,flink
Removing * from ZooKeeper,info,flink
Failed to cleanly close a checkpoint master hook ( | ),warn,flink
No master state to restore,info,flink
Calling master restore hooks,info,flink
Found state to restore for hook '*',debug,flink
Dropping unmatched state from '*',info,flink
Trying to start actor system at *,info,flink
Using akka configuration  *,debug,flink
TaskManager start command: ,debug,flink
Overriding Fink's temporary file directories with those specified in the Flink config: *,info,flink
Setting directories for temporary files to: *,info,flink
The plugins directory ' | ' doesn't exist.,warn,flink
Unable to locate a Hadoop configuration; HDFS will use defaults.,warn,flink
"Initializing *: Storage directory *, expiration time *, maximum cache size * bytes.",info,flink
Could not load archived execution graph for job id *.,debug,flink
Could not find archived execution graph file for *. Estimating the size instead.,debug,flink
Could not delete file *.,debug,flink
Stopping dispatcher *.,info,flink
Received JobGraph submission * (*).,info,flink
Submitting job * (*).,info,flink
Could not properly remove job * from submitted job graph store.,warn,flink
Could not properly remove job * from the running jobs registry.,warn,flink
Could not properly release job * from submitted job graph store.,warn,flink
Stopping all currently running jobs of dispatcher *.,info,flink
Recovering all persisted jobs.,info,flink
Recover job *.,debug,flink
Job * reached globally terminal state *.,info,flink
Could not store completed job *(*).,info,flink
Job * was not finished by JobManager.,info,flink
Dispatcher * accepted leadership with fencing token *. Start recovered jobs.,debug,flink
Dispatcher * lost leadership before accepting it. Stop recovering jobs for fencing token *.,debug,flink
Ignore added JobGraph because the job * is already running.,debug,flink
Ignore added JobGraph because the job * has already been completed.,debug,flink
Failed to load web based job submission extension.,debug,flink
Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.,info,flink
Web-based job submission is not enabled.,info,flink
Could not parse command line arguments *.,error,flink
Starting *.,info,flink
Install default filesystem.,info,flink
Install security context.,info,flink
Initializing cluster services.,info,flink
Fatal error occurred in the cluster entrypoint.,error,flink
Shutting * down with application status *. Diagnostics *.,info,flink
Could not start cluster entrypoint %s.,error,flink
Starting Dispatcher REST endpoint.,debug,flink
Starting ResourceManager.,debug,flink
Starting Dispatcher.,debug,flink
Failed to release user code class loader for ,warn,flink
Connecting ExecutionJobVertex %s (%s) to %d predecessors.,debug,flink
Connecting input %d of vertex %s (%s) to intermediate result referenced via ID %s.,debug,flink
Connecting input %d of vertex %s (%s) to intermediate result referenced via predecessor %s (%s).,debug,flink
Resetting execution vertex * for new execution.,debug,flink
Cannot create JSON plan for job,warn,flink
Running initialization on master for job * (*).,info,flink
Successfully ran initialization on master in * ms.,info,flink
Adding * vertices from job graph * (*).,debug,flink
Successfully created execution graph from job graph * (*).,debug,flink
The setting for '* : *' is invalid. Using default value of *,warn,flink
Deploying %s (attempt #%d) to %s,info,flink
The execution has no slot assigned. This indicates that the execution is no longer running.,debug,flink
The execution has no slot assigned. This indicates that the execution is no longer running.,debug,flink
"Task FINISHED, but concurrently went to state ",debug,flink
$$$Empty Message$$$,error,flink
Ignoring transition of vertex * to * while being *.,debug,flink
"Sending out cancel request, to remove task execution from TaskManager.",debug,flink
Error triggering cancel call while marking task * as failed.,error,flink
Concurrent canceling/failing of * while deployment was in progress.,debug,flink
$$$Empty Message$$$,debug,flink
Discarding the results produced by task execution *.,info,flink
Discarding the results produced by task execution *.,info,flink
* (*) switched from * to *.,info,flink
* (*) switched from * to *.,info,flink
Error while notifying execution graph of execution state transition.,error,flink
Job recovers via failover strategy: *,info,flink
Trying to register multiple checkpoint hooks with the name: *,warn,flink
Could not serialize accumulator ,error,flink
Attaching * topologically sorted vertices to existing job graph with * vertices and * intermediate results.,debug,flink
Canceled during restart.,info,flink
The failing attempt * belongs to an already not running task thus won't fail the job,debug,flink
Concurrent full restart subsumed this restart.,info,flink
Canceled job during restart. Aborting restart.,info,flink
Failed job during restart. Aborting restart.,info,flink
Suspended job during restart. Aborting restart.,info,flink
Failed to restart the job.,warn,flink
Couldn't create ArchivedExecutionConfig for job * ,error,flink
$$$Empty Message$$$,error,flink
Job * (*) switched from state * to *.,info,flink
Job has entered globally terminal state without waiting for all job vertices to reach final state.,warn,flink
Try to restart or fail the job * (*) if no longer possible.,debug,flink
Try to restart or fail the job * (*) if no longer possible.,info,flink
Restarting the job * (*).,info,flink
Could not restart the job * (*) because *.,info,flink
Error while cleaning up after execution,error,flink
Failed to deserialize final accumulator results.,error,flink
Received accumulator result for unknown execution *.,debug,flink
Cannot update accumulators for job *.,error,flink
Error while notifying JobStatusListener,warn,flink
Error in failover strategy - falling back to global restart,warn,flink
Fail to pass the restart strategy validation in region failover. Fallback to fail global.,info,flink
Skip current region failover as a global failover is ongoing.,info,flink
Not enough resources to schedule * - triggering full recovery.,info,flink
Recovering task failure for * (#*) via individual restart.,info,flink
Created failover region * with vertices: *,debug,flink
FailoverRegion * is * when allVerticesInTerminalState.,info,flink
FailoverRegion * is * when notified to failover.,info,flink
FailoverRegion * is * when cancel.,info,flink
"FailoverRegion * switched from CANCELLING to CREATED fail, will fail this region again.",info,flink
"FailoverRegion * reset fail, will failover again.",info,flink
"FailoverRegion * switched from CREATED to RUNNING fail, will fail this region again.",info,flink
"FailoverRegion * restart failed, failover again.",info,flink
FailoverRegion * switched from state * to *.,info,flink
Recovering task failure for * #* (*) via restart of failover region,info,flink
Creating * individual failover regions for job * (*),info,flink
Cannot decompose ExecutionGraph into individual failover regions due to use of Co-Location constraints (iterations). Job will fail over as one holistic unit.,warn,flink
Null config value for * ; using default failover strategy (full restarts).,warn,flink
Cannot decompose the topology into individual failover regions due to use of Co-Location constraints (iterations). Job will fail over as one holistic unit.,warn,flink
Start building failover regions.,info,flink
Creating a failover region with * vertices.,debug,flink
Created * failover regions.,info,flink
Calculating tasks to restart to recover the failed task *.,info,flink
* tasks should be restarted to recover the failed task *. ,info,flink
Could not find restart strategy class *.,warn,flink
Class * does not has static method *.createFactory,warn,flink
Cannot call static method * from class *.createFactory,warn,flink
Illegal access while calling method * from class *.createFactory,warn,flink
User file cache uses directory ,info,flink
User file cache cannot create directory ,error,flink
User file cache cannot remove prior directory ,warn,flink
removed file cache directory *,info,flink
File cache could not properly clean up storage directory: *,error,flink
Could not delete file from local file cache.,error,flink
Trigger heartbeat request.,debug,flink
The target with resource ID * is already been monitored.,debug,flink
Received heartbeat from *.,debug,flink
Received heartbeat request from *.,debug,flink
Embedded leader election service encountered a fatal error. Shutting down service.,error,flink
"Received confirmation of leadership for leader * , session=*",info,flink
Received confirmation of leadership for a stale leadership grant. Ignoring.,debug,flink
Proposing leadership to contender * @ *,info,flink
Revoking leadership of *.,info,flink
Error notifying leader listener about new leader,warn,flink
Error granting leadership to contender,warn,flink
Error granting leadership to contender,warn,flink
Embedded leader election service encountered a fatal error. Shutting down service.,error,flink
Error notifying leader listener about new leader,warn,flink
Close and clean up all data for ZooKeeperHaServices.,info,flink
Retrying to delete owned znode because of other concurrent delete operation.,debug,flink
Job * has been archived at *.,info,flink
Failed to archive job.,error,flink
FileChannelManager uses directory * for spill files.,info,flink
IOManager failed to delete temporary file *,warn,flink
Shutting down I/O manager.,debug,flink
IO Thread ' | ' terminated due to an exception. Shutting down I/O Manager.,error,flink
IOManagerAsync did not shut down properly.,warn,flink
The handler of the request complete callback threw an exception | .,error,flink
 was interrupted without shutdown.,warn,flink
I/O reading thread encountered an error | .,error,flink
The handler of the request-complete-callback threw an exception | .,error,flink
The handler of the request complete callback threw an exception | .,error,flink
 was interrupted without shutdown.,warn,flink
I/O writing thread encountered an error | .,error,flink
The handler of the request-complete-callback threw an exception | .,error,flink
registering *,debug,flink
unregistering *,debug,flink
Starting the network environment and its components.,info,flink
Starting network connection manager,debug,flink
Shutting down the network environment and its components.,info,flink
Shutting down network connection manager,debug,flink
Cannot shut down the network connection manager.,warn,flink
Shutting down intermediate result partition manager,debug,flink
Cannot shut down the result partition manager.,warn,flink
Network buffer pool did not shut down properly.,warn,flink
Cannot close the file channel manager properly.,warn,flink
An exception happened while flushing the outputs,error,flink
Using a local buffer pool with *-* buffers,debug,flink
"Allocated * MB for network buffer pool (number of memory segments: *, bytes per segment: *).",info,flink
Encountered error while consuming partitions,error,flink
Memory statistics not available,warn,flink
Requesting subpartition * of partition * with * ms delay.,debug,flink
Transport type 'auto': using EPOLL.,info,flink
Transport type 'auto': using NIO.,info,flink
Successful initialization (took * ms). Listening on SocketAddress *.,info,flink
Successful shutdown (took * ms).,info,flink
Transport type 'auto': using EPOLL.,info,flink
Transport type 'auto': using NIO.,info,flink
Successful initialization (took * ms).,info,flink
Successful shutdown (took * ms).,info,flink
An Exception was thrown during error notification of a remote input channel.,warn,flink
Read channel on *: *.,debug,flink
Received unexpected client request: *,warn,flink
Responding with error: *.,debug,flink
$$$Empty Message$$$,info,flink
An Exception was thrown during error notification of a remote input channel.,warn,flink
Registered *.,debug,flink
Requesting subpartition * of *.,debug,flink
Released partition * produced by *.,debug,flink
Releasing * partitions because of shutdown.,debug,flink
Successful shutdown.,debug,flink
Received consume notification from *.,debug,flink
Released partition * produced by *.,debug,flink
*: Received consumed notification for subpartition *.,debug,flink
*: Finished *.,debug,flink
*: Released *.,debug,flink
*: Creating read view for subpartition * of partition *.,debug,flink
*: Initialized *,debug,flink
Cannot determine memory architecture. Using pure file-based shuffle.,warn,flink
*: Releasing *.,debug,flink
Error during release of result subpartition: ,error,flink
Created *,debug,flink
*: Received release notification for subpartition *.,debug,flink
*: Created * input channels (*).,debug,flink
*: Requesting LOCAL subpartition * of partition *.,debug,flink
"Ignore a partition producer state notification for task *, because it's not running.",debug,flink
Cancelling task * after the producer of partition * with attempt ID * has entered state *.,debug,flink
$$$Empty Message$$$,info,flink
*: Updated unknown input channel to *.,debug,flink
*: Retriggering partition request *:*.,debug,flink
*: Releasing *.,debug,flink
*: Error during release of channel resources: *.,warn,flink
[ | ] elements updated in the solutionset in iteration [ | ],info,flink
Error closing the solution set hash table after unsuccessful creation.,error,flink
Error freeing memory after error during solution set hash table creation.,error,flink
starting iteration [ | ],info,flink
finishing iteration [ | ],info,flink
waiting for other workers in iteration [ | ],info,flink
head received termination request in iteration [ | ],info,flink
streaming out final result after [ | ] iterations,info,flink
Sending end-of-superstep to all iteration outputs.,debug,flink
sending  |  to sync,info,flink
Error while shutting down an iterative operator.,error,flink
starting iteration [ | ],info,flink
finishing iteration [ | ],info,flink
signaling that all workers are to terminate in iteration [ | ],info,flink
signaling that all workers are done in iteration [ | ],info,flink
"maximum number of iterations [ | ] reached, terminating...",info,flink
"convergence reached after [ | ] iterations, terminating...",info,flink
"empty workset convergence reached after [ | ] iterations, terminating...",info,flink
starting iteration [ | ],info,flink
finishing iteration [ | ],info,flink
starting iteration [ | ],info,flink
finishing iteration [ | ],info,flink
Recovering job graph * from **.,debug,flink
Recovered *.,info,flink
Adding job graph * to **.,debug,flink
Updated * in ZooKeeper.,info,flink
Added * to ZooKeeper.,info,flink
Removing job graph * from **.,debug,flink
Removed job graph * from ZooKeeper.,info,flink
Releasing locks of job graph * from **.,debug,flink
Released locks of job graph * from ZooKeeper.,info,flink
Retrieving all stored job ids from ZooKeeper under *.,debug,flink
Could not parse job id from *. This indicates a malformed path.,warn,flink
Received * event (path: *),debug,flink
Received * event,debug,flink
Received CHILD_ADDED event notification for job *,debug,flink
Error in callback,error,flink
Error in JobGraphsPathCacheListener,error,flink
Received CHILD_REMOVED event notification for job *,debug,flink
Error in callback,error,flink
Error in JobGraphsPathCacheListener,error,flink
ZooKeeper connection SUSPENDING. Changes to the submitted job graphs are not monitored (temporarily).,warn,flink
ZooKeeper connection LOST. Changes to the submitted job graphs are not monitored (permanently).,warn,flink
ZooKeeper connection RECONNECTED. Changes to the submitted job graphs are monitored again.,info,flink
JobGraphsPathCacheListener initialized,info,flink
Initializing job * (*).,info,flink
Stopping the JobMaster for job *(*).,info,flink
Error while requesting next input split,warn,flink
Error while requesting partition state,info,flink
Disconnect TaskExecutor * because: *,debug,flink
Error while request key-value state location,info,flink
Error while receiving notification about key-value state registration,info,flink
Error while receiving notification about key-value state de-registration,info,flink
Cannot fail slot  |  because the TaskManager  |  is unknown.,warn,flink
Error while requesting operator back pressure stats,info,flink
Error while attempting to deserialize user AggregateFunction.,error,flink
Already started the job execution with JobMasterId *.,info,flink
Starting execution of job * (*) under job master id *.,info,flink
Restarting old job with JobMasterId *. The new JobMasterId is *.,info,flink
Job has already been suspended or shutdown.,debug,flink
Failed to stop resource manager leader retriever when suspending.,warn,flink
Fatal error occurred on JobManager.,error,flink
Connecting to ResourceManager *,info,flink
"JobManager successfully registered at ResourceManager, leader id: *.",info,flink
Ignoring resource manager connection to * because it's duplicated or outdated.,debug,flink
Close ResourceManager connection *.,debug,flink
Close ResourceManager connection *: *.,info,flink
The heartbeat of ResourceManager with id * timed out.,info,flink
Could not start the JobManager because the leader election service did not start.,error,flink
Could not un-register from high-availability services job * (*).Other JobManager's may attempt to recover it and re-execute it.,error,flink
JobManagerRunner already shutdown.,info,flink
JobManager runner for job * (*) was granted leadership with session id * at *.,info,flink
Granted leader ship but job * has been finished. ,info,flink
Ignoring confirmation of leader session id because * is no longer the leader.,debug,flink
JobManagerRunner already shutdown.,info,flink
JobManager for job * (*) was revoked leadership at *.,info,flink
Leader Election Service encountered a fatal error.,error,flink
Create multi task slot [*] in slot [*].,debug,flink
Create nested multi task slot [*] in parent multi task slot [*] for group [*].,debug,flink
Create single task slot [*] in multi task slot [*] for group *.,debug,flink
"Not all requests are fulfilled due to over-allocated, number of requests is *, number of evicted requests is *, underlying allocated is *, fulfilled is *, evicted requests is *,",debug,flink
Suspending SlotPool.,info,flink
Stopping SlotPool.,info,flink
Requesting new slot [*] and profile * from resource manager.,info,flink
Ignoring failed request to the resource manager for a batch slot request.,debug,flink
Unregistered slot request [*] failed.,debug,flink
"Cannot serve slot request, no ResourceManager connected. Adding as pending request [*]",info,flink
Releasing slot [*] because: *,debug,flink
There is no allocated slot [*]. Ignoring the release slot request.,debug,flink
Failing pending slot request [*]: *,info,flink
Fulfilling pending slot request [*] early with returned slot [*],debug,flink
Adding returned slot [*] to available slots,debug,flink
Received outdated slot offering [*] from unregistered TaskManager: *,debug,flink
Received repeated offer for slot [*]. Ignoring.,info,flink
Fulfilled slot request [*] with allocated slot [*].,debug,flink
Failed allocated slot [*]: *,debug,flink
Register new TaskExecutor *.,debug,flink
Pending slot request [*] timed out.,info,flink
Releasing idle slot [*].,info,flink
$$$Empty Message$$$,debug,flink
Received slot request [*] for task: *,debug,flink
Could not find slot [*] in slot sharing group *. Ignoring release slot request.,debug,flink
Could not find slot sharing group *. Ignoring release slot request.,debug,flink
Starting ZooKeeperLeaderElectionService *.,info,flink
Stopping ZooKeeperLeaderElectionService *.,info,flink
Confirm leader session ID * for leader *.,debug,flink
"Ignoring the leader session Id * confirmation, since the ZooKeeperLeaderElectionService has already been stopped.",debug,flink
The leader session ID * was confirmed even though the corresponding JobManager was not elected as the leader.,warn,flink
Grant leadership to contender * with session ID *.,debug,flink
Ignoring the grant leadership notification since the service has already been stopped.,debug,flink
Revoke leadership of *.,debug,flink
Ignoring the revoke leadership notification since the service has already been stopped.,debug,flink
Leader node changed while * is the leader with session ID *.,debug,flink
Writing leader information into empty node by *.,debug,flink
Writing leader information into node with empty data field by *.,debug,flink
Correcting leader information by *.,debug,flink
Ignoring node change notification since the service has already been stopped.,debug,flink
"Write leader information: Leader=*, session ID=*.",debug,flink
"Successfully wrote leader information: Leader=*, session ID=*.",debug,flink
Connected to ZooKeeper quorum. Leader election can start.,debug,flink
Connection to ZooKeeper suspended. The contender  |  no longer participates in the leader election.,warn,flink
Connection to ZooKeeper was reconnected. Leader election can be restarted.,info,flink
Connection to ZooKeeper lost. The contender  |  no longer participates in the leader election.,warn,flink
Starting ZooKeeperLeaderRetrievalService *.,info,flink
Stopping ZooKeeperLeaderRetrievalService *.,info,flink
Leader node has changed.,debug,flink
"New leader information: Leader=*, session ID=*.",debug,flink
Ignoring node change notification since the service has already been stopped.,debug,flink
Connected to ZooKeeper quorum. Leader retrieval can start.,debug,flink
Connection to ZooKeeper suspended. Can no longer retrieve the leader from ZooKeeper.,warn,flink
Connection to ZooKeeper was reconnected. Leader retrieval can be restarted.,info,flink
Connection to ZooKeeper lost. Can no longer retrieve the leader from ZooKeeper.,warn,flink
It is advisable to set 'taskmanager.memory.preallocate' to true when the memory type 'taskmanager.memory.off-heap' is set to true.,warn,flink
"Initialized MemoryManager with total memory size *, number of slots *, page size *, memory type *, pre allocate memory * and number of non allocated pages *.",debug,flink
"Failed to parse scope format, using default scope formats",warn,flink
"Failed to parse delimiter, using default delimiter.",warn,flink
"No metrics reporter configured, no metrics will be exposed/reported.",info,flink
Cannot parse report interval from config:  |  - please use values like '10 SECONDS' or '500 MILLISECONDS'.  | Using default reporting interval.,error,flink
Periodically reporting metrics in intervals of * * for reporter * of type *.,info,flink
Reporting metrics for reporter * of type *.,info,flink
"Failed to parse delimiter '*' for reporter '*', using global delimiter '*'.",warn,flink
Could not instantiate metrics reporter *. Metrics might not be exposed/reported.,error,flink
Could not start MetricDumpActor. No metrics will be submitted to the WebInterface.,warn,flink
"Delimiter for reporter index * not found, returning global delimiter.",warn,flink
"Cannot register metric, because the MetricRegistry has already been shut down.",warn,flink
Error while registering metric.,warn,flink
Error while registering metric.,warn,flink
Error while registering metric.,warn,flink
"Cannot unregister metric, because the MetricRegistry has already been shut down.",warn,flink
Error while registering metric.,warn,flink
Error while registering metric.,warn,flink
Error while registering metric.,warn,flink
Error while reporting metrics,warn,flink
Configuring * with *.,info,flink
Duplicate class configuration detected for reporter *.,warn,flink
"Excluding reporter *, not configured in reporter list (*).",info,flink
Could not instantiate metrics reporter *. Metrics might not be exposed/reported.,error,flink
Error while loading reporter factory.,warn,flink
No reporter class nor factory set for reporter *. Metrics might not be exposed/reported.,warn,flink
The reporter factory (*) could not be found for reporter *. Available factories: ,warn,flink
The reporter configuration of * is out-dated (but still supported). Please configure a factory class instead: '**.*: *' to ensure that the configuration continues to work with future versions.metrics.reporter.factory.class,info,flink
Failed to serialize counter.,debug,flink
Failed to serialize gauge.,debug,flink
Failed to serialize histogram.,debug,flink
Failed to serialize meter.,debug,flink
Failed to deserialize counter.,debug,flink
Failed to deserialize gauge.,debug,flink
Failed to deserialize meter.,debug,flink
Failed to deserialize histogram.,debug,flink
* will not be reported as the metric dump would exceed the maximum size of * bytes.,debug,flink
* will not be reported as the metric dump would exceed the maximum size of * bytes.Some metrics,info,flink
Ignoring attempted registration of a metric due to being null for name *.,warn,flink
Name collision: Adding a metric with the same name as a metric subgroup: ' | '. Metric might not get properly reported. ,warn,flink
Name collision: Group already contains a Metric with the name ' | '. Metric will not be reported.,warn,flink
Name collision: Adding a metric subgroup with the same name as an existing metric: ' | '. Metric might not get properly reported. ,warn,flink
The operator name * exceeded the * characters length limit and was truncated.80,warn,flink
* has failed,warn,flink
Failed to initialize system resource metrics because of missing class definitions. Did you forget to explicitly add the oshi-core optional dependency?,warn,flink
"Could not create object name *.java.nio:type=BufferPool,name=direct",warn,flink
"Could not create object name *.java.nio:type=BufferPool,name=mapped",warn,flink
Cannot access com.sun.management.OperatingSystemMXBean.getProcessCpuLoad() - CPU load metrics will not be available.,warn,flink
Could not read attribute *.,warn,flink
Starting Flink Mini Cluster,info,flink
Using configuration *,debug,flink
Starting Metrics Registry,info,flink
Starting RPC Service(s),info,flink
Flink Mini Cluster started successfully,info,flink
Starting high-availability services,info,flink
Shutting down Flink Mini Cluster,info,flink
Starting * TaskManger(s),info,flink
TaskManager #* failed.,error,flink
Error in MiniCluster. Shutting the MiniCluster down.,warn,flink
Trying to connect to ,info,flink
Could not connect. Waiting for * msecs before next attempt,info,flink
Could not connect. Waiting for * msecs before next attempt,debug,flink
Could not connect to *. Selecting a local address using heuristics.,warn,flink
Could not find any IPv4 address that is not loopback or link-local. Using localhost address.,warn,flink
Preferring * (InetAddress.getLocalHost()) for local bind point over previous candidate *,debug,flink
Could not resolve local hostname to an IP address: *,warn,flink
Using InetAddress.getLocalHost() immediately for the connecting address,debug,flink
Target address * and local address * share prefix - trying to connect.,debug,flink
Trying to connect to * from local address * with timeout *,debug,flink
Choosing InetAddress.getLocalHost() address as a heuristic.,debug,flink
Trying to connect to ( | ) from local address  |  with timeout ,debug,flink
$$$Empty Message$$$,debug,flink
$$$Empty Message$$$,info,flink
Retrieved new target address *.,info,flink
Trying to connect to address *,info,flink
Could not connect to *. Selecting a local address using heuristics.,warn,flink
Could not find any IPv4 address that is not loopback or link-local. Using localhost address.,warn,flink
"Received non-SSL request, redirecting to **",trace,flink
Start registering input and output.,debug,flink
Finished registering input and output.,debug,flink
Start task code.,debug,flink
Input [ | ] reads in supersteps with [ | ] event(s) till next superstep.,debug,flink
Broadcast input [ | ] reads in supersteps with [ | ] event(s) till next superstep.,debug,flink
Task cancelled before task code was started.,debug,flink
Finished task code.,debug,flink
Task code cancelled.,debug,flink
Cancelling task code,debug,flink
"Setting broadcast variable ' | ' | , superstep  | ",debug,flink
"Releasing broadcast variable ' | ' | , superstep  | ",debug,flink
Releasing all broadcast variables.,debug,flink
Error closing local strategy for input ,error,flink
Error closing temp barrier for input ,error,flink
Error closing cache for input ,error,flink
Error in task code,error,flink
Start task code,debug,flink
Finished task code,debug,flink
ReduceDriver object reuse:  | ENABLED | .,debug,flink
Reducer preprocessing done. Running Reducer code.,debug,flink
AllReduceDriver object reuse:  | ENABLED | .,debug,flink
AllReduce preprocessing done. Running Reducer code.,debug,flink
FlatMapDriver object reuse:  | ENABLED | .,debug,flink
CoGroup task iterator ready.,debug,flink
ReduceCombineDriver object reuse:  | ENABLED | .,debug,flink
Combiner starting.,debug,flink
Start registering input and output,debug,flink
Finished registering input and output,debug,flink
Starting data source operator,debug,flink
An exception occurred during the metrics setup.,warn,flink
Rich Source detected. Initializing runtime context.,debug,flink
Rich Source detected. Opening the InputFormat.,debug,flink
DataSourceTask object reuse:  | ENABLED | .,debug,flink
Opening input split ,debug,flink
Starting to read input from split ,debug,flink
Closing input split ,debug,flink
Rich Source detected. Closing the InputFormat.,debug,flink
Finished data source operator,debug,flink
Data source operator cancelled,debug,flink
Cancelling data source operator,debug,flink
AllGroupReduceDriver object reuse:  | ENABLED | .,debug,flink
AllGroupReduceDriver preprocessing done. Running Reducer code.,debug,flink
Outer Join Driver object reuse:  | ENABLED | .,debug,flink
outer join task iterator ready.,debug,flink
GroupReduceCombineDriver object reuse: *.,debug,flink
Combiner starting.,debug,flink
"Cannot write record to fresh sort buffer, record is too large. Oversized record count: *",debug,flink
NoOpDriver object reuse:  | ENABLED | .,debug,flink
Join Driver object reuse:  | ENABLED | .,debug,flink
join task iterator ready.,debug,flink
GroupReduceDriver object reuse:  | ENABLED | .,debug,flink
GroupReducer preprocessing done. Running GroupReducer code.,debug,flink
GroupCombineDriver object reuse:  | ENABLED | .,debug,flink
AllGroupCombine starting.,debug,flink
CoGroupDriver object reuse:  | ENABLED | .,debug,flink
CoGroup task iterator ready.,debug,flink
CrossDriver object reuse:  | ENABLED | .,debug,flink
"Running Cross with Block-Nested-Loops:  | First input is outer (blocking) side, second input is inner (spilling) side.",debug,flink
"Running Cross with Block-Nested-Loops:  | First input is inner (spilling) side, second input is outer (blocking) side.",debug,flink
"Running Cross with Nested-Loops:  | First input is outer side, second input is inner (spilling) side.",debug,flink
"Running Cross with Nested-Loops:  | First input is inner (spilling) side, second input is outer side.",debug,flink
Start registering input and output,debug,flink
Finished registering input and output,debug,flink
Starting data sink operator,debug,flink
An exception occurred during the metrics setup.,warn,flink
Rich Sink detected. Initializing runtime context.,debug,flink
Starting to produce output,debug,flink
Cleanup on error failed.,error,flink
Error in user code: ,error,flink
Error closing the output format,warn,flink
Error closing local strategy,error,flink
Finished data sink operator,debug,flink
Data sink operator cancelled,debug,flink
Cleanup on error failed.,error,flink
Cancelling data sink operator,debug,flink
MapPartitionDriver object reuse:  | ENABLED | .,debug,flink
SynchronousChainedCombineDriver object reuse:  | ENABLED | .,debug,flink
ChainedReduceCombineDriver object reuse:  | ENABLED | .,debug,flink
ChainedAllReduceDriver object reuse:  | ENABLED | .,debug,flink
SynchronousChainedCombineDriver object reuse:  | ENABLED | .,debug,flink
Closing InPlaceMutableHashTable and releasing resources.,debug,flink
Aborting InPlaceMutableHashTable.,debug,flink
Closing hash table and releasing resources.,debug,flink
Cancelling hash table operations.,debug,flink
Could not close and delete the temp file for the current spilled partition probe side.,warn,flink
"Create BloomFilter with average input entries per bucket[%d], bytes size[%d], false positive probability[%f].",debug,flink
Error during partition cleanup.,error,flink
Creating spilling resettable iterator with  |  pages of memory.,debug,flink
Spilling Resettable Iterator closing. Stored  |  records.,debug,flink
Iterator initialized using  |  memory buffers.,debug,flink
Block Resettable Iterator opened.,debug,flink
Block Resettable Iterator closed.,debug,flink
Creating spilling resettable iterator with  |  pages of memory.,debug,flink
Spilling Resettable Iterator opened.,debug,flink
Spilling Resettable Iterator closing. Stored  |  records.,debug,flink
Error closing block memory iterator: ,error,flink
Sorting thread was interrupted (without being shut down) while grabbing a buffer. Retrying to grab buffer...,error,flink
Initiating in memory merge.,debug,flink
Releasing unused sort-buffer memory.,debug,flink
Sorting thread was interrupted (without being shut down) while grabbing a buffer. Retrying to grab buffer...,error,flink
Creating temp file ,debug,flink
Combining buffer ,debug,flink
Combined and spilled buffer  | .,debug,flink
Spilling done.,debug,flink
Releasing sort-buffer memory.,debug,flink
Closing combiner user code.,debug,flink
User code closed.,debug,flink
Beginning final merge.,debug,flink
Spilling and merging thread done.,debug,flink
Error retrieving a value from a buffer.,error,flink
Reducing maximal merge fan-in to  |  due to limited memory availability during merge,debug,flink
Instantiating sorter with %d pages of sorting memory (= | %d bytes total) divided over %d sort buffers (%d pages per buffer). Using %d |  buffers for writing sorted results and merging maximally %d streams at once.  | Using %d memory segments for large record spilling.,debug,flink
Error shutting down reader thread: ,error,flink
Error shutting down sorter thread: ,error,flink
Error shutting down spilling thread: ,error,flink
Closing of sort/merger was interrupted. The reading/sorting/spilling threads may still be working.,debug,flink
Retrieved empty read buffer  | .,debug,flink
Large record did not fit into a fresh sort buffer. Putting into large record store.,debug,flink
Emitting full buffer from reader thread:  | .,debug,flink
Emitting full buffer from reader thread:  | .,debug,flink
Emitting final buffer from reader thread:  | .,debug,flink
Reading thread done.,debug,flink
Sorting thread was interrupted (without being shut down) while grabbing a buffer. Retrying to grab buffer...,error,flink
Sorting buffer  | .,debug,flink
Sorted buffer  | .,debug,flink
Sorting thread done.,debug,flink
Going to disk-based merge because of large records.,debug,flink
"Sorting large records, to add them to in-memory merge.",debug,flink
Initiating in memory merge.,debug,flink
Releasing unused sort-buffer memory.,debug,flink
Sorting thread was interrupted (without being shut down) while grabbing a buffer. Retrying to grab buffer...,error,flink
Spilling buffer  | .,debug,flink
Spilled buffer  | .,debug,flink
Spilling done.,debug,flink
Releasing sort-buffer memory.,debug,flink
Sorting keys for large records.,debug,flink
Beginning final merge.,debug,flink
Spilling and merging thread done.,debug,flink
Spilling thread was interrupted (without being shut down) while collecting empty buffers to release them. Retrying to collect buffers...,error,flink
Performing merge of  |  sorted streams.,debug,flink
Put a large record ( >10485760 into the sort buffer,debug,flink
Spilling sort buffer without large record handling.,debug,flink
Spilling sort buffer with large record handling.,debug,flink
Spilling large record to large record fetch file.,debug,flink
Initializing the large record spilling...,debug,flink
Cannot close the large records spill file.,error,flink
Cannot close the large records key spill file.,error,flink
Cannot close the large records reader.,error,flink
Cannot close the large records key reader.,error,flink
Cannot delete the large records spill file.,error,flink
Cannot delete the large records key spill file.,error,flink
Cannot properly dispose the key sorter and clean up its temporary files.,error,flink
 Cause: ,debug,flink
"Could not load Queryable State Client Proxy. Probable reason: flink-queryable-state-runtime is not in the classpath. To enable Queryable State, please move the flink-queryable-state-runtime jar from the opt to the lib folder.",info,flink
Queryable State Client Proxy could not be created: ,error,flink
Failed to instantiate the Queryable State Client Proxy.,error,flink
 Cause: ,debug,flink
"Could not load Queryable State Server. Probable reason: flink-queryable-state-runtime is not in the classpath. To enable Queryable State, please move the flink-queryable-state-runtime jar from the opt to the lib folder.",info,flink
Queryable State Server could not be created: ,error,flink
Failed to instantiate the Queryable State Server.,error,flink
Registration at * attempt * (timeout=*ms),info,flink
Could not add job * to job leader id service.,error,flink
Registering job manager *@* for job *.,info,flink
Could not obtain the job leader id future to verify the correct job leader.,debug,flink
Request slot with profile * for job * with allocation id *.,info,flink
Invalid registration id for slot available message. This indicates an outdated request.,debug,flink
Could not find registration for resource id *. Discarding the slot availablemessage *.,debug,flink
"Shut down cluster because application is in *, diagnostics *.",info,flink
Could not properly shutdown the application.,warn,flink
Request file * upload from TaskExecutor *.,debug,flink
Requested file * upload from unregistered TaskExecutor *.,debug,flink
Job manager *@* was already registered.,debug,flink
Registered job manager *@* for job *.,info,flink
Replacing old registration of TaskExecutor *.,debug,flink
Discard registration from TaskExecutor * at (*) because the framework did not recognize it,warn,flink
Registering TaskManager with ResourceID * (*) at ResourceManager,info,flink
Disconnect job manager *@* for job * from the resource manager.,info,flink
There was no registered job manager for job *.,debug,flink
Closing TaskExecutor connection * because: *,info,flink
No open TaskExecutor connection *. Ignoring close TaskExecutor connection. Closing reason was: *,debug,flink
Could not properly remove the job * from the job leader id service.,warn,flink
"Discarding job leader lost leadership, because a new job leader was found for job *. ",debug,flink
Discard job leader lost leadership for outdated leader * for job *.,debug,flink
Worker * could not be stopped.,debug,flink
Fatal error occurred in ResourceManager.,error,flink
ResourceManager * was granted leadership with fencing token *,info,flink
The heartbeat of TaskManager with id * timed out.,info,flink
Received slot report from TaskManager * which is no longer registered.,debug,flink
The heartbeat of JobManager with id * timed out.,info,flink
Add job * to job leader id monitoring.,debug,flink
Remove job * from job leader id monitoring.,debug,flink
Found a new job leader *@*.,debug,flink
A leader id change *@* has been detected after the listener has been stopped.,debug,flink
An error occurred in the * after the listener has been stopped.,debug,flink
Config key * is deprecated; use * instead.,warn,flink
Starting the SlotManager.,info,flink
Suspending the SlotManager.,info,flink
Closing the SlotManager.,info,flink
Ignoring a duplicate slot request with allocation id *.,debug,flink
Cancel slot request *.,debug,flink
No pending slot request with allocation id * found. Ignoring unregistration request.,debug,flink
Registering TaskManager * under * at the SlotManager.,debug,flink
Unregister TaskManager * from the SlotManager.,debug,flink
There is no task manager registered with instance ID *. Ignoring this message.,debug,flink
Received slot report from instance *: *.,debug,flink
Received slot report for unknown task manager with instance id *. Ignoring this report.,debug,flink
"Received request to free slot * with expected allocation id *, but actual allocation id * differs. Ignoring the request.",debug,flink
Slot * has not been allocated.,debug,flink
Trying to free a slot * which has not been registered. Ignoring this message.,debug,flink
Trying to update unknown slot with slot id *.,debug,flink
There was no slot registered with slot id *.,debug,flink
Ignore slot request removal for slot *.,debug,flink
There was no slot with * registered. Probably this slot has been already freed.,debug,flink
Slot request with allocation id * failed for slot *.,debug,flink
There was not pending slot request with allocation id *. Probably the request has been fulfilled or cancelled.,debug,flink
"Cannot reject pending slot request *, since no request has been sent.",debug,flink
Release TaskExecutor * because it exceeded the idle timeout.,debug,flink
Starting rest endpoint.,info,flink
Binding rest endpoint to *:*.,debug,flink
Rest endpoint listening at *:*,info,flink
Cannot access local server address,error,flink
Shutting down rest endpoint.,info,flink
Register handler * under *@*.,debug,flink
Register handler * under *@*.,debug,flink
Upload directory * does not exist. ,info,flink
Upload directory * has been deleted externally. Previously uploaded files are no longer available.,warn,flink
Using directory * for file uploads.,info,flink
Created directory * for file uploads.,info,flink
Upload directory * cannot be created or is not writable.,warn,flink
Received request. URL:* Method:*,trace,flink
Initializing multipart file upload.,trace,flink
Received http content.,trace,flink
Upload of file * complete.,trace,flink
Upload of attribute * complete.,trace,flink
Finalizing multipart file upload.,trace,flink
$$$Empty Message$$$,warn,flink
Could not cleanup uploaded files.,warn,flink
Error while resetting handler.,debug,flink
Rest client endpoint started.,info,flink
Rest endpoint shutdown complete.,info,flink
Rest endpoint shutdown failed.,warn,flink
Shutting down rest endpoint.,info,flink
Sending request of class * to *:**,debug,flink
Adding file * to request.,trace,flink
Received response was neither of the expected type (*) nor an error. Response=*,error,flink
Implementation error: Received a response that wasn't a FullHttpResponse.,error,flink
Received response *.,debug,flink
Response was not valid JSON.,error,flink
Unexpected plain-text response: *,error,flink
Response could not be read.,error,flink
Unknown message received: *,warn,flink
Unhandled exception,warn,flink
Received request ,trace,flink
Implementation error: Received a request that wasn't a FullHttpRequest.,error,flink
Could not create the handler request.,error,flink
Starting request processing.,trace,flink
Exception occurred in REST handler.,error,flink
Exception occurred in REST handler: *,error,flink
Unhandled exception.,error,flink
Could not cleanup uploaded files.,warn,flink
Invalid value * specified for integer range. Not a number.,warn,flink
The metric * is not numeric and can't be aggregated.,warn,flink
Triggering stack trace sample for tasks: ,debug,flink
"Ignoring sample, because job is in state  | .",debug,flink
Failed to gather stack trace sample.,debug,flink
Error during stats completion.,error,flink
"Outdated sample. A task, which is part of the sample has been reset.",debug,flink
Triggering stack trace sample *,debug,flink
Cancelling sample ,info,flink
Cancelling sample *,info,flink
Shutting down stack trace sample coordinator.,info,flink
Collecting stack trace sample * of task *,debug,flink
Received late stack trace sample * of task *,debug,flink
Unknown sample ID ,debug,flink
Loading missing file from classloader: *,debug,flink
error while responding,error,flink
Unable to load requested file * from classloader,debug,flink
Responding 'NOT MODIFIED' for file ',debug,flink
Responding with file ',debug,flink
Failed to serve file.,error,flink
Caught exception,error,flink
Invalid metric dump category: ,debug,flink
Malformed metric dump.,debug,flink
Start fetching metrics.,debug,flink
Exception while fetching metrics.,debug,flink
Retrieve metric query service gateway for *,debug,flink
Query metrics for *.,debug,flink
Request could not be routed to any handler. Uri:* Method:*,trace,flink
Load file from TaskManager *.,debug,flink
Remove cached file for TaskExecutor *.,debug,flink
Configuring the job submission via query parameters is deprecated. Please migrate to submitting a JSON request instead.,warn,flink
Internal server error. Could not map response to JSON.,error,flink
Internal server error. Could not map error response to JSON.,error,flink
$$$Empty Message$$$,warn,flink
Could not create remote rpc invocation message. Failing rpc invocation because...,warn,flink
Fencing token not set: Ignoring message * because the fencing token is null.,debug,flink
Fencing token mismatch: Ignoring message * because the fencing token * did not match the expected fencing token *.,debug,flink
Unknown message type: Ignoring message * because it is neither of type * nor *.,debug,flink
The rpc endpoint * has not been started yet. Discarding message * until processing is started.,info,flink
$$$Empty Message$$$,warn,flink
Received message of unknown type * with value *. Dropping this message!,warn,flink
Could not load method arguments.,error,flink
Could not deserialize rpc invocation message.,error,flink
Could not find rpc method for rpc invocation.,error,flink
Reporting back error thrown in remote procedure *,debug,flink
Error while executing remote procedure call *.,error,flink
Caught exception while executing runnable in main thread.,error,flink
Starting RPC endpoint for * at * .,info,flink
RPC endpoint * already stopped or from different RPC service,debug,flink
Stopping Akka RPC service.,info,flink
Try to connect to remote RPC endpoint with address *. Returning a * gateway.,debug,flink
Using restart strategy * for * (*).,info,flink
Can not find Execution for attempt *.,debug,flink
Send next input split *.,debug,flink
Lookup key-value state for job * with registration name *.,debug,flink
Request of key-value state location for unknown job * received.,debug,flink
Key value state registered for job * under name *.,debug,flink
Key value state unregistered for job * under name *.,debug,flink
"Trying to cancel job * with savepoint, but no savepoint directory configured.",info,flink
$$$Empty Message$$$,error,flink
$$$Empty Message$$$,debug,flink
$$$Empty Message$$$,error,flink
$$$Empty Message$$$,debug,flink
"Trying to cancel job * with savepoint, but no savepoint directory configured.",info,flink
Allocate slot with id * for execution *,debug,flink
overriding previous security context,warn,flink
Cannot install HadoopSecurityContext because Hadoop cannot be found in the Classpath.,info,flink
Cannot install HadoopSecurityContext.,error,flink
unable to uninstall a security module,warn,flink
Could not find method implementations in the shaded jar. Exception: *,warn,flink
Could not find method implementations in the shaded jar. Exception: *,warn,flink
Hadoop security is enabled but current login user does not have Kerberos credentials,warn,flink
Hadoop user set to *,info,flink
Cannot create Hadoop Security Module because Hadoop cannot be found in the Classpath.,info,flink
Cannot create Hadoop Security Module.,error,flink
Identified duplicate state registration under key *. New state * was determined to be an unnecessary copy of existing state * and will be dropped.,trace,flink
Registered shared state * under key *.,trace,flink
Unregistered shared state * under key *.,trace,flink
Scheduled delete of state handle *.,trace,flink
A problem occurred during asynchronous disposal of a shared state object: *,warn,flink
Stored local state for checkpoint * in subtask (* - * - *) : *.,debug,flink
Stored local state for checkpoint * in subtask (* - * - *),debug,flink
Found registered local state for checkpoint * in subtask (* - * - *) : *,trace,flink
Found registered local state for checkpoint * in subtask (* - * - *),debug,flink
Did not find registered local state for checkpoint * in subtask (* - * - *),debug,flink
Received confirmation for checkpoint * in subtask (* - * - *). Starting to prune history.,debug,flink
Discarding local task state snapshot of checkpoint * for subtask (* - * - *).,trace,flink
Discarding local task state snapshot * of checkpoint * for subtask (* - * - *).,debug,flink
Exception while discarding local task state snapshot of checkpoint * in subtask (* - * - *).,warn,flink
Deleting local state directory * of checkpoint * for subtask (* - * - *).,debug,flink
Exception while deleting local state directory of checkpoint * in subtask (* - * - *).,warn,flink
Discarding IncrementalRemoteKeyedStateHandle (registered = *) for checkpoint * from backend with id *.,trace,flink
Could not properly discard meta data.,warn,flink
Could not properly discard misc file states.,warn,flink
Could not properly discard new sst file states.,warn,flink
Registering IncrementalRemoteKeyedStateHandle for checkpoint * from backend with id *.,trace,flink
Operator * has remote state * from job manager and local state alternatives * from local state store *.,debug,flink
$$$Empty Message$$$,debug,flink
Could not properly close incremental snapshot streams.,warn,flink
"Cancelled execution of snapshot future runnable. Cancellation produced the following exception, which is expected an can be ignored.",debug,flink
Exception from secondary/local checkpoint stream.,warn,flink
Exception when opening secondary/local checkpoint output stream. Continue only with the primary stream.,warn,flink
Registered new allocation id * for local state stores for job *.,debug,flink
Registered new local state store with configuration * for * - * - * under allocation id *.,debug,flink
Found existing local state store for * - * - * under allocation id *: *,debug,flink
Releasing local state under allocation id *.,debug,flink
Shutting down TaskExecutorLocalStateStoresManager.,info,flink
Exception while disposing local state store *.,warn,flink
Exception while deleting local state directory for allocation id *.,warn,flink
State backend is set to heap memory (checkpoint to JobManager) *,info,flink
"State backend is set to heap memory (checkpoints to filesystem ""*"")",info,flink
Loading state backend via factory *,info,flink
Using application-defined state backend: *,info,flink
Configuring application-defined state backend with job/cluster config,info,flink
"No state backend has been configured, using default (Memory / JobManager) *",info,flink
Ignoring invalid file size threshold value (*): * - using default value * instead.,warn,flink
Could not close the state stream for *.,warn,flink
Could not delete the checkpoint stream file *.,warn,flink
Could not close the state stream for *.,warn,flink
Cannot delete closed and discarded state stream for *.,warn,flink
Could not delete the checkpoint stream file *.,warn,flink
Could not close the state stream for *.,warn,flink
Could not delete the checkpoint stream file *.,warn,flink
Initializing heap keyed state backend with stream factory.,info,flink
Maximum capacity of 2^30 in StateMap reached. Cannot increase hash map size. This can lead to more collisions and lower performance. Please consider scaling-out your job or using a different keyed state backend implementation!,warn,flink
Successful registration at resource manager * under registration id *.,info,flink
Failed to register at resource manager *.,info,flink
Messages have a max timeout of ,info,flink
Start job leader service.,info,flink
Stop job leader service.,info,flink
Remove job * from job leader monitoring.,info,flink
Add job * for job leader monitoring.,info,flink
Cannot reconnect to job * because it is not registered.,info,flink
Cannot reconnect because the JobManagerLeaderListener has already been stopped.,debug,flink
Could not reconnect to the JobMaster *.,debug,flink
Ongoing registration to JobMaster *.,debug,flink
Cannot reconnect to an unknown JobMaster.,debug,flink
"*'s leader retrieval listener reported a new leader for job *. However, the service is no longer running.",debug,flink
"New leader information for job *. Address: *, leader id: *.",debug,flink
Try to register at job manager * with leader id *.,info,flink
"*'s leader retrieval listener reported an exception for job *. However, the service is no longer running.",debug,flink
Successful registration at job manager * for job *.,info,flink
Encountered obsolete JobManager registration success from * with leader session ID *.,debug,flink
Failed to register at job  manager * for job *.,info,flink
Obsolete JobManager registration failure from * with leader session ID *.,debug,flink
Using * MB for managed memory.,info,flink
"Limiting managed memory to * MB, memory will be allocated lazily.",info,flink
Using * of the currently free heap space for managed heap memory (* MB).,info,flink
"Limiting managed memory to * of the currently free heap space (* MB), memory will be allocated lazily.",info,flink
Using * of the maximum memory size for managed off-heap memory (* MB).,info,flink
"Limiting managed memory to * of the maximum memory size (* MB), memory will be allocated lazily.",info,flink
"Temporary file directory '%s': total %d GB,  | usable %d GB (%.2f%% usable)",info,flink
Stopping TaskExecutor *.,info,flink
Stopped TaskExecutor *.,info,flink
$$$Empty Message$$$,debug,flink
$$$Empty Message$$$,debug,flink
$$$Empty Message$$$,debug,flink
Received task *.,info,flink
$$$Empty Message$$$,debug,flink
$$$Empty Message$$$,debug,flink
Discard update for input partitions of task *. Task is no longer running.,debug,flink
Trigger checkpoint *@* for *.,debug,flink
$$$Empty Message$$$,debug,flink
Confirm checkpoint *@* for *.,debug,flink
$$$Empty Message$$$,debug,flink
Receive slot request * for job * from resource manager with leader id *.,info,flink
$$$Empty Message$$$,debug,flink
Allocated slot for *.,info,flink
Could not allocate slot for *.,info,flink
$$$Empty Message$$$,info,flink
Request file * upload.,debug,flink
Could not upload file *.,debug,flink
The file * does not exist on the TaskExecutor *.,debug,flink
The file * is unavailable on the TaskExecutor *.,debug,flink
Connecting to ResourceManager *.,info,flink
Close ResourceManager connection *.,debug,flink
Close ResourceManager connection *.,info,flink
Terminating registration attempts towards ResourceManager *.,debug,flink
Terminating registration attempts towards ResourceManager *.,info,flink
There is no job manager connection to the leader of job *.,debug,flink
Offer reserved slots to the leader of job *.,info,flink
There are no unassigned slots for the job *.,debug,flink
Ignore JobManager gained leadership message for * because we are already connected to it.,debug,flink
Establish JobManager connection for job *.,info,flink
Close JobManager connection for job *.,debug,flink
Close JobManager connection for job *.,info,flink
Could not mark the slot * inactive.,debug,flink
Could not properly disassociate from JobManager *.,warn,flink
Could not fail task *.,error,flink
Cannot find task to fail for execution *.,debug,flink
Could not properly fail task.,error,flink
Un-registering task and sending final execution state * to JobManager for task * *.,info,flink
Cannot find task with ID * to unregister.,error,flink
Free slot with allocation id * because: *,debug,flink
Could not free slot for allocation id *.,debug,flink
Could not remove job * from JobLeaderService.,info,flink
Received an invalid timeout for allocation id * with ticket *.,debug,flink
Ignoring allocated slot report from job * because there is no active leader.,debug,flink
Fatal error occurred in TaskExecutor *.,error,flink
JobManager for job * with leader id * lost leadership.,info,flink
$$$Empty Message$$$,error,flink
The heartbeat of JobManager with id * timed out.,info,flink
The heartbeat of ResourceManager with id * timed out.,info,flink
Received heartbeat timeout for outdated ResourceManager id *. Ignoring the timeout.,debug,flink
Starting the kvState service and its components.,info,flink
Failed to start the Queryable State Data Server.,error,flink
Failed to start the Queryable State Client Proxy.,error,flink
Shutting down the kvState service and its components.,info,flink
Shutting down Queryable State Client Proxy.,debug,flink
Cannot shut down Queryable State Client Proxy.,warn,flink
Shutting down Queryable State Data Server.,debug,flink
Cannot shut down Queryable State Data Server.,warn,flink
Fatal error occurred while executing the TaskManager. Shutting it down...,error,flink
Maximum number of open file descriptors is *.,info,flink
Cannot determine the maximum number of open file descriptors,info,flink
TaskManager initialization failed.,error,flink
Could not parse the command line options.,error,flink
Starting TaskManager with ResourceID: *,info,flink
Using configured hostname/address for TaskManager: *.,info,flink
TaskManager will use hostname/address '*' (*) for communication.,info,flink
Activate slot *.,info,flink
Free slot *.,debug,flink
Free slot *.,info,flink
The scheduled executor service did not properly terminate. Shutting it down now.,debug,flink
Could not properly await the termination of the scheduled executor service.,debug,flink
Starting periodic memory usage logger,info,flink
Failed to initialize direct buffer pool bean.,warn,flink
$$$Empty Message$$$,info,flink
$$$Empty Message$$$,info,flink
$$$Empty Message$$$,info,flink
$$$Empty Message$$$,info,flink
Memory logger terminated with exception,error,flink
Ignoring old (but still present) network buffer configuration via *.,info,flink
Creating FileSystem stream leak safety net for task *,info,flink
Loading JAR files for task *.,info,flink
Registering task at network: *.,info,flink
Obtaining local cache file for '*'.,info,flink
Encountered fatal error * - terminating the JVM,error,flink
Unexpected state in task * (*) during an exception: *.,error,flink
$$$Empty Message$$$,error,flink
Freeing task resources for * (*).,info,flink
Ensuring all FileSystem streams are closed for task *,info,flink
$$$Empty Message$$$,error,flink
Error during metrics de-registration of task * (*).,error,flink
Release task * network resources (state: *).,debug,flink
Failed to release result partition for task *.,error,flink
Failed to release input gate for task *.,error,flink
Getting user code class loader for task * at library cache manager took * milliseconds,debug,flink
* (*) switched from * to *.,info,flink
* (*) switched from * to *.,info,flink
Attempting to cancel task * (*).,info,flink
Attempting to fail task externally * (*).,info,flink
Task * is already in state *,info,flink
Triggering cancellation of task code * (*).,info,flink
Creating FileSystem stream leak safety net for *,debug,flink
Encountered error while triggering checkpoint * for * (*) while being not in state running.,debug,flink
Declining checkpoint request for non-running task * (*).,debug,flink
Ignoring checkpoint commit notification for non-running task *.,debug,flink
Invoking async call * on task *,debug,flink
Error while canceling task *.,error,flink
Error while canceling the task *.,error,flink
Error in the task canceler for task *.,error,flink
"Task '*' did not react to cancelling signal for * seconds, but is stuck in method:  *",warn,flink
Error in the task canceler for task *.,error,flink
$$$Empty Message$$$,error,flink
Error in Task Cancellation Watch Dog,error,flink
Unable to determine the canonical hostname. Input split assignment (such as for HDFS files) may be non-local when the canonical hostname is missing.,warn,flink
getCanonicalHostName() Exception:,debug,flink
"No hostname could be resolved for the IP address *, using IP address as host name. Local input split assignment (such as for HDFS files) may be impacted.",warn,flink
Access to physical memory size: com.sun.management.OperatingSystemMXBean incompatibly changed.,warn,flink
Cannot determine size of physical memory for unknown operating system,error,flink
Unrecognized OS: ,error,flink
Cannot determine the size of the physical memory for Linux host (using '/proc/meminfo'). Unexpected format.,error,flink
Cannot determine the size of the physical memory for Linux host (using '/proc/meminfo'). Unexpected format.,error,flink
Cannot determine the size of the physical memory for Linux host (using '/proc/meminfo') ,error,flink
Cannot determine physical memory of machine for MacOS host,error,flink
Cannot determine the size of the physical memory for FreeBSD host (using 'sysctl hw.physmem').,error,flink
Cannot determine the size of the physical memory for FreeBSD host (using 'sysctl hw.physmem'),error,flink
Cannot determine the size of the physical memory for Windows host (using 'wmic memorychip'),error,flink
$$$Empty Message$$$,warn,flink
Enforcing creator for ZK connections,info,flink
Enforcing default ACL for ZK connections,info,flink
Using '*' as Zookeeper namespace.,info,flink
Initialized * in '*'.,info,flink
$$$Empty Message$$$,error,flink
Could not stop the leader retrieval service.,warn,flink
Trying to select the network interface and address to use by connecting to the leading JobManager.,info,flink
TaskManager will try to connect for  |  before falling back to heuristics,info,flink
Could not stop the leader retrieval service.,warn,flink
Actor system shut down timed out.,error,flink
Failure during actor system shut down.,error,flink
Shutdown completed. Stopping JVM.,info,flink
Cannot determine code revision: Unable to read version property file.,debug,flink
Cannot determine code revision: Unable to read version property file.,info,flink
Cannot determine user/group information using Hadoop utils. Hadoop classes not loaded or compatible,debug,flink
Error while accessing user/group information via Hadoop utils.,warn,flink
Unexpected error when accessing file handle limit,warn,flink
--------------------------------------------------------------------------------,info,flink
" Starting  |  (Version:  | ,  | Rev: | ,  | Date: | )",info,flink
 OS current user:  | user.name,info,flink
 Current Hadoop/Kerberos user: ,info,flink
 JVM: ,info,flink
 Maximum heap size:  |  MiBytes,info,flink
 JAVA_HOME:  | (not set),info,flink
 Hadoop version: ,info,flink
 No Hadoop Dependency available,info,flink
 JVM Options: (none),info,flink
 JVM Options:,info,flink
    ,info,flink
 Program Arguments: (none),info,flink
 Program Arguments:,info,flink
    ,info,flink
 Classpath:  | java.class.path,info,flink
--------------------------------------------------------------------------------,info,flink
Cannot invoke VersionInfo.getVersion reflectively.,error,flink
FATAL: Thread ' | ' produced an uncaught exception. Stopping the process...,error,flink
RECEIVED SIGNAL *: SIG*. Shutting down as requested.,info,flink
Error while registering signal handler,info,flink
$$$Empty Message$$$,info,flink
Log file environment variable '*' is not set.log.file,warn,flink
JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable '*' or configuration key '*'.log.file,warn,flink
Determined location of main cluster component log file: *,info,flink
Determined location of main cluster component stdout file: *,info,flink
Could not load web content handler.,warn,flink
Cannot load log file handler.,info,flink
Web frontend listening at *.,info,flink
* was granted leadership with leaderSessionID=*,info,flink
* lost leadership,info,flink
"Could not create the HistoryServer's URL from protocol: *, hostname: * and port: *.",debug,flink
Not hostname has been specified for the HistoryServer. This indicates that it has not been started.,debug,flink
Could not obtain the current leader.,warn,flink
Error while retrieving the leader gateway. Retrying to connect to *.,warn,flink
Error while retrieving the leader gateway. Retrying to connect to *.,warn,flink
Received error from LeaderRetrievalService.,error,flink
Could not get all ZooKeeper children. Node * contained corrupted data. Ignoring this node.,warn,flink
Could not retrieve the state handle from node *.,warn,flink
Could not delete znode * because it is still locked.,debug,flink
Removing * from ZooKeeper,info,flink
Error running ZooKeeper quorum peer: ,error,flink
Configuration: ,info,flink
Running distributed ZooKeeper quorum peer (total peers: *).,info,flink
Running standalone ZooKeeper quorum peer.,info,flink
No 'clientPort' configured. Set to '*'.2181,warn,flink
No 'initLimit' configured. Set to '*'.10,warn,flink
No 'syncLimit' configured. Set to '*'.5,warn,flink
No 'dataDir' configured. Set to '*'.,warn,flink
Set peer and leader port of '*': '*' => '*'.,info,flink
Set peer port of '*': '*' => '*'.,info,flink
Writing * to myid file in 'dataDir'.,info,flink
Delaying retry of job execution forever,info,flink
Could not properly shutdown RestServerEndpoint.,warn,flink
Exception while shutting down blob server.,error,flink
Could not properly terminate the *.,warn,flink
Jar storage directory * has been deleted externally. Previously uploaded jars are no longer available.,warn,flink
Using directory * for web frontend JAR file uploads.,info,flink
Created directory * for web frontend JAR file uploads.,info,flink
Jar upload directory * cannot be created or is not writable.,warn,flink
Unknown message received: *,debug,flink
Unhandled exception: *,debug,flink
"Jar upload dir * does not exist, or had been deleted externally. Previously uploaded jars are no longer available.",warn,flink
Loading configuration from *,info,flink
Failed to run HistoryServer.,error,flink
Enabling SSL for the history server.,info,flink
Failed to create Path or FileSystem for directory '*'. Directory will not be monitored.,warn,flink
Failure while running HistoryServer.,error,flink
Starting history server.,info,flink
Using directory * as local cache.,info,flink
Stopping history server.,info,flink
Error while shutting down WebFrontendBootstrap.,warn,flink
Removing web dashboard root cache directory *,info,flink
Error while deleting web root directory *,warn,flink
Stopped history server.,info,flink
Failed to write config file.,error,flink
Monitoring directory * for archived jobs.,info,flink
Failed to access job archive location for path *.,error,flink
Archive directory * contained file with unexpected name *. Ignoring file.,debug,flink
Failure while fetching/processing job archive for job *.,error,flink
Could not delete file from overview directory.,debug,flink
Could not clean up job directory.,debug,flink
Critical failure while fetching/processing job archives.,error,flink
Failed to update job overview.,error,flink
Loading missing file from classloader: *,debug,flink
error while responding,error,flink
Unable to load requested file * from classloader,debug,flink
Responding 'NOT MODIFIED' for file ',debug,flink
Responding with file ',debug,flink
Failed to serve file.,error,flink
Caught exception,error,flink
Web frontend listening at *:*,info,flink
Cannot access local server port,error,flink
Creating S3 FileSystem without configuring the factory. All behavior will be default.,warn,flink
Creating S3 file system backed by *,debug,flink
Loading Hadoop configuration for *,debug,flink
Committing * with MPU ID *,info,flink
Successfully committed * with MPU ID *,debug,flink
Successfully committed * with MPU ID * after * retries.,debug,flink
No data to commit for file: *,debug,flink
Trying to commit after recovery * with MPU ID *,info,flink
Failed to commit after recovery * with MPU ID *. Checking if file was committed before...,info,flink
Exception when committing:,trace,flink
$$$Empty Message$$$,warn,flink
Object * not existing after failed recovery commit with MPU ID *,warn,flink
No data to commit for file: *,debug,flink
Using scheme * for s3a file system backing the S3 File System,debug,flink
Using session environment file: *,info,flink
SQL Client must stop.,error,flink
SQL Client must stop. Unexpected exception. This is a bug. Please consider filing an issue.,error,flink
$$$Empty Message$$$,warn,flink
Could not complete statement at  | :,debug,flink
Property '*.*' not specified. Using default value: *deployment,info,flink
Property '*.*' not specified. Using default value: *execution,info,flink
Using default environment file: *,info,flink
Could not complete statement at  | :,debug,flink
Cancelling job * and result retrieval.,info,flink
Using the following dependencies: *,debug,flink
Submitting job * for query *`,info,flink
Submitting job * with the following environment:  *,debug,flink
Savepoint written to ,info,flink
Using predefined options: *.,info,flink
$$$Empty Message$$$,error,flink
Using application-defined options factory: *.,info,flink
Using default options factory: *.,info,flink
Using configured options factory: *.,info,flink
Attempting to load RocksDB native library and store it under '*',info,flink
Attempting to create RocksDB native library folder *,debug,flink
Successfully loaded RocksDB native library,info,flink
RocksDB JNI library loading attempt * failed,debug,flink
Failed to reset 'initialized' flag in RocksDB native code loader,debug,flink
Failed to instance base path for RocksDB: ,warn,flink
$$$Empty Message$$$,error,flink
Error while cleaning the state.,warn,flink
Deleting existing instance base directory *.,info,flink
Could not delete instance base path for RocksDB: ,warn,flink
"Performing state migration for state * because the state serializer's schema, i.e. serialization format, has changed.",info,flink
Failed to read native metric %s from RocksDB,warn,flink
Restoring keyed backend uid in operator * from incremental snapshot to *.,debug,flink
$$$Empty Message$$$,error,flink
Failed to clean up path ,warn,flink
$$$Empty Message$$$,error,flink
Local RocksDB checkpoint goes to backup path *.,trace,flink
Taking incremental snapshot for checkpoint *. Snapshot is based on last completed checkpoint * assuming the following (shared) files as base: *.,trace,flink
Running cleanup for local RocksDB backup directory *.,trace,flink
Could not properly cleanup local RocksDB backup directory.,debug,flink
Could not properly cleanup local RocksDB backup directory.,warn,flink
Could not properly discard states.,warn,flink
Could not properly discard local state.,warn,flink
Asynchronous RocksDB snapshot performed on empty keyed state at *. Returning null.,debug,flink
RocksDB filter native code log: ,debug,flink
Cannot configure RocksDB TTL compaction filter for state <*>: feature is disabled for the state backend.,warn,flink
Close previous DBOptions's instance failed.,error,flink
Close previous ColumnOptions's instance failed.,error,flink
Running job on local embedded Flink mini cluster,info,flink
"Since tolerableCheckpointFailureNumber has been configured as *, deprecated #setFailOnCheckpointingErrors(boolean) method would not take any effect and please use #setTolerableCheckpointFailureNumber(int) method to determine your expected behaviour when checkpoint errors on task side.",warn,flink
Running remotely at *:*,info,flink
Could not properly shut down the cluster client.,warn,flink
"Job was executed in detached mode, the results will be available on completion.",warn,flink
"* - checkpoint * complete, committing transaction * from checkpoint *",info,flink
* - committed checkpoint transaction *,debug,flink
"* - checkpoint * triggered, flushing transaction '*'",debug,flink
* - stored pending transactions *,debug,flink
* - started new transaction '*',debug,flink
* - restoring state,info,flink
* committed recovered transaction *,info,flink
* aborted recovered transaction *,info,flink
* - no state to restore,info,flink
* - started new transaction '*',debug,flink
Error while committing transaction *. Transaction has been open for longer than the transaction timeout (*).Commit will not be attempted again. Data loss might have occurred.,error,flink
Transaction * has been open for * ms. This is close to or even exceeding the transaction timeout of * ms.,warn,flink
Cleanup on error failed.,error,flink
Failed to send message ' | ' to socket server at  | : | . Trying to reconnect...,error,flink
Could not close output stream from failed write attempt,error,flink
Could not close socket from failed write attempt,error,flink
Re-connect to socket server and send message failed. Retry time(s): ,error,flink
Subtask * merging buckets for bucket id=*,debug,flink
Subtask * closing in-progress part file for bucket id=* due to element *.,debug,flink
"Subtask * opening new part file ""*"" for bucket id=*.",debug,flink
Subtask * closing in-progress part file for bucket id=* on checkpoint.,debug,flink
Subtask * successfully deleted incomplete part for bucket id=*.,debug,flink
"Subtask * closing in-progress part file for bucket id=* due to processing time rolling policy (in-progress file created @ *, last updated @ * and current time is *).",debug,flink
Unable to create filesystem for path: *,error,flink
Subtask * initializing its state (max part counter=*).,info,flink
Subtask * restoring: *,debug,flink
Subtask * received completion notification for checkpoint with id=*.,info,flink
Subtask * checkpointing for checkpoint with id=* (max part counter=*).,info,flink
Subtask * checkpointing: *,debug,flink
Restoring state for the *.,info,flink
* retrieved a global mod time of *.,debug,flink
No state to restore for the *.,info,flink
Opened * (taskIdx= *) for path: *,debug,flink
Forwarding split: ,info,flink
Path does not exist: *,warn,flink
"Ignoring  | , with mod time=  |  and global mod time= ",debug,flink
Closed File Monitoring Source for path:  | .,debug,flink
* checkpointed *.,debug,flink
Restoring state for the *.,info,flink
No state to restore for the *.,info,flink
"Checkpointing: Messages: *, checkpoint id: *, timestamp: *",debug,flink
Committing Messages externally for checkpoint *,debug,flink
Committing Messages with following IDs *,trace,flink
Acknowledging ids for checkpoint *,debug,flink
Connecting to server socket ,info,flink
Lost connection to server socket. Retrying in  |  msecs...,warn,flink
"File processed: *, *, *",info,flink
Path does not exist: *,warn,flink
Restoring state for the * (taskIdx=*).,info,flink
* (taskIdx=*) restored *.,debug,flink
No state to restore for the * (taskIdx=*).,info,flink
The reader is stuck in method:  *,warn,flink
Reading split: ,debug,flink
"Reader terminated, and exiting...",debug,flink
* (taskIdx=*) checkpointed * splits: *.,debug,flink
Timestamp monotony violated: * < *,warn,flink
Vertex: *,debug,flink
CO-TASK: *,debug,flink
Outputselector set for *,debug,flink
"Generated hash ' | ' for node  | ' | ' {id:  | ,  | parallelism:  | ,  | user function:  | }",debug,flink
Transforming ,debug,flink
Parallelism set: * for *,debug,flink
CONNECTED: * - * -> *,debug,flink
Error while emitting latency marker.,warn,flink
Creating * with empty state.,debug,flink
Creating * and restoring with state * from alternative (*/*).,trace,flink
Creating * and restoring with state from alternative (*/*).,debug,flink
"Exception while restoring * from alternative (*/*), will retry while more alternatives are available.",warn,flink
An error occurred while instantiating task metrics.,warn,flink
* has been set to a value equal or below 0: *. Using default.,warn,flink
Configured value * option for * is invalid. Defaulting to *.,warn,flink
An error occurred while instantiating latency metrics.,warn,flink
$$$Empty Message$$$,info,flink
Could not close raw keyed operator state stream for *. This might have prevented deleting some state data.,warn,flink
Errors occurred while closing the AsyncWaitOperator.,warn,flink
Wait for next completed async stream element result.,debug,flink
"Emitter thread got interrupted, shutting down.",debug,flink
Output async watermark.,debug,flink
Output async stream element collection result.,debug,flink
Peeked head element from ordered stream element queue with filling degree (*/*).,debug,flink
Polled head element from ordered stream element queue. New filling degree (*/*).,debug,flink
Put element into ordered stream element queue. New filling degree (*/*).,debug,flink
Failed to put element into ordered stream element queue because it was full (*/*).,debug,flink
Signal ordered stream element queue has completed head element.,debug,flink
Put element into unordered stream element queue. New filling degree (*/*).,debug,flink
Failed to put element into unordered stream element queue because it was full (*/*).,debug,flink
Peeked head element from unordered stream element queue with filling degree (*/*).,debug,flink
Polled element from unordered stream element queue. New filling degree (*/*).,debug,flink
Signal unordered stream element queue has completed entries.,debug,flink
onEventTime @ *,trace,flink
Removing from left buffer @ *,trace,flink
Removing from right buffer @ *,trace,flink
Received barrier for checkpoint * from channel *,debug,flink
Received all barriers for checkpoint *,debug,flink
Received cancellation barrier for checkpoint *,debug,flink
"*: End of stream alignment, feeding buffered data back.",debug,flink
*: Received checkpoint barrier for checkpoint * before completing current checkpoint *. Skipping current checkpoint.,warn,flink
"*: Received all barriers, triggering checkpoint * at *.",debug,flink
*: Starting stream alignment for checkpoint *.,debug,flink
*: Received barrier from channel *.,debug,flink
"*: Checkpoint * canceled, aborting alignment.",debug,flink
*: Received cancellation barrier for checkpoint * before completing current checkpoint *. Skipping current checkpoint.,warn,flink
"*: Checkpoint * canceled, skipping alignment.",debug,flink
*: Checkpoint skipped via buffered data:Pushing back current alignment buffers and feeding back new alignment data first.,debug,flink
*: Size of buffered data: * bytes,debug,flink
*: Finished feeding back buffered data.,debug,flink
Restoring state for the GenericWriteAheadSink (taskIdx=*).,info,flink
GenericWriteAheadSink idx * restored *.,debug,flink
No state to restore for the GenericWriteAheadSink (taskIdx=*).,info,flink
* (taskIdx= *) checkpointed *.,debug,flink
Could not commit checkpoint.,error,flink
Merging * into *,debug,flink
Iteration head * added feedback queue under *,info,flink
Iteration head * removed feedback queue under *,info,flink
An exception occurred during the metrics setup.,warn,flink
An exception occurred during the metrics setup.,warn,flink
Initializing *.,debug,flink
Invoking *,debug,flink
Finished task *,debug,flink
Closed operators for task *,debug,flink
Could not shut down async checkpoint threads,error,flink
Error during cleanup of stream task,error,flink
Error during disposal of stream operator.,error,flink
Timer service is shutting down.,info,flink
Could not perform checkpoint * for operator * while the invokable was not in state running.,debug,flink
Operator * was cancelled while performing checkpoint *.,info,flink
Aborting checkpoint via cancel-barrier * for task *,debug,flink
Starting checkpoint (*) * on task *,debug,flink
Notification of complete checkpoint for task *,debug,flink
Ignoring notification of complete checkpoint for not-running task *,debug,flink
Timer service shutdown exceeded time limit of * ms while waiting for pending timers. Will continue with shutdown procedure.,warn,flink
Could not shut down timer service,error,flink
* - asynchronous part of checkpoint * could not be completed because it was closed before.,debug,flink
* - finished asynchronous part of checkpoint *. Asynchronous duration: * ms,debug,flink
* - reported the following states in snapshot for checkpoint *: *.,trace,flink
Caught followup exception from a failed checkpoint thread. This can be ignored.,trace,flink
Could not properly clean up the async checkpoint runnable.,warn,flink
Cleanup AsyncCheckpointRunnable for checkpoint * of *.,debug,flink
"* - asynchronous checkpointing operation for checkpoint * has already been completed. Thus, the state handles are not cleaned up.",debug,flink
Finished synchronous checkpoints for checkpoint * on task *,debug,flink
"* - finished synchronous part of checkpoint *. Alignment duration: * ms, snapshot duration * ms",debug,flink
Could not properly cancel an operator snapshot result.,warn,flink
"* - did NOT finish synchronous part of checkpoint *. Alignment duration: * ms, snapshot duration * ms",debug,flink
Using partitioner * for output * of task *,debug,flink
Iteration tail * trying to acquire feedback queue under *,info,flink
Iteration tail * acquired feedback queue *,info,flink
Intercepted attempt to interrupt timer service shutdown.,trace,flink
Closing the mailbox dropped letters *.,debug,flink
Action context could not submit priority letter to mailbox.,debug,flink
readRecords(lastExpectedRecord = *),debug,flink
Creating swift file system (backed by a Hadoop native swift file system),debug,flink
Loading Hadoop configuration for swift native file system,debug,flink
Adding Flink config entry for * as *=* to Hadoop config for Swift native File System,debug,flink
The factory has not been configured prior to loading the Swift native file system. Using Hadoop configuration from the classpath.,warn,flink
Using scheme * for swift file system backing the Swift Native File System,debug,flink
Handling deprecation for all properties in config...,debug,flink
Handling deprecation for ,debug,flink
Unexpected SecurityException in Configuration,warn,flink
$$$Empty Message$$$,info,flink
No unit for  | ( | ) assuming ,warn,flink
Regular expression ' | ' for property ' | ' not valid. Using default,warn,flink
Could not make  |  in local directories from ,warn,flink
[ | ]=,warn,flink
 not found,info,flink
found resource  |  at ,info,flink
 not found,info,flink
found resource  |  at ,info,flink
parsing URL ,debug,flink
parsing input stream ,debug,flink
Failed to set setXIncludeAware(true) for parser  | :,error,flink
parsing File ,debug,flink
bad conf file: top-level element not <configuration>,fatal,flink
bad conf file: element not <property>,warn,flink
error parsing conf ,fatal,flink
error parsing conf ,fatal,flink
error parsing conf ,fatal,flink
:an attempt to override final parameter:  | ;  Ignoring.,warn,flink
Set the current default catalog as [*] and the current default database as [*].,info,flink
Set the current default database as [*] in the current default catalog [*].,info,flink
Could not load service provider for table factories.,error,flink
After unconditional rewrite: *,trace,flink
After validation: *,trace,flink
Plan after removing Correlator,debug,flink
* are not unique keys for *,debug,flink
* are not unique keys for *,debug,flink
There are no unique keys for *,debug,flink
Plan after removing Correlator,debug,flink
* are not unique keys for *,debug,flink
* are not unique keys for *,debug,flink
There are no unique keys for *,debug,flink
"Exception in regexpReplace('%s', '%s', '%s')",error,flink
"Exception in regexpExtract('%s', '%s', '%d')",error,flink
Exception when parse key-value,error,flink
"Unsupported encoding:  | , fallback to system charset",warn,flink
Parse URL error: ,error,flink
"len of 'substring(str, start, len)' must be >= 0 and Int type, but len = {0}",error,flink
"len or start of 'substring(str, start, len)' must be Int type, but len = {0}, start = {0}",error,flink
Exception when compile and match regex: |  on: ,error,flink
Exception when formatting: ' | ' from: ' | ' to: ' | ',error,flink
Exception when parsing datetime string '%s' in format '%s',error,flink
Exception when formatting.,error,flink
Compiling: *    Code: *,debug,flink
The rehash take * ms for * segments,info,flink
Begin to process spilled partition [%d],info,flink
Recursive hash join: partition number is ,info,flink
Hash join: Partition(%d)  | build side block [%d] more than probe side block [%d],info,flink
Build in memory hash table from spilled partition [%d],info,flink
Build hybrid hash table from spilled partition [%d] with recursion level [%d],info,flink
Error during partition cleanup.,error,flink
"Grace hash join: Ran out memory, choosing partition  | [%d] to spill, %d memory segments being freed",info,flink
Out of memory,error,flink
"Initialize hash table with %d memory segments, each size [%d], the reserved memory %d |  MB, the max memory %d MB, per allocate * segments from floating memory pool.",info,flink
* allocate * floating segments successfully!,info,flink
"BinaryHashMap can't allocate * floating pages, and now used * pages",warn,flink
Could not close and delete the temp file for the current spilled partition probe side.,warn,flink
The rehash take * ms for * segments,info,flink
LongHybridHashTable: Use dense mode!,info,flink
Begin to process spilled partition [%d],info,flink
Recursive hash join: partition number is ,info,flink
Hash join: Partition(%d)  | build side block [%d] more than probe side block [%d],info,flink
Build in memory hash table from spilled partition [%d],info,flink
Build hybrid hash table from spilled partition [%d] with recursion level [%d],info,flink
"Grace hash join: Ran out memory, choosing partition  | [%d] to spill, %d memory segments being freed",info,flink
Error during partition cleanup.,error,flink
BytesHashMap with hashSetMode = true.,info,flink
"BytesHashMap with initial memory segments *, * in bytes, init allocating * for bucket area.",info,flink
We can't handle more than Integer.MAX_VALUE buckets (eg. because hash functions return int),warn,flink
"BytesHashMap can't allocate * pages, and now used * pages",warn,flink
The rehash take * ms for * segments,info,flink
"reset BytesHashMap with record memory segments *, * in bytes, init allocating * for bucket area.",info,flink
BundleOperator's trigger info: ,info,flink
Errors occurred while closing the BundleOperator.,warn,flink
Finish build phase.,info,flink
Finish probe phase.,info,flink
Finish rebuild phase.,info,flink
Instantiating JoinFunction: *    Code: *,debug,flink
The state is cleared because of state ttl. This will result in incorrect result. You can increase the state ttl to avoid this.,warn,flink
The state is cleared because of state ttl. This will result in incorrect result. You can increase the state ttl to avoid this.,warn,flink
The state is cleared because of state ttl. This will result in incorrect result. You can increase the state ttl to avoid this.,warn,flink
The state is cleared because of state ttl. This will result in incorrect result. You can increase the state ttl to avoid this.,warn,flink
Top* operator is using LRU caches key-size: *,info,flink
The state is cleared because of state ttl. This will result in incorrect result. You can increase the state ttl to avoid this.,warn,flink
The state is cleared because of state ttl. This will result in incorrect result. You can increase the state ttl to avoid this.,warn,flink
The state is cleared because of state ttl. This will result in incorrect result. You can increase the state ttl to avoid this.,warn,flink
Top* operator is using LRU caches key-size: *,info,flink
"Failed to build sorted map from state, this may result in wrong result. The sort key is *, partition key is *, treeMap is *. The expected inner rank is *, but current size is *.",warn,flink
"Failed to find the sortKey: *, rowkey: * in the buffer. This should never happen",error,flink
Fail to synchronize state!,error,flink
RANK() on streaming table is not supported currently,error,flink
DENSE_RANK() on streaming table is not supported currently,error,flink
Streaming tables do not support *,error,flink
"Rank end is not specified. Currently rank only support TopN, which means the rank end must be specified.",error,flink
"variable rank index column must be long, short or int type, while input type is *",error,flink
Opening StreamSortOperator,info,flink
Closing StreamSortOperator,info,flink
Can't allocate * pages from fixed memory pool.,error,flink
"BinaryExternalSorter with initial memory segments *, maxNumFileHandles(*), compressionEnable(*), compressionCodecFactory(*), compressionBlockSize(*).",info,flink
Error shutting down sorter thread: ,error,flink
Error shutting down spilling thread: ,error,flink
Error shutting down merging thread: ,error,flink
Closing of sort/merger was interrupted. The reading/sorting/spilling/merging threads may still be working.,debug,flink
error.,info,flink
error.,info,flink
Retrieved empty read buffer  | .,debug,flink
Emitting full buffer:  | .,debug,flink
Sending done.,debug,flink
Sorting thread was interrupted (without being shut down) while grabbing a buffer. Retrying to grab buffer...,error,flink
Sorting buffer  | .,debug,flink
Sorted buffer  | .,debug,flink
Sorting thread done.,debug,flink
Spilling thread was interrupted (without being shut down) while grabbing a buffer. Retrying to grab buffer...,error,flink
here spill the *th sort buffer data with * bytes and * compressed bytes,info,flink
Spilling thread was interrupted (without being shut down) while collecting empty buffers to release them. Retrying to collect buffers...,error,flink
Merging thread was interrupted (without being shut down) while grabbing a channel with meta. Retrying...,error,flink
Opening ProcTimeSortOperator,info,flink
Performing merge of  |  sorted streams.,debug,flink
Opening SortOperator,info,flink
Closing SortOperator,info,flink
here spill the *th kv external buffer data with * bytes and * compressed bytes,info,flink
Opening RowTimeSortOperator,info,flink
Compiling GenericInputFormat: $name    Code: $code,debug,flink
Instantiating GenericInputFormat.,debug,flink
Merging * into *,debug,flink
It is dangerous to copy a non-HashMap to a HashMap.,debug,flink
"jsonString is null or empty, or path is null or empty, or path is not start with '$'!  | jsonString:  | , path: ",error,flink
path String illegal! path String: ,error,flink
"Exception when read json value with type : | , and json string: ",error,flink
"path look up fail at:  | , pathString:  | json: ",error,flink
Exception when MAPPER.writeValueAsString :,error,flink
"path look up fail at:  | , pathString:  | json: ",error,flink
"jsonString is null or empty, or path is null or empty!  | jsonString: ",error,flink
"Exception when read json value with type : | , and json string: ",error,flink
th path String is null or empty!  | pathString: ,error,flink
th path String illegal! path String: ,error,flink
"Exception when read json value with type : | , and json string: ",error,flink
"th path look up fail at:  | , pathString:  | json: ",error,flink
Exception when MAPPER.writeValueAsString :,error,flink
"th path look up fail at:  | , pathString:  | json: ",error,flink
here spill the reset buffer data with * bytes,info,flink
Attempt to open proxy channel from [*] to [*:*] in state [blocked = *],debug,flink
Closing communication channel because of an exception,error,flink
Closing communication channel because of an exception,error,flink
Proxying [*:*] to [*:*],info,flink
$$$Empty Message$$$,info,flink
All environment variables: *,debug,flink
Current working Directory: *,info,flink
YARN TaskManager initialization failed.,error,flink
Current working/local Directory: *,info,flink
TM: remote keytab path obtained *,info,flink
TM: remote keytab principal obtained *,info,flink
keytab path: *,info,flink
YARN daemon is running as: * Yarn client user obtainer: *,info,flink
The heartbeat interval of the Flink Application master (*) is greater than YARN's expiry interval (*). The application is likely to be killed by YARN.,warn,flink
Recovered * containers from previous attempts (*).,info,flink
Unregister application from the YARN Resource Manager with final status *.,info,flink
Could not unregister the application master.,error,flink
Stopping container *.,info,flink
Error while calling YARN Node Manager to stop container,warn,flink
Removing container request *. Pending container requests *.,info,flink
Requesting new TaskExecutor container with resources *. Number pending requests *.,info,flink
"TaskExecutor * will be started with container size * MB, JVM heap size * MB, JVM direct memory limit * MB",debug,flink
TaskManager configuration: *,debug,flink
Copying from * to *,debug,flink
Got FileNotFoundException while fetching uploaded remote resources at retry num *,debug,flink
Sleeping for *ms100,debug,flink
Failed to sleep for *ms at retry num * while fetching uploaded remote resources100,warn,flink
Got modification time * from remote path *,debug,flink
"Failed to fetch remote modification time from *, using local timestamp *",debug,flink
Deleting yarn application files under * was unsuccessful.,error,flink
Could not properly delete yarn application files directory *.,error,flink
"No yarn application files directory set. Therefore, cannot clean up the data.",debug,flink
Adding user token  |  with ,info,flink
Wrote tokens. Credentials buffer length: ,debug,flink
Attempting to obtain Kerberos security token for HBase,info,flink
HBase security setting: *,info,flink
HBase has not been configured to use Kerberos.,info,flink
Obtaining Kerberos security token for HBase,info,flink
No Kerberos security token for HBase available,error,flink
Added HBase Kerberos security token to credentials.,info,flink
"HBase is not available (not packaged with this application): * : ""*"".",info,flink
TM:remote keytab path obtained *,debug,flink
TM:remote keytab principal obtained *,debug,flink
TM:remote yarn conf path obtained *,debug,flink
TM:remote krb5 path obtained *,debug,flink
Adding keytab * to the AM container local resource bucket,info,flink
TM:Adding remoteYarnConfPath * to the container local resource bucket,info,flink
TM:Adding remoteKrb5Path * to the container local resource bucket,info,flink
Writing TaskManager configuration to *,debug,flink
Prepared local resource for modified yaml: *,debug,flink
Could not delete temporary configuration file ,info,flink
Creating container launch context for TaskManagers,info,flink
Starting TaskManagers with command: ,debug,flink
Starting TaskManagers,info,flink
Adding security tokens to TaskExecutor's container launch context.,debug,flink
Failed to add Hadoop's security tokens.,error,flink
Could not set security tokens because Hadoop's token file location is unknown.,info,flink
Neither the HADOOP_CONF_DIR nor the YARN_CONF_DIR environment variable is set. The Flink YARN Client needs one of these to be set to properly load the Hadoop configuration for accessing YARN.,warn,flink
Neither the HADOOP_CONF_DIR nor the YARN_CONF_DIR environment variable is set.The Flink YARN Client needs one of these to be set to properly load the Hadoop configuration for accessing YARN.,warn,flink
The application * doesn't run anymore. It has previously completed with final status: *,error,flink
Found Web Interface *:* of application '*'.,info,flink
Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials,error,flink
Cluster specification: *,info,flink
"The JobManager or TaskManager memory is below the smallest possible YARN Container size.  | The value of 'yarn.scheduler.minimum-allocation-mb' is ' | '. Please increase the memory size. | YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances  | you requested will start.",warn,flink
This YARN session requires  | MB of memory in the cluster.  | There are currently only  | MB available.,warn,flink
The requested amount of memory for the TaskManagers ( | MB) is more than  | the largest possible YARN container: ,warn,flink
The requested amount of memory for the JobManager ( | MB) is more than  | the largest possible YARN container: ,warn,flink
Unable to find a NodeManager that can fit the JobManager/Application master.  | The JobManager requires  | MB. NodeManagers available: ,warn,flink
"There is not enough memory available in the YARN cluster.  | The TaskManager(s) require  | MB each.  | NodeManagers available:  | \n | After allocating the JobManager ( | MB) and ( | / | ) TaskManagers,  | the following NodeManagers are available: ",warn,flink
The specified queue ' | ' does not exist.  | Available queues: ,warn,flink
The YARN cluster does not have any queues configured,debug,flink
Error while getting queue information from YARN: ,warn,flink
Error details,debug,flink
The file system scheme is ' | '. This indicates that the  | specified Hadoop configuration path is wrong and the system is using the default Hadoop configuration values. | The Flink YARN client needs to store its files in a distributed file system,warn,flink
The configuration directory (' | ') contains both LOG4J and  | Logback configuration files. Please delete or rename one of them.,warn,flink
Add job graph to local resource fail,warn,flink
Adding Yarn configuration * to the AM container local resource bucket,info,flink
Adding KRB5 configuration * to the AM container local resource bucket,info,flink
Adding keytab * to the AM container local resource bucket,info,flink
Adding delegation token to the AM container..,info,flink
Submitting application master ,info,flink
Waiting for the cluster to be allocated,info,flink
Application State: *,debug,flink
YARN application has been deployed successfully.,info,flink
"Deploying cluster, current state ",info,flink
Deployment took more than 60 seconds. Please check if the requested resources are available in the YARN cluster,info,flink
"The Flink YARN client has been started in detached mode. In order to stop  | Flink on YARN, use the following command or a YARN web interface to stop  | it:\nyarn application -kill  | \nPlease also note that the  | temporary files of the YARN session in the home directory will not be removed.",info,flink
Killing YARN application,info,flink
Error while killing YARN application,debug,flink
* supports method *.setApplicationTags,debug,flink
* does not support method *.setApplicationTags,debug,flink
* supports method *.setAttemptFailuresValidityInterval,debug,flink
* does not support method *.setAttemptFailuresValidityInterval,debug,flink
* supports method *.setKeepContainersAcrossApplicationAttempts,debug,flink
* does not support method *.setKeepContainersAcrossApplicationAttempts,debug,flink
* supports method *.setNodeLabelExpression,debug,flink
* does not support method *.setNodeLabelExpression,debug,flink
Calling method * of *.,debug,flink
* does not support method *. Doing nothing.setApplicationTags,debug,flink
Calling method * of *.,debug,flink
* does not support method *. Doing nothing.setNodeLabelExpression,debug,flink
Calling method * of *.,debug,flink
* does not support method *. Doing nothing.setAttemptFailuresValidityInterval,debug,flink
Calling method * of *.,debug,flink
* does not support method *. Doing nothing.setKeepContainersAcrossApplicationAttempts,debug,flink
Cancelling deployment from Deployment Failure Hook,info,flink
Deleting files in *.,info,flink
Failed to delete Flink Jar and configuration files in HDFS,error,flink
Environment variable '*' not set and ship files have not been provided manually. Not shipping any library files.FLINK_LIB_DIR,warn,flink
The environment variable ' | ' is set to ' | ' but the directory doesn't exist.,warn,flink
Application Master start command: ,debug,flink
Cannot reconnect to previously allocated containers. This YARN version does not support 'getContainersFromPreviousAttempts()',info,flink
Error invoking 'getContainersFromPreviousAttempts()',error,flink
Found Yarn properties file under *.,info,flink
No path for the flink jar passed. Using the location of  |  to locate the jar,info,flink
Ship directory * is not a directory. Ignoring it.,warn,flink
The argument * is deprecated in will be ignored.,info,flink
Could not properly shutdown cluster client.,info,flink
Could not properly terminate the Flink cluster.,info,flink
"The Flink YARN client has been started in detached mode. In order to stop  | Flink on YARN, use the following command or a YARN web interface to stop it:\n | yarn application -kill ",info,flink
Could not properly close the yarn cluster descriptor.,info,flink
Could not properly close the Yarn application status monitor.,info,flink
Could not properly shutdown cluster client.,info,flink
Could not log the final application report.,info,flink
Application  |  finished with state  |  and final state  |  at ,info,flink
Application failed. Diagnostics ,warn,flink
"If log aggregation is activated in the Hadoop cluster, we recommend to retrieve  | the full application log using this command: | \tyarn logs -applicationId  | (It sometimes takes a few seconds until the logs are aggregated)",warn,flink
Deleted Yarn properties file at *,info,flink
Couldn't delete Yarn properties file at *,warn,flink
Exception while deleting the JobManager address file,warn,flink
$$$Empty Message$$$,info,flink
Exception while running the interactive command line interface.,warn,flink
Could not parse the command line arguments.,error,flink
Error while running the Flink Yarn session.,error,flink
Could not retrieve the Yarn application report for *.,info,flink
Yarn client is no longer in state STARTED. Stopping the Yarn application status monitor.,info,flink
Could not log YARN environment information.,warn,flink
YARN daemon is running as: * Yarn client user obtainer: *,info,flink
Could not log YARN environment information.,warn,flink
Flink YARN application will store recovery data at *,info,flink
Unable to parse the value as a map; reverting to string,debug,kafka
"Failed to deserialize value for header '*' on topic '*', so using byte array",warn,kafka
Error loading credentials file ,error,kafka
Hostname for node * changed from * to *.,info,kafka
Manually disconnected from *. Removed requests: *.,debug,kafka
No version information found when sending * with correlation id * to node *. Assuming version *.,trace,kafka
Version mismatch when attempting to send * with correlation id * to *,debug,kafka
Sending * * with correlation id * to node *,trace,kafka
Using older server API v* to send * * with correlation id * to node *,debug,kafka
Unexpected error during I/O,error,kafka
Uncaught error in request completion:,error,kafka
Attempting to close NetworkClient that has already been closed.,warn,kafka
Found least loaded node * connected with no in-flight requests,trace,kafka
Removing node * from least loaded node selection since it is neither ready for sending or connecting,trace,kafka
Found least loaded node * with * inflight requests,trace,kafka
Found least loaded connecting node *,trace,kafka
Found least loaded node * with no active connection,trace,kafka
Least loaded node selection failed to find an available node,trace,kafka
Connection to node * (*) failed authentication due to: *,error,kafka
"Connection to node * (*) terminated during authentication. This may happen due to any of the following reasons: (1) Authentication failed due to invalid credentials with brokers older than 1.0.0, (2) Firewall blocking Kafka TLS traffic (eg it may only allow HTTPS traffic), (3) Transient network issue.",warn,kafka
Connection to node * (*) could not be established. Broker may not be available.,warn,kafka
Cancelled request * * with correlation id * due to node * being disconnected,trace,kafka
Disconnecting from node * due to request timeout.,debug,kafka
Connection to node * is throttled for * ms until timestamp *,trace,kafka
"Completed receive from node * for * with correlation id *, received *",trace,kafka
Received error * from node * when making an ApiVersionsRequest with correlation id *. Disconnecting.,warn,kafka
Recorded API versions for node *: *,debug,kafka
Node * disconnected.,debug,kafka
Completed connection to node *. Fetching API versions.,debug,kafka
Completed connection to node *. Ready.,debug,kafka
Initiating API versions fetch from node *.,debug,kafka
Initiating connection to node * using address *,debug,kafka
Error connecting to node *,warn,kafka
Give up sending metadata request since no node is available,debug,kafka
Bootstrap broker * disconnected,warn,kafka
"* partitions have leader brokers without a matching listener, including *",warn,kafka
Error while fetching metadata with correlation id * : *,warn,kafka
Ignoring empty metadata response with correlation id *.,trace,kafka
Sending metadata request * to node *,debug,kafka
Initialize connection to node * for sending metadata request,debug,kafka
"Disabling exponential reconnect backoff because * is set, but * is not.reconnect.backoff.msreconnect.backoff.max.ms",debug,kafka
Couldn't resolve server * from * as DNS resolution of the canonical hostname [} failed for *bootstrap.servers,warn,kafka
Couldn't resolve server * from * as DNS resolution failed for *bootstrap.servers,warn,kafka
An error occurred in broker-to-broker communication.,debug,kafka
Built full fetch * for node * with *.,debug,kafka
"Built incremental fetch * for node *. Added *, altered *, removed * out of *",debug,kafka
Node * was unable to process the fetch request with *: *.,info,kafka
Node * sent an invalid full fetch response with *,info,kafka
Node * sent a full fetch response*,debug,kafka
Node * sent a full fetch response that created a new incremental fetch session **,debug,kafka
Node * sent an invalid incremental fetch response with *,info,kafka
Node * sent an incremental fetch response closing session **,debug,kafka
Node * sent an incremental fetch response for session **,debug,kafka
Error sending fetch request * to node *: *.,info,kafka
Determining if we should replace existing epoch * with new epoch *,trace,kafka
Updating last seen epoch from * to * for partition *,debug,kafka
Not replacing existing epoch * with new epoch * for partition *,debug,kafka
Cluster ID: *,info,kafka
Updated cluster metadata updateVersion * to *,debug,kafka
Metadata response reported invalid topics *,error,kafka
Topic authorization failed for topics *,error,kafka
Requesting metadata update for partition * due to error *,debug,kafka
Requesting metadata update for topic * due to error *,debug,kafka
Kafka admin client initialized,debug,kafka
Initiating close operation.,debug,kafka
Moving hard shutdown time forward.,debug,kafka
Hard shutdown time is already earlier than requested.,debug,kafka
Waiting for the I/O thread to exit. Hard shutdown in * ms.,debug,kafka
Kafka admin client closed.,debug,kafka
Interrupted while joining I/O thread,debug,kafka
* aborted at * after * attempt(s),debug,kafka
* attempting protocol downgrade and then retry.,debug,kafka
* timed out at * after * attempt(s),debug,kafka
* failed with non-retriable exception after * attempt(s),debug,kafka
* failed after * attempt(s),debug,kafka
* failed: *. Beginning retry #*,debug,kafka
Timed out * pending calls.,debug,kafka
Timed out * call(s) with assigned nodes.,debug,kafka
Trying to choose nodes for * at *,trace,kafka
Assigned * to node *,trace,kafka
Unable to assign * to a node.,trace,kafka
Unable to choose node for *,debug,kafka
Client is not ready to send to *. Must delay * ms,trace,kafka
Sending * to *. correlationId=*,trace,kafka
Aborted call * is still in callsInFlight.,warn,kafka
Closing connection to * to time out *,debug,kafka
Timed out * call(s) in flight.,debug,kafka
"Internal server error on *: server returned information about unknown correlation ID *, requestHeader = *",error,kafka
Internal server error on *: ignoring call * in correlationIdToCall that did not exist in callsInFlight,error,kafka
* got response *,trace,kafka
* handleResponse failed with *,trace,kafka
"All work has been completed, and the I/O thread is now exiting.",trace,kafka
Forcing a hard I/O thread shutdown. Requests in progress will be aborted.,info,kafka
Hard shutdown in * ms.,debug,kafka
Thread starting,trace,kafka
Entering KafkaClient#poll(timeout=*),trace,kafka
KafkaClient#poll retrieved * response(s),trace,kafka
Timed out * remaining operation(s).,debug,kafka
Exiting AdminClientRunnable thread.,debug,kafka
Queueing * with a timeout * ms from now.,debug,kafka
The AdminClient thread has exited. Timing out *.,debug,kafka
The AdminClient is not accepting new calls. Timing out *.,debug,kafka
Node * is no longer the Coordinator. Retrying with new coordinator.,info,kafka
Skipping return offset for * due to error *.,warn,kafka
Metadata is not usable: failed to get metadata.,debug,kafka
Metadata is not ready: bootstrap nodes have not been initialized yet.,trace,kafka
Metadata is not ready: we have not fetched metadata from the bootstrap nodes yet.,trace,kafka
Metadata is ready to use.,trace,kafka
Requesting metadata update.,debug,kafka
Clearing cached controller node *.,trace,kafka
Metadata update failed due to authentication error,warn,kafka
Metadata update failed,info,kafka
Setting bootstrap cluster metadata *.,debug,kafka
Updating cluster metadata to *,debug,kafka
Partition '*' is assigned to multiple consumers following sticky assignment generation *.,warn,kafka
* is assigned to more than one consumer.,error,kafka
* can be moved from consumer * to consumer * for a more balanced assignment.,debug,kafka
The consumer * is assigned more partitions than the maximum possible.,error,kafka
Expected more than one potential consumer for partition '*',error,kafka
Expected partition '*' to be assigned to a consumer,error,kafka
A cycle of length * was found: *,error,kafka
Stickiness is violated for topic * Partition movements for this topic occurred among the following consumer pairs: *,error,kafka
Support for using the empty group id by consumers is deprecated and will be removed in the next major release.,warn,kafka
Initializing the Kafka consumer,debug,kafka
Kafka consumer initialized,debug,kafka
Subscribed to topic(s): *,info,kafka
Subscribed to pattern: '*',info,kafka
Unsubscribed all topics or patterns and assigned partitions,info,kafka
Subscribed to partition(s): *,info,kafka
Still waiting for metadata,warn,kafka
Committing offsets: *,debug,kafka
Seeking to offset * for partition *,info,kafka
Seeking to offset * for partition * with epoch *,info,kafka
Seeking to offset * for partition *,info,kafka
Pausing partitions *,debug,kafka
Resuming partitions *,debug,kafka
Closing the Kafka consumer,trace,kafka
Failed to close coordinator,error,kafka
Kafka consumer has been closed,debug,kafka
"Missing partition * from response, ignoring",warn,kafka
Handling OffsetsForLeaderEpoch response for *. Got offset * for epoch *,debug,kafka
"Attempt to fetch offsets for partition * failed due to *, retrying.",debug,kafka
"Attempt to fetch offsets for partition * failed due to *, retrying.",debug,kafka
Received unknown topic or partition error in ListOffset request for partition *,warn,kafka
"Attempt to fetch offsets for partition * failed due to: *, retrying.",warn,kafka
Error executing interceptor onConsume callback,warn,kafka
Error executing interceptor onCommit callback,warn,kafka
Failed to close consumer interceptor ,error,kafka
Assigned partition * for non-subscribed topic regex pattern; subscription pattern is *,info,kafka
Assigned partition * for non-subscribed topic; subscription is *,info,kafka
Skipping reset of partition * since it is no longer assigned,debug,kafka
Skipping reset of partition * since reset is no longer needed,debug,kafka
Skipping reset of partition * since an alternative reset has been requested,debug,kafka
Resetting offset for partition * to offset *.,info,kafka
Skipping completed validation for partition * which is not currently assigned.,debug,kafka
Skipping completed validation for partition * which is no longer expecting validation.,debug,kafka
Skipping completed validation for partition * since the current position * no longer matches the position * when the request was sent,debug,kafka
"Truncation detected for partition * at offset *, resetting offset to the first offset known to diverge *",info,kafka
"Truncation detected for partition * at offset * (the end offset from the broker is *), but no reset policy is set",warn,kafka
Skipping assignment for topic * since no metadata is available,debug,kafka
Received user wakeup,debug,kafka
Raising WakeupException in response to user wakeup,debug,kafka
Cancelled request with header * due to node * being disconnected,debug,kafka
Joining group with current subscription: *,debug,kafka
We received an assignment * that doesn't match our current subscription *; it is likely that the subscription has changed since we joined the group. Will try re-join the group with current subscription,warn,kafka
"Coordinator has owned partitions * that are not revoked with * protocol, it is likely client is woken up before a previous pending rebalance completes its callback",info,kafka
Setting newly assigned partitions: *,info,kafka
User provided listener * failed on partition assignment,error,kafka
"Updating with newly assigned partitions: *, compare with already owned partitions: *, newly added partitions: *, revoking partitions: *",info,kafka
User provided listener * failed on partition assignment,error,kafka
User provided listener * failed on partition revocation,error,kafka
Performing assignment using strategy * with subscriptions *,debug,kafka
The following subscribed topics are not assigned to any members: * ,warn,kafka
"The following not-subscribed topics are assigned, and their metadata will be fetched from the brokers: *",info,kafka
Finished assignment for group: *,debug,kafka
Revoking previously assigned partitions *,info,kafka
User provided listener * failed on partition revocation,error,kafka
Setting offset for partition * to the committed offset *,info,kafka
Sending asynchronous auto-commit of offsets *,debug,kafka
Sending synchronous auto-commit of offsets *,debug,kafka
Auto-commit of offsets * timed out before completion,debug,kafka
Auto-commit of offsets * was interrupted before completion,debug,kafka
Synchronous auto-commit of offsets * failed: *,warn,kafka
Offset commit with offsets * failed,error,kafka
Failing OffsetCommit request since the consumer is not part of an active group,info,kafka
Sending OffsetCommit request with * to coordinator *,trace,kafka
Committed offset * for partition *,debug,kafka
Offset commit failed on partition * at offset *: *,warn,kafka
Offset commit failed on partition * at offset *: *,error,kafka
Received fatal exception: group.instance.id gets fenced,error,kafka
Not authorized to commit to topics *,error,kafka
Fetching committed offsets for partitions: *,debug,kafka
Offset fetch failed: *,debug,kafka
Failed to fetch offset for partition *: *,debug,kafka
Found no committed offset for partition *,info,kafka
Sending * * to broker *,debug,kafka
Unable to find FetchSessionHandler for node *. Ignoring fetch response.,error,kafka
Fetch * at offset * for partition * returned fetch data *,debug,kafka
Topic metadata fetch included errors: *,debug,kafka
Not returning fetched records for partition * since it is no longer assigned,debug,kafka
Not returning fetched records for assigned partition * since it is no longer fetchable,debug,kafka
Returning fetched records at offset * for assigned partition * and update position to *,trace,kafka
Ignoring fetched records for * at offset * since the current position is *,debug,kafka
Discarding error in ListOffsetResponse because another error is pending,error,kafka
Leader for partition * is unknown for fetching offset *,debug,kafka
Leader for partition * is unavailable for fetching offset *,debug,kafka
Leader * for partition * is unavailable for fetching offset until reconnect backoff expires,debug,kafka
Sending ListOffsetRequest * to broker *,debug,kafka
Received ListOffsetResponse * from broker *,trace,kafka
Handling v0 ListOffsetResponse response for *. Fetched offset *,debug,kafka
"Handling ListOffsetResponse response for *. Fetched offset *, timestamp *",debug,kafka
Cannot search by timestamp for partition * because the message format version is before 0.10.0,debug,kafka
"Attempt to fetch offsets for partition * failed due to *, retrying.",debug,kafka
"Attempt to fetch offsets for partition * failed due to *, retrying.",debug,kafka
Received unknown topic or partition error in ListOffset request for partition *,warn,kafka
"Attempt to fetch offsets for partition * failed due to: *, retrying.",warn,kafka
"Not fetching from * for partition * since it is marked offline or is missing from our metadata, using the leader instead.",trace,kafka
Skipping fetch for partition * because node * is awaiting reconnect backoff,trace,kafka
Skipping fetch for partition * because previous request to * has not been processed,trace,kafka
Added * fetch request for partition * at position * to node *,debug,kafka
Ignoring fetched records for partition * since it is no longer fetchable,debug,kafka
Discarding stale fetch response for partition * since its offset * does not match the expected offset *,debug,kafka
Preparing to read * bytes of data for partition * with offset *,trace,kafka
Updating high watermark for partition * to *,trace,kafka
Updating log start offset for partition * to *,trace,kafka
Updating last stable offset for partition * to *,trace,kafka
Error in fetch for partition *: *,debug,kafka
Received unknown topic or partition error in fetch for partition *,warn,kafka
Discarding stale fetch response for partition * since the fetched offset * does not match the current offset *,debug,kafka
"Fetch offset * is out of range for partition *, resetting offset",info,kafka
Unset the preferred read replica * for partition * since we got * when fetching *,debug,kafka
Not authorized to read from partition *.,warn,kafka
Received unknown leader epoch error in fetch for partition *,debug,kafka
Unknown error fetching data for topic-partition *,warn,kafka
Skipping aborted record batch from partition * with producerId * and offsets * to *,debug,kafka
"Coordinator discovery failed, refreshing metadata",debug,kafka
No broker available to send FindCoordinator request,debug,kafka
still waiting to ensure active group,warn,kafka
Interrupted while waiting for consumer heartbeat thread to close,warn,kafka
Successfully joined group with generation *,info,kafka
(Re-)joining group,info,kafka
Sending JoinGroup (*) to coordinator *,debug,kafka
Received successful JoinGroup response: *,debug,kafka
Attempt to join group rejected since coordinator * is loading the group.,debug,kafka
Attempt to join group failed due to unknown member id.,debug,kafka
Attempt to join group failed due to obsolete coordinator information: *,debug,kafka
Received fatal exception: group.instance.id gets fenced,error,kafka
Attempt to join group failed due to fatal error: *,error,kafka
Attempt to join group failed due to unsupported version error. Please unset field group.instance.id and retryto see if the problem resolves,error,kafka
Attempt to join group failed due to unexpected error: *,error,kafka
Sending follower SyncGroup to coordinator *: *,debug,kafka
Sending leader SyncGroup to coordinator *: *,debug,kafka
SyncGroup failed because the group began another rebalance,debug,kafka
Received fatal exception: group.instance.id gets fenced,error,kafka
SyncGroup failed: *,debug,kafka
SyncGroup failed: *,debug,kafka
Sending FindCoordinator request to broker *,debug,kafka
Received FindCoordinator response *,debug,kafka
Discovered group coordinator *,info,kafka
"Group coordinator * is unavailable or invalid, will attempt rediscovery",info,kafka
"Close timed out with * pending requests to coordinator, terminating client connections",warn,kafka
Member * sending LeaveGroup request to coordinator * due to *,info,kafka
LeaveGroup request returned successfully,debug,kafka
LeaveGroup request failed with error: *,debug,kafka
Sending Heartbeat request to coordinator *,debug,kafka
Received successful Heartbeat response,debug,kafka
Attempt to heartbeat failed since coordinator * is either not started or not valid.,info,kafka
Attempt to heartbeat failed since group is rebalancing,info,kafka
Attempt to heartbeat failed since generation * is not current,info,kafka
Received fatal exception: group.instance.id gets fenced,error,kafka
Attempt to heartbeat failed for since member id * is not valid.,info,kafka
Enabling heartbeat thread,debug,kafka
Disabling heartbeat thread,debug,kafka
Heartbeat thread started,debug,kafka
Caught fenced group.instance.id * error in heartbeat thread,error,kafka
An authentication error occurred in the heartbeat thread,error,kafka
A group authorization error occurred in the heartbeat thread,error,kafka
Unexpected interrupt received in heartbeat thread,error,kafka
Heartbeat thread failed due to unexpected error,error,kafka
Heartbeat thread has closed,debug,kafka
Could not cast response body,error,kafka
Received * * from broker *,trace,kafka
Starting the Kafka producer,trace,kafka
Kafka producer started,debug,kafka
* should be equal to or larger than * + *. Setting it to *.delivery.timeout.mslinger.msrequest.timeout.ms,warn,kafka
Instantiated a transactional producer.,info,kafka
Instantiated an idempotent producer.,info,kafka
Overriding the default retries config to the recommended value of * since the idempotent producer is enabled.2147483647,info,kafka
Overriding the default * to all since idempotence is enabled.acks,info,kafka
Sending record * with callback * to topic * partition *,trace,kafka
Waking up the sender since topic * partition * is either full or getting a new batch,trace,kafka
Exception occurred during message send:,debug,kafka
Requesting metadata update for partition * of topic *.,trace,kafka
Requesting metadata update for topic *.,trace,kafka
Flushing accumulated records in producer.,trace,kafka
Closing the Kafka producer with timeoutMillis = * ms.,info,kafka
Overriding close timeout * ms to 0 ms in order to prevent useless blocking due to self-join. This means you have incorrectly invoked close with a non-zero timeout from the producer call-back.,warn,kafka
Interrupted while joining ioThread,error,kafka
Proceeding to force close the producer since pending requests could not be completed within timeout * ms.,info,kafka
Kafka producer has been closed,debug,kafka
"Removing unused topic * from the metadata list, expiryMs * now *",debug,kafka
Begin adding offsets * for consumer group * to transaction,debug,kafka
Begin adding new partition * to transaction,debug,kafka
Skipping transition to abortable error state since the transaction is already being aborted. Underlying exception: ,debug,kafka
ProducerId set to * with epoch *,info,kafka
Partition * keeps lastOffset at *,trace,kafka
"Ignoring completed batch * with producer id *, epoch *, and sequence number * since the producerId has been reset internally",debug,kafka
ProducerId: *; Set last ack'd sequence number for topic-partition * to *,debug,kafka
"Ignoring failed batch * with producer id *, epoch *, and sequence number * since the producerId has been reset internally",debug,kafka
"The broker returned * for topic-partition * with producerId *, epoch *, and sequence number *",error,kafka
"producerId: *, send to partition * failed fatally. Reducing future sequence numbers by *",debug,kafka
Marking partition * unresolved,debug,kafka
"No inflight batches remaining for *, last ack'd sequence for partition is *, next sequence is *. Going to reset producer state.",info,kafka
Not sending transactional request * because we are in an error state,trace,kafka
Not sending EndTxn for completed transaction since no partitions or offsets were successfully added,debug,kafka
Request * dequeued for sending,trace,kafka
Transition from state * to error state *,debug,kafka
Transition from state * to *,debug,kafka
Enqueuing transactional request *,debug,kafka
Disconnected from *. Will retry.,debug,kafka
Received transactional response * for request *,trace,kafka
Did not attempt to add partition * to transaction because other partitions in the batch had errors.,debug,kafka
Could not add partition * due to unexpected error *,error,kafka
Successfully added partitions * to transaction,debug,kafka
Successfully added partition for consumer group * to transaction,debug,kafka
Received TxnOffsetCommit response for consumer group *: *,debug,kafka
"Error executing interceptor onSend callback for topic: *, partition: *",warn,kafka
Error executing interceptor onSend callback,warn,kafka
Error executing interceptor onAcknowledgement callback,warn,kafka
Error executing interceptor onAcknowledgement callback,warn,kafka
Failed to close producer interceptor ,error,kafka
Allocating a new * byte message buffer for topic * partition *,trace,kafka
"Skipping next batch expiry time update due to addition overflow: batch.createMs=*, deliveryTimeoutMs=*",warn,kafka
Reordered incoming batch with sequence * for partition *. It was placed in the queue at position *,debug,kafka
Assigned producerId * and producerEpoch * to batch with base sequence * being sent to partition *,debug,kafka
Starting Kafka producer I/O thread.,debug,kafka
Uncaught error in kafka producer I/O thread: ,error,kafka
"Beginning shutdown of Kafka producer I/O thread, sending remaining records.",debug,kafka
Uncaught error in kafka producer I/O thread: ,error,kafka
Aborting incomplete transaction due to shutdown,info,kafka
Uncaught error in kafka producer I/O thread: ,error,kafka
Aborting incomplete transactional requests due to forced shutdown,debug,kafka
Aborting incomplete batches due to forced shutdown,debug,kafka
Failed to close network client,error,kafka
Shutdown of Kafka producer I/O thread has completed.,debug,kafka
Authentication exception while processing transactional request: *,trace,kafka
Requesting metadata update due to unknown leader topics from the batched records: *,debug,kafka
Expired * batches in accumulator,trace,kafka
Nodes with data ready to send: *,trace,kafka
Sending transactional request * to node *,debug,kafka
Disconnect from * while trying to send request *. Going to back off and retry.,debug,kafka
Aborting producer batches due to fatal error,error,kafka
Retriable error from InitProducerId response,debug,kafka
Could not find an available broker to send InitProducerIdRequest to. Will back off and retry.,debug,kafka
Broker * disconnected while awaiting InitProducerId response,debug,kafka
Retry InitProducerIdRequest in *ms.,trace,kafka
Cancelled request with header * due to node * being disconnected,trace,kafka
Cancelled request * due to a version mismatch with node *,warn,kafka
Received produce response from node * with correlation id *,trace,kafka
"Got error produce response in correlation id * on topic-partition *, splitting and retrying (* attempts left). Error: *",warn,kafka
"Got error produce response with correlation id * on topic-partition *, retrying (* attempts left). Error: *",warn,kafka
Retrying batch to topic-partition *. ProducerId: *; Sequence number : *,debug,kafka
Received unknown topic or partition error in produce request on partition *. The topic-partition may not exist or the user may not have Describe access to it,warn,kafka
Received invalid metadata error in produce request on partition * due to *. Going to request metadata update now,warn,kafka
Sent produce request to *: *,trace,kafka
Aborting batch for partition *,trace,kafka
Successfully produced messages to * with base offset *.,trace,kafka
Failed to produce messages to * with base offset *.,trace,kafka
ProduceResponse returned * for * after batch with base offset * had already been *.,debug,kafka
Ignored state transition * -> * for * batch with base offset *,debug,kafka
Error executing user-provided callback on message for topic-partition '*',error,kafka
"Error when sending message to topic * with key: *, value: * with error:",error,kafka
$$$Empty Message$$$,info,kafka
The configuration '*' was supplied but isn't a known config.,warn,kafka
ClassNotFoundException exception occurred: ,error,kafka
refused to allocate buffer of size *,trace,kafka
allocated buffer of size * ,trace,kafka
released buffer of size *,trace,kafka
allocated buffer of size * and identity *,trace,kafka
released buffer of size * and identity *,trace,kafka
Reclaimed buffer of size * and identity * that was not properly release()ed. This is a bug.,error,kafka
interrupted,debug,kafka
GC listener shutting down,info,kafka
Added sensor with name *,debug,kafka
Removed sensor with name *,debug,kafka
Error when removing metric from ,error,kafka
Removed metric named *,trace,kafka
Error when registering metric on ,error,kafka
Registered metric named *,trace,kafka
Removing expired sensor *,debug,kafka
Error when closing ,error,kafka
Error getting JMX attribute '*',warn,kafka
Failed to send SSL Close message,debug,kafka
"SSLHandshake NEED_TASK channelId *, appReadBuffer pos *, netReadBuffer pos *, netWriteBuffer pos *",trace,kafka
"SSLHandshake NEED_WRAP channelId *, appReadBuffer pos *, netReadBuffer pos *, netWriteBuffer pos *",trace,kafka
"SSLHandshake NEED_WRAP channelId *, handshakeResult *, appReadBuffer pos *, netReadBuffer pos *, netWriteBuffer pos *",trace,kafka
"SSLHandshake NEED_UNWRAP channelId *, appReadBuffer pos *, netReadBuffer pos *, netWriteBuffer pos *",trace,kafka
"SSLHandshake NEED_UNWRAP channelId *, handshakeResult *, appReadBuffer pos *, netReadBuffer pos *, netWriteBuffer pos *",trace,kafka
SSL handshake completed successfully with peerHost '*' peerPort * peerPrincipal '*' cipherSuite '*',debug,kafka
"SSLHandshake FINISHED channelId *, appReadBuffer pos *, netReadBuffer pos *, netWriteBuffer pos * ",trace,kafka
SSLHandshake handshakeWrap *,trace,kafka
SSLHandshake handshakeUnwrap *,trace,kafka
SSLHandshake handshakeUnwrap: handshakeStatus * status *,trace,kafka
"Renegotiation requested, but it is not supported, channelId *, appReadBuffer pos *, netReadBuffer pos *, netWriteBuffer pos *",trace,kafka
"SSL peer is not authenticated, returning ANONYMOUS instead",debug,kafka
SSLEngine.closeInBound() raised an exception.,debug,kafka
Failed to flush all bytes before closing channel,debug,kafka
"SSLException while unwrapping data after IOException, original IOException will be propagated",debug,kafka
Failed to create channel due to ,info,kafka
Failed to create channel due to ,info,kafka
Immediately connected to node *,debug,kafka
"Unexpected exception during send, closing connection * and rethrowing exception *",error,kafka
Broker no longer low on memory - unmuting incoming sockets,trace,kafka
"Created socket with SO_RCVBUF = *, SO_SNDBUF = *, SO_TIMEOUT = * to node *",debug,kafka
Should never happen: re-authentication latency for a re-authenticated channel was null; continuing...,warn,kafka
Connection with * disconnected,debug,kafka
Unexpected error from *; closing connection,warn,kafka
About to close the idle connection from * due to being idle for * millis,trace,kafka
Exception handling close on authentication failure node *,error,kafka
Tracking closing connection * to process outstanding requests,debug,kafka
Exception closing connection to node *:,error,kafka
Failed to create channel due to ,warn,kafka
Broker low on memory - could not allocate buffer of size * for source *,trace,kafka
Unexpected error code: *.,warn,kafka
mismatch in sending bytes over socket; expected: * actual: *,error,kafka
"Bytes written as part of multi-send call: *, total bytes written so far: *, expected bytes to write: *",trace,kafka
Constructed overflow message batch for partition * with length=*,debug,kafka
Down-converted records for partition * with length=*,debug,kafka
Received end transaction marker value version *. Parsing as version *0,debug,kafka
Record batch from * with last offset * exceeded max record batch size * after cleaning (new size is *). Consumers with version earlier than 0.10.1.0 may need to increase their fetch sizes.,warn,kafka
Received unknown control record key version *. Parsing as version *0,debug,kafka
"Server config * should be prefixed with SASL mechanism name, ignoring configsasl.jaas.config",warn,kafka
"System property 'java.security.auth.login.config' and Kafka SASL property 'sasl.jaas.config' are not set, using default JAAS configuration.",debug,kafka
"System property 'java.security.auth.login.config' is not set, using default JAAS configuration.",debug,kafka
"JAAS configuration is present, but system property zookeeper.sasl.client is set to false, which disables SASL in the ZooKeeper client",error,kafka
Successfully logged in.,info,kafka
* for mechanism=*: *connections.max.reauth.ms,debug,kafka
Creating SaslServer for * with mechanism *,debug,kafka
Cannot add private credential to subject; clients authentication may fail,warn,kafka
Failed during *: *,debug,kafka
Beginning re-authentication: *,debug,kafka
Set SASL server state to * during *,debug,kafka
Handling Kafka request * during *,debug,kafka
"Received client packet of length * starting with bytes 0x*, process as GSSAPI packet",debug,kafka
"First client packet is not a SASL mechanism request, using default mechanism GSSAPI",debug,kafka
Using SASL mechanism '*' provided by client,debug,kafka
SASL mechanism '*' requested by client is not supported,debug,kafka
$$$Empty Message$$$,debug,kafka
"Authentication complete; session max lifetime from broker config=* ms, credential expiration=* (* ms); session expiration = * (* ms), sending * ms to client",debug,kafka
"Authentication complete; session max lifetime from broker config=* ms, credential expiration=* (* ms); no session expiration, sending 0 ms to client",debug,kafka
"Authentication complete; session max lifetime from broker config=* ms, no credential expiration; session expiration = * (* ms), sending * ms to client",debug,kafka
"Authentication complete; session max lifetime from broker config=* ms, no credential expiration; no session expiration, sending 0 ms to client",debug,kafka
* acquired,trace,kafka
* released,trace,kafka
Set SASL client state to *,debug,kafka
"Invalid SASL mechanism response, server may be expecting only GSSAPI tokens",debug,kafka
Finished * with session expiration in * ms and session re-authentication on or after * ms,debug,kafka
Finished * with no session expiration and no session re-authentication,debug,kafka
Client supplied realm: * ,trace,kafka
Successfully authenticated client: authenticationID=*; authorizationID=*.,info,kafka
[Principal=*]: It is not a Kerberos ticket,debug,kafka
[Principal=*]: It is a Kerberos ticket,debug,kafka
[Principal=*]: Error while waiting for Login thread to shutdown.,warn,kafka
[Principal=*]: TGT valid starting at: *,info,kafka
[Principal=*]: TGT expires: *,info,kafka
Found TGT with client principal '*' and server principal '*'.,debug,kafka
[Principal=*]: Not attempting to re-login since the last re-login was attempted less than * seconds before.,warn,kafka
Initiating logout for *,info,kafka
Initiating re-login for *,info,kafka
Kerberos return code could not be determined from * due to *,trace,kafka
"Logged in without a token, this login cannot be used to establish client connections",debug,kafka
Login succeeded; invoke commit() to commit it; current committed token count=*,debug,kafka
$$$Empty Message$$$,error,kafka
Login failed: * : * (URI=*),info,kafka
$$$Empty Message$$$,error,kafka
CallbackHandler * does not support SASL extensions. No extensions will be added,debug,kafka
SASL Extensions cannot be null. Check whether your callback handler is explicitly setting them as null.,error,kafka
Nothing here to log out,debug,kafka
Logging out my token; current committed token count = *,trace,kafka
Done logging out my token; committed token count is now *,debug,kafka
No tokens to logout for this login,debug,kafka
Logging out my extensions,trace,kafka
Done logging out my extensions,debug,kafka
No extensions to logout for this login,debug,kafka
Nothing here to commit,debug,kafka
Committing my token; current committed token count = *,trace,kafka
Done committing my token; committed token count is now *,debug,kafka
"No tokens to commit, this login cannot be used to establish client connections",debug,kafka
Login aborted,debug,kafka
Nothing here to abort,debug,kafka
Sending %%x01 response to server after receiving an error: *,debug,kafka
Successfully authenticated as *,debug,kafka
Setting SASL/* client state to *OAUTHBEARER,debug,kafka
"Extensions callback is not supported by client callback handler *, no extensions will be added",debug,kafka
Found expiring credential with principal '*'.,debug,kafka
"Found * OAuth Bearer tokens in Subject's private credentials; the oldest expires at *, will use the newest, which expires at *",warn,kafka
Received %x01 response from client after it received our error,debug,kafka
$$$Empty Message$$$,debug,kafka
$$$Empty Message$$$,debug,kafka
Successfully authenticate User=*,debug,kafka
$$$Empty Message$$$,debug,kafka
$$$Empty Message$$$,debug,kafka
[Principal=*]: Expiring credential re-login thread started.,info,kafka
[Principal=*]: Expiring credential re-login sleep time was calculated to be in the past! Will explicitly adjust. (*),warn,kafka
[Principal=*]: Expiring credential re-login sleeping until: *,info,kafka
[Principal=*]: Expiring credential re-login thread has been interrupted and will exit.,info,kafka
$$$Empty Message$$$,error,kafka
[Principal=%s]: LoginException during login retry; will sleep %d seconds before trying again.,warn,kafka
[Principal=*]: Interrupted while trying to perform a subsequent expiring credential re-login after one or more initial re-login failures: re-login thread exiting now: *,error,kafka
Successfully logged in.,info,kafka
No Expiring Credential,debug,kafka
"[Principal=*]: Current clock: * is later than expiry *. This may indicate a clock skew problem. Check that this host's and remote host's clocks are in sync. Not starting refresh thread. This process is likely unable to authenticate SASL connections (for example, it is unlikely to be able to authenticate a connection with a Kafka Broker).",error,kafka
[Principal=*]: It is an expiring credential,debug,kafka
[Principal=*]: Interrupted while waiting for re-login thread to shutdown.,warn,kafka
[Principal=*]: No Expiring credential found: will try again at *,warn,kafka
[Principal=*]: Current clock: * is later than expiry *. This may indicate a clock skew problem. Check that this host's and remote host's clocks are in sync. Exiting refresh thread.,error,kafka
[Principal=*]: Expiring credential already expired at *: will try to refresh again at *,warn,kafka
"[Principal=*]: Expiring credential refresh thread exiting because the expiring credential's current expiration time (*) exceeds the latest possible refresh time (*). This process will not be able to authenticate new SASL connections after that time (for example, it will not be able to authenticate a new connection with a Kafka Broker).",warn,kafka
[Principal=*]: Expiring credential valid from * to *,info,kafka
"[Principal=*]: Expiring credential expires at *, so buffer times of * and * seconds at the front and back, respectively, cannot be accommodated.  We will refresh at *.",warn,kafka
"[Principal=*]: Proposed refresh time of * extends into the desired buffer time of * seconds before expiration, so refresh it at the desired buffer begin point, at *",info,kafka
[Principal=*]: Expiring credential re-login thread time adjusted from * to * since the former is sooner than the minimum refresh interval (* seconds from now).,info,kafka
Initiating logout for *,info,kafka
"Initiating re-login for *, logout() still needs to be called on a previous login = *",info,kafka
No Expiring Credential after a supposedly-successful re-login,error,kafka
[Principal=*]: It is an expiring credential after re-login as expected,debug,kafka
"Token not provided, this login cannot be used to establish client connections",debug,kafka
Retrieved token with principal *,info,kafka
Successfully validated token with principal *: *,info,kafka
"Unsupported extensions will be ignored, supported *, provided *",debug,kafka
Setting SASL/* server state to *,debug,kafka
"Extensions callback is not supported by client callback handler *, no extensions will be added",debug,kafka
Setting SASL/* client state to *,debug,kafka
Unrecognized client authentication configuration *.  Falling back to NONE.  Recognized client authentication configurations are *.,warn,kafka
"Created SSL context with keystore *, truststore *",debug,kafka
Modification time of key store could not be obtained: ,error,kafka
Created new * SSL engine builder with keystore * truststore *,info,kafka
Validation of dynamic config update of SSLFactory failed.,debug,kafka
"Registered signal handlers for  | , ",info,kafka
Terminating process due to signal *,info,kafka
Error reading the error stream,warn,kafka
Interrupted while reading the error stream,warn,kafka
Error while closing the input stream,warn,kafka
Error while closing the error stream,warn,kafka
Non-atomic move of * to * succeeded after atomic move failed due to *,debug,kafka
Failed to close * with type *,warn,kafka
Failed to close * with type *,error,kafka
Error registering AppInfo mbean,warn,kafka
Error unregistering AppInfo mbean,warn,kafka
Kafka version: *,info,kafka
Kafka commitId: *,info,kafka
Kafka startTimeMs: *,info,kafka
Uncaught exception in thread '*':,error,kafka
$$$Empty Message$$$,trace,kafka
$$$Empty Message$$$,trace,kafka
$$$Empty Message$$$,trace,kafka
$$$Empty Message$$$,trace,kafka
$$$Empty Message$$$,trace,kafka
$$$Empty Message$$$,trace,kafka
$$$Empty Message$$$,trace,kafka
$$$Empty Message$$$,trace,kafka
$$$Empty Message$$$,trace,kafka
$$$Empty Message$$$,trace,kafka
$$$Empty Message$$$,debug,kafka
$$$Empty Message$$$,debug,kafka
$$$Empty Message$$$,debug,kafka
$$$Empty Message$$$,debug,kafka
$$$Empty Message$$$,debug,kafka
$$$Empty Message$$$,debug,kafka
$$$Empty Message$$$,debug,kafka
$$$Empty Message$$$,debug,kafka
$$$Empty Message$$$,debug,kafka
$$$Empty Message$$$,debug,kafka
$$$Empty Message$$$,warn,kafka
$$$Empty Message$$$,warn,kafka
$$$Empty Message$$$,warn,kafka
$$$Empty Message$$$,warn,kafka
$$$Empty Message$$$,warn,kafka
$$$Empty Message$$$,warn,kafka
$$$Empty Message$$$,warn,kafka
$$$Empty Message$$$,warn,kafka
$$$Empty Message$$$,warn,kafka
$$$Empty Message$$$,warn,kafka
$$$Empty Message$$$,error,kafka
$$$Empty Message$$$,error,kafka
$$$Empty Message$$$,error,kafka
$$$Empty Message$$$,error,kafka
$$$Empty Message$$$,error,kafka
$$$Empty Message$$$,error,kafka
$$$Empty Message$$$,error,kafka
$$$Empty Message$$$,error,kafka
$$$Empty Message$$$,error,kafka
$$$Empty Message$$$,error,kafka
$$$Empty Message$$$,info,kafka
$$$Empty Message$$$,info,kafka
$$$Empty Message$$$,info,kafka
$$$Empty Message$$$,info,kafka
$$$Empty Message$$$,info,kafka
$$$Empty Message$$$,info,kafka
$$$Empty Message$$$,info,kafka
$$$Empty Message$$$,info,kafka
$$$Empty Message$$$,info,kafka
$$$Empty Message$$$,info,kafka
Invoking * at *,trace,kafka
Scheduling * for * ms from now.,trace,kafka
Writing line to *: *,trace,kafka
Flushing output stream for *,trace,kafka
"Found previous offset, trying to skip to file offset *",debug,kafka
Error while trying to seek to previous offset in file *: ,error,kafka
Skipped to offset *,debug,kafka
Opened * for reading,debug,kafka
"Couldn't find file * for FileStreamSourceTask, sleeping to wait for it to be created",warn,kafka
Error while trying to open file *: ,error,kafka
Read * bytes from *,trace,kafka
Read a line from *,trace,kafka
Stopping,trace,kafka
Closed input stream,trace,kafka
Failed to close FileStreamSourceTask stream: ,error,kafka
Kafka producer connected to ,debug,kafka
Logging for topic: ,debug,kafka
[ | ],debug,kafka
Exception while getting response,debug,kafka
Usage: ConnectDistributed worker.properties,info,kafka
Stopping due to error,error,kafka
Scanning for plugin classes. This might take a moment ...,info,kafka
Kafka cluster ID: *,debug,kafka
Kafka Connect distributed worker initialization took *ms,info,kafka
Failed to start Connect,error,kafka
Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...],info,kafka
Kafka Connect standalone worker initializing ...,info,kafka
Scanning for plugin classes. This might take a moment ...,info,kafka
Kafka cluster ID: *,debug,kafka
Kafka Connect standalone worker initialization took *ms,info,kafka
Failed to create job for *,error,kafka
Created connector *,info,kafka
Stopping after connector error,error,kafka
Stopping due to error,error,kafka
Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden,info,kafka
Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden,info,kafka
Setting up Principal policy for ConnectorClientConfigOverride. This will allow `sasl` client configuration to be overridden.,info,kafka
Registering Connect metrics with JMX for worker '*',debug,kafka
Unregistering Connect metrics with JMX for worker '*',debug,kafka
* Setting offsets for topic partitions *,debug,kafka
* Setting offset for topic partition * to *,debug,kafka
* Setting timeout to * ms,debug,kafka
"* Connector is paused, so not pausing consumer's partitions *",debug,kafka
* Pausing partitions *. Connector is not paused.,debug,kafka
"* Connector is paused, so not resuming consumer's partitions *",debug,kafka
* Resuming partitions: *,debug,kafka
* Requesting commit,debug,kafka
Kafka Connect instance created,debug,kafka
Kafka Connect starting,info,kafka
Kafka Connect started,info,kafka
Kafka Connect stopping,info,kafka
Kafka Connect stopped,info,kafka
Interrupted waiting for Kafka Connect to shutdown,error,kafka
Interrupted in shutdown hook while waiting for Kafka Connect startup to finish,error,kafka
Scheduling a restart of connector * in * ms,info,kafka
Unexpected error during connector restart: ,error,kafka
$$$Empty Message$$$,info,kafka
Graceful shutdown of offset commitOffsets thread timed out.,error,kafka
Offset commit thread was cancelled by another thread while removing connector task with id: *,trace,kafka
* Committing offsets,debug,kafka
* Failed to commit offsets,error,kafka
* Unhandled exception when committing: ,error,kafka
"Worker configuration property '*'* is deprecated and may be removed in an upcoming release. The specified value '*' matches the default, so this property can be safely removed from the worker configuration.",info,kafka
Worker configuration property '*'* is deprecated and may be removed in an upcoming release. The specified value '*' does NOT match the default and recommended value '*'.,warn,kafka
Worker configuration property '*'* is deprecated and may be removed in an upcoming release.,warn,kafka
* Task failed initialization and will not be started.,error,kafka
Could not stop task,warn,kafka
Could not close consumer,warn,kafka
Could not close transformation chain,warn,kafka
* Commit of offsets timed out,warn,kafka
* Consumer woken up,trace,kafka
"* Received out of order commit callback for sequence number *, but most recent sequence number is *",debug,kafka
* Commit of offsets threw an unexpected exception for sequence number *: *,error,kafka
* Finished offset commit successfully in * ms for sequence number *: *,debug,kafka
* Setting last committed offsets to *,debug,kafka
* Initializing and starting task for topics *,debug,kafka
* Initializing and starting task for topics regex *,debug,kafka
* Sink task finished initialization and start,info,kafka
* Polling consumer with timeout * ms,trace,kafka
* Polling returned * messages,trace,kafka
* Committing offsets synchronously using sequence number *: *,info,kafka
* Committing offsets asynchronously using sequence number *: *,info,kafka
* Calling task.preCommit with current offsets: *,trace,kafka
* Offset commit failed during close,warn,kafka
"* Offset commit failed, rewinding to last committed offsets",error,kafka
* Rewinding topic partition * to offset *,debug,kafka
* Closing the task before committing the offsets: *,trace,kafka
"* Skipping offset commit, task opted-out by returning no offsets from preCommit",debug,kafka
"* Ignoring invalid task provided offset */* -- not yet consumed, taskOffset=* currentOffset=*",warn,kafka
"* Ignoring invalid task provided offset */* -- partition not assigned, assignment=*",warn,kafka
"* Skipping offset commit, no change since last commit",debug,kafka
* Consuming and converting message in topic '*' partition * at offset * and timestamp *,trace,kafka
"* Converters and transformations returned null, possibly because of too many retries, so dropping record in topic '*' partition * at offset *",trace,kafka
* Applying transformations to record in topic '*' partition * at offset * and timestamp * with key * and value *,trace,kafka
* Delivering batch of * messages to task,trace,kafka
* RetriableException from SinkTask:,error,kafka
* Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted.,error,kafka
* Rewind * to offset *,trace,kafka
* Cannot rewind * to null offset,warn,kafka
* Partitions assigned *,debug,kafka
* Assigned topic partition * with offset *,debug,kafka
* Partitions revoked,debug,kafka
* Task threw an uncaught and unrecoverable exception during shutdown,error,kafka
* Task threw an uncaught and unrecoverable exception,error,kafka
* Task is being killed and will not recover until manually restarted,error,kafka
Worker starting,info,kafka
Worker started,info,kafka
Worker stopping,info,kafka
Shutting down connectors * uncleanly; herder should have shut down connectors before the Worker is stopped,warn,kafka
Shutting down tasks * uncleanly; herder should have shut down tasks before the Worker is stopped,warn,kafka
Worker stopped,info,kafka
Creating connector * of type *,info,kafka
Instantiated connector * with version * of type *,info,kafka
Failed to start connector *,error,kafka
Finished creating connector *,info,kafka
Reconfiguring connector tasks for *,trace,kafka
Stopping connector *,info,kafka
Ignoring stop request for unowned connector *,warn,kafka
Stopped connector *,info,kafka
Creating task *,info,kafka
Instantiated task * with version * of type *,info,kafka
Set up the key converter * for task * using the worker config,info,kafka
Set up the key converter * for task * using the connector config,info,kafka
Set up the value converter * for task * using the worker config,info,kafka
Set up the value converter * for task * using the connector config,info,kafka
Set up the header converter * for task * using the worker config,info,kafka
Set up the header converter * for task * using the connector config,info,kafka
Failed to start task *,error,kafka
Initializing: *,info,kafka
Initializing: *,info,kafka
Tasks must be a subclass of either SourceTask or SinkTask,error,kafka
Ignoring stop request for unowned task *,warn,kafka
Stopping task *,info,kafka
Ignoring await stop request for non-present task *,warn,kafka
Graceful stop of task * failed.,error,kafka
Graceful stop of task * succeeded.,debug,kafka
Setting connector * state to *,info,kafka
* Task failed initialization and will not be started.,error,kafka
Could not close producer,warn,kafka
Could not close transformation chain,warn,kafka
Could not stop task,warn,kafka
* Source task finished initialization and start,info,kafka
* Nothing to send to Kafka. Polling source for additional records,trace,kafka
* About to send  |  records to Kafka,debug,kafka
* failed to poll records from SourceTask. Will retry operation.,warn,kafka
"* Appending record with key *, value *",trace,kafka
* failed to send record to *:,error,kafka
* Failed record: *,debug,kafka
* Wrote record successfully: topic * partition * offset *,trace,kafka
"* Failed to send *, backing off before retrying:",warn,kafka
* Exception thrown while calling task.commitRecord(),error,kafka
* CRITICAL Saw callback for record that was not present in the outstanding message set: *,error,kafka
* Committing offsets,info,kafka
* flushing * outstanding messages for offset commit,info,kafka
"* Failed to flush, timed out while waiting for producer to flush outstanding * messages",error,kafka
"* Interrupted while flushing messages, offsets will not be committed",error,kafka
* Finished offset commitOffsets successfully in * ms,debug,kafka
* Failed to flush offsets to storage: ,error,kafka
* Finished flushing offsets to storage,trace,kafka
"* Flush of offsets interrupted, cancelling",warn,kafka
* Flush of offsets threw an unexpected exception: ,error,kafka
* Timed out waiting to flush offsets to storage,error,kafka
* Finished commitOffsets successfully in * ms,info,kafka
* Exception thrown while calling task.commit(),error,kafka
* Initializing connector * with config *,debug,kafka
* Connector raised an error,error,kafka
* Error initializing connector,error,kafka
* Error while starting connector,error,kafka
* Error while shutting down connector,error,kafka
* Error while shutting down connector,error,kafka
* Cannot transition connector to * since it has failed,warn,kafka
* Transition connector to *,debug,kafka
Applying transformation * to *,trace,kafka
Deserialized new assignment: *,debug,kafka
After revocations snapshot of assignment: *,debug,kafka
Augmented new assignment: *,debug,kafka
Rebalance started,info,kafka
Revoking previous assignment *,debug,kafka
Cooperative rebalance triggered. Keeping assignment * until it's explicitly revoked.,debug,kafka
Herder starting,info,kafka
Herder started,info,kafka
Herder stopped,info,kafka
"Uncaught exception in herder work thread, exiting: ",error,kafka
Scheduled rebalance at: * (now: * nextRequestTimeoutMs: *) ,debug,kafka
Requesting rebalance due to reconfiguration of tasks (needsReconfigRebalance: *),debug,kafka
Requesting rebalance due to reconfiguration of tasks (needsReconfigRebalance: *),debug,kafka
Received target state change for unknown connector: *,debug,kafka
Handling task config update by restarting tasks *,info,kafka
Stopping connectors and tasks that are still assigned to this worker.,info,kafka
Herder stopping,info,kafka
Herder stopped,info,kafka
Submitting connector listing request,trace,kafka
Submitting connector info request *,trace,kafka
Submitting connector config read request *,trace,kafka
Handling connector config request *,trace,kafka
Removing connector config * *,trace,kafka
Submitting connector config write request *,trace,kafka
Handling connector config request *,trace,kafka
Submitting connector config * * *,trace,kafka
Submitting connector task reconfiguration request *,trace,kafka
Unexpected error during task reconfiguration: ,error,kafka
"Task reconfiguration for * failed unexpectedly, this connector will not be properly reconfigured unless manually triggered.",error,kafka
Submitting get task configuration request *,trace,kafka
Submitting put task configuration request *,trace,kafka
Returning early because rebalance is marked as resolved (rebalanceResolved: true),trace,kafka
"Join group completed, but assignment failed and we are the leader. Reading to end of config and retrying.",warn,kafka
"Join group completed, but assignment failed and we lagging. Reading to end of config and retrying.",warn,kafka
"Join group completed, but assignment failed. We were up to date, so just retrying.",warn,kafka
Catching up to assignment's config offset.,warn,kafka
Requesting rebalance because scheduled rebalance timeout has been reached (now: * scheduledRebalance: *,debug,kafka
Current config state offset * does not match group assignment *. Forcing rebalance.,info,kafka
"Current config state offset * is behind group assignment *, reading to end of config log",info,kafka
"Finished reading to end of log and updated config snapshot, new config log offset: *",info,kafka
Didn't reach end of config log quickly enough,warn,kafka
Starting connectors and tasks using config offset *,info,kafka
Finished starting connectors and tasks,info,kafka
Starting task *,info,kafka
Couldn't instantiate task * because it has an invalid task configuration. This task will not execute until reconfigured.,error,kafka
Starting connector *,info,kafka
Couldn't instantiate connector  |  because it has an invalid connector  | configuration. This connector will not execute until reconfigured.,error,kafka
Failed to shut down connector ,error,kafka
"Failed to reconfigure connector's tasks, retrying after backoff:",error,kafka
Unexpected error during connector task reconfiguration: ,error,kafka
"Task reconfiguration for * failed unexpectedly, this connector will not be properly reconfigured unless manually triggered.",error,kafka
Skipping reconfiguration of connector * since it is not running,info,kafka
"Change in connector task count from * to *, writing updated task configurations",debug,kafka
"Change in task configurations, writing updated task configurations",debug,kafka
Request to leader to reconfigure connector tasks failed,error,kafka
Connector * config removed,info,kafka
Connector * config updated,info,kafka
Tasks * configs updated,info,kafka
Connector * target state change,info,kafka
Cleaning status information for connector *,debug,kafka
Joined group at generation * and got assignment: *,info,kafka
Finished stopping tasks in preparation for rebalance,info,kafka
"Wasn't unable to resume work after last rebalance, can skip stopping connectors and tasks",info,kafka
Performing task assignment,debug,kafka
"Was selected to perform assignments, but do not have latest config found in sync request. Returning an empty configuration to trigger re-sync.",info,kafka
Assigning connector * to *,trace,kafka
Assigning task * to *,trace,kafka
Assignment: * -> *,debug,kafka
Finished assignment,debug,kafka
"Max config offset root: *, local snapshot config offsets root: *",debug,kafka
Performing task assignment,debug,kafka
Member configs: *,debug,kafka
"Max config offset root: *, local snapshot config offsets root: *",debug,kafka
"Was selected to perform assignments, but do not have latest config found in sync request. Returning an empty configuration to trigger re-sync.",info,kafka
Previous assignments: *,debug,kafka
Configured assignments: *,debug,kafka
Active assignments: *,debug,kafka
Deleted assignments: *,debug,kafka
Remaining (excluding deleted) active assignments: *,debug,kafka
Lost assignments: *,debug,kafka
New assignments: *,debug,kafka
Complete (ignoring deletions) worker assignments: *,debug,kafka
Complete (ignoring deletions) connector assignments: *,debug,kafka
Complete (ignoring deletions) task assignments: *,debug,kafka
Connector and task to delete assignments: *,debug,kafka
Can leader revoke tasks in this assignment? * (delay: *),debug,kafka
Connector and task to revoke assignments: *,debug,kafka
Current complete assignments: *,debug,kafka
New complete assignments: *,debug,kafka
Incremental connector assignments: *,debug,kafka
Incremental task assignments: *,debug,kafka
Actual assignments: *,debug,kafka
Connectors and tasks to delete assignments: *,debug,kafka
Found the following connectors and tasks missing from previous assignments: ,debug,kafka
No task revocation required; workers with existing load: * workers with no load * total workers *,debug,kafka
Task revocation is required; workers with existing load: * workers with no load * total workers *,debug,kafka
Previous rounded down (floor) average number of connectors per worker *,debug,kafka
New rounded down (floor) average number of connectors per worker *,debug,kafka
Previous rounded down (floor) average number of tasks per worker *,debug,kafka
New rounded down (floor) average number of tasks per worker *,debug,kafka
Filling assignment: * -> *,debug,kafka
Finished assignment,debug,kafka
Received assignments: *,debug,kafka
Assigning connector * to *,debug,kafka
Assigning task * to *,debug,kafka
Connect group member created,debug,kafka
Stopping the Connect group member.,trace,kafka
The Connect group member has stopped.,debug,kafka
Topic * doesn't exist. Will attempt to create topic.,error,kafka
Could not serialize stacktrace.,error,kafka
$$$Empty Message$$$,error,kafka
ProcessingContext is already in failed state. Ignoring requested operation.,debug,kafka
Caught a retriable exception while executing * operation with *,trace,kafka
Thread was interrupted. Marking operation as failed.,trace,kafka
"Can't retry. start=*, attempt=*, deadline=*",trace,kafka
Sleeping for * millis,debug,kafka
Class '*' not found. Delegating to parent,trace,kafka
Configuring the header converter with configuration keys:**,debug,kafka
Getting plugin class loader for connector: '*',debug,kafka
Plugin class loader for connector: '*' was not found. Returning: *,error,kafka
Added plugin '*',info,kafka
Invalid path in plugin path: *. Ignoring.,error,kafka
Could not get listing for plugin path: *. Ignoring.,error,kafka
Could not instantiate plugins in: *. Ignoring: *,error,kafka
Loading plugin from: *,info,kafka
Loading plugin urls: *,debug,kafka
Registered loader: *,info,kafka
Registered java.sql.Driver: * to java.sql.DriverManager,debug,kafka
Ignoring java.sql.Driver classes listed in resources but not present in class loader's classpath: ,debug,kafka
Skipping * as it is not concrete implementation,debug,kafka
Retrieving loaded class '*' from '*',trace,kafka
Added alias '*' to plugin '*',info,kafka
Added aliases '*' and '*' to plugin '*',info,kafka
could not create Vfs.Dir from url. ignoring the exception and continuing,warn,kafka
Resolving symbolic link '*' failed. Ignoring this path.,warn,kafka
Plugin path contains both java archives and class files. Returning only the archives,warn,kafka
Added connector for ,info,kafka
Initializing REST server,info,kafka
Initializing REST resources,info,kafka
REST resources initialized; server is started and ready to handle requests,info,kafka
Stopping REST server,info,kafka
Error while invoking close on ,warn,kafka
REST server stopped,info,kafka
The resource * is already registered,warn,kafka
The resource * is already registered,warn,kafka
Failed to start RestClient: ,error,kafka
Sending * with input * to *,trace,kafka
Request's response code: *,debug,kafka
IO error forwarding REST request: ,error,kafka
Failed to stop HTTP client,error,kafka
Ignoring unknown expanion type *,info,kafka
Unable to get connector info for * on this worker,debug,kafka
Forwarding request * * *,debug,kafka
Herder starting,info,kafka
Herder started,info,kafka
Herder stopping,info,kafka
Herder stopped,info,kafka
Task that requested reconfiguration does not exist: *,error,kafka
Skipping update of connector * since it is not running,info,kafka
Starting FileOffsetBackingStore with file *,info,kafka
Stopped FileOffsetBackingStore,info,kafka
Creating admin client to manage Connect internal status topic,debug,kafka
Failed to write status update,error,kafka
Invalid connector status type *,error,kafka
Failed to deserialize connector status,error,kafka
Invalid task status type *,error,kafka
Failed to deserialize task status,error,kafka
Invalid task status key *,warn,kafka
Discarding record with invalid connector status key *,warn,kafka
Removing status for connector *,trace,kafka
Received connector * status update *,trace,kafka
Discarding record with invalid task status key *,warn,kafka
Removing task status for *,trace,kafka
Failed to parse task status with key *,warn,kafka
Received task * status update *,trace,kafka
Discarding record with invalid key *,warn,kafka
Starting KafkaConfigBackingStore,info,kafka
Started KafkaConfigBackingStore,info,kafka
Closing KafkaConfigBackingStore,info,kafka
Closed KafkaConfigBackingStore,info,kafka
Writing connector configuration for connector '*',debug,kafka
Removing connector configuration for connector '*',debug,kafka
Failed to remove connector configuration from Kafka: ,error,kafka
Failed to write connector configuration to Kafka: ,error,kafka
Failed to write root configuration to Kafka: ,error,kafka
Writing configuration for connector '*' task *,debug,kafka
Writing commit for connector '*' with * tasks.,debug,kafka
Failed to write root configuration to Kafka: ,error,kafka
Writing target state * for connector *,debug,kafka
Creating admin client to manage Connect internal config topic,debug,kafka
Unexpected in consumer callback for KafkaConfigBackingStore: ,error,kafka
Failed to convert config data to Kafka Connect format: ,error,kafka
Removed target state for connector * due to null value in topic.,debug,kafka
Found target state (*) in wrong format: *,error,kafka
Setting target state for connector '*' to *,debug,kafka
Invalid target state for connector '*': *,error,kafka
Successfully processed removal of connector '*',info,kafka
Found configuration for connector '*' in wrong format: *,error,kafka
Updating configuration for connector '*',debug,kafka
Ignoring task configuration because * couldn't be parsed as a task config key,error,kafka
Ignoring task configuration for task * because it is unexpectedly null,error,kafka
Ignoring task configuration for task * because the value is not a Map but is *,error,kafka
Invalid data for config of task * 'properties' field should be a Map but is *,error,kafka
Storing new config for task *; this will wait for a commit message before the new config will take effect.,debug,kafka
Ignoring connector tasks configuration commit for connector '*' because it is in the wrong format: *,error,kafka
We have an incomplete set of task configs for connector '*' probably due to compaction. So we are not doing anything with the new configuration.,debug,kafka
Discarding config update record with invalid key: *,error,kafka
"CRITICAL: Failed to serialize partition key when getting offsets for task with namespace *. No value for this data will be returned, which may break the task or cause it to skip some data.",error,kafka
Failed to fetch offsets from namespace *: ,error,kafka
"Should be able to map * back to a requested partition-offset key, backing store may have returned invalid data",error,kafka
"CRITICAL: Failed to deserialize offset data when getting offsets for task with namespace *. No value for this data will be returned, which may break the task or cause it to skip some data. This could either be due to an error in the connector implementation or incompatible schema.",error,kafka
Creating admin client to manage Connect internal offset topic,debug,kafka
Starting KafkaOffsetBackingStore,info,kafka
Finished reading offsets topic and starting KafkaOffsetBackingStore,info,kafka
Stopping KafkaOffsetBackingStore,info,kafka
Stopped KafkaOffsetBackingStore,info,kafka
"Invalid call to OffsetStorageWriter flush() while already flushing, the framework should not allow this",error,kafka
"CRITICAL: Failed to serialize offset data, making it impossible to commit offsets under namespace *. This likely won't recover unless the unserializable partition or offset information is overwritten.",error,kafka
Cause of serialization failure:,error,kafka
Submitting * entries to backing store. The offsets are: *,debug,kafka
Started SchemaSourceTask *-* producing to topic * resuming from seqno *,info,kafka
Started MockSourceTask at * with failure scheduled in * ms,debug,kafka
Triggering source task failure,debug,kafka
Started MockConnector with failure delay of * ms,debug,kafka
Triggering connector failure,debug,kafka
Creating single task for MockConnector,debug,kafka
Started MockSinkTask at * with failure scheduled in * ms,debug,kafka
Triggering sink task failure,debug,kafka
Started VerifiableSourceTask *-* producing to topic * resuming from seqno *,info,kafka
Starting KafkaBasedLog with topic ,info,kafka
Finished reading KafkaBasedLog for topic ,info,kafka
Started KafkaBasedLog for topic ,info,kafka
Stopping KafkaBasedLog for topic ,info,kafka
Failed to stop KafkaBasedLog producer,error,kafka
Failed to stop KafkaBasedLog consumer,error,kafka
Stopped KafkaBasedLog for topic ,info,kafka
Starting read to end log for topic *,trace,kafka
Error polling: ,error,kafka
Reading to end of offset log,trace,kafka
Reading to end of log offsets *,trace,kafka
* started execution,trace,kafka
Finished read to end log for topic *,trace,kafka
Unexpected exception in *,error,kafka
Created topic * on brokers at *,info,kafka
Found existing topic '*' on the brokers at *,debug,kafka
Unable to create topic(s) '*' since the brokers at * do not support the CreateTopics API. Falling back to assume topic(s) exist or will be auto-created by the broker.,debug,kafka
Not authorized to create topic(s) '*'. Falling back to assume topic(s) exist or will be auto-created by the broker.,debug,kafka
Not authorized to create topic(s) '*'. Falling back to assume topic(s) exist or will be auto-created by the broker.,debug,kafka
Creating Kafka admin client,info,kafka
Looking up Kafka cluster ID,debug,kafka
Kafka cluster version is too old to return cluster ID,info,kafka
Fetching Kafka cluster ID,debug,kafka
Kafka cluster ID: *,info,kafka
Thread * exiting with uncaught exception: ,error,kafka
Starting graceful shutdown of thread *,info,kafka
Forcing shutdown of thread *,info,kafka
Removing handle for * task in connector *,info,kafka
Created task * for connector *,info,kafka
"Task * saw * records, expected * records",debug,kafka
"Task * saw * records, expected * records",debug,kafka
Started * connector *,info,kafka
Stopped * connector *,info,kafka
Configured * connector *,info,kafka
Started * task * with properties *,info,kafka
Task * committing offsets,info,kafka
Committing record: *,trace,kafka
Stopped * task *,info,kafka
Starting connector *,info,kafka
Starting task *,debug,kafka
Opening * partitions,debug,kafka
Task * obtained record (key='*' value='*'),trace,kafka
preCommit was called with topic-partition * that is not included in the assignments of this task *,warn,kafka
Forwarding to framework request to commit additional * for *,error,kafka
Kafka did not shutdown gracefully,warn,kafka
Could not stop kafka,error,kafka
Started worker *,info,kafka
Stopping worker *,info,kafka
Worker * did not shutdown gracefully,warn,kafka
Could not stop connect,error,kafka
Starting Connect cluster '*' with * workers,info,kafka
Could not execute PUT request to ,error,kafka
Could not read connector list,error,kafka
Could not read connector state,error,kafka
Executing PUT request to URL=*. Payload=*,debug,kafka
PUT response for URL=* is *,info,kafka
PUT error response for URL=* is *,info,kafka
Executing GET request to URL=*.,debug,kafka
GET response for URL=* is *,debug,kafka
Executing DELETE request to URL=*,debug,kafka
Could not shutdown producer ,error,kafka
$$$Empty Message$$$,error,kafka
$$$Empty Message$$$,error,kafka
$$$Empty Message$$$,error,kafka
"Creating topic { name: *, partitions: *, replication: *, config: * }",debug,kafka
Consuming from * for * millis.,debug,kafka
Cannot transit to * within *ms,debug,kafka
State transition from * to *,info,kafka
All stream threads have died. The instance will be in error state and should be closed.,error,kafka
Global thread has died. The instance will be in error state and should be closed.,error,kafka
Negative cache size passed in. Reverting to cache size of 0 bytes.,warn,kafka
Starting Streams client,debug,kafka
"Stopping Streams client with timeoutMillis = * ms. You are using deprecated method. Please, consider update your code.",debug,kafka
"Already in the pending shutdown state, wait to complete shutdown",info,kafka
Streams client stopped completely,info,kafka
Streams client cannot stop completely within the timeout,info,kafka
Stopping Streams client with timeoutMillis = * ms.,debug,kafka
Using * default value of * as exactly once is enabled.commit.interval.ms100,debug,kafka
consumer,warn,kafka
consumer,warn,kafka
producer,warn,kafka
"Exception caught during Deserialization, taskId: *, topic: *, partition: *, offset: *",error,kafka
"Exception caught during Deserialization, taskId: *, topic: *, partition: *, offset: *",warn,kafka
Skipping record due to null key or value. key=[*] value=[*] topic=[*] partition=[*] offset=[*],warn,kafka
Skipping record due to null key. topic=[*] partition=[*] offset=[*],warn,kafka
"Detected out-of-order KTable update for * at offset *, partition *.",warn,kafka
Adding nodes to topology * child nodes *,debug,kafka
Optimizing the Kafka Streams graph for repartition nodes,debug,kafka
Marking KTable source nodes to optimize using source topic for changelogs ,debug,kafka
Found the child node of the key changer * from the repartition *.,debug,kafka
Removing * from *  children *,debug,kafka
Updated node * children *,debug,kafka
Skipping record due to null key. change=[*] topic=[*] partition=[*] offset=[*],warn,kafka
Using grace period of [*] as the suppress duration for node [*].,info,kafka
Skipping record due to null key or value. key=[*] value=[*] topic=[*] partition=[*] offset=[*],warn,kafka
Skipping record due to null key or value. key=[*] value=[*] topic=[*] partition=[*] offset=[*],warn,kafka
Skipping record due to null key. value=[*] topic=[*] partition=[*] offset=[*],warn,kafka
"Skipping record for expired window. key=[*] topic=[*] partition=[*] offset=[*] timestamp=[*] window=[*,*) expiration=[*] streamTime=[*]",debug,kafka
Skipping record due to null key. change=[*] topic=[*] partition=[*] offset=[*],warn,kafka
Skipping record due to null key. value=[*] topic=[*] partition=[*] offset=[*],warn,kafka
"Skipping record for expired window. key=[*] topic=[*] partition=[*] offset=[*] timestamp=[*] window=[*,*] expiration=[*] streamTime=[*]",debug,kafka
Skipping record due to null key or value. key=[*] value=[*] topic=[*] partition=[*] offset=[*],warn,kafka
Skipping record due to null key. change=[*] topic=[*] partition=[*] offset=[*],warn,kafka
Skipping record due to null key. change=[*] topic=[*] partition=[*] offset=[*],warn,kafka
Empty partitions for topic *,error,kafka
Input record * will be dropped because it has an invalid (negative) timestamp.,warn,kafka
$$$Empty Message$$$,error,kafka
Added restorer for changelog *,trace,kafka
Restoring StreamTasks failed. Deleting StreamTasks stores to recreate from scratch.,warn,kafka
Reinitializing StreamTask * for changelog *,info,kafka
Could not fetch end offset for *; will fall back to partition by partition fetching,debug,kafka
End offset cannot be found form the returned metadata; removing this partition from the current run loop,info,kafka
Start restoring state stores from changelog topics *,debug,kafka
Found checkpoint * from changelog * for store *.,trace,kafka
"Did not find checkpoint from changelog * for store *, rewinding to beginning.",trace,kafka
No checkpoint found for task * state store * changelog * with EOS turned on. Reinitializing the task and restore its state from the beginning.,info,kafka
Restoring task *'s state store * from beginning of the changelog * ,info,kafka
Restoring partition * from offset * to endOffset *,debug,kafka
"Could not fetch topic metadata within the timeout, will retry in the next run loop",debug,kafka
"Restored from * to * with * records, ending offset is *, next starting position is *",trace,kafka
nodeToSourceTopics *,debug,kafka
*updating builder with * topic(s) with possible matching regex subscription(s),debug,kafka
*found * topics possibly matching regex,debug,kafka
Unexpected state transition from * to *,error,kafka
State transition from * to *,info,kafka
Updating global state failed. You can restart KafkaStreams to recover from this error.,error,kafka
Failed to close global consumer due to the following error:,error,kafka
Error happened during initialization of the global state store; this thread has shutdown,warn,kafka
Shutting down,info,kafka
Failed to close state maintainer due to the following error:,error,kafka
Shutdown complete,info,kafka
Could not lock global state directory. This could happen if multiple KafkaStreams instances are running on the same host using the same state directory.,error,kafka
Source node * extracted timestamp * for record *,trace,kafka
Skipping record due to negative extracted timestamp. topic=[*] partition=[*] offset=[*] extractedTimestamp=[*] extractor=[*],warn,kafka
Pausing partitions: *,trace,kafka
Adding assigned tasks as active: *,debug,kafka
Failed to resume an active task * due to the following error:,error,kafka
Task * owned partitions * are not contained in the assignment *,warn,kafka
New active tasks to be created: *,trace,kafka
Adding assigned standby tasks *,debug,kafka
New standby tasks to be created: *,trace,kafka
Suspending all active tasks * and standby tasks *,debug,kafka
"Shutting down all active tasks *, standby tasks *, suspended tasks *, and suspended standby tasks *",debug,kafka
Resuming partitions *,trace,kafka
Previous delete-records request has failed: *. Try sending the new request now,debug,kafka
Sent delete-records request: *,trace,kafka
Checkpointable offsets read from checkpoint: *,trace,kafka
Created state store manager for task * with the acquired state dir lock,debug,kafka
Registering state store * to its state manager,debug,kafka
Preparing standby replica of persistent state store * with changelog topic *,trace,kafka
Restoring state store * from changelog topic * at checkpoint *,trace,kafka
Updating store offset limit for partition * to *,trace,kafka
Flushing all stores registered in the state manager,debug,kafka
Flushing store *,trace,kafka
Failed to flush state store *: ,error,kafka
Closing its state manager and all the registered state stores,debug,kafka
Closing storage engine *,debug,kafka
Failed to close state store *: ,error,kafka
Skipping to close non-initialized store *,info,kafka
Checkpointable offsets updated with restored offsets: *,trace,kafka
Checkpointable offsets updated with active acked offsets: *,trace,kafka
Writing checkpoint: *,trace,kafka
Failed to write offset checkpoint file to [*],warn,kafka
Register global stores *,debug,kafka
Failed to unlock the global state directory,error,kafka
Restoring state for global store *,info,kafka
Failed to get end offsets for topic partitions of global store * after * retry attempts. You can increase the number of retries via configuration parameter `retries`.,error,kafka
"Failed to get end offsets for partitions *, backing off for * ms to retry (attempt * of *)",debug,kafka
Failed to get partitions for topic * after * retry attempts due to timeout. The broker may be transiently unavailable at the moment. You can increase the number of retries via configuration parameter `retries`.,error,kafka
Failed to get partitions for topic * due to timeout. The broker may be transiently unavailable at the moment. Backing off for * ms to retry (attempt * of *),debug,kafka
Restoring GlobalStore * failed due to: *. Deleting global store to recreate from scratch.,warn,kafka
Flushing all global globalStores registered in the state manager,debug,kafka
Flushing global store=*,trace,kafka
Closing global storage engine *,debug,kafka
Failed to close global state store *,error,kafka
Skipping to close non-initialized store *,info,kafka
Failed to write offset checkpoint file to * for global stores: *,warn,kafka
Closing all restoring stream tasks *,trace,kafka
Closing restoring task *,debug,kafka
Failed to remove restoring task * due to the following error:,error,kafka
Stream task changelog partitions that have completed restoring so far: *,trace,kafka
Stream task * completed restoration as all its changelog partitions * have been applied to restore state,trace,kafka
Stream task * cannot resume processing yet since some of its changelog partitions have not completed restoring: *,trace,kafka
Committed active task * per user request in,debug,kafka
Failed to commit * since it got migrated to another thread already. Closing it as zombie before triggering a new rebalance.,info,kafka
Failed to commit StreamTask * due to the following error:,error,kafka
Failed to process stream task * since it got migrated to another thread already. Closing it as zombie before triggering a new rebalance.,info,kafka
Failed to process stream task * due to the following error:,error,kafka
Failed to punctuate stream task * since it got migrated to another thread already. Closing it as zombie before triggering a new rebalance.,info,kafka
Failed to punctuate stream task * due to the following error:,error,kafka
Downgrading metadata version from * to 1 for upgrade from 0.10.0.x.4,info,kafka
Downgrading metadata version from * to 2 for upgrade from *.x.4,info,kafka
$$$Empty Message$$$,error,kafka
$$$Empty Message$$$,error,kafka
$$$Empty Message$$$,error,kafka
$$$Empty Message$$$,error,kafka
"* is unknown yet during rebalance, please make sure they have been pre-created before starting the Streams application.",error,kafka
Received a future (version probing) subscription (version: *). Sending empty assignment back (with supported version *).4,info,kafka
Downgrading metadata to version *. Latest supported version is *.4,info,kafka
Constructed client metadata * from the member subscriptions.,debug,kafka
Missing source topic * durign assignment. Returning error *.,error,kafka
Created repartition topics * from the parsed topology.,debug,kafka
Partition * is assigned to more than one tasks: *,warn,kafka
"Partition * is not assigned to any tasks: * Possible causes of a partition not getting assigned is that another topic defined in the topology has not been created when starting your streams application, resulting in no tasks created for this topology at all.",warn,kafka
No partitions found for topic *,warn,kafka
No tasks found for topic group *,debug,kafka
Created state changelog topics * from the parsed topology.,debug,kafka
Assigning tasks * to clients * with number of replicas *,debug,kafka
Assigned tasks to clients as *.,info,kafka
Sent a version * subscription and got version * assignment back (successful version probing). Downgrading subscription metadata to received version and trigger new rebalance.,info,kafka
Sent a version * subscription and got version * assignment back (successful version probing). Setting subscription metadata to leaders supported version * and trigger new rebalance.,info,kafka
Sent a version * subscription and group leader's latest supported version is *. Upgrading subscription metadata version to * for next rebalance.,info,kafka
Sent a version * subscription and group leader's latest supported version is *. Upgrading subscription metadata version to * for next rebalance.,info,kafka
Starting to validate internal topics * in partition assignor.,debug,kafka
Completed validating internal topics * in partition assignor.,debug,kafka
$$$Empty Message$$$,error,kafka
Initializing state stores,trace,kafka
Resuming,debug,kafka
Start processing one record [*],trace,kafka
Completed processing one record [*],trace,kafka
Encountered error extracting stacktrace from this exception,error,kafka
Punctuating processor * with timestamp * and punctuation type *,trace,kafka
Committing,debug,kafka
Flushing state and producer,trace,kafka
Initializing processor nodes of the topology,trace,kafka
Suspending,debug,kafka
Failed to close producer due to the following error:,error,kafka
Closing processor topology,trace,kafka
Could not close state manager due to the following error:,error,kafka
Closing,debug,kafka
Could not close task due to the following error:,error,kafka
"Added records into the buffered queue of partition *, new queue size is *",trace,kafka
"Timeout exception caught when initializing transactions for task *. This might happen if the broker is slow to respond, if the network connection to the broker was interrupted, or if similar circumstances arise. You can increase producer parameter `max.block.ms` to increase this timeout.",error,kafka
Initializing *s *,debug,kafka
Transitioning * * to restoring,debug,kafka
Could not create * * due to *; will retry,trace,kafka
Suspending running * *,trace,kafka
Close created * *,trace,kafka
"Failed to close *, *",error,kafka
Failed to suspend * * since it got migrated to another thread already. Closing it as zombie and move on.,info,kafka
Suspending * * failed due to the following error:,error,kafka
"After suspending failed, closing the same * * failed again due to the following error:",error,kafka
Failed to close zombie * * due to *; ignore and proceed.,warn,kafka
Found suspended * *,trace,kafka
Failed to resume * * since it got migrated to another thread already. Closing it as zombie before triggering a new rebalance.,info,kafka
Resuming suspended * *,trace,kafka
"Couldn't resume task * assigned partitions *, task partitions *",warn,kafka
Transitioning * * to running,debug,kafka
Failed to commit * * since it got migrated to another thread already. Closing it as zombie before triggering a new rebalance.,info,kafka
Failed to commit * * due to the following error:,error,kafka
Closing suspended and not re-assigned * *,debug,kafka
Failed to remove suspended * * due to the following error:,error,kafka
Failed to close * * since it got migrated to another thread already. Closing it as zombie and move on.,info,kafka
Failed while closing * * due to the following error:,error,kafka
Try to close * * unclean.,info,kafka
Failed while closing * * due to the following error:,error,kafka
Deserialization error callback failed after deserialization error for record *,error,kafka
Skipping record due to deserialization error. topic=[*] partition=[*] offset=[*],warn,kafka
Failed to write offset checkpoint file to * while re-initializing *: *,error,kafka
Failed to reinitialize store *.,error,kafka
Failed to reinitialize store *.,error,kafka
Updating store offset limits * for changelog *,trace,kafka
Initializing state stores,trace,kafka
Initializing store *,trace,kafka
Closing state manager,trace,kafka
Initializing state stores,trace,kafka
Resuming,debug,kafka
Committing,trace,kafka
Suspending,debug,kafka
Closing,debug,kafka
Updating standby replicas of its state store for partition [*],trace,kafka
* Found cached state dir lock for task *,trace,kafka
* Acquired state dir lock for task *,debug,kafka
* Found cached state dir lock for the global task,trace,kafka
* Acquired global state dir lock,debug,kafka
* Released global state dir lock,debug,kafka
* Released state dir lock for task *,debug,kafka
* Failed to delete global state directory due to an unexpected exception,error,kafka
* Deleting obsolete state directory * for task * as *ms has elapsed (cleanup delay is *ms).,info,kafka
* Deleting state directory * for task * as user calling cleanup.,info,kafka
* Failed to get the state directory lock.,error,kafka
* Failed to delete the state directory.,error,kafka
* Failed to release the state directory lock.,error,kafka
Unexpected state transition from * to *,error,kafka
State transition from * to *,info,kafka
at state *: partitions * assigned at the end of consumer rebalance. 	current suspended active tasks: * 	current suspended standby tasks: * ,debug,kafka
Received error code * - shutdown,error,kafka
"Error caught during partition assignment, will abort the current process and re-throw at the end of rebalance: *",error,kafka
partition assignment took * ms. 	current active tasks: * 	current standby tasks: * 	previous active tasks: * ,info,kafka
at state *: partitions * revoked at the beginning of consumer rebalance. 	current assigned active tasks: * 	current assigned standby tasks: * ,debug,kafka
"Error caught during partition revocation, will abort the current process and re-throw at the end of rebalance: *",error,kafka
partition revocation took * ms. 	suspended active tasks: * 	suspended standby tasks: *,info,kafka
Created task * with assigned partitions *,trace,kafka
Creating producer client for task *,info,kafka
Failed to close producer due to the following error:,error,kafka
Skipped standby task * with assigned partitions * since it does not have any state stores to materialize,trace,kafka
Creating restore consumer client,info,kafka
Creating shared producer client,info,kafka
Creating consumer client,info,kafka
Starting,info,kafka
StreamThread already shutdown. Not running,info,kafka
"Encountered the following unexpected Kafka exception during processing, this usually indicate Streams internal errors:",error,kafka
Encountered the following error during processing:,error,kafka
Version probing detected. Triggering new rebalance.,info,kafka
Detected task * that got migrated to another thread. This implies that this thread missed a rebalance and dropped out of the consumer group. Will try to rejoin the consumer group. Below is the detailed description of the task: *,warn,kafka
Unexpected state * during normal iteration,error,kafka
$$$Empty Message$$$,info,kafka
Unable to locate active task for received-record partition *. Current tasks: *,error,kafka
"Stream task * is already closed, probably because it got unexpectedly migrated to another thread already. Notifying the thread to trigger a new rebalance immediately.",info,kafka
Committing all active tasks * and standby tasks * since *ms has elapsed (commit interval is *ms),trace,kafka
Committed all active tasks * and standby tasks * in *ms,debug,kafka
"Standby task * is already closed, probably because it got unexpectedly migrated to another thread already. Notifying the thread to trigger a new rebalance immediately.",info,kafka
Updated standby tasks * in *ms,debug,kafka
"Standby task * is already closed, probably because it got unexpectedly migrated to another thread already. Notifying the thread to trigger a new rebalance immediately.",info,kafka
Updating StandbyTasks failed. Deleting StandbyTasks stores to recreate from scratch.,warn,kafka
"Standby task * is already closed, probably because it got unexpectedly migrated to another thread already. Notifying the thread to trigger a new rebalance immediately.",info,kafka
Reinitializing StandbyTask * from changelogs *,info,kafka
Informed to shut down,info,kafka
Shutting down,info,kafka
Failed to close task manager due to the following error:,error,kafka
Failed to close consumer due to the following error:,error,kafka
Failed to close restore consumer due to the following error:,error,kafka
Shutdown complete,info,kafka
$$$Empty Message$$$,error,kafka
Failed message: key * value * timestamp *,trace,kafka
Error sending record to topic * due to *; No more records will be sent and no more offsets will be recorded for this task. Enable TRACE logging to view failed record key and value.,warn,kafka
Failed message: (key * value * timestamp *) topic=[*] partition=[*],trace,kafka
Error sending records topic=[*] and partition=[*]; The exception handler chose to CONTINUE processing in spite of this error. Enable TRACE logging to view failed messages key and value.,warn,kafka
Failed message: (key * value * timestamp *) topic=[*] partition=[*],trace,kafka
"Timeout exception caught when sending record to topic *. This might happen if the producer cannot send data to the Kafka cluster and thus, its internal buffer fills up. This can also happen if the broker is slow to respond, if the network connection to the broker was interrupted, or if similar circumstances arise. You can increase producer parameter `max.block.ms` to increase this timeout.",error,kafka
Flushing producer,debug,kafka
Closing producer,debug,kafka
	* = *retriesreplication.factorwindowstore.changelog.additional.retention.ms,debug,kafka
Going to create topic * with * partitions and config *.,debug,kafka
Thread got interrupted. This indicates a bug. Please report at https://issues.apache.org/jira/projects/KAFKA or dev-mailing list (https://kafka.apache.org/contact).,error,kafka
Could not create topic *. Topic is probably marked for deletion (number of partitions is unknown). Will retry to create this topic in * ms (to let broker finish async delete operation first). Error message was: *,info,kafka
Unexpected error during topic creation for *. Error message was: *,error,kafka
Topics * can not be made ready with * retries left,info,kafka
$$$Empty Message$$$,error,kafka
Trying to check if topics * have been created with expected number of partitions.,debug,kafka
Thread got interrupted. This indicates a bug. Please report at https://issues.apache.org/jira/projects/KAFKA or dev-mailing list (https://kafka.apache.org/contact).,error,kafka
"Topic * is unknown or not found, hence not existed yet.",debug,kafka
Unexpected error during topic description for *. Error message was: *,error,kafka
$$$Empty Message$$$,error,kafka
$$$Empty Message$$$,error,kafka
Unable to assign * of * standby tasks for task [*]. There is not enough available capacity. You should increase the number of threads and/or application instances to maintain the requested number of standby replicas.,warn,kafka
Unable to decode subscription data: used version: *; latest supported version: *4,info,kafka
The default close will be removed in 3.0.0 -- you should overwrite it if you have implemented RocksDBConfigSetter,warn,kafka
Returning empty iterator for fetch with invalid key range: from > to. This may be due to serdes that don't preserve ordering when lexicographically comparing the serialized bytes. Note that the built-in numerical serdes do not follow this for negative numbers,warn,kafka
Returning empty iterator for fetch with invalid key range: from > to. This may be due to serdes that don't preserve ordering when lexicographically comparing the serialized bytes. Note that the built-in numerical serdes do not follow this for negative numbers,warn,kafka
Returning empty iterator for fetch with invalid key range: from > to. This may be due to serdes that don't preserve ordering when lexicographically comparing the serialized bytes. Note that the built-in numerical serdes do not follow this for negative numbers,warn,kafka
Skipping record for expired segment.,debug,kafka
Warning: window end time was truncated to Long.MAX,warn,kafka
Opening store * in upgrade mode,info,kafka
Opening store * in regular mode,info,kafka
Opening store * in upgrade mode,info,kafka
"Cache stats on flush: #puts=*, #gets=*, #evicts=*, #flushes=*",trace,kafka
Evicted * entries from cache *,trace,kafka
Error destroying *,error,kafka
Unable to parse segmentName * to a date. This segment will be skipped,warn,kafka
Returning empty iterator for fetch with invalid key range: from > to. This may be due to serdes that don't preserve ordering when lexicographically comparing the serialized bytes. Note that the built-in numerical serdes do not follow this for negative numbers,warn,kafka
"Named cache * stats on flush: #hits=*, #misses=*, #overwrites=*, #flushes=*",trace,kafka
Returning empty iterator for fetch with invalid key range: from > to. This may be due to serdes that don't preserve ordering when lexicographically comparing the serialized bytes. Note that the built-in numerical serdes do not follow this for negative numbers,warn,kafka
Skipping record for expired segment.,warn,kafka
Returning empty iterator for fetch with invalid key range: from > to. This may be due to serdes that don't preserve ordering when lexicographically comparing the serialized bytes. Note that the built-in numerical serdes do not follow this for negative numbers,warn,kafka
Closing * open iterators for store *,warn,kafka
Warning: window end time was truncated to Long.MAX,warn,kafka
Skipping record for expired segment.,debug,kafka
Returning empty iterator for fetch with invalid key range: from > to. This may be due to serdes that don't preserve ordering when lexicographically comparing the serialized bytes. Note that the built-in numerical serdes do not follow this for negative numbers,warn,kafka
Closing * open iterators for store *,warn,kafka
Returning empty iterator for fetch with invalid key range: from > to. This may be due to serdes that don't preserve ordering when lexicographically comparing the serialized bytes. Note that the built-in numerical serdes do not follow this for negative numbers,warn,kafka
Returning empty iterator for fetch with invalid key range: from > to. This may be due to serdes that don't preserve ordering when lexicographically comparing the serialized bytes. Note that the built-in numerical serdes do not follow this for negative numbers,warn,kafka
Closing * open iterators for store *,warn,kafka
Initiating embedded Kafka cluster startup,debug,kafka
Starting a ZooKeeper instance,debug,kafka
ZooKeeper instance is running at *,debug,kafka
"Kafka instance is running at *, connected to ZooKeeper at *",debug,kafka
Starting embedded Kafka broker (with log.dirs=* and ZK ensemble at *) ...,debug,kafka
Startup of embedded Kafka broker at * completed (with ZK ensemble at *) ...,debug,kafka
Shutting down embedded Kafka broker at * (with ZK ensemble at *) ...,debug,kafka
Removing log dir at * ...,debug,kafka
Shutdown of embedded Kafka broker at * completed (with ZK ensemble at *) ...,debug,kafka
"Creating topic { name: *, partitions: *, replication: *, config: * }",debug,kafka
Deleting topic { name: * },debug,kafka
$$$Empty Message$$$,info,kafka
Configured PushHttpMetricsReporter for * to report every * seconds,info,kafka
Adding metric *,debug,kafka
Updating metric *,debug,kafka
Removing metric *,debug,kafka
Reporting * metrics to *,trace,kafka
"Error reporting metrics, *: *",error,kafka
"PushHttpMetricsReporter does not currently support redirects, saw *",error,kafka
Finished reporting metrics with response code *,info,kafka
Error reporting metrics,error,kafka
"Caught WakeupException because consumer is shutdown, ignore and terminate.",trace,kafka
"Error during processing, terminating consumer process: ",error,kafka
Starting agent process.,info,kafka
"*: Ignoring request to create worker *, because there is already a worker with that id.",info,kafka
*: Will not run worker * as it has expired.,info,kafka
*: Worker * start() exception,info,kafka
*: request conflict while creating worker * for task * with spec *.,info,kafka
*: Error creating worker * for task * with spec *,info,kafka
*: Created worker * with spec *,info,kafka
"*: unable to create worker * for task *, with spec *",info,kafka
*: Worker * was cancelled while it was starting up.  Transitioning to STOPPING.,info,kafka
*: Worker * is now RUNNING.  Scheduled to stop in * ms.,info,kafka
*: Worker * * during startup.  Transitioning to DONE.,info,kafka
*: Worker * * during startup.  Transitioning to CANCELLING.,info,kafka
*: Cancelling worker * *.  ,info,kafka
*: Running worker * *.  Transitioning to STOPPING.,info,kafka
*: Stopping worker * *.,info,kafka
*: Can't halt worker * because it is already DONE.,info,kafka
*: destroying worker * with error *,info,kafka
*: completed worker * with error *,info,kafka
*: Can't stop worker * because there is no worker with that ID.,info,kafka
*: Cancelling worker * during its startup process.,info,kafka
"*: Can't stop worker *, because it is already being cancelled.",info,kafka
*: Stopping running worker *.,info,kafka
"*: Can't stop worker *, because it is already stopping.",info,kafka
*: destroying worker * with error *,info,kafka
"*: Can't stop worker *, because it is already done.",debug,kafka
*: worker.stop() exception,error,kafka
*: Shutting down WorkerManager.,info,kafka
*: Waiting for shutdownManager quiescence...,info,kafka
*: Waiting for workerCleanupExecutor to terminate...,info,kafka
*: Waiting for stateChangeExecutor to terminate...,info,kafka
*: Shutting down shutdownExecutor.,info,kafka
*: Caught exception while shutting down WorkerManager,info,kafka
*: Destroying all workers.,info,kafka
Failed to stop worker *,error,kafka
RUN: *. RESULT: [*],info,kafka
RUN: *. ERROR: [*],info,kafka
* caught an exception,warn,kafka
Failed to create or verify topics *,warn,kafka
Request to create topics has an empty topic list.,warn,kafka
Topic(s) * already exist.,warn,kafka
Attempting to create * topics (try *)...,info,kafka
Successfully created *.,debug,kafka
Attempt to create topic `*` failed: *,warn,kafka
Topic * already exists.,info,kafka
Failed to create *,warn,kafka
$$$Empty Message$$$,warn,kafka
$$$Empty Message$$$,warn,kafka
*: error creating worker *.,error,kafka
*: error stopping worker *.,error,kafka
*: failed to get agent status: ConnectException *,error,kafka
*: failed to get agent status,error,kafka
*: got heartbeat status *,trace,kafka
*: Unhandled exception in NodeHeartbeatRunnable,error,kafka
*: scheduling unknown worker with ID * for stopping.,warn,kafka
*: worker state is still *,debug,kafka
*: worker state changed from * to *,info,kafka
*: there is already a worker * with ID *.,error,kafka
*: scheduling worker * to start.,info,kafka
*: unable to locate worker to stop with ID *.,error,kafka
*: Worker * is already scheduled to stop.,error,kafka
*: scheduling worker * to stop.,info,kafka
*: unable to locate worker to destroy with ID *.,error,kafka
*: Failed to send shutdown request,error,kafka
Created TaskManager for agent(s) on: *,info,kafka
"createTask(id=*, spec=*) error",info,kafka
Task * already exists with spec *,info,kafka
Failed to create a new task * with spec *: *,info,kafka
"Created a new task * with spec *, scheduled to start * ms from now.",info,kafka
"Can't start task *, because it is already in state *.",info,kafka
Unable to find nodes for task *,error,kafka
Running task * on node(s): *,info,kafka
stopTask(id=*) error,info,kafka
Can't cancel non-existent task *.,info,kafka
Stopped pending task *.,info,kafka
Task * is now complete with no errors.,info,kafka
Task * is now complete with error: *,info,kafka
Cancelling task * with worker(s) *,info,kafka
Can't cancel task * because it is already stopping.,info,kafka
Can't cancel task * because it is already done.,info,kafka
destroyTask(id=*) error,info,kafka
Can't destroy task *: no such task found.,info,kafka
Destroying task *.,info,kafka
Task *: Updating worker state for * on * from * to *.,debug,kafka
Error updating worker state for * on *.  Stopping worker.,error,kafka
*: task * stopped with error *.  Stopping worker(s): *,info,kafka
Starting coordinator process.,info,kafka
Activating ProcessStopFault *.,info,kafka
Deactivating ProcessStopFault *.,info,kafka
Failed to parse process ID from line *,error,kafka
*: no processes containing * found to send * to.,error,kafka
*: sending * to * pid(s) *,info,kafka
Activating DegradedNetworkFaultWorker *.,info,kafka
Deactivating DegradedNetworkFaultWorker *.,info,kafka
Activating * *: *.,info,kafka
Deactivating * *: *.,info,kafka
Activating NetworkPartitionFault *.,info,kafka
Deactivating NetworkPartitionFault *.,info,kafka
Uncaught exception in REST call: ,debug,kafka
Uncaught exception in REST call: *,info,kafka
Starting REST server,info,kafka
Registered resource *,info,kafka
Sending * with input * to *,debug,kafka
* *: error: *,info,kafka
*: Activating NoOpTask.,info,kafka
*: Deactivating NoOpTask.,info,kafka
*: Activating RoundTripWorker.,info,kafka
*: Starting RoundTripWorker#ProducerRunnable.,debug,kafka
*: ProducerRunnable is exiting.  messagesSent=*; uniqueMessagesSent=*; ackedSends=*/*.,info,kafka
"*: consumer waiting for * message(s), starting with: *",info,kafka
*: Starting RoundTripWorker#ConsumerRunnable.,debug,kafka
*: Consumer received the full count of * unique messages.  Waiting for all * sends to be acked...,info,kafka
*: all sends have been acked.,info,kafka
*: Consumer got WakeupException,debug,kafka
*: Consumer got TimeoutException,debug,kafka
*: ConsumerRunnable is exiting.  Invoked poll * time(s).  messagesReceived = *; uniqueMessagesReceived = *.,info,kafka
*: Deactivating RoundTripWorker.,info,kafka
*: Deactivated RoundTripWorker.,info,kafka
*: Activating ConnectionStressWorker with *,info,kafka
*: Deactivating ConnectionStressWorker.,info,kafka
*: Activating ProduceBenchWorker with *,info,kafka
SendRecordsCallback: error,error,kafka
Sent * total record(s) in * ms.  status: *,info,kafka
Beginning transaction.,debug,kafka
Committing transaction.,debug,kafka
Aborting transaction.,debug,kafka
*: Deactivating ProduceBenchWorker.,info,kafka
*: Activating ConsumeBenchWorker with *,info,kafka
Will consume from topics * via dynamic group assignment.,info,kafka
Will consume from topic partitions * via manual assignment.,info,kafka
"* Consumed total number of messages=*, bytes=* in * ms.  status: *",info,kafka
* was interrupted. Closing...,debug,kafka
Status=*,info,kafka
*: Deactivating ConsumeBenchWorker.,info,kafka
*: Activating ExternalCommandWorker with *,info,kafka
*: Unable to start process,error,kafka
*: starting stdout monitor.,trace,kafka
*: can't read any more from stdout: *,info,kafka
*: read line from stdin: *,trace,kafka
*: error: *,error,kafka
*: error reading from stdout.,info,kafka
*: starting stderr monitor.,trace,kafka
*: can't read any more from stderr: *,info,kafka
*: (stderr):*,error,kafka
*: error reading from stderr.,info,kafka
*: stdin writer ready.,info,kafka
*: StdinWriter terminating.,trace,kafka
*: writing to stdin: *,info,kafka
*: can't write any more to stdin: *,info,kafka
*: error writing to stdin.,info,kafka
*: error closing stdinWriter: *,debug,kafka
*: process exited with return code *,info,kafka
*: ExitMonitor error,error,kafka
*: destroying process,info,kafka
*: forcibly destroying process,info,kafka
*: closing Terminator thread.,trace,kafka
*: Terminator error,error,kafka
*: Deactivating ExternalCommandWorker.,info,kafka
RAN *: *,debug,kafka
Creating MiniTrogdorCluster with agents: * and coordinator: *,info,kafka
Closing MiniTrogdorCluster.,info,kafka
"Applying SetSchemaMetadata SMT. Original schema: *, updated schema: *",trace,kafka
Cast field '*' from '*' to '*',trace,kafka
New skip list,trace,Zookeeper
"addMark (time: | , bytes:  | , skipped:  | )",trace,Zookeeper
findMarkBefore( | ),trace,Zookeeper
return ,trace,Zookeeper
Opened file( | ) with FD ( | ),debug,Zookeeper
Opened file( | ) coulds get FD,debug,Zookeeper
fill(buffer= | ),debug,Zookeeper
"read(buf, off= | , len=",trace,Zookeeper
tocopy=,trace,Zookeeper
read=,trace,Zookeeper
seek( | ),debug,Zookeeper
Unknown op: ,info,Zookeeper
Error reading transaction from ( | ) :,error,Zookeeper
size() called,trace,Zookeeper
saved pos () = ,trace,Zookeeper
size() = ,trace,Zookeeper
Error reading next entry in file ( | ): ,error,Zookeeper
"handle(start=  | , end= | , period= | )",debug,Zookeeper
"handle(start=  | , end= | , numEntries= | )",debug,Zookeeper
Session '%s' expired after  | '%d' milliseconds.,info,Zookeeper
Interrupted while closing ZooKeeper connection.,error,Zookeeper
creating new  | connection for : '%s',info,Zookeeper
Unable to find the keystore file: ,error,Zookeeper
Unable to load keystore: ,error,Zookeeper
Failed while trying to create a new session,error,Zookeeper
Error occurred loading ZooInspector,error,Zookeeper
$$$Empty Message$$$,warn,Zookeeper
"Error loading about.html, file may be corrupt",error,Zookeeper
An Error occurred loading connection properties from file,error,Zookeeper
An Error occurred saving the default connection properties file,error,Zookeeper
Error loading default node viewers.,error,Zookeeper
Error occurred while connecting to ZooKeeper server,error,Zookeeper
Error occurred while connecting to ZooKeeper server,error,Zookeeper
Error occurred while disconnecting from ZooKeeper server,error,Zookeeper
Error occurred while disconnecting from ZooKeeper server,error,Zookeeper
Error occurred while disconnecting from ZooKeeper server,error,Zookeeper
Error instantiating class: ,error,Zookeeper
An error occurred while instaniating the node viewer. ,error,Zookeeper
Error saving node viewer configuration from file.,error,Zookeeper
Error loading node viewer configuration from file.,error,Zookeeper
Error setting default node viewer configuration.,error,Zookeeper
Error retrieving meta data for node: ,error,Zookeeper
Error retrieving meta data for node: ,error,Zookeeper
Error retrieving ACL Information for node: ,error,Zookeeper
Error retrieving ACL Information for node: ,error,Zookeeper
Error retrieving data for node: ,error,Zookeeper
Error retrieving data for node: ,error,Zookeeper
Error occurred retrieving child of node: ,error,Zookeeper
Error occurred retrieving child  | of node: ,error,Zookeeper
Error occurred while disconnecting from ZooKeeper server,error,Zookeeper
Error occurred getting data for node: ,error,Zookeeper
Error occurred retrieving ACLs of node: ,error,Zookeeper
Error occurred retrieving ACLs of node: ,error,Zookeeper
Error occurred retrieving meta data for node: ,error,Zookeeper
Error occurred getting the number of children of node: ,error,Zookeeper
Error occurred determining whether node is allowed children: ,error,Zookeeper
Error occurred retrieving session meta data.,error,Zookeeper
Error occurred creating node:  | /,error,Zookeeper
Error occurred deleting node: ,error,Zookeeper
Error occurred setting data for node: ,error,Zookeeper
Error occurred adding node watcher for node: ,error,Zookeeper
Error occurred re-adding node watcherfor node ,error,Zookeeper
List of default node viewers is empty,warn,Zookeeper
ZooKeeper connection lost.  Trying to reconnect.,warn,Zookeeper
ZooKeeper connection lost.  Trying to reconnect.,warn,Zookeeper
ZooKeeper connection lost.  Trying to reconnect.,warn,Zookeeper
ZooKeeper connection lost.  Trying to reconnect.,warn,Zookeeper
ZooKeeper connection lost.  Trying to reconnect.,warn,Zookeeper
ZooKeeper connection lost.  Trying to reconnect.,warn,Zookeeper
ZooKeeper connection lost.  Trying to reconnect.,warn,Zookeeper
ZooKeeper connection lost.  Trying to reconnect.,warn,Zookeeper
ZooKeeper connection lost.  Trying to reconnect.,warn,Zookeeper
ZooKeeper connection lost.  Trying to reconnect.,warn,Zookeeper
ZooKeeper connection lost.  Trying to reconnect.,warn,Zookeeper
ZooKeeper connection lost.  Trying to reconnect.,warn,Zookeeper
"Initializing metrics, configuration: *",info,Zookeeper
Starting /metrics HTTP endpoint at port * exportJvmInfo: *,info,Zookeeper
Cannot start /metrics server,error,Zookeeper
Cannot safely stop Jetty server,error,Zookeeper
invalid delta * for metric *,error,Zookeeper
invalid delta * for metric *,error,Zookeeper
invalid value * for metric * with key *,error,Zookeeper
Starting leader election support,info,Zookeeper
Stopping leader election support,info,Zookeeper
Removed leader offer *,info,Zookeeper
Created leader offer *,debug,Zookeeper
There are * leader offers. I am * in line.,debug,Zookeeper
* not elected leader. Watching node: *,info,Zookeeper
We're behind * in line and they're alive. Keeping an eye on them.,debug,Zookeeper
We were behind * but it looks like they died. Back to determination.,info,Zookeeper
Becoming leader with node: *,info,Zookeeper
Failed in state *,error,Zookeeper
Node * deleted. Need to run through the election process.,debug,Zookeeper
Dispatching event: *,debug,Zookeeper
Number format exception for *.,warn,Zookeeper
Array out of bounds for *.,warn,Zookeeper
Session expired *. Reconnecting...,warn,Zookeeper
Attempt * failed with connection loss. Reconnecting...,debug,Zookeeper
Unexpected exception,warn,Zookeeper
Failed to sleep.,warn,Zookeeper
Unexpected exception,warn,Zookeeper
Unexpected exception,warn,Zookeeper
Watcher fired: *,debug,Zookeeper
Failed to acquire lock,warn,Zookeeper
Found id created last time: *,debug,Zookeeper
Created id: *,debug,Zookeeper
No children in: * when we've just created one! Lets recreate it...,warn,Zookeeper
Watching less than me node: *,debug,Zookeeper
Could not find the stats for less than me: *,warn,Zookeeper
Found child node with improper name: *,warn,Zookeeper
Found child node with improper format : *,warn,Zookeeper
Unexpected exception,warn,Zookeeper
Found child node with improper name: *,warn,Zookeeper
Found child node with improper format : *,warn,Zookeeper
Watcher fired: *,debug,Zookeeper
We are triggering an exists watch for delete! Shouldn't happen!,warn,Zookeeper
$$$Empty Message$$$,error,Zookeeper
"Initiating client connection, connectString=* sessionTimeout=* watcher=*",info,Zookeeper
"Initiating client connection, connectString=* sessionTimeout=* watcher=* sessionId=0x* sessionPasswd=*",info,Zookeeper
Close called on already closed client,debug,Zookeeper
Closing session: 0x,debug,Zookeeper
Ignoring unexpected exception during close,debug,Zookeeper
Session: 0x* closed,info,Zookeeper
Unexpected exception,error,Zookeeper
Unexpected exception,error,Zookeeper
unknown type ,warn,Zookeeper
"Could not login: the * is being asked for a password, but the ZooKeeper * code does not currently support obtaining a password from the user. Make sure that the * is configured to use a ticket cache (using the JAAS configuration setting 'useTicketCache=true)' and restart the *. If you still get this message after that, the TGT in the ticket cache has expired and must be manually refreshed. To do so, first determine if you are using a password or a keytab. If the former, run kinit in a Unix shell in the environment of the user who is running this Zookeeper * using the command 'kinit <princ>' (where <princ> is the name of the *'s Kerberos principal). If the latter, do 'kinit -k -t <keytab> <princ>' (where <princ> is the name of the Kerberos principal, and <keytab> is the location of the keytab file). After manually refreshing your cache, restart this *. If you continue to see this message after manually refreshing your cache, ensure that your KDC host's clock is in sync with this host's clock.",warn,Zookeeper
Unexpected exception,warn,Zookeeper
Event thread exiting due to interruption,error,Zookeeper
EventThread shut down for session: 0x*,info,Zookeeper
Error while calling watcher ,error,Zookeeper
Somehow a null cb got to EventThread!,warn,Zookeeper
Unexpected throwable,error,Zookeeper
Got ping response for session id: 0x* after *ms.,debug,Zookeeper
Got auth session id: 0x*,debug,Zookeeper
Got notification session id: 0x*,debug,Zookeeper
Got server path * which is too short for chroot path *.,warn,Zookeeper
Got * for session id 0x*,debug,Zookeeper
"Reading reply session id: 0x*, packet:: *",debug,Zookeeper
"Socket connection established, initiating session, client: *, server: *",info,Zookeeper
Session establishment request sent on *,debug,Zookeeper
Unexpected exception,warn,Zookeeper
"SASL configuration failed. Will continue connection to Zookeeper server without SASL authentication, if Zookeeper server allows it.",warn,Zookeeper
Opening socket connection to server *.,info,Zookeeper
SASL config status: *,info,Zookeeper
SASL authentication with Zookeeper Quorum member failed.,error,Zookeeper
$$$Empty Message$$$,warn,Zookeeper
An exception was thrown while closing send thread for session 0x*.,warn,Zookeeper
"Session 0x* for sever *, Closing socket connection. Attempting reconnect except it is a SessionExpiredException.",warn,Zookeeper
Checking server * for being r/w. Timeout *,info,Zookeeper
Exception while seeking for r/w server.,warn,Zookeeper
Unexpected exception,warn,Zookeeper
Unexpected exception,warn,Zookeeper
$$$Empty Message$$$,warn,Zookeeper
Read/write client got connected to read-only server,error,Zookeeper
"Session establishment complete on server *, session id = 0x*, negotiated timeout = **",info,Zookeeper
Disconnecting client for session: 0x*,debug,Zookeeper
Got interrupted while waiting for the sender thread to close,warn,Zookeeper
Closing client for session: 0x*,debug,Zookeeper
Timeout error occurred for the packet '*'.,error,Zookeeper
* value is *. feature enabled=*zookeeper.request.timeout,info,Zookeeper
Configured value * for property * can not be parsed to long.zookeeper.request.timeout,error,Zookeeper
$$$Empty Message$$$,info,Zookeeper
"Could not parse config * ""*"" into a boolean using default *zookeeper.sasl.client.canonicalize.hostname",warn,Zookeeper
Canonicalized address to *,debug,Zookeeper
TGT refresh thread started.,info,Zookeeper
No TGT found: will try again at *,warn,Zookeeper
"The TGT cannot be renewed beyond the next expiry date: *.This process will not be able to authenticate new SASL connections after that time (for example, it will not be authenticate a new connection with a Zookeeper Quorum member).  Ask your system administrator to either increase the 'renew until' time by doing : 'modprinc -maxrenewlife *' within kadmin, or instead, to generate a keytab for *. Because the TGT's expiry cannot be further extended by refreshing, exiting refresh thread now.",error,Zookeeper
TGT refresh thread time adjusted from : * to : * since the former is sooner than the minimum refresh interval (* seconds) from now.60,warn,Zookeeper
next refresh: * is later than expiry *. This may indicate a clock skew problem. Check that this host and the KDC's hosts' clocks are in sync. Exiting refresh thread.,error,Zookeeper
refreshing now because expiry is before next scheduled refresh time.,info,Zookeeper
TGT refresh sleeping until: *,info,Zookeeper
TGT renewal thread has been interrupted and will exit.,warn,Zookeeper
nextRefresh:* is in the past: exiting refresh thread. Check clock sync between this host and KDC - (KDC's clock is likely ahead of this host). Manual intervention will be required for this client to successfully authenticate. Exiting refresh thread.,error,Zookeeper
running ticket cache refresh command: * *,debug,Zookeeper
"Interrupted while renewing TGT, exiting Login thread",error,Zookeeper
Could not renew TGT due to problem running shell command: '* *'. Exiting refresh thread.,warn,Zookeeper
Interrupted during login retry after LoginException:,error,Zookeeper
Could not refresh TGT for principal: *.,error,Zookeeper
Failed to refresh TGT: refresh thread exiting now.,error,Zookeeper
error while waiting for Login thread to shutdown.,warn,Zookeeper
* successfully logged in.,info,Zookeeper
TGT valid starting at:        *,info,Zookeeper
TGT expires:                  *,info,Zookeeper
"Client principal is ""*"".",debug,Zookeeper
"Server principal is ""*"".",debug,Zookeeper
Not attempting to re-login since the last re-login was attempted less than * seconds before.60,warn,Zookeeper
Initiating logout for *,info,Zookeeper
Initiating re-login for *,info,Zookeeper
Deleting tree: *,debug,Zookeeper
Deleting tree: *,debug,Zookeeper
future isn't success.,warn,Zookeeper
connect attempt cancelled,info,Zookeeper
channel is connected: *,info,Zookeeper
channel is told closing,info,Zookeeper
SSL handler added for channel: *,info,Zookeeper
channel is disconnected: *,info,Zookeeper
Unexpected throwable,error,Zookeeper
readConnectResult * *,trace,Zookeeper
Connected to an old server; r-o mode will be unavailable,warn,Zookeeper
* value is * Bytesjute.maxbuffer,info,Zookeeper
$$$Empty Message$$$,error,Zookeeper
Unable to start jline,debug,Zookeeper
Processing *,debug,Zookeeper
Deferring non-priming packet * until SASL authentication completes.,debug,Zookeeper
Ignoring exception during shutdown input,debug,Zookeeper
Ignoring exception during shutdown output,debug,Zookeeper
Ignoring exception during socket close,debug,Zookeeper
Ignoring exception during channel close,debug,Zookeeper
"SendThread interrupted during sleep, ignoring",debug,Zookeeper
Doing client selector close,trace,Zookeeper
Closed client selector,trace,Zookeeper
Ignoring exception during selector close,warn,Zookeeper
Unable to open socket to *,error,Zookeeper
testableCloseSocket() called,info,Zookeeper
$$$Empty Message$$$,error,Zookeeper
Error reading the error stream,warn,Zookeeper
Interrupted while reading the error stream,warn,Zookeeper
Error while closing the input stream,warn,Zookeeper
Error while closing the error stream,warn,Zookeeper
$$$Empty Message$$$,info,Zookeeper
Unexpected exception,warn,Zookeeper
Unexpected exception,warn,Zookeeper
Unexpected exception,warn,Zookeeper
Unexpected exception,warn,Zookeeper
Unexpected exception,warn,Zookeeper
Unexpected exception,warn,Zookeeper
Unexpected exception,warn,Zookeeper
Unexpected exception,warn,Zookeeper
Unexpected exception,warn,Zookeeper
Unexpected exception,warn,Zookeeper
Unexpected exception,warn,Zookeeper
Unexpected exception,warn,Zookeeper
child removed during quota check,debug,Zookeeper
child removed during quota check,debug,Zookeeper
Unable to resolve address: *,error,Zookeeper
Unexpected exception,warn,Zookeeper
sasl client was unexpectedly null: cannot respond to Zookeeper server.,warn,Zookeeper
ServerSaslResponseCallback(): saslToken server response: (length=*),debug,Zookeeper
ServerSaslResponseCallback(): using empty data[] as server response (length=*),debug,Zookeeper
JAAS loginContext is: *,debug,Zookeeper
Exception while trying to create SASL client.,error,Zookeeper
saslClient is unexpectedly null. Cannot respond to server's SASL message; ignoring.,error,Zookeeper
SASL authentication failed using login context '*'.,error,Zookeeper
saslClient.evaluateChallenge(len=*),debug,Zookeeper
$$$Empty Message$$$,error,Zookeeper
ClientCnxn:sendSaslPacket:length=*,debug,Zookeeper
ClientCnxn:sendSaslPacket:length=*,debug,Zookeeper
Could not retrieve login configuration,debug,Zookeeper
connecting to * *,info,Zookeeper
using secure socket,info,Zookeeper
Setup cipher suites for * socket: *,debug,Zookeeper
Setup enabled protocols for * socket: *,debug,Zookeeper
"Invalid value for *: *, using the default value of *5000",warn,Zookeeper
Failed to verify host address: * attempting to verify host name with reverse dns lookup,debug,Zookeeper
Failed to verify host address: *,error,Zookeeper
Failed to verify hostname: *,error,Zookeeper
Unable to delete tmp file *,warn,Zookeeper
Unable to abort file *,warn,Zookeeper
Unable to delete tmp file during abort *,warn,Zookeeper
Error creating SSL context and options,error,Zookeeper
Error parsing config property *,error,Zookeeper
Loading SSLContext supplier from property '*',debug,Zookeeper
* not specified,warn,Zookeeper
* not specified,warn,Zookeeper
Using Java9+ optimized cipher suites for Java version *,debug,Zookeeper
Using Java8 optimized cipher suites for Java version *,debug,Zookeeper
"Could not parse java version *, using Java8 optimized cipher suites",debug,Zookeeper
enabling cert file reloading,info,Zookeeper
Attempting to reset default SSL context after receiving watch event: * with context: *,debug,Zookeeper
Ignoring watch event and keeping previous default SSL context. Event kind: * with context: *,debug,Zookeeper
*,debug,Zookeeper
*,debug,Zookeeper
*,debug,Zookeeper
Ignoring link-local InetAddress *,debug,Zookeeper
Ignoring multicast InetAddress *,debug,Zookeeper
Ignoring loopback InetAddress *,debug,Zookeeper
Detected * local network addresses: *,debug,Zookeeper
"Failed to list all network interfaces, assuming 1",warn,Zookeeper
Exception in closing ,warn,Zookeeper
Unexpected exception,debug,Zookeeper
key *'s value * is replaced with new value *,debug,Zookeeper
Reading configuration from: *,info,Zookeeper
Error while configuration from: *,error,Zookeeper
Registering with watch service: *,debug,Zookeeper
* thread started,info,Zookeeper
Error in runLoop(),warn,Zookeeper
Error closing watch service,warn,Zookeeper
* thread finished,info,Zookeeper
* was interrupted and is shutting down...,debug,Zookeeper
Got file changed event: * with context: *,debug,Zookeeper
Error from callback,error,Zookeeper
"Watch key no longer valid, maybe the directory is inaccessible?",error,Zookeeper
Log4j found but jmx support is disabled.,info,Zookeeper
Log4j found with jmx enabled.,info,Zookeeper
Log4j not found.,info,Zookeeper
registerLog4jMBeans(),debug,Zookeeper
Problems while registering log4j jmx beans!,error,Zookeeper
Failed to register MBean *,warn,Zookeeper
Unregister MBean [*],debug,Zookeeper
Error during unregister of [*],warn,Zookeeper
Unexpected exception during unregister of [*]. It should be reviewed and fixed.,error,Zookeeper
"Invalid name ""*"" for class *",warn,Zookeeper
Cannot boot MetricsProvider *,error,Zookeeper
Cannot boot MetricsProvider *,error,Zookeeper
$$$Empty Message$$$,warn,Zookeeper
Message:* Value:*,warn,Zookeeper
Last transaction was partial.,error,Zookeeper
Exception occurred from thread *,warn,Zookeeper
Processing request:: *,debug,Zookeeper
*,debug,Zookeeper
Failed to process *,error,Zookeeper
Dumping request buffer: 0x*,error,Zookeeper
FIXMSG,error,Zookeeper
shutdown of request processor complete,info,Zookeeper
Set text trace mask to 0x*,info,Zookeeper
$$$Empty Message$$$,trace,Zookeeper
:,trace,Zookeeper
close called for session id: 0x*,debug,Zookeeper
cnxns size:*,debug,Zookeeper
close in progress for session id: 0x*,debug,Zookeeper
Problem sending to *,debug,Zookeeper
Command * is not executed because it is not in the whitelist.,debug,Zookeeper
Processing * command from *,info,Zookeeper
0x* queuedBuffer: *,debug,Zookeeper
0x* buf *,trace,Zookeeper
Received message while throttled,debug,Zookeeper
allocating queue,debug,Zookeeper
0x* queuedBuffer *,trace,Zookeeper
not throttled,debug,Zookeeper
Before copy *,trace,Zookeeper
Copy is *,trace,Zookeeper
0x* queuedBuffer *,trace,Zookeeper
processing queue 0x* queuedBuffer *,trace,Zookeeper
"Processed queue - channel closed, dropping remaining bytes",debug,Zookeeper
Processed queue - no bytes remaining,debug,Zookeeper
Processed queue - bytes remaining,debug,Zookeeper
queue empty,debug,Zookeeper
message readable * bb len * *,trace,Zookeeper
0x* bb *,trace,Zookeeper
after readBytes message readable * bb len * *,trace,Zookeeper
after readbytes 0x* bb *,trace,Zookeeper
got conn req request from *,debug,Zookeeper
message readable * bblenrem *,trace,Zookeeper
0x* bbLen *,trace,Zookeeper
0x* bbLen *,trace,Zookeeper
0x* bbLen len is *,trace,Zookeeper
Closing connection to *,warn,Zookeeper
Closing connection to *,debug,Zookeeper
Throttling - disabling recv *,debug,Zookeeper
Sending unthrottle event *,debug,Zookeeper
SessionTrackerImpl exited loop!,info,Zookeeper
Session closing: 0x*,trace,Zookeeper
Removing session 0x*,debug,Zookeeper
Shutting down,info,Zookeeper
Adding session 0x*,debug,Zookeeper
Checking session 0x*,debug,Zookeeper
ServerMetrics initialized with provider *,info,Zookeeper
Unable to closeSession() for session: 0x*,warn,Zookeeper
"Thread * exits, error code *",info,Zookeeper
Error sending data synchronously ,error,Zookeeper
"Add a buffer to outgoingBuffers, sk * is valid: *",trace,Zookeeper
trying to do i/o on a null socket for session: 0x*,warn,Zookeeper
CancelledKeyException causing close of session: 0x*,warn,Zookeeper
CancelledKeyException stack trace,debug,Zookeeper
Unexpected exception,warn,Zookeeper
Closing session 0x*,warn,Zookeeper
Close of session 0x*,warn,Zookeeper
Error cancelling command selection key,error,Zookeeper
Command * is not executed because it is not in the whitelist.,debug,Zookeeper
Processing * command from *,info,Zookeeper
ignoring exception during selectionkey cancel,debug,Zookeeper
$$$Empty Message$$$,debug,Zookeeper
ignoring exception during output shutdown,debug,Zookeeper
ignoring exception during input shutdown,debug,Zookeeper
ignoring exception during socket close,debug,Zookeeper
ignoring exception during socketchannel close,debug,Zookeeper
Unexpected exception. Destruction averted.,warn,Zookeeper
"The configured * is invalid, going to use the default *zookeeper.snapshotSizeFactor0.33",warn,Zookeeper
"Error parsing *, using default value *zookeeper.snapshotSizeFactor0.33",error,Zookeeper
* = *zookeeper.snapshotSizeFactor,info,Zookeeper
"The configured commitLogCount * is less than the recommended *, going to use the recommended onezookeeper.commitLogCount500",warn,Zookeeper
Error parsing * - use default value *zookeeper.commitLogCount500,error,Zookeeper
*=*zookeeper.commitLogCount,info,Zookeeper
Snapshot loaded in * ms,info,Zookeeper
On disk txn sync enabled with snapshotSizeFactor *,info,Zookeeper
On disk txn sync disabled,info,Zookeeper
Unable to get size of most recent snapshot,error,Zookeeper
Negative size limit - retrieving proposal via txnlog is disabled,debug,Zookeeper
Unable to find proposals from txnlog for zxid: 0x*,warn,Zookeeper
Txnlog size: * exceeds sizeLimit: *,info,Zookeeper
Unable to read txnlog from disk,error,Zookeeper
Error closing file iterator,warn,Zookeeper
"configuration znode missing (should only happen during upgrade), creating the node",warn,Zookeeper
Update * to *zookeeper.closeSessionTxn.enabled,info,Zookeeper
Created server with tickTime * minSessionTimeout * maxSessionTimeout * clientPortListenBacklog * datadir * snapdir *,info,Zookeeper
Added JvmPauseMonitor to server,info,Zookeeper
"Severe unrecoverable error, exiting",error,Zookeeper
Snapshot taken in * ms,info,Zookeeper
Closing session 0x*,info,Zookeeper
"Expiring session 0x*, timeout of *ms exceeded",info,Zookeeper
Failed to register with JMX,warn,Zookeeper
Failed to register with JMX,warn,Zookeeper
"ZKShutdownHandler is not registered, so ZooKeeper server won't take any action on ERROR or SHUTDOWN server state changes",debug,Zookeeper
"ZooKeeper server is not running, so not proceeding to shutdown!",debug,Zookeeper
shutting down,info,Zookeeper
Error updating DB,error,Zookeeper
Failed to unregister with JMX,warn,Zookeeper
Failed to unregister with JMX,warn,Zookeeper
Incorrect password from * for session 0x*,warn,Zookeeper
Failed to register with JMX,warn,Zookeeper
Established session 0x* with negotiated timeout * for client *,debug,Zookeeper
"Invalid session 0x* for client *, probably expired",info,Zookeeper
"Exception while establishing session, closing",warn,Zookeeper
Unexpected interruption,warn,Zookeeper
Unexpected interruption,warn,Zookeeper
Received packet at server of unknown type *,warn,Zookeeper
Dropping request.,debug,Zookeeper
Unable to process request,error,Zookeeper
"SnapCount should be 2 or more. Now, snapCount is reset to 2",warn,Zookeeper
zookeeper.snapSizeLimitInKb set to a non-positive value *; disabling feature,info,Zookeeper
tickTime set to *,info,Zookeeper
minSessionTimeout set to *,info,Zookeeper
maxSessionTimeout set to *,info,Zookeeper
clientPortListenBacklog set to *,info,Zookeeper
Session establishment request from client * client's lastZxid is 0x*,debug,Zookeeper
Connection request from old client *; will be dropped if server is in r-o mode,warn,Zookeeper
$$$Empty Message$$$,info,Zookeeper
$$$Empty Message$$$,info,Zookeeper
"Client attempting to establish new session: session = 0x*, zxid = 0x*, timeout = *, address = *",debug,Zookeeper
"Client attempting to renew session: session = 0x*, zxid = 0x*, timeout = *, address = *",debug,Zookeeper
*=*zookeeper.flushDelay,info,Zookeeper
*=*zookeeper.maxWriteQueuePollTime,info,Zookeeper
*=*zookeeper.maxBatchSize,info,Zookeeper
Invalid max bytes for all large requests *. It should be a positive number.,warn,Zookeeper
Will not change the setting. The max bytes stay at *,warn,Zookeeper
The max bytes for all large requests are set to *,info,Zookeeper
Invalid large request threshold *. It should be -1 or positive. Setting to -1 ,warn,Zookeeper
The large request threshold is set to *,info,Zookeeper
got auth packet *,info,Zookeeper
Caught runtime exception from AuthenticationProvider: *,warn,Zookeeper
Authentication succeeded for scheme: *,debug,Zookeeper
auth success *,info,Zookeeper
No authentication provider for scheme: * has *,warn,Zookeeper
Authentication failed for scheme: *,warn,Zookeeper
Responding to client SASL token.,debug,Zookeeper
Size of client SASL token: *,debug,Zookeeper
adding SASL authorization for authorizationID: *,info,Zookeeper
Client * failed to SASL authenticate: *,warn,Zookeeper
Maintaining client connection despite SASL authentication failure.,warn,Zookeeper
"Closing client connection due to server requires client SASL authenticaiton,but client SASL authentication has failed, or client is not configured with SASL authentication.",warn,Zookeeper
Closing client connection due to SASL authentication failure.,warn,Zookeeper
cnxn.saslServer is null: cnxn object did not initialize its saslServer properly.,error,Zookeeper
Size of server SASL response: *,debug,Zookeeper
Zxid outstanding 0x* is less than current 0x*,warn,Zookeeper
*****>>>>> Got * *,warn,Zookeeper
Permission requested: * ,debug,Zookeeper
ACLs for node: *,debug,Zookeeper
Client credentials: *,debug,Zookeeper
* = *zookeeper.digest.enabled,info,Zookeeper
Request failed ACL check,debug,Zookeeper
Request has an invalid ACL check,debug,Zookeeper
ACL check against non-existent node: *,debug,Zookeeper
ACL check against illegal node path: *,debug,Zookeeper
Uncaught exception in authWriteRequest with: ,error,Zookeeper
IOException : *,error,Zookeeper
Thread * died,error,Zookeeper
ignored exception during selector close.,warn,Zookeeper
ignoring exception during selectionkey cancel,debug,Zookeeper
"Unable to set socket linger to 0, socket close may stall in CLOSE_WAIT",warn,Zookeeper
Ignoring unexpected runtime exception,warn,Zookeeper
Ignoring unexpected exception,warn,Zookeeper
accept thread exitted run method,info,Zookeeper
Unexpected ops in accept select *,warn,Zookeeper
Ignoring IOException while selecting,warn,Zookeeper
Accepted socket connection from *,debug,Zookeeper
Ignoring unexpected runtime exception,warn,Zookeeper
Ignoring unexpected exception,warn,Zookeeper
selector thread exitted run method,info,Zookeeper
Unexpected ops in select *,warn,Zookeeper
Ignoring IOException while selecting,warn,Zookeeper
ConnnectionExpirerThread interrupted,info,Zookeeper
$$$Empty Message$$$,info,Zookeeper
binding to port *,info,Zookeeper
Error while closing server socket.,error,Zookeeper
Error joining old acceptThread when reconfiguring client port.,error,Zookeeper
binding to port *,info,Zookeeper
Error reconfiguring client port to *,error,Zookeeper
Ignoring exception closing cnxn session id 0x*,warn,Zookeeper
Error closing listen socket,warn,Zookeeper
Ignoring interrupted exception during shutdown,warn,Zookeeper
Ignoring unexpected exception during shutdown,warn,Zookeeper
"Invalid arguments, exiting abnormally",error,Zookeeper
Usage: ZooKeeperServerMain configfile | port datadir [ticktime] [maxcnxns],info,Zookeeper
"Invalid config, exiting abnormally",error,Zookeeper
"Unable to access datadir, exiting abnormally",error,Zookeeper
"Unable to start AdminServer, exiting abnormally",error,Zookeeper
"Unexpected exception, exiting abnormally",error,Zookeeper
Exiting normally,info,Zookeeper
Unable to register log4j JMX control,warn,Zookeeper
Starting server,info,Zookeeper
Server interrupted,warn,Zookeeper
Error while stopping metrics,warn,Zookeeper
Problem stopping AdminServer,warn,Zookeeper
$$$Empty Message$$$,info,Zookeeper
autopurge.snapRetainCount set to *,info,Zookeeper
autopurge.purgeInterval set to *,info,Zookeeper
Purge task is already running.,warn,Zookeeper
Purge task is not scheduled.,info,Zookeeper
Shutting down purge task.,info,Zookeeper
Purge task not started. Ignoring shutdown!,warn,Zookeeper
Purge task started.,info,Zookeeper
Error occurred while purging.,error,Zookeeper
Purge task completed.,info,Zookeeper
"Too busy to snap, skipping",warn,Zookeeper
Unexpected exception,warn,Zookeeper
SyncRequestProcessor exited!,info,Zookeeper
Shutting down,info,Zookeeper
Interrupted while wating for * to finish,warn,Zookeeper
Got IO exception during shutdown,warn,Zookeeper
Got request processor exception during shutdown,warn,Zookeeper
Unable to read txnlog from disk,error,Zookeeper
Error closing file iterator,warn,Zookeeper
PrepRequestProcessor exited loop!,info,Zookeeper
Invalid path * with session 0x*,info,Zookeeper
Reconfig operation requested but reconfig feature is disabled.,error,Zookeeper
"skipACL is set, reconfig operation will skip ACL checks!",warn,Zookeeper
Non-incremental reconfig,info,Zookeeper
Incremental reconfig,info,Zookeeper
$$$Empty Message$$$,warn,Zookeeper
$$$Empty Message$$$,warn,Zookeeper
$$$Empty Message$$$,warn,Zookeeper
$$$Empty Message$$$,warn,Zookeeper
unknown type *,warn,Zookeeper
"Invalid path * with session 0x*, reason: *",info,Zookeeper
Got user-level KeeperException when processing * aborting remaining multi ops. Error Path:* Error:*,info,Zookeeper
unknown type *,warn,Zookeeper
Got user-level KeeperException when processing * Error Path:* Error:*,info,Zookeeper
Failed to process *,error,Zookeeper
Dumping request buffer: 0x*,error,Zookeeper
Processing ACL: *,debug,Zookeeper
Missing AuthenticationProvider for *,error,Zookeeper
Shutting down,info,Zookeeper
Error closing PrintWriter ,info,Zookeeper
Error closing a command socket ,error,Zookeeper
ExecutorService rejected execution,warn,Zookeeper
Unexpected exception,warn,Zookeeper
ERROR: ACL not available for long *,error,Zookeeper
Ignoring acl * as it does not exist in the cache,info,Zookeeper
Ignoring acl * as it does not exist in the cache,info,Zookeeper
exception during session close,warn,Zookeeper
Using * as server connection factory,info,Zookeeper
Could not register connection,warn,Zookeeper
$$$Empty Message$$$,error,Zookeeper
Unexpected interruption,error,Zookeeper
RequestThrottler shutdown. Dropped * requests,info,Zookeeper
Draining request throttler queue,info,Zookeeper
Shutdown in progress. Request cannot be processed,debug,Zookeeper
Shutting down,info,Zookeeper
Interrupted while waiting for * to finish,warn,Zookeeper
Interrupted while waiting for * to finish,warn,Zookeeper
"Unexpected exception when creating WatchManager, exiting abnormally",error,Zookeeper
Missing count node for stat *,error,Zookeeper
Missing count node for quota *,error,Zookeeper
Quota exceeded: * count=* limit=*,warn,Zookeeper
Quota exceeded: * bytes=* limit=*,warn,Zookeeper
Failed: *:*,debug,Zookeeper
Failed: *:*,debug,Zookeeper
Adjusting parent cversion for Txn: * path: * err: *,debug,Zookeeper
Failed to set parent cversion for: *,error,Zookeeper
Ignoring processTxn failure hdr: * : error: *,debug,Zookeeper
Unexpected extra paths under session * which are not in txn 0x*,warn,Zookeeper
Deleting ephemeral node * for session 0x*,debug,Zookeeper
Ignoring NoNodeException for path * while removing ephemeral for dead session 0x*,warn,Zookeeper
Missing quota stat node *,warn,Zookeeper
"Got EOF exception while reading the digest, likely due to the reading an older snapshot.",warn,Zookeeper
"Digest version changed, local: *, new: *, skip comparing digest now.",info,Zookeeper
"Watching for zxid 0x* during snapshot recovery, but it wasn't found.",error,Zookeeper
"first byte * does not match TLS handshake, failing to plaintext",debug,Zookeeper
creating ssl handler for session *,debug,Zookeeper
creating plaintext handler for session *,debug,Zookeeper
Channel active *,trace,Zookeeper
Too many connections from * - max is *,warn,Zookeeper
Channel inactive *,trace,Zookeeper
Channel inactive caused close *,trace,Zookeeper
Exception caught,warn,Zookeeper
Closing *,debug,Zookeeper
Received ReadEvent.ENABLE,debug,Zookeeper
Issued a read after queuedBuffer drained,debug,Zookeeper
Received ReadEvent.DISABLE,debug,Zookeeper
message received called *,trace,Zookeeper
New message * from *,debug,Zookeeper
channelRead() on a closed or closing NettyServerCnxn,error,Zookeeper
Unexpected exception in receive,error,Zookeeper
Issued a read since we do not have anything to consume after channelReadComplete,debug,Zookeeper
Successful handshake with session 0x*,debug,Zookeeper
Error getting peer certificates,error,Zookeeper
Error getting peer certificates,error,Zookeeper
X509 Auth provider not found: *,error,Zookeeper
Authentication failed for session 0x*,error,Zookeeper
Unsuccessful handshake with session 0x*,error,Zookeeper
*=*zookeeper.client.portUnification,info,Zookeeper
"unable to set up SslAuthProvider, turning off client port unification",error,Zookeeper
* = *zookeeper.netty.advancedFlowControl.enabled,info,Zookeeper
Auth provider not found: *,error,Zookeeper
dual mode SSL handler added for channel: *,debug,Zookeeper
SSL handler added for channel: *,debug,Zookeeper
closeAll(),debug,Zookeeper
Ignoring exception closing cnxn sessionid 0x*,warn,Zookeeper
allChannels size: * cnxns size: *,debug,Zookeeper
already shutdown *,info,Zookeeper
shutdown called *,info,Zookeeper
binding to port *,info,Zookeeper
bound to port *,info,Zookeeper
"binding to port *, *",info,Zookeeper
"address is the same, skip rebinding",info,Zookeeper
bound to port *,info,Zookeeper
Error while reconfiguring,error,Zookeeper
Weighed connection throttling is enabled. But it will only be effective if connection throttling is enabled,info,Zookeeper
The weights for different session types are: global * renew * local *,info,Zookeeper
Weighed connection throttling is disabled,info,Zookeeper
Using checkIntervalMs=* maxPerMinute=*,info,Zookeeper
interrupted,info,Zookeeper
Error checking containers,error,Zookeeper
Attempting to delete candidate container: *,info,Zookeeper
Could not delete container: *,error,Zookeeper
"Severe unrecoverable error, from thread : *",error,Zookeeper
Re-registering command * (primary name = *),warn,Zookeeper
running stat,info,Zookeeper
Successfully loaded private key from *,info,Zookeeper
Successfully loaded certificate authority from *,info,Zookeeper
Failed to load authentication certificates for admin server.,error,Zookeeper
"Started AdminServer on address *, port * and command URL *",info,Zookeeper
Unable to start JettyAdminServer,warn,Zookeeper
Unable to start JettyAdminServer,warn,Zookeeper
Unable to start JettyAdminServer,warn,Zookeeper
Unable to start JettyAdminServer,warn,Zookeeper
Unable to start JettyAdminServer,warn,Zookeeper
"Unable to load jetty, not starting JettyAdminServer",warn,Zookeeper
Incoming connection has no data,warn,Zookeeper
UnifiedConnectionFactory: newConnection() with SSL = %b,debug,Zookeeper
Exception writing command response to JSON:,warn,Zookeeper
Exception writing command response to JSON:,warn,Zookeeper
Exception writing command response to JSON:,warn,Zookeeper
$$$Empty Message$$$,error,Zookeeper
User '*' not found in list of DIGEST-MD5 authenticateable users.,warn,Zookeeper
No password found for user: *,warn,Zookeeper
client supplied realm: *,debug,Zookeeper
Successfully authenticated client: authenticationID=*;  authorizationID=*.,info,Zookeeper
Setting authorizedID: *,info,Zookeeper
Failed to set name based on Kerberos authentication rules.,error,Zookeeper
keystore not specified for client connection,warn,Zookeeper
Failed to create key manager,error,Zookeeper
Truststore not specified for client connection,warn,Zookeeper
Failed to create trust manager,error,Zookeeper
No trust manager available to authenticate session 0x*,error,Zookeeper
Failed to trust certificate for session 0x*,error,Zookeeper
Authenticated Id '*' as super user,info,Zookeeper
Authenticated Id '*' for Scheme '*',info,Zookeeper
getData failed,error,Zookeeper
bad formatting,error,Zookeeper
UTF-8,error,Zookeeper
UTF-8,error,Zookeeper
"KeyAuthenticationProvider handleAuthentication (*, *) -> FAIL. ",debug,Zookeeper
KeyAuthenticationProvider handleAuthentication -> OK. ,debug,Zookeeper
Set expected ensemble names to *,info,Zookeeper
Unexpected ensemble name: ensemble name: * client ip: *,warn,Zookeeper
Missing algorithm,error,Zookeeper
Problems loading *,warn,Zookeeper
The list of known four letter word commands is : *,info,Zookeeper
The list of enabled four letter word commands is : *,info,Zookeeper
Error in running command ,error,Zookeeper
Stat command output,info,Zookeeper
Current zxid * is <= * for *,warn,Zookeeper
Creating new log file: *,info,Zookeeper
Unexpected exception,warn,Zookeeper
Error closing file iterator,warn,Zookeeper
fsync-ing the write ahead log in * took *ms which will adversely effect operation latency.File size is * bytes. See the ZooKeeper troubleshooting guide,warn,Zookeeper
Log size limit reached: *,debug,Zookeeper
Unable to truncate *,warn,Zookeeper
Ignoring exception during close,warn,Zookeeper
Created new input stream: *,debug,Zookeeper
Created new input archive: *,debug,Zookeeper
EOF exception,debug,Zookeeper
Opening datadir:* snapDir:*,debug,Zookeeper
* : *zookeeper.snapshot.trust.empty,info,Zookeeper
"Initialize file found, an empty database will not block voting participation",info,Zookeeper
"*This should only be allowed during upgrading.No snapshot found, but there are log entries. ",warn,Zookeeper
"Unexpected empty data tree, setting zxid to -1",warn,Zookeeper
"Highest txn zxid 0x* is not covering the snapshot digest zxid 0x*, which might lead to inconsistent state",warn,Zookeeper
*(highestZxid) > *(next log) for type *,error,Zookeeper
* txns loaded in * ms,info,Zookeeper
"Ignoring processTxn failure hdr: *, error: *, path: *",debug,Zookeeper
Snapshotting: 0x* to *,info,Zookeeper
Deleted empty snapshot file: *,info,Zookeeper
Could not delete empty snapshot file: *,warn,Zookeeper
Last transaction was partial.,error,Zookeeper
Reading snapshot *,info,Zookeeper
problem reading snap file *,warn,Zookeeper
invalid snapshot *,warn,Zookeeper
Read incorrect number of bytes from *,error,Zookeeper
Unable to open file *,error,Zookeeper
Read incorrect number of bytes from *,error,Zookeeper
Unable to open file *,error,Zookeeper
"Invalid snapshot *. too short, len = * bytes",info,Zookeeper
"Invalid snapshot *. len = *, byte = *",info,Zookeeper
ACK for 0x* received before ACK for 0x*,warn,Zookeeper
Forcing snapshot sync is enabled,info,Zookeeper
"Server failed to authenticate quorum learner, addr: *, closing connection",error,Zookeeper
Exception while closing socket,error,Zookeeper
Unexpected exception at *,warn,Zookeeper
Error closing socket for handler *,warn,Zookeeper
Unexpected exception,warn,Zookeeper
Unexpected exception,warn,Zookeeper
First packet * is not FOLLOWERINFO or OBSERVERINFO!,error,Zookeeper
Follower sid: * not in the current config *,info,Zookeeper
Follower sid: * : info : *,info,Zookeeper
* is not ACKEPOCH,error,Zookeeper
"Sending snapshot last zxid of peer is 0x*, zxid of leader is 0x*, send zxid of db as 0x*, * concurrent snapshot sync, snapshot sync was * from throttle",info,Zookeeper
Sending NEWLEADER message to *,debug,Zookeeper
"Next packet was supposed to be an ACK, but received packet: *",error,Zookeeper
Received NEWLEADER-ACK message from *,debug,Zookeeper
Sending UPTODATE message to *,debug,Zookeeper
Received ACK from Observer *,debug,Zookeeper
"unexpected quorum packet, type: *",warn,Zookeeper
Unexpected exception causing shutdown while sock still open,error,Zookeeper
Unexpected exception in LearnerHandler.,error,Zookeeper
too many concurrent sync.,error,Zookeeper
Unexpected exception in LearnerHandler.,error,Zookeeper
******* GOODBYE * ********,warn,Zookeeper
Unexpected interruption,warn,Zookeeper
Attempting to start sending thread after it already started,error,Zookeeper
Synchronizing with Learner sid: * maxCommittedLog=0x* minCommittedLog=0x* lastProcessedZxid=0x* peerLastZxid=0x*,info,Zookeeper
Forcing snapshot sync - should not see this in production,warn,Zookeeper
Sending DIFF zxid=0x* for peer sid: *,info,Zookeeper
Sending TRUNC to follower zxidToSend=0x* for peer sid:*,debug,Zookeeper
Using committedLog for peer sid: *,info,Zookeeper
Use txnlog and committedLog for peer sid: *,info,Zookeeper
Detected gap between end of txnlog: 0x* and start of committedLog: 0x*,info,Zookeeper
Queueing committedLog 0x*,debug,Zookeeper
Unhandled scenario for peer sid: * maxCommittedLog=0x* minCommittedLog=0x* lastProcessedZxid=0x* peerLastZxid=0x* txnLogSyncEnabled=*,warn,Zookeeper
Start forwarding 0x* for peer sid: *,debug,Zookeeper
Unhandled scenario for peer sid: * fall back to use snapshot,error,Zookeeper
Sending DIFF zxid=0x*  for peer sid: *,info,Zookeeper
Sending DIFF zxid=0x*  for peer sid: *,info,Zookeeper
Cannot send TRUNC to peer sid:  |  peer zxid is from different epoch,warn,Zookeeper
Sending TRUNC zxid=0x*  for peer sid: *,info,Zookeeper
Sending TRUNC zxid=0x*  for peer sid: *,info,Zookeeper
Ignoring unexpected exception,warn,Zookeeper
Ignoring unexpected exception during socket close,warn,Zookeeper
Closing connection to peer due to transaction timeout.,warn,Zookeeper
terminating learner handler connection on demand *,info,Zookeeper
IO exception while sending response,error,Zookeeper
ReadOnlyRequestProcessor exited loop!,info,Zookeeper
"Closing connection to leader, exception during packet send",warn,Zookeeper
Ignoring error closing the connection,debug,Zookeeper
"Closing connection to leader, exception during packet send",warn,Zookeeper
Ignoring error closing the connection,debug,Zookeeper
Couldn't bind to port *,error,Zookeeper
Couldn't bind to *,error,Zookeeper
exception while shutting down acceptor.,warn,Zookeeper
Exception while connecting to quorum learner,error,Zookeeper
Error closing socket,warn,Zookeeper
Exception while accepting follower,warn,Zookeeper
LEADING - LEADER ELECTION TOOK - * *MS,info,Zookeeper
NEWLEADER proposal has Zxid of *,info,Zookeeper
Enough followers present. Perhaps the initTicks need to be increased.,warn,Zookeeper
Shutting down,info,Zookeeper
Shutdown called. For the reason *,info,Zookeeper
Ignoring unexpected exception during close,warn,Zookeeper
Commiting zxid 0x* from * noy first!,warn,Zookeeper
First is *,warn,Zookeeper
Going to commit null: *,warn,Zookeeper
Committing a reconfiguration! *,debug,Zookeeper
Ack zxid: 0x*,trace,Zookeeper
outstanding proposal: 0x*,trace,Zookeeper
outstanding proposals all,trace,Zookeeper
outstanding is 0,debug,Zookeeper
"proposal has already been committed, pzxid: 0x* zxid: 0x*",debug,Zookeeper
Trying to commit future proposal: zxid 0x* from *,warn,Zookeeper
Committed request not found on toBeApplied: *,error,Zookeeper
Shutting down,info,Zookeeper
Proposing:: *,debug,Zookeeper
Set * to *mszookeeper.leader.maxTimeToWaitForEpoch,info,Zookeeper
Quit leading due to voter changed mind.,info,Zookeeper
"Have quorum of supporters, sids: [*]; starting up and setting last processed zxid: 0x*",info,Zookeeper
NEWLEADER ACK from sid: * is from a different epoch - current 0x* received 0x*,error,Zookeeper
Somehow session 0x* expired right after being renewed! (impossible),error,Zookeeper
Upgrading session 0x*,info,Zookeeper
"Invalid arguments, exiting abnormally",error,Zookeeper
Usage: QuorumPeerMain configfile,info,Zookeeper
"Invalid config, exiting abnormally",error,Zookeeper
"Unable to access datadir, exiting abnormally",error,Zookeeper
"Unable to start AdminServer, exiting abnormally",error,Zookeeper
"Unexpected exception, exiting abnormally",error,Zookeeper
Exiting normally,info,Zookeeper
"Either no config or no quorum defined in config, running in standalone mode",warn,Zookeeper
Unable to register log4j JMX control,warn,Zookeeper
Starting quorum peer,info,Zookeeper
Quorum Peer interrupted,warn,Zookeeper
Error while stopping metrics,warn,Zookeeper
"LearnerHandler is too far behind (0x* < 0x*), disconnecting * at *",error,Zookeeper
"finished syncing observer from retained commit queue: sid *, queue head 0x*, queue tail 0x*, sync position 0x*, num packets used *, num bytes used *",info,Zookeeper
ignore missing proposal packet for *,debug,Zookeeper
$$$Empty Message$$$,error,Zookeeper
Ignoring accept exception (maybe shutting down),debug,Zookeeper
Ignoring accept exception (maybe client closed),debug,Zookeeper
Not starting Read-only server as startup follows shutdown!,warn,Zookeeper
Read-only server started,info,Zookeeper
Failed to register with JMX,warn,Zookeeper
Failed to register with JMX,warn,Zookeeper
Failed to unregister with JMX,warn,Zookeeper
Failed to unregister with JMX,warn,Zookeeper
"ZooKeeper server is not running, so not proceeding to shutdown!",debug,Zookeeper
Failed to register with JMX,warn,Zookeeper
Failed to register with JMX,warn,Zookeeper
Failed to register with JMX,warn,Zookeeper
Failed to unregister with JMX,warn,Zookeeper
Failed to unregister with JMX,warn,Zookeeper
"ZooKeeper server is not running, so not proceeding to shutdown!",debug,Zookeeper
Shutting down,info,Zookeeper
Ignoring unexpected exception during shutdown,warn,Zookeeper
Ignoring unexpected exception in syncprocessor shutdown,warn,Zookeeper
Updating header,debug,Zookeeper
Error creating upgrade request,warn,Zookeeper
Unexpected error in upgrade,error,Zookeeper
Shutting down,info,Zookeeper
Reading configuration from: ,info,Zookeeper
NextQuorumVerifier is initiated to null,warn,Zookeeper
Invalid autopurge.snapRetainCount:  | . Defaulting to ,warn,Zookeeper
clientPort is not set,info,Zookeeper
clientPortAddress is *,info,Zookeeper
clientPortAddress is *,info,Zookeeper
secureClientPort is not set,info,Zookeeper
secureClientPortAddress is *,info,Zookeeper
secureClientPortAddress is *,info,Zookeeper
observerMasterPort is not set,info,Zookeeper
observerMasterPort is *,info,Zookeeper
metricsProvider.className is *,info,Zookeeper
deleting * failed,warn,Zookeeper
$$$Empty Message$$$,info,Zookeeper
"Invalid configuration, only one server specified (ignoring)",error,Zookeeper
No server failure will be tolerated. You need at least 3 servers.,warn,Zookeeper
"Non-optimial configuration, consider an odd number of servers.",warn,Zookeeper
Peer type from servers list (*) doesn't match peerType (*). Defaulting to servers list.,warn,Zookeeper
FOLLOWING - LEADER ELECTION TOOK - * *MS,info,Zookeeper
Proposed leader epoch  |  is less than our accepted epoch ,error,Zookeeper
Starting ObserverMaster,info,Zookeeper
Exception when following the leader,warn,Zookeeper
Disconnected from leader (with address: *). Was connected for *ms. Sync state: *,info,Zookeeper
Got zxid 0x* expected 0x*,warn,Zookeeper
Received an UPTODATE message after Follower started,error,Zookeeper
Unknown packet type: *,warn,Zookeeper
error getting zxid,warn,Zookeeper
shutdown Follower,info,Zookeeper
Tracking global session 0x*,info,Zookeeper
Committing global session 0x*,info,Zookeeper
ObserverRequestProcessor exited loop!,info,Zookeeper
Error creating upgrade request,info,Zookeeper
Unexpected error in upgrade,error,Zookeeper
Shutting down,info,Zookeeper
Upgrading session 0x*,info,Zookeeper
Submitting * closeSession request for session 0x*,info,Zookeeper
syncEnabled =*,info,Zookeeper
Not expecting a sync.,warn,Zookeeper
"ZooKeeper server is not running, so not proceeding to shutdown!",debug,Zookeeper
"Socket mode detection timed out after * ms, assuming PLAINTEXT",warn,Zookeeper
Failed to restore old socket timeout value of * ms,warn,Zookeeper
Accepted TLS connection from * - * - *,info,Zookeeper
Accepted plaintext connection from *,info,Zookeeper
No challenge mutex object,error,Zookeeper
Ignoring exception receiving,warn,Zookeeper
Got a short response: * *,warn,Zookeeper
Got bad Msg type: *,warn,Zookeeper
unknown type *,warn,Zookeeper
"Incorrect challenge: *, *",warn,Zookeeper
No challenge for host: * *,warn,Zookeeper
Empty ack semaphore,error,Zookeeper
No such address in the ensemble configuration *,warn,Zookeeper
Received message of incorrect type *,warn,Zookeeper
Exception while sending challenge: ,warn,Zookeeper
Exception while sending challenge: ,warn,Zookeeper
Address is not in the configuration: *,error,Zookeeper
Challenge request exception: ,warn,Zookeeper
No challenge with tag: *,warn,Zookeeper
Ack exception: ,warn,Zookeeper
Sending exception: ,warn,Zookeeper
Exception while sending ack: ,warn,Zookeeper
unknown type *,warn,Zookeeper
Failed to register with JMX,warn,Zookeeper
Election tally,info,Zookeeper
Passed predicate,info,Zookeeper
Failed to unregister with JMX,warn,Zookeeper
Server address has not been initialized,warn,Zookeeper
Election address has not been initialized,warn,Zookeeper
Failed to resolve address: *,warn,Zookeeper
Resolved address for *: *,debug,Zookeeper
Got more than just an xid! Len = *,warn,Zookeeper
Unexpected runtime exception in ResponderThread,warn,Zookeeper
Unexpected IO exception in ResponderThread,warn,Zookeeper
QuorumPeer responder thread exited,warn,Zookeeper
Peer state changed: *,info,Zookeeper
Peer state changed: *,info,Zookeeper
Peer state changed: *,info,Zookeeper
Problem starting AdminServer,warn,Zookeeper
* not found! Creating with a reasonable default of *. This should only happen when you are upgrading your installationcurrentEpoch,info,Zookeeper
* not found! Creating with a reasonable default of *. This should only happen when you are upgrading your installationacceptedEpoch,info,Zookeeper
Unable to load database on disk,error,Zookeeper
Clobbering already-set QuorumCnxManager (restarting leader election?),warn,Zookeeper
Null listener when initializing cnx manager,error,Zookeeper
Initializing leader election protocol...,debug,Zookeeper
Starting quorum peer,debug,Zookeeper
Failed to register with JMX,warn,Zookeeper
Failed to register with JMX,warn,Zookeeper
Failed to register with JMX,warn,Zookeeper
LOOKING,info,Zookeeper
Attempting to start ReadOnlyZooKeeperServer,info,Zookeeper
"Interrupted while attempting to start ReadOnlyZooKeeperServer, not started",info,Zookeeper
FAILED to start ReadOnlyZooKeeperServer,error,Zookeeper
Unexpected exception,warn,Zookeeper
Unexpected exception,warn,Zookeeper
OBSERVING,info,Zookeeper
Unexpected exception,warn,Zookeeper
FOLLOWING,info,Zookeeper
Unexpected exception,warn,Zookeeper
LEADING,info,Zookeeper
Unexpected exception,warn,Zookeeper
QuorumPeer main thread exited,warn,Zookeeper
PeerState set to LOOKING,warn,Zookeeper
PeerState set to LEADING,debug,Zookeeper
PeerState set to FOLLOWING,debug,Zookeeper
PeerState set to OBSERVER,debug,Zookeeper
Should not be here,debug,Zookeeper
Problem stopping AdminServer,warn,Zookeeper
Error closing logs ,warn,Zookeeper
tickTime set to *,info,Zookeeper
Local sessions *,info,Zookeeper
Local session upgrading *,info,Zookeeper
minSessionTimeout set to *,info,Zookeeper
maxSessionTimeout set to *,info,Zookeeper
initLimit set to *,info,Zookeeper
Restarting Leader Election,warn,Zookeeper
configFilename is null! This should only happen in tests.,warn,Zookeeper
setLastSeenQuorumVerifier called with stale config  | . Current version: ,error,Zookeeper
Error writing next dynamic config file to disk,error,Zookeeper
* setQuorumVerifier called with known or old config *. Current version: *,debug,Zookeeper
Error closing file,error,Zookeeper
writeToDisk == true but configFilename == null,info,Zookeeper
syncLimit set to *,info,Zookeeper
connectToLearnerMasterLimit set to *,info,Zookeeper
*=*zookeeper.observer.syncEnabled,info,Zookeeper
Using TLS encrypted quorum communication,info,Zookeeper
Using insecure (non-TLS) quorum communication,info,Zookeeper
Port unification *,info,Zookeeper
"Reconfig feature is disabled, skip reconfig processing.",debug,Zookeeper
Failed to register with JMX,warn,Zookeeper
Failed to unregister with JMX,warn,Zookeeper
Updated learner master list to be *,info,Zookeeper
could not find learner master address=*,info,Zookeeper
could not find learner master sid=*,warn,Zookeeper
"cannot validate request, observer masters not enabled",info,Zookeeper
Becoming an observer,info,Zookeeper
Becoming a voting participant,info,Zookeeper
Becoming a non-voting participant,info,Zookeeper
Suggested leader: *,warn,Zookeeper
* set to *quorum.auth.serverRequireSasl,info,Zookeeper
* set to *quorum.auth.learnerRequireSasl,info,Zookeeper
QuorumPeer communication is not secured! (SASL auth disabled),info,Zookeeper
* set to *quorum.auth.enableSasl,info,Zookeeper
* set to *quorum.auth.kerberos.servicePrincipal,info,Zookeeper
* set to *quorum.auth.learner.saslLoginContext,info,Zookeeper
* set to *quorum.auth.server.saslLoginContext,info,Zookeeper
quorum.cnxn.threads.size set to *,info,Zookeeper
Using *ms as the quorum cnxn socket timeout,info,Zookeeper
$$$Empty Message$$$,error,Zookeeper
CommitProcessor exited loop!,info,Zookeeper
Configuring CommitProcessor with * worker threads.,info,Zookeeper
Configuring CommitProcessor with readBatchSize * commitBatchSize *,info,Zookeeper
Configuring CommitProcessor with readBatchSize *,info,Zookeeper
Configuring CommitProcessor with commitBatchSize *,info,Zookeeper
"Exception thrown by downstream processor, unable to continue.",error,Zookeeper
Committing request:: *,debug,Zookeeper
Processing request:: *,debug,Zookeeper
Shutting down,info,Zookeeper
Got a short response: *,error,Zookeeper
"Backward compatibility mode (36 bits), server id: *",info,Zookeeper
"Backward compatibility mode (28 bits), server id: *",info,Zookeeper
* Received version: * my version: *,info,Zookeeper
"Invoking processReconfig(), state: *",debug,Zookeeper
restarting leader election,info,Zookeeper
"Skip processReconfig(), state: *",debug,Zookeeper
Something went wrong while processing config received from *,error,Zookeeper
Something went wrong while processing config received from *,error,Zookeeper
"Backward compatibility mode (before reconfig), server id: *",info,Zookeeper
Receive new notification message. My id = *,debug,Zookeeper
"Notification: my state:*; n.sid:*, n.state:*, n.leader:*, n.round:0x*, n.peerEpoch:0x*, n.zxid:0x*, message format version:0x*, n.config version:0x*",info,Zookeeper
Sending new notification. My id =* recipient=* zxid=0x* leader=* config version = *,debug,Zookeeper
Interrupted Exception while waiting for new message,warn,Zookeeper
WorkerReceiver is down,info,Zookeeper
WorkerSender is down,info,Zookeeper
"About to leave FLE instance: leader=*, zxid=0x*, my id=*, my state=*",debug,Zookeeper
Shutting down connection manager,debug,Zookeeper
Shutting down messenger,debug,Zookeeper
FLE is down,debug,Zookeeper
"Sending Notification: * (n.leader), 0x* (n.zxid), 0x* (n.round), * (recipient), * (myid), 0x* (n.peerEpoch) ",debug,Zookeeper
"id: *, proposed id: *, zxid: 0x*, proposed zxid: 0x*",debug,Zookeeper
"Updating proposal: * (newleader), 0x* (newzxid), * (oldleader), 0x* (oldzxid)",debug,Zookeeper
I am a participant: *,debug,Zookeeper
I am an observer: *,debug,Zookeeper
Failed to register with JMX,warn,Zookeeper
"New election. My id = *, proposed zxid=0x*",info,Zookeeper
Notification time out: *,info,Zookeeper
Ignoring notification as our zxid is -1,debug,Zookeeper
Ignoring notification from member with -1 zxid *,debug,Zookeeper
"Notification election epoch is smaller than logicalclock. n.electionEpoch = 0x*, logicalclock=0x*",debug,Zookeeper
"Adding vote: from=*, proposed leader=*, proposed zxid=0x*, proposed election epoch=0x*",debug,Zookeeper
Notification from observer: *,debug,Zookeeper
"Notification state unrecoginized: * (n.state), *(n.sid)",warn,Zookeeper
Ignoring notification for non-cluster member sid * from sid *,warn,Zookeeper
Ignoring notification for sid * from non-quorum member sid *,warn,Zookeeper
Failed to unregister with JMX,warn,Zookeeper
Number of connection processing threads: *,debug,Zookeeper
Failed to register with JMX,warn,Zookeeper
Failed to register with JMX,warn,Zookeeper
Failed to register with JMX,warn,Zookeeper
Could not register connection,warn,Zookeeper
Failed to unregister with JMX,warn,Zookeeper
Failed to unregister with JMX,warn,Zookeeper
Exception when observing the leader,warn,Zookeeper
Disconnected from leader (with address: *). Was connected for *ms. Sync state: *,info,Zookeeper
requested next learner master * is no longer valid,warn,Zookeeper
No learner master found,warn,Zookeeper
Observing new leader sid=* addr=*,info,Zookeeper
Ignoring proposal,warn,Zookeeper
Ignoring commit,warn,Zookeeper
Received an UPTODATE message after Observer started,error,Zookeeper
Unknown packet type: *,warn,Zookeeper
shutdown Observer,info,Zookeeper
Waiting for * ms before reconnecting with the leader,info,Zookeeper
Interrupted while waiting,warn,Zookeeper
Already connected to requested learner master sid=* addr=*,info,Zookeeper
Requesting disconnect and reconnect to new learner master sid=* addr=*,info,Zookeeper
* = *zookeeper.observer.election.DelayMs,info,Zookeeper
Not initializing connection executor as quorum sasl auth is disabled,debug,Zookeeper
Opening channel to server *,debug,Zookeeper
"Exception while connecting, id: *, addr: *, closing learner connection",error,Zookeeper
"Connection request to server id: * is already in progress, so skipping this request",debug,Zookeeper
Exception while submitting quorum connection request,error,Zookeeper
Ignoring exception reading or writing challenge: ,warn,Zookeeper
"Have smaller server identifier, so dropping the connection: (*, *)",info,Zookeeper
"Exception handling connection, addr: *, closing server connection",error,Zookeeper
"Exception handling connection, addr: *, closing server connection",error,Zookeeper
$$$Empty Message$$$,error,Zookeeper
Setting arbitrary identifier to observer: *,info,Zookeeper
Exception reading or writing challenge,warn,Zookeeper
Create new connection to server: *,debug,Zookeeper
There is a connection already for server *,debug,Zookeeper
Opening channel to server *,debug,Zookeeper
SSL handshake complete with * - * - *,info,Zookeeper
Connected to server *,debug,Zookeeper
Cannot open channel to * at election address *,warn,Zookeeper
Cannot open secure channel to * at election address *,warn,Zookeeper
Cannot open channel to * at election address *,warn,Zookeeper
There is a connection already for server *,debug,Zookeeper
Invalid server id: * ,warn,Zookeeper
Queue size: *,debug,Zookeeper
Halting listener,debug,Zookeeper
Got interrupted before joining the listener,warn,Zookeeper
Halting sender: *,debug,Zookeeper
Exception while closing,error,Zookeeper
Election port bind maximum retries is *,info,Zookeeper
'*' contains invalid value: *(must be >= 0). Use default value of * instead.zookeeper.electionPortBindRetry3,info,Zookeeper
Creating TLS-enabled quorum server socket,info,Zookeeper
Creating TLS-only quorum server socket,info,Zookeeper
My election bind port: *,info,Zookeeper
Received connection request *,info,Zookeeper
"The socket is listening for the election accepted and it timed out unexpectedly, but will retry.see ZOOKEEPER-2836",warn,Zookeeper
Exception while listening,error,Zookeeper
Error closing server socket,error,Zookeeper
Interrupted while sleeping. Ignoring exception,error,Zookeeper
Leaving listener,info,Zookeeper
As I'm leaving the listener thread after * errors. I won't be able to participate in leader election any longer: *.Use * property to increase retry count.zookeeper.electionPortBindRetry,error,Zookeeper
Error closing server socket,debug,Zookeeper
Trying to close listener: *,debug,Zookeeper
Closing listener: *,debug,Zookeeper
Exception when shutting down listener,warn,Zookeeper
Unable to access socket output stream,error,Zookeeper
Address of remote peer: *,debug,Zookeeper
Calling finish for *,debug,Zookeeper
Removing entry from senderWorkerMap sid=*,debug,Zookeeper
BufferUnderflowException ,error,Zookeeper
Attempting to send lastMessage to sid=*,debug,Zookeeper
Failed to send last message. Shutting down thread.,error,Zookeeper
No queue of incoming messages for server *,error,Zookeeper
Interrupted while waiting for message on queue,warn,Zookeeper
Exception when using channel: for id * my id = *,warn,Zookeeper
Send worker leaving thread id * my id = *,warn,Zookeeper
Error while accessing socket for *,error,Zookeeper
"Connection broken for id *, my id = *",warn,Zookeeper
Interrupting SendWorker,warn,Zookeeper
Trying to remove from an empty Queue. Ignoring exception.,debug,Zookeeper
Unable to insert an element in the queue ,error,Zookeeper
Trying to remove from an empty recvQueue. Ignoring exception.,debug,Zookeeper
Unable to insert element in the recvQueue ,error,Zookeeper
Null QuorumPeer,error,Zookeeper
Committing  |  without seeing txn,warn,Zookeeper
Committing zxid 0x |  but next pending txn 0x,error,Zookeeper
Not expecting a sync.,warn,Zookeeper
Could not register connection,warn,Zookeeper
FollowerRequestProcessor exited loop!,info,Zookeeper
Error creating upgrade request,warn,Zookeeper
Unexpected error in upgrade,error,Zookeeper
Shutting down,info,Zookeeper
Revalidating client: 0x*,info,Zookeeper
Couldn't find the leader with id = *,warn,Zookeeper
connectToLeader exceeded on retries.,error,Zookeeper
"Unexpected exception, connectToLeader exceeded. tries=*, remaining init limit=*, connecting to *",error,Zookeeper
"Unexpected exception, retries exceeded. tries=*, remaining init limit=*, connecting to *",error,Zookeeper
"Unexpected exception, tries=*, remaining init limit=*, connecting to *",warn,Zookeeper
First packet should have been NEWLEADER,error,Zookeeper
Getting a diff from the leader 0x*,info,Zookeeper
Getting a snapshot from leader 0x*,info,Zookeeper
Reset config node content from local config after deserialization of snapshot.,debug,Zookeeper
Missing signature. Got *,error,Zookeeper
Truncating log to get in sync with the leader 0x*,warn,Zookeeper
Not able to truncate the log 0x*,error,Zookeeper
"Got unexpected packet from leader: *, exiting ... ",error,Zookeeper
Got zxid 0x* expected 0x*,warn,Zookeeper
"Committing 0x*, but next proposal is 0x*",warn,Zookeeper
Got zxid 0x* expected 0x*,warn,Zookeeper
Learner received UPTODATE message,info,Zookeeper
Learner received NEWLEADER message,info,Zookeeper
"Committing 0x*, but next proposal is 0x*",warn,Zookeeper
Missing session 0x* for validation,warn,Zookeeper
Ignoring error closing connection to leader,warn,Zookeeper
Shutting down,info,Zookeeper
Committing global session 0x*,info,Zookeeper
Set maxConcurrentSnapSyncs to *,info,Zookeeper
Set maxConcurrentDiffSyncs to *,info,Zookeeper
"Failed to authenticate using SASL, server addr: *, retries=* exceeded.",warn,Zookeeper
Successfully completed the authentication using SASL. learner addr: *,info,Zookeeper
Exception while sending failed status,warn,Zookeeper
Failed to authenticate using SASL,error,Zookeeper
Failed to authenticate using SASL,warn,Zookeeper
"Maintaining learner connection despite SASL authentication failure. server addr: *, *: *quorum.auth.serverRequireSasl",warn,Zookeeper
SaslServer dispose() failed,error,Zookeeper
Skipping SASL authentication as *=*quorum.auth.learnerRequireSasl,info,Zookeeper
Unknown status:*!,warn,Zookeeper
SaslClient dispose() failed,error,Zookeeper
"Successfully completed the authentication using SASL. server addr: *, status: *",info,Zookeeper
saslClient.evaluateChallenge(len=*),debug,Zookeeper
$$$Empty Message$$$,error,Zookeeper
Unknown status:*!,error,Zookeeper
$$$Empty Message$$$,error,Zookeeper
User '*' not found in list of DIGEST-MD5 authenticateable users.,warn,Zookeeper
No password found for user: *,warn,Zookeeper
QuorumLearner supplied realm: *,debug,Zookeeper
"SASL authorization completed, * is not authorized to connect",error,Zookeeper
Successfully authenticated learner: authenticationID=*;  authorizationID=*.,info,Zookeeper
"SASL authorization completed, authorized flag set to *",debug,Zookeeper
"*, *, *",info,Zookeeper
Reading configuration from: *,info,Zookeeper
Group weight: *,debug,Zookeeper
"One zero-weight group: 1, *",debug,Zookeeper
Set size: *,debug,Zookeeper
"Group info: *, *, *",debug,Zookeeper
"Majority group counter: *, *",debug,Zookeeper
Positive set size: *,debug,Zookeeper
Negative set size: *,debug,Zookeeper
This really should be impossible,error,Zookeeper
 is relative. Prepend . |  to indicate that you're sure!,warn,Zookeeper
Starting JVM Pause Monitor with infoThresholdMs:* warnThresholdMs:* and sleepTimeMs:*,info,Zookeeper
$$$Empty Message$$$,warn,Zookeeper
$$$Empty Message$$$,info,Zookeeper
* = *zookeeper.pathStats.slotCapacity,info,Zookeeper
* = *zookeeper.pathStats.slotDuration,info,Zookeeper
* = *zookeeper.pathStats.maxDepth,info,Zookeeper
* = *zookeeper.pathStats.initialDelay,info,Zookeeper
* = *zookeeper.pathStats.delay,info,Zookeeper
* = *zookeeper.pathStats.enabled,info,Zookeeper
shutdown scheduledExecutor,info,Zookeeper
Start the RequestPath collector,info,Zookeeper
We should not handle *,error,Zookeeper
Not able to load class or method for com.sun.managment.UnixOperatingSystemMXBean.,warn,Zookeeper
Not able to get the number of open file descriptors,warn,Zookeeper
Not able to get the max number of file descriptors,warn,Zookeeper
No buffered timestamps for messages * *,info,Zookeeper
Last * timestamps for messages * *:,warn,Zookeeper
* *  *,warn,Zookeeper
Using * as watch manager,info,Zookeeper
"The maxInProcessingDeadWatchers config is smaller than the suggested one, change it to use *",info,Zookeeper
"watcherCleanThreshold=*, watcherCleanIntervalInSeconds=*, watcherCleanThreadsNum=*, maxInProcessingDeadWatchers=*",info,Zookeeper
Got interrupted while waiting for dead watches queue size,info,Zookeeper
Received InterruptedException while waiting for cleanEvent,info,Zookeeper
Processing * dead watchers,info,Zookeeper
Takes * to process * watches,info,Zookeeper
WatcherCleaner thread exited,info,Zookeeper
WatcherCleaner thread shutdown is initiated,info,Zookeeper
Ignoring addWatch with closed cnxn,debug,Zookeeper
Ignoring addWatch with closed cnxn,debug,Zookeeper
* will use DIGEST-MD5 as SASL mechanism.,info,Zookeeper
Added private credential to * principal name: '*',debug,Zookeeper
Cannot add private credential to subject; authentication at the server may fail,warn,Zookeeper
* will use GSSAPI as SASL mechanism.,info,Zookeeper
creating sasl client: *=*;service=*;serviceHostname=*,debug,Zookeeper
Exception while trying to create SASL client,error,Zookeeper
serviceHostname is '*',debug,Zookeeper
servicePrincipalName is '*',debug,Zookeeper
SASL mechanism(mech) is '*'GSSAPI,debug,Zookeeper
"Added private credential to service principal name: '*', GSSCredential name: *",debug,Zookeeper
Cannot add private credential to subject; clients authentication may fail,warn,Zookeeper
Zookeeper Server failed to create a SaslServer to interact with a client during session initiation,error,Zookeeper
Zookeeper Quorum member experienced a PrivilegedActionException exception while creating a SaslServer using a JAAS principal context,error,Zookeeper
server principal name/hostname determination error,error,Zookeeper
Zookeeper Quorum member failed to create a SaslServer to interact with a client during session initiation,error,Zookeeper
Assigned port * from range *.,info,Zookeeper
Could not bind to port * from range *.  Attempting next port.,debug,Zookeeper
Error parsing test.junit.threads = *.,warn,Zookeeper
Error parsing threadid from *.,warn,Zookeeper
Test process */* using ports from *.,info,Zookeeper
Single test process using ports from *.,info,Zookeeper
Configuration:,info,Zookeeper
---------------------------------------------------------------,info,Zookeeper
  *: *,info,Zookeeper
---------------------------------------------------------------,info,Zookeeper
MiniKdc stated.,info,Zookeeper
MiniKdc stopped.,info,Zookeeper
WARNING: cannot delete file *,warn,Zookeeper
WARNING: cannot delete directory *,warn,Zookeeper
Failed to delete keytab file: *,error,Zookeeper
exception during write,warn,Zookeeper
socket timeout,error,Zookeeper
Interrupted,warn,Zookeeper
Unexpected exception,error,Zookeeper
Unexpected exception,error,Zookeeper
Shutting down forward for *,info,Zookeeper
accepting socket local:* to:*,info,Zookeeper
accepted: local:* from:* to:*,info,Zookeeper
"connection failed, retrying(*): local:* from:* to:*",warn,Zookeeper
connected: local:* from:* to:*,info,Zookeeper
socket timed out,warn,Zookeeper
connection exception local:* from:* to:*,warn,Zookeeper
unexpected exception local:* from:* to:*,warn,Zookeeper
Unexpected exception to:*,error,Zookeeper
Interrupted to:*,error,Zookeeper
Failed to access resource [*],debug,elasticsearch
Got successful response [*] from URL [*],info,elasticsearch
mapped dependency name * to * for license/notice check,info,elasticsearch
Checking sha for *,info,elasticsearch
$$$Empty Message$$$,warn,elasticsearch
$$$Empty Message$$$,warn,elasticsearch
Error while executing bulk request,warn,elasticsearch
Authentication to  |  failed (scheme:  | ). Preserving credentials for next request,debug,elasticsearch
removed [ | ] from blacklist,debug,elasticsearch
added [ | ] to blacklist,debug,elasticsearch
updated [ | ] already in blacklist,debug,elasticsearch
request [ |   | ] returned [ | ],debug,elasticsearch
$$$Empty Message$$$,warn,elasticsearch
error while reading request for trace purposes,trace,elasticsearch
error while reading response for trace purposes,trace,elasticsearch
$$$Empty Message$$$,trace,elasticsearch
request [ |   | ] failed,debug,elasticsearch
error while reading request for trace purposes,trace,elasticsearch
$$$Empty Message$$$,trace,elasticsearch
unknown role [ | ] on node [ | ],warn,elasticsearch
skipping node [ | ] with http disabled,debug,elasticsearch
adding node [ | ],trace,elasticsearch
error while sniffing nodes,error,elasticsearch
sniffed nodes: ,debug,elasticsearch
"no nodes to set, nodes will be updated at the next sniffing round",warn,elasticsearch
Synonym rule for [ | ] was ignored,info,elasticsearch
Synonym rule for [ | ] was ignored,info,elasticsearch
loaded [*] geo-IP database,debug,elasticsearch
$$$Empty Message$$$,error,elasticsearch
[*]: starting,debug,elasticsearch
[*]: finishing early because the task was cancelled,debug,elasticsearch
[*]: got scroll response with [*] hits,debug,elasticsearch
[*]: finishing early because the task was cancelled,debug,elasticsearch
[*]: preparing bulk request,debug,elasticsearch
[*]: finishing early because the task was cancelled,debug,elasticsearch
"[*]: sending [*] entry, [*] bulk request",debug,elasticsearch
[*]: finishing early because the task was cancelled,debug,elasticsearch
[*]: Finishing early because the task was cancelled,debug,elasticsearch
[*]: finishing early because the task was cancelled,debug,elasticsearch
[*]: refreshing,debug,elasticsearch
[*]: finishing without any catastrophic failures,debug,elasticsearch
rethrottling children of task [*] to [*] requests per second,debug,elasticsearch
"children of task [*] are already finished, nothing to rethrottle",debug,elasticsearch
rethrottling local task [*] to [*] requests per second,debug,elasticsearch
Failed to properly stop client thread [*],error,elasticsearch
First response looks like a scan response. Jumping right to the second. scroll=[*],debug,elasticsearch
Successfully cleared [*],debug,elasticsearch
$$$Empty Message$$$,debug,elasticsearch
$$$Empty Message$$$,warn,elasticsearch
cannot parse the specified url [*],warn,elasticsearch
$$$Empty Message$$$,warn,elasticsearch
disabling sd_notify as the build type [*] is not a package distribution,debug,elasticsearch
ES_SD_NOTIFY is set to [*],trace,elasticsearch
sd_notify returned [*],trace,elasticsearch
sd_notify returned [*],trace,elasticsearch
sd_notify returned error [*],warn,elasticsearch
"using max_chunk_size[*], max_header_size[*], max_initial_line_length[*], max_content_length[*], receive_predictor[*], max_composite_buffer_components[*], pipelining_max_events[*]",debug,elasticsearch
unexpected error while releasing pipelined http responses,error,elasticsearch
Failed to create a new channel from an accepted socket.,warn,elasticsearch
Failed to close a socket.,warn,elasticsearch
"using profile[*], worker_count[*], port[*], bind_host[*], publish_host[*], receive_predictor[*->*]",debug,elasticsearch
"creating new Azure client for [*], [*]",trace,elasticsearch
"creating new Azure client for [*], [*]",debug,elasticsearch
error while closing Azure client,error,elasticsearch
using cache to retrieve node list,trace,elasticsearch
start building nodes list using Azure API,debug,elasticsearch
Azure discovery service has been disabled. Returning empty list of nodes.,debug,elasticsearch
can not get list of azure nodes: [*]. Returning empty list of nodes.,warn,elasticsearch
AzureServiceRemoteException caught,trace,elasticsearch
ip of current node: [*],trace,elasticsearch
exception while finding ip,trace,elasticsearch
current deployment slot [*] for [*] is different from [*]. skipping...,debug,elasticsearch
current deployment name [*] different from [*]. skipping...,debug,elasticsearch
[*] status is [*]. skipping...,debug,elasticsearch
no network address found. ignoring [*]...,warn,elasticsearch
"adding *, transport_address *",trace,elasticsearch
can not convert [*] to transport address. skipping. [*],warn,elasticsearch
* addresses added,debug,elasticsearch
no private ip provided. ignoring [*]...,trace,elasticsearch
ignoring endpoint [*] as different than [*],trace,elasticsearch
starting azure classic discovery plugin...,trace,elasticsearch
obtaining ec2 hostname from ec2 meta-data url *,debug,elasticsearch
using explicit ec2 endpoint [*],debug,elasticsearch
Using default provider chain,debug,elasticsearch
Using basic key/secret credentials,debug,elasticsearch
"Using either environment variables, system properties or instance profile credentials",debug,elasticsearch
Using basic key/secret credentials,debug,elasticsearch
Using basic session credentials,debug,elasticsearch
"Register _ec2_, _ec2:xxx_ network names",debug,elasticsearch
obtaining ec2 [placement/availability-zone] from ec2 meta-data url *,debug,elasticsearch
failed to get metadata for [placement/availability-zone],error,elasticsearch
"using host_type [*], tags [*], groups [*] with any_group [*], availability_zones [*]",debug,elasticsearch
Exception while retrieving instance list from AWS API: *,info,elasticsearch
Full exception:,debug,elasticsearch
finding seed nodes...,trace,elasticsearch
"filtering out instance * based on groups *, not part of *",trace,elasticsearch
"filtering out instance * based on groups *, does not include all of *",trace,elasticsearch
reading hostname from [*] instance tag,debug,elasticsearch
using [*] as the instance address,debug,elasticsearch
"adding *, address *, transport_address *",trace,elasticsearch
$$$Empty Message$$$,warn,elasticsearch
"not adding *, address is null, host_type *",trace,elasticsearch
using dynamic transport addresses *,debug,elasticsearch
--> mocking describeInstances,debug,elasticsearch
--> expected tags: [*],debug,elasticsearch
--> instance tags: [*],debug,elasticsearch
--> instance added,debug,elasticsearch
--> instance filtered,debug,elasticsearch
get metadata from [*],debug,elasticsearch
metadata found [*],debug,elasticsearch
unable to shutdown GCE Http Transport,warn,elasticsearch
"get instances for project [*], zones [*]",debug,elasticsearch
disabling GCE discovery. Can not get list of nodes,warn,elasticsearch
unable to resolve project from metadata server for GCE discovery service,warn,elasticsearch
unable to resolve default zone from metadata server for GCE discovery service,warn,elasticsearch
using cache to retrieve client,trace,elasticsearch
starting GCE discovery service,info,elasticsearch
token [*] will expire in [*] s,debug,elasticsearch
unable to start GCE discovery service,warn,elasticsearch
configure GceModule (bind compute service),debug,elasticsearch
Retrying [*] times : [*],debug,elasticsearch
using tags *,debug,elasticsearch
using cache to retrieve node list,trace,elasticsearch
start building nodes list using GCE API,debug,elasticsearch
"no instance found for project [*], zones [*].",trace,elasticsearch
gce instance * with status * found.,trace,elasticsearch
node * is TERMINATED. Ignoring,debug,elasticsearch
start filtering instance * with tags *.,trace,elasticsearch
no tags for this instance but we asked for tags. * won't be part of the cluster.,trace,elasticsearch
comparing instance tags * with tags filter *.,trace,elasticsearch
"filtering out instance * based tags *, not part of *",trace,elasticsearch
instance * with tags * is added to discovery,trace,elasticsearch
current node found. Ignoring * - *,trace,elasticsearch
es_port is defined with *,trace,elasticsearch
es_port is instance of *. Ignoring...,trace,elasticsearch
"adding *, type *, address *, transport_address *, status *",trace,elasticsearch
$$$Empty Message$$$,warn,elasticsearch
exception caught during discovery,warn,elasticsearch
* addresses added,debug,elasticsearch
using transport addresses *,debug,elasticsearch
starting gce discovery plugin...,trace,elasticsearch
"Register _gce_, _gce:xxx network names",debug,elasticsearch
--> Simulate GCE Auth/Metadata response for [*],info,elasticsearch
--> Simulate GCE API response for [*],info,elasticsearch
blobExists(*),trace,elasticsearch
can not access [*] in container {*}: *,warn,elasticsearch
readBlob(*),trace,elasticsearch
"writeBlob(*, stream, *)",trace,elasticsearch
deleteBlob(*),trace,elasticsearch
listBlobsByPrefix(*),trace,elasticsearch
can not access [*] in container {*}: *,warn,elasticsearch
listBlobs(),trace,elasticsearch
"""Application Default Credentials"" are not supported out of the box. Additional file system permissions have to be granted to the plugin.",warn,elasticsearch
"using bucket [*], base_path [*], chunk_size [*], compress [*]",debug,elasticsearch
Adding configuration to HDFS Client Configuration : * = *,debug,elasticsearch
"Using file-system [*] for URI [*], path [*]",debug,elasticsearch
"Hadoop authentication method is set to [SIMPLE], but a Kerberos principal is specified. Continuing with [KERBEROS] authentication.",warn,elasticsearch
Hadoop security enabled: [*],debug,elasticsearch
Using Hadoop authentication method: [*],debug,elasticsearch
Using kerberos principal [*] and keytab located at [*],debug,elasticsearch
Found service principal. Converted original principal name [*] to server principal [*],debug,elasticsearch
using endpoint [*],debug,elasticsearch
Using instance profile credentials,debug,elasticsearch
Using basic key/secret credentials,debug,elasticsearch
"using bucket [*], chunk_size [*], server_side_encryption [*], buffer_size [*], cannedACL [*], storageClass [*]",debug,elasticsearch
"using max_chunk_size[*], max_header_size[*], max_initial_line_length[*], max_content_length[*], pipelining_max_events[*]",debug,elasticsearch
unexpected exception while stopping nio group,warn,elasticsearch
unexpected error while releasing pipelined http responses,error,elasticsearch
unexpected exception while stopping nio group,warn,elasticsearch
exception caught on transport layer [thread=*],warn,elasticsearch
Exception from http client,error,elasticsearch
Package type: ,info,elasticsearch
Got connection refused when waiting for cluster health,debug,elasticsearch
Installing file: ,info,elasticsearch
Exception cause unwrapping ran for 10 levels...,warn,elasticsearch
Using REST wrapper from plugin ,debug,elasticsearch
"explaining the allocation for [*], found shard [*]",debug,elasticsearch
attempt to execute a cluster health operation without a task,warn,elasticsearch
stopped being master while waiting for events with priority [*]. retrying.,trace,elasticsearch
Calculating health based on state version [*],trace,elasticsearch
cancelling task * on child nodes,trace,elasticsearch
task * doesn't have any children that should be cancelled,trace,elasticsearch
task * is already cancelled,trace,elasticsearch
"Sending ban for tasks with the parent [*] to the node [*], ban [*]",trace,elasticsearch
Cannot send ban for tasks with the parent [*] to the node [*],warn,elasticsearch
Sending remove ban for tasks with the parent [*] to the node [*],debug,elasticsearch
"Received ban for the parent [*] on the node [*], reason: [*]",debug,elasticsearch
Removing ban for the parent [*] on the node [*],debug,elasticsearch
Running cleanup operations on repository [*][*],info,elasticsearch
Initialized repository cleanup in cluster state for [*][*],debug,elasticsearch
Finished repository cleanup operations on [*][*],debug,elasticsearch
Done with repository cleanup on [*][*] with result [*],info,elasticsearch
ignoring existing unknown * setting: [*] with value [*]; archiving,warn,elasticsearch
$$$Empty Message$$$,warn,elasticsearch
"Skipping reroute after cluster update settings, because node is no longer master",debug,elasticsearch
failed to preform reroute after cluster settings were updated - current node is no longer a master,debug,elasticsearch
restore of [*] completed,debug,elasticsearch
"snapshot status request ignoring snapshot [*], not found in repository [*]",debug,elasticsearch
Serving cluster state request using version *,trace,elasticsearch
fetching pending tasks from cluster service,trace,elasticsearch
done fetching pending tasks from cluster service,trace,elasticsearch
failed to perform aliases,debug,elasticsearch
* shard is ready for closing,trace,elasticsearch
* flush request executed on replica,trace,elasticsearch
serving getMapping request based on version *,trace,elasticsearch
* refresh request executed on replica,trace,elasticsearch
using cluster state version [*] to determine shards,trace,elasticsearch
"Not updating settings for the index [*] because upgraded of some primary shards failed - expected[*], received[*]",warn,elasticsearch
"cluster is blocked, scheduling a retry",trace,elasticsearch
Retry of bulk request scheduled in * ms.,trace,elasticsearch
$$$Empty Message$$$,trace,elasticsearch
$$$Empty Message$$$,debug,elasticsearch
* primary-replica resync to replica on node [*] failed,info,elasticsearch
[*] Failed to execute * phase,debug,elasticsearch
"Partial shards failure (unavailable: *, successful: *, skipped: *, num-shards: *, phase: *)",debug,elasticsearch
"[*] Moving to next phase: [*], based on results from: * (cluster state version: *)",trace,elasticsearch
Failed to execute [*] while moving to [*] phase,debug,elasticsearch
got first-phase result from *,trace,elasticsearch
failed to release context,trace,elasticsearch
*: Failed to execute [*],debug,elasticsearch
*: Failed to execute [*],trace,elasticsearch
*: Failed to execute [*] lastShard [*],debug,elasticsearch
[*] cluster service closed while waiting for enough shards to be started.,debug,elasticsearch
Error during transport action execution.,trace,elasticsearch
resolving shards based on cluster state version [*],trace,elasticsearch
received response for *,trace,elasticsearch
*: failed to execute [*],trace,elasticsearch
*: failed to execute [*],debug,elasticsearch
resolving shards for [*] based on cluster state version [*],trace,elasticsearch
received response for [*] from node [*],trace,elasticsearch
failed to execute [*] on node [*],debug,elasticsearch
failed to combine responses from nodes,debug,elasticsearch
[*] executing operation on [*] shards,trace,elasticsearch
[*]  executing operation for shard [*],trace,elasticsearch
[*]  completed operation for shard [*],trace,elasticsearch
[*] failed to execute operation for shard [*],trace,elasticsearch
[*] failed to execute operation for shard [*],debug,elasticsearch
"can't execute due to a cluster block, retrying",trace,elasticsearch
"no known master node, scheduling a retry",debug,elasticsearch
"connection exception while trying to forward request with action name [*] to master node [*], scheduling a retry. Error: [*]",debug,elasticsearch
failed to execute on node [*],debug,elasticsearch
failed to combine responses from nodes,debug,elasticsearch
"cluster is blocked, action failed on primary",trace,elasticsearch
action [*] completed on shard [*] for request [*],trace,elasticsearch
"cluster is blocked, scheduling a retry",trace,elasticsearch
send action [*] to local primary [*] for request [*] with cluster state version [*] to [*] ,trace,elasticsearch
"failed to find primary [*] for request [*] despite sender thinking it would be here. Local cluster state version [*]] is older than on sending node (version [*]), scheduling a retry...",trace,elasticsearch
send action [*] on primary [*] for request [*] with cluster state version [*] to [*],trace,elasticsearch
"primary shard [*] is not yet active, scheduling a retry: action [*], request [*], cluster state version [*]",trace,elasticsearch
"primary shard [*] is assigned to an unknown node [*], scheduling a retry: action [*], request [*], cluster state version [*]",trace,elasticsearch
"operation succeeded. action [*],request [*]",trace,elasticsearch
[*] op [*] completed on primary for request [*],trace,elasticsearch
[*] sending op [*] to replica * for request [*],trace,elasticsearch
"[*] not enough active copies to meet shard count of [*] (have *, needed *), scheduling a retry. op [*], request [*]",trace,elasticsearch
*: got response from *,trace,elasticsearch
*: got failure from *,trace,elasticsearch
*: got all shard responses,trace,elasticsearch
[*] *,warn,elasticsearch
executing [*] based on cluster state version [*],trace,elasticsearch
sending request [*] to shard [*] on node [*],trace,elasticsearch
executing [*] on shard [*],trace,elasticsearch
failed to generate empty response,debug,elasticsearch
failed to execute on node [*],debug,elasticsearch
failed to combine responses from nodes,debug,elasticsearch
"Invalid upsert operation [*] for script [*], doing nothing...",warn,elasticsearch
"Used upsert operation [*] for script [*], doing nothing...",warn,elasticsearch
Retry attempt [*] of [*] on version conflict on [*][*][*],trace,elasticsearch
windows/Kernel32 library loaded,debug,elasticsearch
JNA not found. native methods and handlers will be disabled.,warn,elasticsearch
unable to link Windows/Kernel32 library. native methods and handlers will be disabled.,warn,elasticsearch
console control handler receives event [*@*],debug,elasticsearch
Unable to retrieve resource limits: *,warn,elasticsearch
"Unable to lock JVM Memory: error=*, reason=*",warn,elasticsearch
This can result in part of the JVM being swapped out.,warn,elasticsearch
"Increase RLIMIT_MEMLOCK, soft limit: *, hard limit: *",warn,elasticsearch
"These can be adjusted by modifying /etc/security/limits.conf, for example:  	# allow user '*' mlockall 	* soft memlock unlimited 	* hard memlock unlimited",warn,elasticsearch
"If you are logged in interactively, you will have to re-login for the new limits to take effect.",warn,elasticsearch
Increase RLIMIT_MEMLOCK (ulimit).,warn,elasticsearch
unable to retrieve max number of threads [ | ],warn,elasticsearch
unable to retrieve max size virtual memory [ | ],warn,elasticsearch
unable to retrieve max file size [ | ],warn,elasticsearch
Unable to lock JVM memory. Failed to set working set size. Error code *,warn,elasticsearch
failed to get short path name: *,warn,elasticsearch
failed to get short path name: *,warn,elasticsearch
console ctrl handler correctly set,debug,elasticsearch
unknown error * when adding console ctrl handler,warn,elasticsearch
unable to install syscall filter,debug,elasticsearch
unable to install syscall filter: ,warn,elasticsearch
running graceful exit on windows,info,elasticsearch
Thread got interrupted while waiting for the node to shutdown.,warn,elasticsearch
Thread got interrupted while waiting for the node to shutdown.,warn,elasticsearch
Guice Exception: *,error,elasticsearch
node validation exception *,error,elasticsearch
Exception,error,elasticsearch
"bound or publishing to a non-loopback address, enforcing bootstrap checks",info,elasticsearch
explicitly enforcing bootstrap checks,info,elasticsearch
$$$Empty Message$$$,warn,elasticsearch
cannot mlockall because JNA is not available,warn,elasticsearch
cannot check if running as root because JNA is not available,warn,elasticsearch
cannot virtual lock because JNA is not available,warn,elasticsearch
cannot obtain short path for [*] because JNA is not available,warn,elasticsearch
cannot register console handler because JNA is not available,warn,elasticsearch
cannot install system call filter because JNA is not available,warn,elasticsearch
cannot getrlimit RLIMIT_NPROC because JNA is not available,warn,elasticsearch
cannot getrlimit RLIMIT_AS because JNA is not available,warn,elasticsearch
cannot getrlimit RLIMIT_FSIZE because JNA is not available,warn,elasticsearch
"seccomp(SECCOMP_SET_MODE_FILTER): *, falling back to prctl(PR_SET_SECCOMP)...",debug,elasticsearch
"Linux seccomp filter installation successful, threads: [*]",debug,elasticsearch
OS X seatbelt initialization successful,debug,elasticsearch
Solaris priv_set initialization successful,debug,elasticsearch
BSD RLIMIT_NPROC initialization successful,debug,elasticsearch
Windows ActiveProcessLimit initialization successful,debug,elasticsearch
node_sampler_interval[*],debug,elasticsearch
"address [*] already exists with [*], ignoring...",debug,elasticsearch
adding address [*],debug,elasticsearch
removing address [*] from listed nodes,debug,elasticsearch
disconnecting from node with address [*],debug,elasticsearch
connecting to node [*],trace,elasticsearch
failed to sample,warn,elasticsearch
"node * not part of the cluster *, ignoring...",warn,elasticsearch
connecting to cluster node [*],trace,elasticsearch
"node * not part of the cluster *, ignoring...",warn,elasticsearch
"I have been elected master, scheduling a ClusterInfoUpdateJob",trace,elasticsearch
Couldn't schedule cluster info update task - node might be shutting down,debug,elasticsearch
"data node was added, retrieving new cluster info",debug,elasticsearch
Removing node from cluster info: *,trace,elasticsearch
Submitting new rescheduling cluster info update job,trace,elasticsearch
Couldn't re-schedule cluster info update task - node might be shutting down,debug,elasticsearch
Skipping ClusterInfoUpdatedJob since it is disabled,trace,elasticsearch
Performing ClusterInfoUpdateJob,trace,elasticsearch
NodeStatsAction timed out for ClusterInfoUpdateJob,error,elasticsearch
Failed to execute NodeStatsAction for ClusterInfoUpdateJob,trace,elasticsearch
Failed to execute NodeStatsAction for ClusterInfoUpdateJob,warn,elasticsearch
IndicesStatsAction timed out for ClusterInfoUpdateJob,error,elasticsearch
Failed to execute IndicesStatsAction for ClusterInfoUpdateJob,trace,elasticsearch
Failed to execute IndicesStatsAction for ClusterInfoUpdateJob,warn,elasticsearch
Failed to update node information for ClusterInfoUpdateJob within * timeout,warn,elasticsearch
Failed to update shard information for ClusterInfoUpdateJob within * timeout,warn,elasticsearch
notifying [*] of new cluster info,trace,elasticsearch
failed to notify [*] of new cluster info,info,elasticsearch
shard: * size: *,trace,elasticsearch
Unable to retrieve node FS stats for *,warn,elasticsearch
"node: [*], most available: total disk: *, available disk: * / least available: total disk: *, available disk: *",trace,elasticsearch
"node: [*] least available path has less than 0 total bytes of disk [*], skipping",trace,elasticsearch
"node: [*] most available path has less than 0 total bytes of disk [*], skipping",trace,elasticsearch
connectDisconnectedTargets: *,trace,elasticsearch
unexpected error while checking for node reconnects,warn,elasticsearch
connected to *,debug,elasticsearch
disconnected from *,debug,elasticsearch
"failed to disconnect from *, possible connection leak",warn,elasticsearch
"observer timed out. notifying listener. timeout setting [*], time since start [*]",trace,elasticsearch
observer: sampled state accepted by predicate (*),trace,elasticsearch
observer: sampled state rejected by predicate (*). adding listener to ClusterService,trace,elasticsearch
observer: accepting cluster state change (*),trace,elasticsearch
observer: predicate approved change but observing context has changed - ignoring (new cluster state version [*]),trace,elasticsearch
observer: predicate rejected change (new cluster state version [*]),trace,elasticsearch
observer: post adding listener: accepting current cluster state (*),trace,elasticsearch
observer: postAdded - predicate approved state but observing context has changed - ignoring (*),trace,elasticsearch
observer: postAdded - predicate rejected state (*),trace,elasticsearch
observer: cluster service closed. notifying listener.,trace,elasticsearch
"observer: timeout notification from cluster service. timeout setting [*], time since start [*]",trace,elasticsearch
"can't send mapping refresh for [*], no master known.",warn,elasticsearch
no master known for action [*] for shard entry [*],warn,elasticsearch
sending [*] to [*] for shard entry [*],debug,elasticsearch
unexpected failure while sending request [*] |  to [*] for shard entry [*],warn,elasticsearch
new cluster state [*] after waiting for master election for shard entry [*],trace,elasticsearch
node closed while execution action [*] for shard entry [*],warn,elasticsearch
* no longer master while failing shard [*],error,elasticsearch
* ignoring shard failed task [*] (unknown index *),debug,elasticsearch
* failing shard failed task [*] (primary term * does not match current term *),debug,elasticsearch
* marking shard * as stale (shard failed task: [*]),debug,elasticsearch
* ignoring shard failed task [*] (shard does not exist anymore),debug,elasticsearch
* failing shard * (shard failed task: [*]),debug,elasticsearch
"*, scheduling a reroute",trace,elasticsearch
* received shard started for [*],debug,elasticsearch
* ignoring shard started task [*] (shard does not exist anymore),debug,elasticsearch
* ignoring shard started task [*] (primary term * does not match current term *),debug,elasticsearch
* ignoring shard started task [*] (shard exists but is not initializing: *),debug,elasticsearch
* ignoring shard started task [*] (already scheduled to start *),trace,elasticsearch
* starting shard * (shard started task: [*]),debug,elasticsearch
failed to send back failure on join request,warn,elasticsearch
attempting to join * with *,debug,elasticsearch
successfully joined * with *,debug,elasticsearch
"already attempting to join * with request *, not sending request",debug,elasticsearch
successful response to * from *,debug,elasticsearch
failure in response to * from *,debug,elasticsearch
"processing node joins, but we are not the master. current master: *",trace,elasticsearch
received a join request for an existing node [*],debug,elasticsearch
"removing existing node [*], which conflicts with incoming join from [*]",debug,elasticsearch
"removing existing node [*], which conflicts with incoming join from [*]",debug,elasticsearch
becomeMasterAndTrimConflictingNodes: *,trace,elasticsearch
setCurrentNodes: *,trace,elasticsearch
non-master handling *,debug,elasticsearch
leader check from unknown node: *,debug,elasticsearch
handling *,trace,elasticsearch
"disconnect event ignored for *, no check scheduler",trace,elasticsearch
"already closed, doing nothing",trace,elasticsearch
closed,debug,elasticsearch
"closed check scheduler woken up, doing nothing",trace,elasticsearch
checking * with [*] = *,trace,elasticsearch
"closed check scheduler received a response, doing nothing",debug,elasticsearch
"closed check scheduler received a response, doing nothing",debug,elasticsearch
leader [*] disconnected during check,debug,elasticsearch
leader [*] has failed * consecutive checks (limit [*] is *); last failure was:,debug,elasticsearch
* consecutive failures (limit [*] is *) with leader [*],debug,elasticsearch
"already closed, not failing leader",trace,elasticsearch
leader [*] disconnected,debug,elasticsearch
scheduling next check of * for [*] = *,trace,elasticsearch
bootstrapping cancelled,warn,elasticsearch
"nodesMatchingRequirements=*, unsatisfiedRequirements=*, bootstrapRequirements=*",trace,elasticsearch
skipping cluster bootstrapping as local node does not match bootstrap requirements: *,info,elasticsearch
"no discovery configuration found, will perform best-effort cluster bootstrapping after [*] unless existing master is discovered",info,elasticsearch
performing best-effort cluster bootstrapping with *,debug,elasticsearch
avoiding best-effort cluster bootstrapping due to discovery of pre-7.0 nodes *,info,elasticsearch
"exception when bootstrapping with *, rescheduling",warn,elasticsearch
responding to * on fast path,trace,elasticsearch
responding to * on slow path,trace,elasticsearch
exception while responding to *,debug,elasticsearch
handleWakeUp: not running,trace,elasticsearch
handleWakeUp: checking * with *,trace,elasticsearch
* no longer running,trace,elasticsearch
* check successful,trace,elasticsearch
* no longer running,debug,elasticsearch
"* no longer running, not marking faulty",trace,elasticsearch
* marking node as faulty,debug,elasticsearch
setInitialState: rejecting since last-accepted configuration is nonempty: *,debug,elasticsearch
handleStartJoin: ignoring [*] as term provided is not greater than current term [*],debug,elasticsearch
handleStartJoin: leaving term [*] due to *,debug,elasticsearch
handleStartJoin: discarding *: *,debug,elasticsearch
"handleJoin: ignored join due to term mismatch (expected: [*], actual: [*])",debug,elasticsearch
handleJoin: ignored join as term was not incremented yet after reboot,debug,elasticsearch
"handleJoin: ignored join as joiner has a better last accepted term (expected: <=[*], actual: [*])",debug,elasticsearch
"handleJoin: ignored join as joiner has a better last accepted version (expected: <=[*], actual: [*]) in term *",debug,elasticsearch
handleJoin: rejecting join since this node has not received its initial configuration yet,debug,elasticsearch
"handleJoin: added join * from [*] for election, electionWon=* lastAcceptedTerm=* lastAcceptedVersion=*",debug,elasticsearch
handleJoin: election won in term [*] with *,debug,elasticsearch
handleClientValue: ignored request as election not won,debug,elasticsearch
handleClientValue: cannot start publishing next value before accepting previous one,debug,elasticsearch
"handleClientValue: ignored request due to term mismatch (expected: [term * version >*], actual: [term * version *])",debug,elasticsearch
"handleClientValue: ignored request due to version mismatch (expected: [term * version >*], actual: [term * version *])",debug,elasticsearch
handleClientValue: only allow reconfiguration while not already reconfiguring,debug,elasticsearch
handleClientValue: only allow reconfiguration if joinVotes have quorum for new config,debug,elasticsearch
handleClientValue: processing request for version [*] and term [*],trace,elasticsearch
"handlePublishRequest: ignored publish request due to term mismatch (expected: [*], actual: [*])",debug,elasticsearch
"handling publish request in compatibility mode despite version mismatch (expected: >[*], actual: [*])",debug,elasticsearch
"handlePublishRequest: ignored publish request due to version mismatch (expected: >[*], actual: [*])",debug,elasticsearch
handlePublishRequest: accepting publish request for version [*] and term [*],trace,elasticsearch
handlePublishResponse: ignored response as election not won,debug,elasticsearch
"handlePublishResponse: ignored publish response due to term mismatch (expected: [*], actual: [*])",debug,elasticsearch
"handlePublishResponse: ignored publish response due to version mismatch (expected: [*], actual: [*])",debug,elasticsearch
handlePublishResponse: accepted publish response for version [*] and term [*] from [*],trace,elasticsearch
handlePublishResponse: value committed for version [*] and term [*],trace,elasticsearch
"handleCommit: ignored commit request due to term mismatch (expected: [term * version *], actual: [term * version *])",debug,elasticsearch
"handleCommit: ignored commit request due to term mismatch (expected: [term * version *], actual: [term * version *])",debug,elasticsearch
"handleCommit: ignored commit request due to version mismatch (term *, expected: [*], actual: [*])",debug,elasticsearch
handleCommit: applying commit request for term [*] and version [*],trace,elasticsearch
cluster UUID set to [*],info,elasticsearch
"master node [*] failed, restarting discovery",info,elasticsearch
"onFollowerCheckRequest: current term is [*], rejecting *",trace,elasticsearch
onFollowerCheckRequest: responding successfully to *,trace,elasticsearch
"onFollowerCheckRequest: rejoining master, responding successfully to *",trace,elasticsearch
"onFollowerCheckRequest: received check from faulty master, rejecting *",trace,elasticsearch
handleApplyCommit: applying commit *,trace,elasticsearch
handlePublishRequest: handling [*] from [*],trace,elasticsearch
"received cluster state from * but currently following *, rejecting",debug,elasticsearch
"received cluster state from * with a different cluster uuid * than local cluster uuid *, rejecting",warn,elasticsearch
"updateMaxTermSeen: maxTermSeen = * > currentTerm = *, enqueueing term bump",debug,elasticsearch
"updateMaxTermSeen: maxTermSeen = * > currentTerm = *, bumping term",debug,elasticsearch
failed to bump term to *,warn,elasticsearch
skip election as local node may not win it: *,trace,elasticsearch
starting election with *,debug,elasticsearch
abdicating to * with term *,info,elasticsearch
joinLeaderInTerm: for [*] with term *,debug,elasticsearch
"handleJoinRequest: as *, handling *",trace,elasticsearch
"*: coordinator becoming CANDIDATE in term * (was *, lastKnownLeader was [*])",debug,elasticsearch
"*: coordinator becoming LEADER in term * (was *, lastKnownLeader was [*])",debug,elasticsearch
*: coordinator remaining FOLLOWER of [*] in term *,trace,elasticsearch
"*: coordinator becoming FOLLOWER of [*] in term * (was *, lastKnownLeader was [*])",debug,elasticsearch
failed to clean-up after stepping down as master,trace,elasticsearch
cluster UUID [*],info,elasticsearch
"initial configuration already set, ignoring *",debug,elasticsearch
skip setting initial configuration as local node is not a master-eligible node,debug,elasticsearch
skip setting initial configuration as local node is not part of initial configuration,debug,elasticsearch
"skip setting initial configuration as not enough nodes discovered to form a quorum in the initial configuration [knownNodes=*, *]",debug,elasticsearch
setting initial configuration to *,info,elasticsearch
scheduling reconfiguration,trace,elasticsearch
reconfiguration failed,debug,elasticsearch
failed to add * - ignoring,debug,elasticsearch
skip prevoting as local node may not win election: *,trace,elasticsearch
Cancelled publication of [*].,debug,elasticsearch
publication ended unsuccessfully: *,debug,elasticsearch
publication ended successfully: *,debug,elasticsearch
handling *,trace,elasticsearch
"onMissingJoin: no join vote from *, bumping term to exceed *",debug,elasticsearch
"updating with preVoteResponse=*, leader=*",trace,elasticsearch
* requesting pre-votes from *,debug,elasticsearch
"* is closed, ignoring * from *",debug,elasticsearch
* ignoring * from * as it is fresher,debug,elasticsearch
"* added * from *, no quorum yet",debug,elasticsearch
* added * from * but election has already started,debug,elasticsearch
"* added * from *, starting election",debug,elasticsearch
"upgrading=*, minimumMasterNodes=*, nodes=*",debug,elasticsearch
"elected *, sending join",debug,elasticsearch
unexpected exception when pinging *,debug,elasticsearch
publishing * to *,trace,elasticsearch
cancel: [*] cancelled before committing (reason: *),debug,elasticsearch
onPossibleCompletion: [*] commit failed,debug,elasticsearch
onPossibleCompletion: [*] was successful,trace,elasticsearch
"onPossibleCommitFailure: non-failed nodes * do not form a quorum, so * cannot succeed",debug,elasticsearch
handlePublishResponse: handling [*] from [*]),trace,elasticsearch
"onFaultyNode: [*] is faulty, failing target in publication *",debug,elasticsearch
"PublishResponseHandler.handleResponse: already failed, ignoring response from [*]",debug,elasticsearch
handling join within publish response: *,trace,elasticsearch
publish response from * contained no join,trace,elasticsearch
"ApplyCommitResponseHandler.handleResponse: already failed, ignoring response from [*]",debug,elasticsearch
failed to send response on commit,debug,elasticsearch
failed to send response on commit,debug,elasticsearch
sending full cluster state version * to *,trace,elasticsearch
sending cluster state diff for version * to *,trace,elasticsearch
unexpected error while deserializing an incoming cluster state,warn,elasticsearch
received full cluster state version [*] with size [*],debug,elasticsearch
received diff for but don't have any local cluster state - requesting full state,debug,elasticsearch
unexpected error while deserializing an incoming cluster state,warn,elasticsearch
"received diff cluster state version [*] with uuid [*], diff size [*]",debug,elasticsearch
"* reconfiguring * based on liveNodes=*, retiredNodeIds=*, currentMaster=*",trace,elasticsearch
* not scheduling election,debug,elasticsearch
unexpected exception in wakeup of *,debug,elasticsearch
* not starting election,debug,elasticsearch
* starting election,debug,elasticsearch
scheduling *,debug,elasticsearch
node * applied version * but this node's version is not being tracked,trace,elasticsearch
lag detection for version * is unnecessary: *,trace,elasticsearch
starting lag detector for version *: *,debug,elasticsearch
"* applied version *, max now *",trace,elasticsearch
* no longer active when checking version *,trace,elasticsearch
"* satisfied when checking version *, node applied version *",trace,elasticsearch
"node [*] is lagging at cluster state version [*], although publication of cluster state version [*] completed [*] ago",warn,elasticsearch
"node [*] does not exist in cluster state, ignoring",debug,elasticsearch
no longer master while processing node removal [*],debug,elasticsearch
unexpected exception scheduling cluster formation warning,debug,elasticsearch
$$$Empty Message$$$,warn,elasticsearch
Skipping unknown custom object with type *,warn,elasticsearch
* deleting index,info,elasticsearch
* tombstones purged from the cluster state. Previous tombstone size: *. Current tombstone size: *.,trace,elasticsearch
"index * is already closed, ignoring",debug,elasticsearch
"index * has been blocked before closing and is now deleted, ignoring",debug,elasticsearch
"index * has been blocked before closing and is already closed, ignoring",debug,elasticsearch
"primary shard * is unassigned, ignoring",debug,elasticsearch
verification of shards before closing * failed [*],debug,elasticsearch
verification of shards before closing * succeeded but index is already closed,debug,elasticsearch
verification of shards before closing * succeeded but block has been removed in the meantime,debug,elasticsearch
verification of shards before closing * succeeded but index is being restored in the meantime,debug,elasticsearch
verification of shards before closing * succeeded but index is being snapshot in the meantime,debug,elasticsearch
closing index * succeeded,debug,elasticsearch
"index * has been deleted since it was blocked before closing, ignoring",debug,elasticsearch
completed closing of indices *,info,elasticsearch
"Starting template upgrade to version *, * templates will be updated and * will be removed",info,elasticsearch
"Error updating template [*], request was not acknowledged",warn,elasticsearch
Error updating template [*],warn,elasticsearch
"Error deleting template [*], request was not acknowledged",warn,elasticsearch
Error deleting template [*],warn,elasticsearch
Templates were partially upgraded to version *,info,elasticsearch
Templates were upgraded successfully to version *,info,elasticsearch
Templates are still reported as out of date after the upgrade. The template upgrade will be retried.,warn,elasticsearch
updating number_of_replicas to [*] for indices *,info,elasticsearch
"[*] creating index, cause [*], templates *, shards [*]/[*], mappings *",info,elasticsearch
ignoring a mapping task of type [*] with a null index.,debug,elasticsearch
[*] ignoring tasks - index meta data doesn't exist,debug,elasticsearch
* ignoring task [*] - index meta data doesn't match task uuid,debug,elasticsearch
[*] re-syncing mappings with cluster state because of types [*],warn,elasticsearch
* update_mapping [*] with source [*],debug,elasticsearch
* update_mapping [*],info,elasticsearch
* create_mapping [*] with source [*],debug,elasticsearch
* create_mapping [*],info,elasticsearch
removing template [*],info,elasticsearch
adding template [*] for index patterns *,info,elasticsearch
"already has pending reroute at priority [*], adding [*] with priority [*] to batch",trace,elasticsearch
"already has pending reroute at priority [*], promoting batch to [*] and adding [*]",trace,elasticsearch
"no pending reroute, scheduling reroute [*] at priority [*]",trace,elasticsearch
performing batched reroute [*],trace,elasticsearch
batched reroute [*] was promoted,trace,elasticsearch
failed to submit schedule/execute reroute post unassigned shard,warn,elasticsearch
failed to schedule/execute reroute post unassigned shard,warn,elasticsearch
cancelling existing delayed reroute task,trace,elasticsearch
no need to schedule reroute - no delayed unassigned shards,trace,elasticsearch
cancelling existing delayed reroute task as delayed reroute has to happen [*] earlier,trace,elasticsearch
scheduling reroute for delayed shards in [*] (* delayed shards),info,elasticsearch
no need to reschedule delayed reroute - currently scheduled delayed reroute in [*] is enough,trace,elasticsearch
* marked shard as started (routing: *),trace,elasticsearch
* failing shard * with unassigned info (*),debug,elasticsearch
* is removed due to the failure/cancellation of the source shard,trace,elasticsearch
"*, relocation source failed / cancelled, mark as initializing without relocation source",trace,elasticsearch
"* is a relocation target, resolving source to cancel relocation (*)",trace,elasticsearch
"*, resolved source to [*]. canceling relocation ... (*)",trace,elasticsearch
"flood stage disk watermark [*] exceeded on *, all indices on this node will be marked read-only",warn,elasticsearch
"high disk watermark [*] exceeded on *, shards will be relocated away from this node",warn,elasticsearch
"low disk watermark [*] exceeded on *, replicas will not be assigned to this node",info,elasticsearch
"flood stage disk watermark [*] exceeded on *, all indices on this node will be marked read-only",warn,elasticsearch
"high disk watermark [*] exceeded on *, shards will be relocated away from this node",warn,elasticsearch
"low disk watermark [*] exceeded on *, replicas will not be assigned to this node",info,elasticsearch
skipping monitor as a check is already in progress,info,elasticsearch
"high disk watermark exceeded on * but an automatic reroute has occurred in the last [*], skipping reroute",debug,elasticsearch
"* has gone below a disk threshold, but an automatic reroute has occurred in the last [*], skipping reroute",debug,elasticsearch
rerouting shards: [*],info,elasticsearch
releasing read-only-allow-delete block on indices: [*],info,elasticsearch
"[*] disabled, not releasing read-only-allow-delete block on indices: [*]es.disk.auto_release_flood_stage_block",debug,elasticsearch
* marking unavailable shards as stale: *,warn,elasticsearch
"* shard routing modified in an earlier iteration (previous: *, current: *)",trace,elasticsearch
failing shard [*],warn,elasticsearch
* shard routing failed in an earlier iteration (routing: *),trace,elasticsearch
updating number_of_replicas to [*] for indices *,info,elasticsearch
Cluster health status changed from [*] to [*] (reason: [*]).,info,elasticsearch
Start balancing cluster,trace,elasticsearch
skipping rebalance due to in-flight shard/store fetches,debug,elasticsearch
skipping rebalance as it is disabled,trace,elasticsearch
skipping rebalance as single node only,trace,elasticsearch
Stop balancing index [*]  min_node [*] weight: [*]  max_node [*] weight: [*]  delta: [*],trace,elasticsearch
Balancing from node [*] weight: [*] to node [*] weight: [*]  delta: [*],trace,elasticsearch
Moved shard [*] to node [*],trace,elasticsearch
[*][*] can't move,trace,elasticsearch
Assigned shard [*] to node [*],trace,elasticsearch
Start allocating unassigned shards,trace,elasticsearch
Assigned shard [*] to [*],trace,elasticsearch
No eligible node found to assign shard [*] allocation_status [*],trace,elasticsearch
Can not allocate on node [*] remove from round decision [*],trace,elasticsearch
No Node found to assign shard [*],trace,elasticsearch
Try relocating shard for index index [*] from node [*] to node [*],trace,elasticsearch
Relocate shard [*] from node [*] to node [*],debug,elasticsearch
Couldn't find shard to relocate from node [*] to node [*] allocation decision [*],trace,elasticsearch
"using node_concurrent_outgoing_recoveries [*], node_concurrent_incoming_recoveries [*], node_initial_primaries_recoveries [*]",debug,elasticsearch
node [*] has *% used disk,trace,elasticsearch
"less than the required * free bytes threshold (* free) on node *, preventing allocation",debug,elasticsearch
"less than the required * free bytes threshold (* free) on node *, but allowing allocation because primary has never been allocated",debug,elasticsearch
"less than the required * free bytes threshold (* free) on node *, preventing allocation even though primary has never been allocated",debug,elasticsearch
"more than the allowed * used disk threshold (* used) on node [*], preventing allocation",debug,elasticsearch
"more than the allowed * used disk threshold (* used) on node [*], but allowing allocation because primary has never been allocated",debug,elasticsearch
"less than the required * free bytes threshold (* bytes free) on node *, preventing allocation even though primary has never been allocated",debug,elasticsearch
"after allocating, node [*] would have less than the required threshold of * free (currently * free, estimated shard size is *), preventing allocation",warn,elasticsearch
"after allocating, node [*] would have more than the allowed * free disk threshold (* free), preventing allocation",warn,elasticsearch
node [*] has *% free disk (* bytes),trace,elasticsearch
"less than the required * free bytes threshold (* bytes free) on node *, shard cannot remain",debug,elasticsearch
"less than the required *% free disk threshold (*% free) on node *, shard cannot remain",debug,elasticsearch
"unable to determine disk usage for *, defaulting to average across nodes [* total] [* free] [*% free]",debug,elasticsearch
usage without relocations: *,trace,elasticsearch
usage with relocations: [* bytes] *,trace,elasticsearch
"only a single data node is present, allowing allocation",trace,elasticsearch
"cluster info unavailable for disk threshold decider, allowing allocation.",trace,elasticsearch
"unable to determine disk usages for disk-aware allocation, allowing allocation",trace,elasticsearch
Preventing snapshotted shard [*] from being moved away from node [*],trace,elasticsearch
using [cluster_concurrent_rebalance] with [*],debug,elasticsearch
Can not allocate [*] on node [*] due to [*],trace,elasticsearch
Shard [*] should be ignored for node [*],trace,elasticsearch
Shard [*] can not remain on node [*] due to [*],trace,elasticsearch
Shard [*] can not be forcefully allocated to node [*] due to [*].,trace,elasticsearch
"[*] has a wrong value *, defaulting to 'indices_all_active'",warn,elasticsearch
using [*] with [*]cluster.routing.allocation.allow_rebalance,debug,elasticsearch
"processing [*]: ignoring, master service not started",debug,elasticsearch
executing cluster state update for [*],debug,elasticsearch
failing [*]: local node is no longer master,debug,elasticsearch
"cluster state updated, source [*] *",trace,elasticsearch
"cluster state updated, version [*], source [*]",debug,elasticsearch
"*, term: *, version: *, reason: *",info,elasticsearch
publishing cluster state version [*],debug,elasticsearch
"took [*] and then failed to publish updated cluster state (version: *, uuid: *) for [*]:\n*",warn,elasticsearch
exception thrown by listener while notifying on all nodes acked,error,elasticsearch
exception thrown by listener while notifying on ack timeout,error,elasticsearch
"took [*], which is over [*], to * for [*]",warn,elasticsearch
took [*] to * for [*],debug,elasticsearch
expecting * acknowledgements for cluster_state update (version: *),trace,elasticsearch
"ack received from node [*], cluster_state update (version: *)",trace,elasticsearch
all expected nodes acknowledged cluster_state update (version: *),trace,elasticsearch
timeout waiting for acknowledgement for cluster_state update (version: *),trace,elasticsearch
failed to notify listeners on shutdown,debug,elasticsearch
"processing [*]: ignoring, cluster applier service not started",debug,elasticsearch
processing [*]: execute,debug,elasticsearch
processing [*]: took [*] no change in cluster state,debug,elasticsearch
"cluster state updated, version [*], source [*] *",debug,elasticsearch
"cluster state updated, version [*], source [*]",debug,elasticsearch
"processing [*]: took [*] done applying updated cluster state (version: *, uuid: *)",debug,elasticsearch
"failed to apply updated cluster state in [*]:\nversion [*], uuid [*], source [*]\n*",warn,elasticsearch
"failed to apply updated cluster state in [*]:\nversion [*], uuid [*], source [*]",warn,elasticsearch
"*, term: *, version: *, reason: *",info,elasticsearch
connecting to nodes of cluster state with version *,trace,elasticsearch
applying settings from cluster state with version *,debug,elasticsearch
apply cluster state with version *,debug,elasticsearch
set locally applied cluster state to version *,debug,elasticsearch
"interrupted while connecting to nodes, continuing",debug,elasticsearch
exception thrown by listener notifying of failure from [*],error,elasticsearch
exception thrown by listener while notifying of cluster state processed from [*],error,elasticsearch
cluster state applier task [*] took [*] which is above the warn threshold of [*]: *,warn,elasticsearch
task [*] timed out after [*],debug,elasticsearch
will process *,trace,elasticsearch
"skipping *, already processed",trace,elasticsearch
creating ChildCircuitBreaker with settings *,trace,elasticsearch
*,debug,elasticsearch
"[*] Adding [*][*] to used bytes [new used: [*], limit: [-1b]]",trace,elasticsearch
"[*] Adding [*][*] to used bytes [new used: [*], limit: * [*], estimate: * [*]]",trace,elasticsearch
"[*] New used memory * [*] for data of [*] would be larger than configured breaker: * [*], breaking",warn,elasticsearch
"[*] Adjusted breaker by [*] bytes, now [*]",trace,elasticsearch
shift: [*],debug,elasticsearch
Component [*]:,debug,elasticsearch
	*,debug,elasticsearch
Holes: *,debug,elasticsearch
	position (*) of edge *: *,debug,elasticsearch
	Component: *,debug,elasticsearch
	Hole intersections (*): *,debug,elasticsearch
[*] directory does not exist.,debug,elasticsearch
[*] should be a directory but is not.,debug,elasticsearch
[*] directory is not readable.,debug,elasticsearch
$$$Empty Message$$$,error,elasticsearch
$$$Empty Message$$$,warn,elasticsearch
Received cluster state update. Setting nodeId=[*] and clusterUuid=[*],debug,elasticsearch
$$$Empty Message$$$,error,elasticsearch
Some logging configurations have %marker but don't have %node_name. We will automatically add %node_name to the pattern to ease the migration for users who customize log4j2.properties but will stop this behavior in 7.0. You should manually replace `%node_name` with `[%node_name]%marker ` in these locations:   *,warn,elasticsearch
* *: *,trace,elasticsearch
unable to gather network information,warn,elasticsearch
configuration:**,debug,elasticsearch
the consistent secure setting [*] does not exist on the local node but there is a published hash for it,warn,elasticsearch
Nothing to publish. What is already published matches this node's view.,debug,elasticsearch
unable to publish secure settings hashes,error,elasticsearch
"I am no longer master, nothing to do",trace,elasticsearch
updating [*],info,elasticsearch
updating [*] from [*] to [*],info,elasticsearch
failed to apply settings,warn,elasticsearch
$$$Empty Message$$$,warn,elasticsearch
thread pool [*] will adjust queue by [*] when determining automatic queue size50,debug,elasticsearch
"[*]: there were [*] tasks in [*], avg task time [*], EWMA task execution [*], [* tasks/s], optimal queue is [*], current capacity [*]",debug,elasticsearch
"adjusted [*] queue size by [*], old capacity: [*], new capacity: [*]",debug,elasticsearch
"[*]: too many incoming tasks while queue size adjustment occurs, resetting measurements to 0",debug,elasticsearch
"Dropping a warning header, as their total size reached the maximum allowed of [ | ] bytes set in [ | ]!",warn,elasticsearch
"Dropping a warning header, as their total size reached the maximum allowed of [ | ] bytes set in [ | ]!",warn,elasticsearch
"Dropping a warning header, as their total count reached the maximum allowed of [ | ] set in [ | ]!",warn,elasticsearch
lifecycle is stopping. exiting,trace,elasticsearch
failed to write candidates,debug,elasticsearch
failed to notify callback,warn,elasticsearch
scheduling * every *,trace,elasticsearch
scheduled * disabled,trace,elasticsearch
using discovery type [*] and seed hosts providers *,info,elasticsearch
activating with *,trace,elasticsearch
deactivating and setting leader to *,trace,elasticsearch
not active,trace,elasticsearch
probing master nodes from cluster state: *,trace,elasticsearch
unexpected exception in wakeup,debug,elasticsearch
startProbe(*) not running,trace,elasticsearch
startProbe(*) not probing local node,trace,elasticsearch
* no longer connected,trace,elasticsearch
* attempting connection,trace,elasticsearch
* not requesting peers from local node,trace,elasticsearch
* requesting peers,trace,elasticsearch
* received *,trace,elasticsearch
* peers request failed,debug,elasticsearch
using initial hosts *,debug,elasticsearch
resolved host [*] to *,trace,elasticsearch
$$$Empty Message$$$,warn,elasticsearch
timed out after [*] resolving host [*],warn,elasticsearch
"using max_concurrent_resolvers [*], resolver timeout [*]",debug,elasticsearch
"resolveConfiguredHosts: lifecycle is *, not proceeding",debug,elasticsearch
failure when resolving unicast hosts list,debug,elasticsearch
"resolveConfiguredHosts.doRun: lifecycle is *, not proceeding",debug,elasticsearch
"expected, but did not find, a dynamic hosts list at [*]",warn,elasticsearch
seed addresses: *,debug,elasticsearch
[*] opening probe connection,trace,elasticsearch
[*] opened probe connection,trace,elasticsearch
[*] handshake successful: *,trace,elasticsearch
[*] full connection successful: *,trace,elasticsearch
handshake failed for [*],warn,elasticsearch
failed to handle transport disconnect for node: *,warn,elasticsearch
"[node  ] uses ping_interval [*], ping_timeout [*], ping_retries [*]",debug,elasticsearch
[node  ] [*] transport disconnected (with verified connect),trace,elasticsearch
[node  ] [*] transport disconnected,trace,elasticsearch
"[node  ] failed to ping [*], tried [*] times, each with  maximum [*] timeout",debug,elasticsearch
dropping pending state [*]. more than [*] pending states.,warn,elasticsearch
failing committed state * together with state *,debug,elasticsearch
"received a cluster state (uuid[*]/v[*]) from a different master than the current one, rejecting (received *, current *)",warn,elasticsearch
removing non-committed state with uuid[*]/v[*] from [*] - a state from [*] was successfully processed,trace,elasticsearch
processing pending state uuid[*]/v[*] together with state uuid[*]/v[*],trace,elasticsearch
"timed out waiting for all nodes to process published state [*] (timeout [*], pending nodes: *)",warn,elasticsearch
publishing cluster state with version [*] failed for the following nodes: [*],warn,elasticsearch
node * responded for cluster state [*] (took longer than [*]),debug,elasticsearch
resending full cluster state to node * reason *,debug,elasticsearch
"sending commit for cluster state (uuid: [*], version [*]) to [*]",trace,elasticsearch
node * responded to cluster state commit [*],debug,elasticsearch
received full cluster state version [*] with size [*],debug,elasticsearch
"received diff cluster state version [*] with uuid [*], diff size [*]",debug,elasticsearch
received diff for but don't have any local cluster state - requesting full state,debug,elasticsearch
unexpected error while deserializing an incoming cluster state,warn,elasticsearch
failed to send response on cluster state processed,debug,elasticsearch
failed to send response on cluster state processed,debug,elasticsearch
ignoring ack from [*] for cluster state version [*]. already failed,trace,elasticsearch
"master node * acked cluster state version [*]. processing ... (current pending [*], needed [*])",trace,elasticsearch
"master node * failed to ack cluster state version [*]. processing ... (current pending [*], needed [*])",trace,elasticsearch
committing version [*],trace,elasticsearch
failed to commit version [*]. *,trace,elasticsearch
"using max_concurrent_resolvers [*], resolver timeout [*]",debug,elasticsearch
unexpected error while pinging,warn,elasticsearch
unexpected error while finishing pinging round,warn,elasticsearch
[*] opening connection to [*],trace,elasticsearch
[*] closing connection to [*] due to failure,trace,elasticsearch
"[*] node [*] just disconnected, will create a temp connection",trace,elasticsearch
[*] sending to *,trace,elasticsearch
Ping execution rejected,debug,elasticsearch
[*] received response from *: *,trace,elasticsearch
[*] skipping received response from *. already closed,trace,elasticsearch
"using ping_timeout [*], join.timeout [*], master_election.ignore_non_master [*]",debug,elasticsearch
"failed to publish cluster state version [*] (not enough nodes acknowledged, min master nodes [*])",debug,elasticsearch
cluster state with version [*] that is published locally has neither been processed nor failed,warn,elasticsearch
thread is no longer in currentJoinThread. Stopping.,trace,elasticsearch
"elected as master, waiting for incoming joins ([*] needed)",debug,elasticsearch
"failed while waiting for nodes to join, rejoining",trace,elasticsearch
"no master node is set, despite of join request completing. retrying pings.",debug,elasticsearch
joining master *,trace,elasticsearch
"failed to send join request to master [*], reason [*], tried [*] times",info,elasticsearch
master * failed with [*]. retrying... (attempts done: [*]),trace,elasticsearch
"failed to send join request to master [*], reason [*]",info,elasticsearch
got first state from fresh master [*],debug,elasticsearch
"received a cluster state that is not newer than the current one, ignoring (received *, current *)",debug,elasticsearch
"received a cluster state that has a lower version than the current one, ignoring (received *, current *)",debug,elasticsearch
"received a cluster state from a different master than the current one, rejecting (received *, current *)",warn,elasticsearch
starting to ping,trace,elasticsearch
No full ping responses,trace,elasticsearch
full ping responses:*,trace,elasticsearch
candidate * won election,trace,elasticsearch
"not enough master nodes discovered during pinging (found [*], but needed [*]), pinging again",warn,elasticsearch
filtered ping responses: (ignore_non_masters [*])*,debug,elasticsearch
"*, current nodes: *",warn,elasticsearch
"discovered [*] which is also master but with an older cluster_state, telling [*] to rejoin the cluster ([*])",warn,elasticsearch
pingAndWait interrupted,trace,elasticsearch
Ping execution failed,warn,elasticsearch
received cluster state from [*] which is also master but with a different cluster name [*],warn,elasticsearch
"received a cluster state from [*] and not part of the cluster, should not happen",warn,elasticsearch
$$$Empty Message$$$,warn,elasticsearch
got a ping from another master *. current ping count: [*],trace,elasticsearch
got a ping from another master *. resolving who should rejoin. current ping count: [*],debug,elasticsearch
failed to send response on rejoin cluster request handling,warn,elasticsearch
"unexpected error while joining cluster, trying again",error,elasticsearch
timed out waiting to be elected. waited [*]. pending master node joins [*],trace,elasticsearch
unexpected failure while waiting for incoming joins,error,elasticsearch
"starting an election context, will accumulate joins",trace,elasticsearch
stopping election ([*]),trace,elasticsearch
"not enough joins for election. Got [*], required [*]",trace,elasticsearch
"have enough joins for election. Got [*], required [*]",trace,elasticsearch
failed to send back failure on join request,warn,elasticsearch
using minimum_master_nodes [*],debug,elasticsearch
"value for setting ""*"" is too low. This can result in data loss! Please set it to at least a quorum of master-eligible nodes (current value: [*], total number of master-eligible nodes used for publishing in this round: [*])",warn,elasticsearch
"[master] uses ping_interval [*], ping_timeout [*], ping_retries [*]",debug,elasticsearch
"[master] restarting fault detection against master [*], reason [*]",debug,elasticsearch
"[master] stopping fault detection against master [*], reason [*]",debug,elasticsearch
[master] [*] transport disconnected (with verified connect),trace,elasticsearch
[master] [*] transport disconnected,trace,elasticsearch
"master failure notification was rejected, it's highly likely the node is shutting down",error,elasticsearch
[master] pinging a master * that is no longer a master,debug,elasticsearch
[master] pinging a master * that is not the master,debug,elasticsearch
"[master] pinging a master * but we do not exists on it, act as if its master failure",debug,elasticsearch
"[master] failed to ping [*], tried [*] times, each with maximum [*] timeout",debug,elasticsearch
master fault detection ping request is targeted for a different [*] cluster then us [*],trace,elasticsearch
checking ping from * under a cluster state thread,trace,elasticsearch
error while sending ping response,warn,elasticsearch
error while sending ping response,warn,elasticsearch
obtaining node lock on * ...,trace,elasticsearch
"using node location [*], local_lock_id [*]",debug,elasticsearch
node data locations details:*,debug,elasticsearch
"using [*] data paths, mounts [*], net usable_space [*], net total_space [*], types [*]",info,elasticsearch
"heap size [*], compressed ordinary object pointers [*]",info,elasticsearch
"deleting shard * directory, paths: [*]",trace,elasticsearch
"acquiring locks for *, paths: [*]",trace,elasticsearch
"acquiring lock for *, custom path: [*]",trace,elasticsearch
deleting custom shard * directory [*],trace,elasticsearch
"deleted shard * directory, paths: [*]",trace,elasticsearch
"deleting index * directory, paths(*): [*]",trace,elasticsearch
deleting custom index * directory [*],trace,elasticsearch
locking all shards for index * - [*],trace,elasticsearch
unable to lock all shards for index *,trace,elasticsearch
"acquiring node shardlock on [*], timeout [*], details [*]",trace,elasticsearch
successfully acquired shardlock for [*],trace,elasticsearch
released shard lock for [*],trace,elasticsearch
shard lock wait count for * is now [*],trace,elasticsearch
"last shard lock wait decremented, removing lock for *",trace,elasticsearch
releasing lock [*],trace,elasticsearch
lock assertion failed,warn,elasticsearch
* loading local shard state info,trace,elasticsearch
* shard state info found: [*],debug,elasticsearch
* no local shard info found,trace,elasticsearch
ignoring unknown * setting: [*] with value [*]; archiving,warn,elasticsearch
took * to load state,debug,elasticsearch
"failed to read or upgrade local state, exiting...",error,elasticsearch
Exception occurred when storing new meta data,warn,elasticsearch
Failed to set current term to *,error,elasticsearch
Failed to set last accepted state with version *,error,elasticsearch
*: fetching new stores for initializing shard,trace,elasticsearch
"*: no primary shard store found or allocated, letting actual allocation figure it out",trace,elasticsearch
"cancelling allocation of replica on [*], sync id match found on node [*]",debug,elasticsearch
"*: ignoring allocation, can't be allocated on any node",trace,elasticsearch
"*: ignoring allocation, still fetching shard stores",trace,elasticsearch
"*: no primary shard store found or allocated, letting actual allocation figure it out",trace,elasticsearch
[*][*]: throttling allocation [*] to [*] in order to reuse its unallocated persistent store,debug,elasticsearch
[*][*]: allocating [*] to [*] in order to reuse its unallocated persistent store,debug,elasticsearch
*: allocation of [*] is delayed,debug,elasticsearch
*: node [*] has same sync id * as primary,trace,elasticsearch
*: node [*] has [*/*] bytes of re-usable data,trace,elasticsearch
[*] failed to find metadata for existing index location,debug,elasticsearch
[*] failed to find metadata for existing index location,debug,elasticsearch
"[_meta] writing state, reason [*]",trace,elasticsearch
[_meta] state written (generation: *),trace,elasticsearch
"[*] writing state, reason [*]",trace,elasticsearch
[*] state written,trace,elasticsearch
"[_global] writing state, reason [*]",trace,elasticsearch
[_global] state written,trace,elasticsearch
"[*] can not be imported as a dangling index, as there is already another index with the same name but a different uuid. local index will be ignored (but not deleted)",warn,elasticsearch
"[*] no longer dangling (created), removing from dangling list",debug,elasticsearch
"[*] can not be imported as a dangling index, as index with same name already exists in cluster metadata",warn,elasticsearch
"[*] can not be imported as a dangling index, as an index with the same name and UUID exist in the index tombstones.  This situation is likely caused by copying over the data directory for an index that was previously deleted.",warn,elasticsearch
"[*] dangling index exists on local file system, but not in cluster metadata, auto import to cluster state",info,elasticsearch
failed to list dangling indices,warn,elasticsearch
allocated dangled,trace,elasticsearch
failed to send allocated dangled,info,elasticsearch
failed to send allocate dangled,warn,elasticsearch
ignoring dangled index [*] on node [*] since it's created version [*] is not supported by at least one node in the cluster minVersion [*],warn,elasticsearch
ignoring dangled index [*] on node [*] due to an existing alias with the same name,warn,elasticsearch
auto importing dangled indices * from [*],info,elasticsearch
failed send response for allocating dangled,warn,elasticsearch
failed send response for allocating dangled,warn,elasticsearch
* scheduling reroute for *,trace,elasticsearch
performing state recovery from *,trace,elasticsearch
failed to fetch state from node,warn,elasticsearch
"[*] found [*], required [*], not adding",debug,elasticsearch
"* ignoring fetched [*] results, already closed",trace,elasticsearch
* processing fetched [*] results,trace,elasticsearch
* received response for [*] from node * for an older fetching round (expected: * but was: *),trace,elasticsearch
* node * has failed for [*] (failure [*]),trace,elasticsearch
"* marking * as done for [*], result is [*]",trace,elasticsearch
* processing failure * for [*],trace,elasticsearch
* received failure for [*] from node * for an older fetching round (expected: * but was: *),trace,elasticsearch
* fetching [*] from *,trace,elasticsearch
[*][*]: found * allocation candidates of * based on allocation ids: [*],debug,elasticsearch
"[*][*]: missing local data, will restore from [*]",debug,elasticsearch
"[*][*]: not allocating, number_of_allocated_shards_found [*]",debug,elasticsearch
[*][*]: allocating [*] to [*] on primary allocation,debug,elasticsearch
[*][*]: allocating [*] to [*] on forced primary allocation,debug,elasticsearch
[*][*]: throttling allocation [*] to [*] on forced primary allocation,debug,elasticsearch
[*][*]: forced primary allocation denied [*],debug,elasticsearch
[*][*]: throttling allocation [*] to [*] on primary allocation,debug,elasticsearch
[*] on node [*] has no shard state information,trace,elasticsearch
[*] on node [*] has allocation id [*],trace,elasticsearch
* candidates for allocation: *,trace,elasticsearch
"not recovering from gateway, no master elected yet",debug,elasticsearch
"not recovering from gateway, nodes_size (data+master) [*] < recover_after_nodes [*]",debug,elasticsearch
"not recovering from gateway, nodes_size (data) [*] < recover_after_data_nodes [*]",debug,elasticsearch
"not recovering from gateway, nodes_size (master) [*] < recover_after_master_nodes [*]",debug,elasticsearch
delaying initial state recovery for [*]. *,info,elasticsearch
delayed state recovery failed,warn,elasticsearch
recover_after_time [*] elapsed. performing state recovery...,info,elasticsearch
state recovery failed,warn,elasticsearch
recovered [*] indices into cluster_state,info,elasticsearch
stepped down as master before recovering state [*],debug,elasticsearch
"successful state recovery, importing cluster state...",trace,elasticsearch
state recovery failed: *,info,elasticsearch
cleaned up *,trace,elasticsearch
clean up failed *,trace,elasticsearch
cleanupOldFiles: cleaning up *,trace,elasticsearch
clean up failed for state location *,trace,elasticsearch
found state file: *,trace,elasticsearch
generation id [*] read from [*],trace,elasticsearch
*,info,elasticsearch
Bound http to address {*},debug,elasticsearch
exception while closing channels,warn,elasticsearch
unexpected exception while closing http channels,warn,elasticsearch
exception from http server channel caught on transport layer [channel=*],error,elasticsearch
failed to invoke before index created callback,warn,elasticsearch
failed to invoke after index created callback,warn,elasticsearch
failed to invoke before index removed callback,warn,elasticsearch
failed to invoke after index removed callback,warn,elasticsearch
failed to invoke before index added to cluster callback,warn,elasticsearch
failed to invoke on store created,warn,elasticsearch
failed to invoke on store closed,warn,elasticsearch
failed to close shard,warn,elasticsearch
"* failed to load shard path, trying to remove leftover",warn,elasticsearch
* creating using a new path [*],debug,elasticsearch
* creating using an existing path [*],debug,elasticsearch
creating shard_id *,debug,elasticsearch
[*] closing... (reason: [*]),debug,elasticsearch
[*] closed (reason: [*]),debug,elasticsearch
"[*] store not initialized prior to closing shard, nothing to close",trace,elasticsearch
failed to close resource,debug,elasticsearch
forced refresh failed after interval change,warn,elasticsearch
failed to sync translog,warn,elasticsearch
* top warming [*],trace,elasticsearch
top warming has been interrupted,warn,elasticsearch
top warming took [*],trace,elasticsearch
$$$Empty Message$$$,warn,elasticsearch
$$$Empty Message$$$,info,elasticsearch
$$$Empty Message$$$,debug,elasticsearch
$$$Empty Message$$$,trace,elasticsearch
$$$Empty Message$$$,warn,elasticsearch
$$$Empty Message$$$,info,elasticsearch
$$$Empty Message$$$,debug,elasticsearch
$$$Empty Message$$$,trace,elasticsearch
"[*] is set to false, this should only be used in tests and can cause serious problems in production environmentsindex.merge.enabled",warn,elasticsearch
"using [tiered] merge mergePolicy with expunge_deletes_allowed[*], floor_segment[*], max_merge_at_once[*], max_merge_at_once_explicit[*], max_merged_segment[*], segments_per_tier[*], deletes_pct_allowed[*]",trace,elasticsearch
changing max_merge_at_once from [*] to [*] because segments_per_tier [*] has to be higher or equal to it,debug,elasticsearch
$$$Empty Message$$$,warn,elasticsearch
$$$Empty Message$$$,info,elasticsearch
$$$Empty Message$$$,debug,elasticsearch
$$$Empty Message$$$,trace,elasticsearch
clearing all bitsets because [*],debug,elasticsearch
Using no query cache,debug,elasticsearch
"full cache clear, reason [*]",debug,elasticsearch
no index mapper found for field: [*] returning default postings format,warn,elasticsearch
Delete index commit [*],debug,elasticsearch
"Safe commit [*], last commit [*]",debug,elasticsearch
"merge [*] starting..., merging [*] segments, [*] docs, [*] size, into [*] estimated_size",trace,elasticsearch
*,debug,elasticsearch
*,trace,elasticsearch
created new InternalEngine,trace,elasticsearch
recovered maximum sequence number [*] and local checkpoint [*],trace,elasticsearch
flushing post recovery from translog. ops recovered [*]. committed translog id [*]. current id [*],trace,elasticsearch
can't sync commit [*]. have pending changes,trace,elasticsearch
can't sync commit [*]. current commit id is not equal to expected.,trace,elasticsearch
can't sync commit [*]. have pending changes,trace,elasticsearch
can't sync commit [*]. current commit id is not equal to expected.,trace,elasticsearch
starting sync commit [*],trace,elasticsearch
successfully sync committed. sync id [*].,debug,elasticsearch
start renewing sync commit [*],trace,elasticsearch
successfully sync committed. sync id [*].,debug,elasticsearch
waiting for in-flight flush to finish,trace,elasticsearch
acquired flush lock after blocking,trace,elasticsearch
acquired flush lock immediately,trace,elasticsearch
starting commit for flush; commitTranslog=true,trace,elasticsearch
finished commit for flush,trace,elasticsearch
"new commit on flush, hasUncommittedChanges:*, force:*, shouldPeriodicallyFlush:*",debug,elasticsearch
failed to read latest segment infos on flush,warn,elasticsearch
starting segment upgrade upgradeOnlyAncientSegments=*,info,elasticsearch
finished segment upgrade,info,elasticsearch
start flush for snapshot,trace,elasticsearch
finish flush for snapshot,trace,elasticsearch
Failed to close ReaderManager,warn,elasticsearch
Failed to close translog,warn,elasticsearch
rollback indexWriter,trace,elasticsearch
rollback indexWriter done,trace,elasticsearch
failed to rollback writer on close,warn,elasticsearch
engine closed [*],debug,elasticsearch
could not lock IndexWriter,warn,elasticsearch
failed to prepare/warm,warn,elasticsearch
"now throttling indexing: numMergesInFlight=*, maxNumMerges=*",info,elasticsearch
"stop throttling indexing: numMergesInFlight=*, maxNumMerges=*",info,elasticsearch
failed to flush after merge has finished,warn,elasticsearch
merge failure action rejected,debug,elasticsearch
failed to access searcher manager,error,elasticsearch
Couldn't mark store corrupted,warn,elasticsearch
failEngine threw exception,warn,elasticsearch
flushAndClose now acquire writeLock,trace,elasticsearch
flushAndClose now acquired writeLock,trace,elasticsearch
flushing shard on close - this might take some time to sync files to disk,debug,elasticsearch
engine already closed - skipping flushAndClose,debug,elasticsearch
close now acquiring writeLock,debug,elasticsearch
close acquired writeLock,debug,elasticsearch
failed to close reader,warn,elasticsearch
global-ordinals [*][*] took [*],debug,elasticsearch
"totalTermBytes: *, terms.size(): *, terms.getSumDocFreq(): *",trace,elasticsearch
Unable to estimate memory overhead,warn,elasticsearch
"Filter exists, can't circuit break normally, using RamAccountingTermsEnum",trace,elasticsearch
default mapping source[*],trace,elasticsearch
"[*] * mapping [*], source [*]",debug,elasticsearch
"[*] * mapping [*], source [*]",trace,elasticsearch
"[*] * mapping [*] (source suppressed due to length, use TRACE level if needed)",debug,elasticsearch
"[*] parsed mapping [*], and got different sources original: * parsed: *",debug,elasticsearch
reloading search analyzers,info,elasticsearch
scroll returned [*] documents with a scroll id of [*],debug,elasticsearch
[*]: preparing bulk request for [*],debug,elasticsearch
[*]: rethrottling to [*] requests per second,debug,elasticsearch
[*]: skipping rescheduling because there is no scheduled task,debug,elasticsearch
[*]: skipping rescheduling because the new throttle [*] is slower than the old one [*],debug,elasticsearch
[*]: skipping rescheduling because we couldn't cancel the task,debug,elasticsearch
[*]: rescheduling for [*] in the future,debug,elasticsearch
executing initial scroll against **,debug,elasticsearch
Freed [*] contexts,debug,elasticsearch
no retention leases are expired from current retention leases [*],debug,elasticsearch
expiring retention leases [*] from current retention leases [*],debug,elasticsearch
adding new retention lease [*] to current retention leases [*],debug,elasticsearch
removing retention lease [*] from current retention leases [*],debug,elasticsearch
"skipping persisting retention leases [*], already persisted",trace,elasticsearch
persisting retention leases [*],trace,elasticsearch
updated global checkpoint from [*] to [*] due to [*],trace,elasticsearch
updated local knowledge for [*] on the primary of the global checkpoint from [*] to [*],trace,elasticsearch
addPeerRecoveryRetentionLeaseForSolePrimary: adding lease [*],trace,elasticsearch
* becoming primary of * with missing lease: *,debug,elasticsearch
marked [*] as in-sync,trace,elasticsearch
updated local checkpoint of [*] from [*] to [*],trace,elasticsearch
"skipped updating local checkpoint of [*] from [*] to [*], current checkpoint is higher",trace,elasticsearch
marked [*] as in-sync,trace,elasticsearch
updated global checkpoint to [*],trace,elasticsearch
createMissingPeerRecoveryRetentionLeases: adding missing lease for *,trace,elasticsearch
createMissingPeerRecoveryRetentionLeases: nothing to do,trace,elasticsearch
* found shard on path: [*] with a different index UUID - this shard seems to be leftover from a different index with the same name. Remove the leftover shard in order to reuse the path with the current index,warn,elasticsearch
"* loaded data path [*], state path [*]",debug,elasticsearch
* deleting leftover shard on path: [*] with a different index UUID,warn,elasticsearch
state: [CREATED],debug,elasticsearch
timed out waiting for relocation hand-off to complete,warn,elasticsearch
"state: [*]->[*], reason [*]",debug,elasticsearch
index [*][*] seq# [*] allocation-id [*] primaryTerm [*] operationPrimaryTerm [*] origin [*],trace,elasticsearch
index-done [*][*] seq# [*] allocation-id [*] primaryTerm [*] operationPrimaryTerm [*] origin [*] result-seq# [*] result-term [*] failure [*],trace,elasticsearch
index-fail [*][*] seq# [*] allocation-id [*] primaryTerm [*] operationPrimaryTerm [*] origin [*],trace,elasticsearch
noop (seq# [*]),trace,elasticsearch
delete [*] (seq no [*]),trace,elasticsearch
refresh with source [*],trace,elasticsearch
trying to sync flush. sync id [*]. expected commit id [*]],trace,elasticsearch
flush with *,trace,elasticsearch
force merge with *,trace,elasticsearch
upgrade with *,trace,elasticsearch
upgraded segments for * from version * to version *,trace,elasticsearch
skip local recovery as no index commit found,trace,elasticsearch
skip local recovery as failed to find the safe commit,debug,elasticsearch
skip local recovery as no safe commit found,trace,elasticsearch
skip local recovery as the safe commit is up to date; safe commit * global checkpoint *,trace,elasticsearch
skip local recovery as the index was closed or not allowed to write; safe commit * global checkpoint *,trace,elasticsearch
shard locally recovered up to *,trace,elasticsearch
failed to recover shard locally up to global checkpoint *,debug,elasticsearch
failed to find the safe commit after recovering shard locally up to global checkpoint *,debug,elasticsearch
[translog] recover op *,trace,elasticsearch
ignoring recovery of a corrupt translog entry,info,elasticsearch
shard is now inactive,debug,elasticsearch
failed to notify index event listener,warn,elasticsearch
Failed to perform engine refresh,warn,elasticsearch
Failed to perform engine refresh,warn,elasticsearch
syncing retention leases [*] after expiration check,trace,elasticsearch
background syncing retention leases [*] after expiration check,trace,elasticsearch
syncing global checkpoint for [*],trace,elasticsearch
check index [failure] *,warn,elasticsearch
check index [failure] *,warn,elasticsearch
check index [success] *,debug,elasticsearch
exception while notifying engine failure,warn,elasticsearch
"* writing shard state, reason [*]",trace,elasticsearch
"* skip writing shard state, has been written before",trace,elasticsearch
operation execution has been combined with primary term update,debug,elasticsearch
failed to sync translog,debug,elasticsearch
submitting async flush request,debug,elasticsearch
failed to flush index,warn,elasticsearch
submitting async roll translog generation request,debug,elasticsearch
failed to roll translog generation,warn,elasticsearch
refresh with source [schedule],trace,elasticsearch
"* sending batch of [*][*] (total sent: [*], skipped: [*])",trace,elasticsearch
"* resync completed (total sent: [*], skipped: [*])",trace,elasticsearch
error notifying global checkpoint listener of updated global checkpoint [*],warn,elasticsearch
error notifying global checkpoint listener of closed shard,warn,elasticsearch
error notifying global checkpoint listener of timeout,warn,elasticsearch
Adding segment * to be upgraded,debug,elasticsearch
Returning * merges for upgrade,debug,elasticsearch
Returning * merges for end of upgrade,debug,elasticsearch
"recovery completed from [shard_store], took [*] *",trace,elasticsearch
"recovery completed from [shard_store], took [*]",debug,elasticsearch
"cleaning existing shard, shouldn't exists",trace,elasticsearch
failed to list file details,debug,elasticsearch
[*] restoring shard [*],trace,elasticsearch
store stats are refreshed with refresh_interval [*],debug,elasticsearch
store reference count on close: *,debug,elasticsearch
Failed to open / find files while reading metadata snapshot,info,elasticsearch
* loaded segment info [*],trace,elasticsearch
Files are different on the recovery target: * ,debug,elasticsearch
Files are missing on the recovery target: * ,debug,elasticsearch
*: delete file *,trace,elasticsearch
Can't mark store as corrupted,warn,elasticsearch
"deleted previously created, but not yet committed, next generation [*]. This can happen due to a tragic exception when creating a new generation",warn,elasticsearch
open uncommitted translog checkpoint *,debug,elasticsearch
recovered local translog from checkpoint *,debug,elasticsearch
translog closed,debug,elasticsearch
current translog set to [*],trace,elasticsearch
"delete translog file [*], not referenced and not current anymore",trace,elasticsearch
closing files. translog is closed and there are no pending retention locks,trace,elasticsearch
"Not all shards are closed yet, waited *sec - stopping service",warn,elasticsearch
"creating Index [*], shards [*]/[*] - reason [*]",debug,elasticsearch
[*] closing ... (reason [*]),debug,elasticsearch
* closing index service (reason [*][*]),debug,elasticsearch
* closed... (reason [*][*]),debug,elasticsearch
* deleting index store reason [*],debug,elasticsearch
* deleting shard reason [*],trace,elasticsearch
* deleted shard reason [*],debug,elasticsearch
"[*] still has shard stores, leaving as is",trace,elasticsearch
* processing pending deletes,debug,elasticsearch
* deleting index store reason [*]pending delete,debug,elasticsearch
* no shard lock for pending delete,warn,elasticsearch
* still pending deletes present for shards * - retrying,warn,elasticsearch
* schedule pending delete retry after * ms,debug,elasticsearch
running periodic field data cache cleanup,trace,elasticsearch
Exception during periodic field data cache cleanup:,warn,elasticsearch
periodic field data cache cleanup finished in * milliseconds,trace,elasticsearch
Exception during periodic request cache cleanup:,warn,elasticsearch
"Query timed out, invalidating cache entry for request on shard [*]:  *",trace,elasticsearch
Cache miss for reader version [*] and request:  *,trace,elasticsearch
Cache hit for reader version [*] and request:  *,trace,elasticsearch
using [node] query cache with size [*] max filter count [*],debug,elasticsearch
"using indexing buffer size [*] with * [*], * [*]",debug,elasticsearch
"total indexing heap bytes used [*] vs * [*], currently writing bytes [*]",trace,elasticsearch
"shard [*] is using [*] heap, writing [*] heap",trace,elasticsearch
"shard [*] is using [*] heap, not writing any bytes",trace,elasticsearch
"now write some indexing buffers: total indexing heap bytes used [*] vs * [*], currently writing bytes [*], [*] shards with non-zero indexing buffer",debug,elasticsearch
write indexing buffer to disk for shard [*] to free up its [*] indexing buffer,debug,elasticsearch
now throttling indexing for shard [*]: segment writing can't keep up,info,elasticsearch
stop throttling indexing for shard [*],info,elasticsearch
Loading hunspell dictionary [*]...,debug,elasticsearch
parent circuit breaker with settings *,trace,elasticsearch
Updated breaker settings request: *,info,elasticsearch
Updated breaker settings for in-flight requests: *,info,elasticsearch
Updated breaker settings field data: *,info,elasticsearch
Updated breaker settings for accounting requests: *,info,elasticsearch
Cannot determine current memory usage due to JDK-8207200.,info,elasticsearch
"[*] re-sending failed shard [*], reason [*]",trace,elasticsearch
"[*] cleaning index, no longer part of the metadata",debug,elasticsearch
[*] failed to lock all shards for index - timed out after 30 seconds,warn,elasticsearch
[*] failed to lock all shards for index - interrupted,warn,elasticsearch
* removing index (*),debug,elasticsearch
* removing shard (not allocated),debug,elasticsearch
"* removing shard (stale allocation id, stale *, new *)",debug,elasticsearch
"* removing shard (not active, current *, new *)",debug,elasticsearch
"* removing shard (not active, current *, new *)",debug,elasticsearch
[*] creating index,debug,elasticsearch
ignoring initializing shard * - no source node can be found.,trace,elasticsearch
* creating shard with primary term [*],debug,elasticsearch
"* master marked shard as initializing, but shard has state [*], resending shard started to *",trace,elasticsearch
can't find replica source node because primary shard * is assigned to an unknown node.,trace,elasticsearch
can't find replica source node because primary shard * is not active.,trace,elasticsearch
can't find relocation source node for shard * because it is assigned to an unknown node [*].,trace,elasticsearch
Failed to call listener on field data cache unloading,error,elasticsearch
* sync flush on inactive shard returned successfully for sync_id: *,trace,elasticsearch
* unexpected error while executing synced flush,debug,elasticsearch
"* failed to resolve node for primary shard *, skipping sync",trace,elasticsearch
* retrieving in flight operation count,trace,elasticsearch
* unexpected error while retrieving in flight op count,debug,elasticsearch
* is assigned to an unknown node. skipping for sync id [*]. shard routing *,trace,elasticsearch
"* can't resolve expected commit id for current node, skipping for sync id [*]. shard routing *",trace,elasticsearch
* can't issue sync id [*] for replica [*] with num docs [*]; num docs on primary [*],debug,elasticsearch
* sending synced flush request to *. sync id [*].,trace,elasticsearch
* sending pre-synced flush request to *,trace,elasticsearch
* shard routing * refers to an unknown node. skipping.,trace,elasticsearch
* performing pre sync flush,trace,elasticsearch
"* pre sync flush done. commit id *, num docs *",trace,elasticsearch
"* performing sync flush. sync id [*], expected commit id *",trace,elasticsearch
"* sync flush done. sync id [*], result [*]",trace,elasticsearch
closing IndexOutput file [*],trace,elasticsearch
cleaning temporary file [*],trace,elasticsearch
delaying recovery of * as source shard is not marked yet as relocating to *,debug,elasticsearch
[*][*] starting recovery to *,trace,elasticsearch
"* started recovery from *, id [*]",trace,elasticsearch
"* restarted recovery from *, id [*], previous id [*]",trace,elasticsearch
"* recovery could not be reset as it is already cancelled, recovery from *, id [*], previous id [*]",trace,elasticsearch
"* canceled recovery from *, id [*] (reason [*])",trace,elasticsearch
"* failing recovery from *, id [*]. Send shard failure: [*]",trace,elasticsearch
"* marking recovery from * as done, id [*]",trace,elasticsearch
"* canceled recovery from *, id [*] (reason [*])",trace,elasticsearch
"[monitor] no status found for [*], shutting down",trace,elasticsearch
[monitor] rescheduling check for [*]. last access time is [*],trace,elasticsearch
using max_bytes_per_sec[*],debug,elasticsearch
will retry recovery with id [*] in [*] (reason [*]),trace,elasticsearch
not running recovery with id [*] - can not find it (probably finished),trace,elasticsearch
* preparing shard for peer recovery,trace,elasticsearch
"unexpected error while preparing shard for peer recovery, failing recovery",trace,elasticsearch
* starting recovery from *,trace,elasticsearch
recovery cancelled,trace,elasticsearch
* collecting local files for [*],trace,elasticsearch
"* shard folder empty, recovering all files",trace,elasticsearch
"error while listing local files, resetting the starting sequence number from *  | to unassigned and recovering as if there are none",warn,elasticsearch
"error while listing local files, recovering as if there are none",warn,elasticsearch
* local file count [*],trace,elasticsearch
history is retained by *,trace,elasticsearch
history is retained by retention lock,trace,elasticsearch
performing sequence numbers based recovery. starting at [*],trace,elasticsearch
performing file-based recovery followed by history replay starting at [*],trace,elasticsearch
Snapshot differs from actual index for file: * meta: *,info,elasticsearch
"recovery [phase1]: not recovering [*], exist in local store and has checksum [*], size [*]",trace,elasticsearch
"recovery [phase1]: recovering [*], exists in local store, but is different: remote [*], local [*]",trace,elasticsearch
"recovery [phase1]: recovering [*], does not exist in remote",trace,elasticsearch
"recovery [phase1]: recovering_files [*] with total_size [*], reusing_files [*] with total_size [*]",trace,elasticsearch
skipping [phase1] since source and target have identical sync id [*],trace,elasticsearch
recovery [phase1]: prepare remote engine for translog,trace,elasticsearch
recovery [phase2]: sending transaction log operations (from [ | ] to [ | ],trace,elasticsearch
finalizing recovery,trace,elasticsearch
checking integrity for file * after remove corruption exception,debug,elasticsearch
* Corrupted file detected * checksum mismatch,warn,elasticsearch
reset of recovery with shard * and id [*],debug,elasticsearch
new recovery target cancelled for shard * while waiting on old recovery target with id [*] to close,trace,elasticsearch
recovery canceled (reason: [*]),debug,elasticsearch
* sending shard active check to *,trace,elasticsearch
* is *active on node *,trace,elasticsearch
"not deleting shard *, expected * active copies, but only * found active copies",trace,elasticsearch
"not deleting shard *, the latest cluster state version[*] is not equal to cluster state before shard active api call [*]",trace,elasticsearch
"shard exists request meant for cluster[*], but this is cluster[*], ignoring request",trace,elasticsearch
listing store meta data for *,trace,elasticsearch
"[*] node is missing index, responding with empty",trace,elasticsearch
"[*] can't read metadata from store, responding with empty",warn,elasticsearch
"* node doesn't have meta data for the requests index, responding with empty",trace,elasticsearch
* loaded store meta data (took [*]),debug,elasticsearch
* didn't find any store meta data to load (took [*]),trace,elasticsearch
failed to update ingest pipelines,warn,elasticsearch
using refresh_interval [*],debug,elasticsearch
unexpected exception reading filesystem info,debug,elasticsearch
"enabled [*], interval [*], gc_threshold [*], overhead [*, *, *]",debug,elasticsearch
failed to monitor,debug,elasticsearch
"[gc][*][*][*] duration [*], collections [*]/[*], total [*]/[*], memory [*]->[*]/[*], all_pools *",warn,elasticsearch
"[gc][*][*][*] duration [*], collections [*]/[*], total [*]/[*], memory [*]->[*]/[*], all_pools *",info,elasticsearch
"[gc][*][*][*] duration [*], collections [*]/[*], total [*]/[*], memory [*]->[*]/[*], all_pools *",debug,elasticsearch
"[gc][*] overhead, spent [*] collecting in the last [*]",warn,elasticsearch
"[gc][*] overhead, spent [*] collecting in the last [*]",info,elasticsearch
"[gc][*] overhead, spent [*] collecting in the last [*]",debug,elasticsearch
using refresh_interval [*],debug,elasticsearch
failed parsing PID from [*],debug,elasticsearch
using refresh_interval [*],debug,elasticsearch
getFreePhysicalMemorySize is not available,warn,elasticsearch
OS reported a negative free memory value [*],warn,elasticsearch
exception retrieving free physical memory,warn,elasticsearch
getTotalPhysicalMemorySize is not available,warn,elasticsearch
OS reported a negative total memory value [*],warn,elasticsearch
exception retrieving total physical memory,warn,elasticsearch
error reading /proc/loadavg,debug,elasticsearch
error reading one minute load average from operating system,debug,elasticsearch
no [cpuacct] data found in cgroup stats,debug,elasticsearch
no [cpu] data found in cgroup stats,debug,elasticsearch
no [memory] data found in cgroup stats,debug,elasticsearch
error reading control group stats,debug,elasticsearch
using refresh_interval [*],debug,elasticsearch
"node name [*], node ID [*], cluster name [*]",info,elasticsearch
"version[*], pid[*], build[*/*/*/*], OS[*/*/*], JVM[*/*/*/*]",info,elasticsearch
JVM home [*],info,elasticsearch
JVM arguments *,info,elasticsearch
version [*] is a pre-release version of Elasticsearch and is not suitable for production,warn,elasticsearch
"using config [*], data [*], logs [*], plugins [*]",debug,elasticsearch
initializing HTTP handlers ...,debug,elasticsearch
initialized,info,elasticsearch
starting ...,info,elasticsearch
waiting to join the cluster. timeout [*],debug,elasticsearch
timed out while waiting for initial discovery state - timeout: *,warn,elasticsearch
started,info,elasticsearch
stopping ...,info,elasticsearch
stopped,info,elasticsearch
closing ...,info,elasticsearch
closed,info,elasticsearch
attempt to complete task [*] with id [*] in the [*] state,warn,elasticsearch
sending notification for completed task [*] with id [*],trace,elasticsearch
notification for task [*] with id [*] was successful,trace,elasticsearch
Unable to start allocated task [ | ] with id [ | ] and allocation id [ | ],error,elasticsearch
Found completed persistent task [*] with id [*] and allocation id [*] - removing,trace,elasticsearch
Found unregistered persistent task [*] with id [*] and allocation id [*] - cancelling,trace,elasticsearch
"Fatal error registering persistent task [ | ] with id [ | ] and allocation id [ | ], removing from persistent tasks",error,elasticsearch
Persistent task [*] with id [*] and allocation id [*] was created,trace,elasticsearch
Persistent task [*] with id [*] and allocation id [*] failed to create,warn,elasticsearch
completion notification for failed task [*] with id [*] was successful,trace,elasticsearch
notification for task [*] with id [*] failed,warn,elasticsearch
Persistent task [*] with id [*] and allocation id [*] was cancelled,trace,elasticsearch
persistent task  |  failed,warn,elasticsearch
"The task [*] with id [*] was found but it has a different allocation id [*], status is not updated",warn,elasticsearch
"The task [*] wasn't found, status is not updated",warn,elasticsearch
trying to update state on task * with unexpected allocation id *,warn,elasticsearch
trying to update state on non-existing task *,warn,elasticsearch
Unassigning task * with allocation id *,trace,elasticsearch
checking task reassignment for cluster state *,trace,elasticsearch
failed to reassign persistent tasks,warn,elasticsearch
reassigning * persistent tasks,trace,elasticsearch
reassigning task * from node * to node *,trace,elasticsearch
ignoring task * because assignment is the same *,trace,elasticsearch
ignoring task * because it is still running,trace,elasticsearch
periodic persistent task assignment check running for cluster state *,trace,elasticsearch
plugin loaded from classpath [*],trace,elasticsearch
no  | s loaded,info,elasticsearch
loaded  |  [ | ],info,elasticsearch
--- adding [*] [*],trace,elasticsearch
put repository [*],info,elasticsearch
put repository [*],info,elasticsearch
update repository [*],info,elasticsearch
delete repository [*],info,elasticsearch
processing new index repositories for state version [*],trace,elasticsearch
unregistering repository [*],debug,elasticsearch
updating repository [*],debug,elasticsearch
registering repository [*],debug,elasticsearch
failure updating cluster state ,warn,elasticsearch
internal repository [*][*] already registered. this prevented the registration of  | internal repository [*][*].,warn,elasticsearch
non-internal repository [*] already registered. this repository will block the  | usage of internal repository [*][*].,warn,elasticsearch
closing repository [*][*],debug,elasticsearch
creating repository [*][*],debug,elasticsearch
failed to create repository [*][*],warn,elasticsearch
[*] [*] restoring to [*] ...,debug,elasticsearch
[*] [*] restoring from to an empty shard,trace,elasticsearch
"[*] [*] Can't read metadata from store, will not reuse local files during restore",warn,elasticsearch
"[*] [*] not_recovering file [*] from [*], exists in local store and is same",trace,elasticsearch
[*] [*] recovering [*] from [*],trace,elasticsearch
"[*] [*] no files to recover, all exist within the local store",trace,elasticsearch
[*] [*] deleting pre-existing file [*],trace,elasticsearch
[*] [*] failed to delete file [*] during snapshot cleanup,warn,elasticsearch
[*] [*] failed to list directory - some of files might not be deleted,warn,elasticsearch
[*] [*] restoring file [*],trace,elasticsearch
store cannot be marked as corrupted,warn,elasticsearch
cannot close blob store,warn,elasticsearch
[*] Found stale root level blobs *. Cleaning them up,info,elasticsearch
[*] Exception during cleanup of root level blobs,warn,elasticsearch
[*] Found stale index [*]. Cleaning it up,debug,elasticsearch
[*] Cleaned up stale index [*],debug,elasticsearch
[*] Exception during cleanup of stale indices,warn,elasticsearch
Repository [*] writing new index generational blob [*],debug,elasticsearch
Repository [*] updating index.latest with generation [*],debug,elasticsearch
Failed to clean up old index blob [*],warn,elasticsearch
[*] Unknown blob in the repository: *,warn,elasticsearch
[*] [*] snapshot to [*] ...,debug,elasticsearch
[*] [*] Loading store metadata using index commit [*],trace,elasticsearch
"[*] [*] Aborted on the file [*], exiting",debug,elasticsearch
[*] [*] Processing [*],trace,elasticsearch
[*] [*] writing shard snapshot file,trace,elasticsearch
Could not find a readable index-N file in a non-empty shard snapshot directory [*],warn,elasticsearch
"[*] [*] Aborted on the file [*], exiting",debug,elasticsearch
store cannot be marked as corrupted,warn,elasticsearch
"the repository location is missing, it should point to a shared file system location that is available on all master and data nodes",warn,elasticsearch
The specified location [*] doesn't start with any repository paths specified by the path.repo setting: [*] ,warn,elasticsearch
"The specified location [*] should start with a repository path specified by the path.repo setting, but the path.repo setting was not set on this node",warn,elasticsearch
failed to send bad request response,warn,elasticsearch
failed to send bad request response,warn,elasticsearch
$$$Empty Message$$$,debug,elasticsearch
$$$Empty Message$$$,warn,elasticsearch
failed to send failure response,error,elasticsearch
"using script cache with max_size [*], expire [*]",debug,elasticsearch
compiling lang: [*] type: [*] script: *,trace,elasticsearch
"compiling script, type: [*], lang: [*], options: [*]",trace,elasticsearch
"removed * from cache, reason: *",debug,elasticsearch
Dfs phase failed,trace,elasticsearch
Query phase failed,trace,elasticsearch
failed to process shard failure to (potentially) send back shard failure on corruption,warn,elasticsearch
"freeing search context [*], time [*], lastAccessTime [*], keepAlive [*]",debug,elasticsearch
*,trace,elasticsearch
*,trace,elasticsearch
Failed to update snapshot state ,warn,elasticsearch
"[*] shard closing, abort snapshotting for snapshot [*]",debug,elasticsearch
[*] - Adding shard to the queue,trace,elasticsearch
"[*] trying to cancel snapshot on shard [*] that is finalizing, letting it finish",debug,elasticsearch
"[*] trying to cancel snapshot on the shard [*] that is already done, updating status on the master",debug,elasticsearch
"[*] trying to cancel snapshot on the shard [*] that has already failed, updating status on the master",debug,elasticsearch
snapshot (*) completed to * with *,debug,elasticsearch
"[*] new master thinks the shard [*] is not completed but the shard is done locally, updating status on the master",debug,elasticsearch
"[*] new master thinks the shard [*] is not completed but the shard failed locally, updating status on master",debug,elasticsearch
[*] [*] updated snapshot state,trace,elasticsearch
received updated snapshot restore state [*],trace,elasticsearch
[*] Updating shard [*] with status [*],trace,elasticsearch
changed cluster state triggered by * snapshot state updates,trace,elasticsearch
no longer master while processing restore state update [*],debug,elasticsearch
Failed to update restore state ,warn,elasticsearch
[*][*] creating snapshot for indices [*],trace,elasticsearch
snapshot [*] started,info,elasticsearch
[*] failed to create snapshot - no longer a master,warn,elasticsearch
Failed to update snapshot state ,warn,elasticsearch
failing snapshot of shard [*] on closed node [*],warn,elasticsearch
cleaned up abandoned snapshot * in INIT state,debug,elasticsearch
failed to clean up abandoned snapshot * in INIT state,warn,elasticsearch
failed to update snapshot state after node removal,warn,elasticsearch
starting shard that we were waiting for [*] on node [*],trace,elasticsearch
failing snapshot of shard [*] on unassigned shard [*],warn,elasticsearch
"[*] finalizing snapshot in repository, state: [*], failure[*]",trace,elasticsearch
snapshot [*] completed with state [*],info,elasticsearch
Failed to notify listeners,warn,elasticsearch
trying to delete completed snapshot - should wait for shards to finalize on all nodes,debug,elasticsearch
trying to delete completed snapshot with no finalizing shards - can delete immediately,debug,elasticsearch
adding snapshot completion listener to wait for deleted snapshot to finish,trace,elasticsearch
deleted snapshot is not running - deleting files,debug,elasticsearch
* finished with response *,info,elasticsearch
register * [*] [*] [*],trace,elasticsearch
cancelling task with id *,trace,elasticsearch
unregister task for id: *,trace,elasticsearch
"couldn't store response *, the node didn't join the cluster yet",warn,elasticsearch
setting ban for the parent task * *,trace,elasticsearch
removing ban for the parent task *,trace,elasticsearch
"Removing ban for the parent [*] on the node [*], reason: the parent node is gone",debug,elasticsearch
created thread pool: *,debug,elasticsearch
could not schedule execution of [*] after [*] on [*] as executor is shut down,debug,elasticsearch
could not schedule execution of [*] on [*] as executor is shut down,debug,elasticsearch
binding server bootstrap to: *,debug,elasticsearch
Bound profile [*] to address {*},debug,elasticsearch
exception from server channel caught on transport layer [channel=*],error,elasticsearch
*,info,elasticsearch
profile [*]: *,info,elasticsearch
"Exception while sending request, handler likely already notified due to timeout",debug,elasticsearch
invalid action name [ | ] must start with one of: ,warn,elasticsearch
[*][*] received request,trace,elasticsearch
[*][*] sent to [*] (timeout: [*]),trace,elasticsearch
[*][*] received response from [*],trace,elasticsearch
[*][*] sent response,trace,elasticsearch
"Received response for a request that has timed out, sent [*ms] ago, timed out [*ms] ago, action [*], node [*], id [*]",warn,elasticsearch
Transport response handler not found of id [*],warn,elasticsearch
[*] received response but can't resolve it to a request,trace,elasticsearch
[*][*] received response from [*],trace,elasticsearch
Rejected execution on onConnectionClosed,debug,elasticsearch
failed to send ping transport message,warn,elasticsearch
failed to close remote cluster connections for cluster: ,warn,elasticsearch
failed to close remote cluster connections for cluster: ,warn,elasticsearch
failed to connect to remote clusters within *,warn,elasticsearch
$$$Empty Message$$$,trace,elasticsearch
an exception occurred formatting a READ trace message,trace,elasticsearch
$$$Empty Message$$$,trace,elasticsearch
an exception occurred formatting a WRITE trace message,trace,elasticsearch
[*] opening connection to seed node: [*] proxy address: [*],debug,elasticsearch
failed to check resource watcher,trace,elasticsearch
cannot notify file changes listener,warn,elasticsearch
cannot notify file changes listener,warn,elasticsearch
cannot notify file changes listener,warn,elasticsearch
cannot notify file changes listener,warn,elasticsearch
cannot notify file changes listener,warn,elasticsearch
starting mock repository with random prefix *,info,elasticsearch
[*] Blocking execution,debug,elasticsearch
[*] Unblocking execution,debug,elasticsearch
checking [*] [*],info,elasticsearch
throwing random IOException for file [*] at path [*],info,elasticsearch
throwing random IOException for file [*] at path [*],info,elasticsearch
[*] blocking I/O operation for file [*] at path [*],info,elasticsearch
blocking I/O operation for file [*] at path [*],info,elasticsearch
running task * of *: *,trace,elasticsearch
"scheduleNow: delaying [*ms], scheduling *",trace,elasticsearch
scheduleNow: adding runnable *,trace,elasticsearch
"scheduleAt: [*ms] is not in the future, adding runnable *",trace,elasticsearch
scheduleAt: adding * with extra delay of [*ms],trace,elasticsearch
advanceTime: from [*ms] to [*ms],trace,elasticsearch
advanceTime: no longer deferred: *,trace,elasticsearch
Checking history of size: *: *,debug,elasticsearch
next master service task: choosing task * of *,debug,elasticsearch
unexpected exception while stopping nio group,warn,elasticsearch
exception caught on transport layer [thread=*],warn,elasticsearch
Accepted [*] connections in a single select loop iteration on [*],warn,elasticsearch
Slow execution on network thread [* milliseconds],warn,elasticsearch
Potentially blocked execution on network thread [*] [*] [* milliseconds]:  *,warn,elasticsearch
* background management of retention lease [*] failed while following,warn,elasticsearch
* Starting to track leader shard *,info,elasticsearch
stopping all auto-followers,trace,elasticsearch
failure occurred while fetching cluster state for auto follow pattern [*],warn,elasticsearch
failure occurred while auto following index [*] for auto follow  | pattern [*],warn,elasticsearch
skipping auto-follower coordination,warn,elasticsearch
starting auto-follower for remote cluster [*],info,elasticsearch
removing auto-follower for remote cluster [*],info,elasticsearch
retrying auto-follower for remote cluster [*] after remote cluster connection was missing,info,elasticsearch
auto-follower is stopped for remote cluster [*],trace,elasticsearch
AutoFollower instance for cluster [*] has been removed,info,elasticsearch
"AutoFollower for cluster [*] has stopped, because there is no autofollow metadata",info,elasticsearch
"AutoFollower for cluster [*] has stopped, because there are no more patterns",info,elasticsearch
stopping auto-follower for remote cluster [*],trace,elasticsearch
$$$Empty Message$$$,warn,elasticsearch
* waiting for global checkpoint advancement from [*] to [*],trace,elasticsearch
* global checkpoint advanced to [*] after waiting for [*],trace,elasticsearch
* shard follow task has been stopped,info,elasticsearch
"* coordinate reads, lastRequestedSeqNo=*, leaderGlobalCheckpoint=*",trace,elasticsearch
*[* ongoing reads] read from_seqno=* max_required_seqno=* batch_count=*,trace,elasticsearch
*[*] peek read [*],trace,elasticsearch
"* no new reads, maximum number of concurrent reads have been reached [*]",trace,elasticsearch
"* no new reads, buffer size limit has been reached [*]",trace,elasticsearch
"* no new reads, buffer count limit has been reached [*]",trace,elasticsearch
* shard follow task has been stopped,info,elasticsearch
*[*] write [*/*] [*],trace,elasticsearch
* maximum number of concurrent writes have been reached [*],trace,elasticsearch
"* received [*] ops, still missing [*/*], continuing to read...",trace,elasticsearch
* mapping version [*] is higher or equal than minimum required mapping version [*],trace,elasticsearch
"* updating mapping, mapping version [*] is lower than minimum required mapping version [*]",trace,elasticsearch
* settings version [*] is higher or equal than minimum required settings version [*],trace,elasticsearch
"* updating settings, settings version [*] is lower than minimum required settings version [*]",trace,elasticsearch
* aliases version [*] is higher or equal than minimum required aliases version [*],trace,elasticsearch
"* updating aliases, aliases version [*] is lower than minimum required aliases version [*]",trace,elasticsearch
"* error during follow shard task, retrying [*]",debug,elasticsearch
shard follow task encounter non-retryable error,warn,elasticsearch
[*] removed retention lease [*] on all leader primary shards,trace,elasticsearch
[*] failure while removing retention lease [*] on leader primary shards,warn,elasticsearch
* removing retention lease [*] while unfollowing leader index,trace,elasticsearch
* retention lease [*] not found on * while unfollowing,trace,elasticsearch
* failed to remove retention lease [*] on * while unfollowing,warn,elasticsearch
put follow * completed with *,debug,elasticsearch
index [*] on the following primary shard *,trace,elasticsearch
operation [*] was processed before on following primary shard * with existing term *,trace,elasticsearch
index [*] on the following replica shard *,trace,elasticsearch
* canceling background renewal of retention lease [*] at the end of restore,trace,elasticsearch
[*] starting CCR restore of * files,trace,elasticsearch
"[*] [*] fetching chunk for file [*], expected offset: *, size: *",trace,elasticsearch
[*] completed CCR restore,trace,elasticsearch
store cannot be marked as corrupted,warn,elasticsearch
not opening new session [*] as it already exists,debug,elasticsearch
opening session [*] for shard [*],debug,elasticsearch
could not get session [*] because session not found,debug,elasticsearch
could not close session [*] because session not found,debug,elasticsearch
closing session [*] for shard [*],debug,elasticsearch
registered self generated license: *,debug,elasticsearch
Updating existing license to the new version.  Old license:  *   New license: *,info,elasticsearch
$$$Empty Message$$$,error,elasticsearch
Existing basic license has an expiration. Basic licenses no longer expire.Regenerating license.  Old license:  *   New license: *,info,elasticsearch
license prior to starting basic license: *,debug,elasticsearch
unexpected failure during [*],error,elasticsearch
*,warn,elasticsearch
initializing license state,debug,elasticsearch
previous [*],debug,elasticsearch
current [*],debug,elasticsearch
skipped license notifications reason: [*],debug,elasticsearch
license [*] - valid,debug,elasticsearch
license [*] - grace,warn,elasticsearch
license [*] - expired,warn,elasticsearch
license [*] mode [*] - valid,info,elasticsearch
couldn't initialize watching license mode file,error,elasticsearch
$$$Empty Message$$$,error,elasticsearch
$$$Empty Message$$$,error,elasticsearch
started self generated trial license: *,debug,elasticsearch
unexpected failure during [*],error,elasticsearch
reloading analyzers for index shard ,info,elasticsearch
Successfully wrote audit message,trace,elasticsearch
Failed to write audit message,debug,elasticsearch
Failed to parse query for data frame transform,warn,elasticsearch
Data frame pivot transform configuration must specify at least 1 aggregation,warn,elasticsearch
Failed to parse aggregation for data frame pivot transform,warn,elasticsearch
Data frame pivot transform configuration must specify at least 1 group_by,warn,elasticsearch
Failed to parse group_by for data frame pivot transform,warn,elasticsearch
" has lifecycle complete set, skipping ",trace,elasticsearch
[*] lifecycle action for index [*] executed but index no longer exists,debug,elasticsearch
[*] index [*] unable to copy execution state to target index [*] as target index does not exist,warn,elasticsearch
[*] lifecycle action for index [*] executed but index no longer exists,debug,elasticsearch
[*] lifecycle action for index [*] executed but index no longer exists,debug,elasticsearch
[*] lifecycle action for index [*] executed but index no longer exists,debug,elasticsearch
[*] lifecycle action for index [*] cannot make progress because not all shards are active,debug,elasticsearch
* lifecycle action [*] waiting for [*] shards to be allocated to nodes matching the given filters,debug,elasticsearch
* lifecycle action for [*] complete,debug,elasticsearch
" has lifecycle complete set, skipping ",trace,elasticsearch
[*] lifecycle action for index [*] executed but index no longer exists,debug,elasticsearch
"* checking for shrink readiness on [*], found * shards and need *",trace,elasticsearch
* successfully found * allocated shards for shrink readiness on node [*] (*),trace,elasticsearch
* failed to find * allocated shards (found *) on node [*] for shrink readiness (*),trace,elasticsearch
[*] lifecycle action for index [*] executed but index no longer exists,debug,elasticsearch
"[*] attempted to run ILM step but a snapshot is in progress, step will retry at a later time",debug,elasticsearch
[*] retrying ILM step after snapshot has completed,debug,elasticsearch
could not find any nodes to allocate index [*] onto prior to shrink,debug,elasticsearch
" has lifecycle complete set, skipping ",trace,elasticsearch
[*] lifecycle action for index [*] executed but index no longer exists,debug,elasticsearch
"Schedule was triggered for job [ | ], but prior indexer is still running  | (with state [ | ]",warn,elasticsearch
Schedule was triggered for job [ | ] but job is stopped.  Ignoring trigger.,debug,elasticsearch
"Schedule was triggered for job [ | ], state: [ | ]",debug,elasticsearch
"Beginning to index [ | ], state: [ | ]",debug,elasticsearch
Could not move from STARTED to INDEXING state because current state is [ | ],debug,elasticsearch
Encountered unexpected state [ | ] while indexing,warn,elasticsearch
"Finished indexing for job [ | ], saving state and shutting down.",debug,elasticsearch
"Indexer job encountered [ | ] state, halting indexer.",info,elasticsearch
Requested shutdown of indexer for job [ | ],info,elasticsearch
Encountered unexpected state [ | ] while indexing,warn,elasticsearch
Datafeed aggregations are not parsable,warn,elasticsearch
Exception trying to setParsedQuery,error,elasticsearch
Exception trying to setParsedAggregations,error,elasticsearch
[*] Search request returned shard failures: *,error,elasticsearch
"Version of mappings for [*] not found, recreating",info,elasticsearch
"Mappings for [*] are outdated [*], updating it[*].",info,elasticsearch
"Version of mappings for [*] not found, recreating",info,elasticsearch
"Failed to retrieve mapping version for [*], recreating",error,elasticsearch
"No mappings found for [*], recreating",info,elasticsearch
Mappings are up to date.,trace,elasticsearch
$$$Empty Message$$$,warn,elasticsearch
scheduler engine was not terminated after waiting 5s,warn,elasticsearch
interrupted while waiting for scheduler engine termination,warn,elasticsearch
listener failed while handling triggered event [*],warn,elasticsearch
failed to read authentication,error,elasticsearch
failed to read authentication,error,elasticsearch
clearing all DLS bitsets because [*],debug,elasticsearch
Unable to apply field level security,error,elasticsearch
"Permission [*] * grant [* , *]",trace,elasticsearch
"Resolved privileges [*] for [*,*]",trace,elasticsearch
Index pattern automaton [*] is too complex,debug,elasticsearch
"received plaintext traffic on an encrypted channel, closing connection *",warn,elasticsearch
connection * closed during ssl handshake,trace,elasticsearch
connection * closed during handshake,debug,elasticsearch
"client did not trust server's certificate, closing connection *",trace,elasticsearch
"client did not trust this server's certificate, closing connection *",warn,elasticsearch
not recording snapshot history item because [*] is [false]: [*],trace,elasticsearch
about to index snapshot history item in index [*]: [*].slm-history-1,trace,elasticsearch
"index [*] was created after checking for its existence, likely due to a concurrent call.slm-history-1-000001",debug,elasticsearch
unexpected IndexOrAlias for [*]: [*].slm-history-1,error,elasticsearch
Configured with trust restrictions: [*],debug,elasticsearch
Rejecting certificate [*] [*] with common-names [*],info,elasticsearch
Name [*] matches trusted pattern [*],debug,elasticsearch
Read innermost ASN.1 Object with type code [*],trace,elasticsearch
Read cn [*] from ASN1Sequence [*],trace,elasticsearch
Certificate [*] has 'otherName' [*] with unsupported object-id [*],debug,elasticsearch
Failed to read 'otherName' from certificate [*],warn,elasticsearch
Certificate [*] has subject alternative names [*],trace,elasticsearch
reloading ssl configuration [*],debug,elasticsearch
reloaded [*] and updated ssl contexts using this file,info,elasticsearch
"unsupported ciphers [*] were requested but cannot be used in this JVM, however there are supported ciphers that will be used [*]. If you are trying to use ciphers with a key length greater than 128 bits on an Oracle JVM, you will need to install the unlimited strength JCE policy files.",error,elasticsearch
using ssl settings [*],debug,elasticsearch
Cannot find SSL configuration for context *. Known contexts are: *,warn,elasticsearch
Error loading template [*] as part of metadata upgrading,error,elasticsearch
Cannot parse the template [*],error,elasticsearch
error adding index template [*] from [*] for [*],error,elasticsearch
error adding lifecycle policy [*] for [*],error,elasticsearch
"adding index template [*] for [*], because it doesn't exist",debug,elasticsearch
"not adding index template [*] for [*], because it already exists",trace,elasticsearch
"adding lifecycle policy [*] for [*], because it doesn't exist",debug,elasticsearch
"not adding lifecycle policy [*] for [*], because it already exists",trace,elasticsearch
$$$Empty Message$$$,error,elasticsearch
failed to execute action [*/*]. failed to transform payload. *,error,elasticsearch
$$$Empty Message$$$,error,elasticsearch
$$$Empty Message$$$,error,elasticsearch
$$$Empty Message$$$,error,elasticsearch
received data for decryption with size [*] that is less than IV length [*],error,elasticsearch
$$$Empty Message$$$,error,elasticsearch
[ | ] Failed to cancel persistent task that could  | not be assigned due to [ | ],error,elasticsearch
Original set of user indices contained more indexes [*],debug,elasticsearch
* for transform [*],warn,elasticsearch
* for transform [*],debug,elasticsearch
* for transform [*],debug,elasticsearch
query for changes based on time: *,trace,elasticsearch
$$$Empty Message$$$,error,elasticsearch
$$$Empty Message$$$,error,elasticsearch
[ | ] unexpected null aggregations in search response.  | Source indices have been deleted or closed.,info,elasticsearch
Encountered unexpected run state [ | ],warn,elasticsearch
Encountered unexpected run state [ | ],warn,elasticsearch
running full run query: *,trace,elasticsearch
running changes query *,trace,elasticsearch
running partial update query: *,trace,elasticsearch
Data frame transform [ | ]:,info,elasticsearch
$$$Empty Message$$$,debug,elasticsearch
Timeout waiting for task [ | ] to be marked as failed in cluster state,error,elasticsearch
[*] start called with force [*] and state [*].,debug,elasticsearch
[*] updating state for data frame transform to [*].,info,elasticsearch
[*] stop called with force [*] and state [*],debug,elasticsearch
[*] data frame task triggered with an unintialized indexer.,warn,elasticsearch
[*] schedule was triggered for transform but task is failed. Ignoring trigger.,debug,elasticsearch
[*] indexer for transform has state [*]. Ignoring trigger.,debug,elasticsearch
"[*] data frame indexer schedule has triggered, state: [*].",debug,elasticsearch
Trigger initial run.,debug,elasticsearch
[*] is already failed but encountered new failure; reason [*].,warn,elasticsearch
[*] attempt to fail transform with reason [*] while it was stopping.,info,elasticsearch
[*] encountered a failure but indexer is STOPPED; reason [*].,info,elasticsearch
"[*] received cancellation request for data frame transform, state: [*].",info,elasticsearch
[*] attempted to start while failed.,debug,elasticsearch
[*] schedule was triggered for transform but task is failed. Ignoring trigger.,debug,elasticsearch
[*] indexer for transform has state [*]. Ignoring trigger.,debug,elasticsearch
[*] attempted to search while failed.,debug,elasticsearch
[*] attempted to bulk index while failed.,debug,elasticsearch
[*] attempted to save state and stats while failed.,debug,elasticsearch
"[*] data frame transform finished indexing all data, initiating stop.",info,elasticsearch
[*] updating persistent state of transform to [*].,debug,elasticsearch
[*] data frame transform encountered an unexpected internal exception: ,error,elasticsearch
[*] finished indexing for data frame transform checkpoint [*].,debug,elasticsearch
[*] data frame transform has stopped.,info,elasticsearch
[*] data frame transform received abort request. Stopping indexer.,info,elasticsearch
[*] data frame transform encountered an exception: ,warn,elasticsearch
[*] transform has failed; experienced: [*].,error,elasticsearch
filter by bucket:  | /,trace,elasticsearch
Failed to parse [*] value: [*],error,elasticsearch
executing expansion graph search request,trace,elasticsearch
executing initial graph search request,trace,elasticsearch
unable to execute the graph query,error,elasticsearch
lifecycle for index [*] executed but index no longer exists,debug,elasticsearch
[*] performing cluster state action (*) [*],trace,elasticsearch
[*] moving cluster state to next step [*],trace,elasticsearch
"[*] waiting for cluster state step condition (*) [*], next: [*]",trace,elasticsearch
"[*] cluster state step condition met successfully (*) [*], moving to next step *",trace,elasticsearch
"[*] condition not met (*) [*], returning existing state",trace,elasticsearch
"[*] step sequence starting with * has completed, running next step * if it is an async action",trace,elasticsearch
policy [*] for index [*] failed on cluster state step [*]. Moving to ERROR step,error,elasticsearch
no index creation date has been set yet,trace,elasticsearch
"[*] checking for index age to be at least [*] before performing actions in the ""*"" phase. Now: *, lifecycle date: *, age: [*/*s]",trace,elasticsearch
current step [*] for index [*] with policy [*] is not recognized,error,elasticsearch
"policy [*] for index [*] complete, skipping execution",debug,elasticsearch
"policy [*] for index [*] on an error step, skipping execution",debug,elasticsearch
[*] maybe running periodic step (*) with current step *,trace,elasticsearch
[*] running periodic policy with current-step [*],debug,elasticsearch
"cs-change-async-wait-callback, [*] current-step: *",trace,elasticsearch
[*] ignoring non periodic step execution from step transition [*],trace,elasticsearch
current step [*] for index [*] with policy [*] is not recognized,warn,elasticsearch
[*] maybe running async action step (*) with current step *,trace,elasticsearch
[*] running policy with async action step [*],debug,elasticsearch
"cs-change-async-action-callback, [*], current-step: *",trace,elasticsearch
[*] ignoring non async action step execution from step transition [*],trace,elasticsearch
current step [*] for index [*] with policy [*] is not recognized,error,elasticsearch
"policy [*] for index [*] complete, skipping execution",debug,elasticsearch
"policy [*] for index [*] on an error step, skipping execution",debug,elasticsearch
[*] maybe running step (*) after state change: *,trace,elasticsearch
[*] running policy with current-step [*],debug,elasticsearch
[*] ignoring step execution from cluster state change event [*],trace,elasticsearch
[*] retrieved current step key: *,trace,elasticsearch
moving index [*] from [*] to [*] in policy [*],info,elasticsearch
[*] moving to step [*] * -> *,debug,elasticsearch
policy [*] for index [*] failed on step [*]. Moving to ERROR step,error,elasticsearch
"policy [*] for index [*] does not exist, recording this in step_info for this index",debug,elasticsearch
"updating cached steps for [*] policy, new steps: *",trace,elasticsearch
"parsed steps for policy [*] in phase [*], definition: [*], steps: [*]",trace,elasticsearch
unable to update lifecycle metadata with new mode [ | ],error,elasticsearch
waiting to stop ILM because index [*] with policy [*] is currently in step [*],info,elasticsearch
skipping policy execution of step [*] for index [*] with policy [*] because ILM is stopping,info,elasticsearch
"job triggered:  | ,  | , ",trace,elasticsearch
waiting to stop ILM because index [*] with policy [*] is currently in step [*],info,elasticsearch
skipping policy execution of step [*] for index [*] with policy [*] because ILM is stopping,info,elasticsearch
moving [*] to next step (*),trace,elasticsearch
"index [ | ] has been deleted after moving to step [ | ], skipping async action check",debug,elasticsearch
adding index lifecycle policy [*],info,elasticsearch
updating index lifecycle policy [*],info,elasticsearch
"index [ | ] has been deleted after moving to step [ | ], skipping async action check",debug,elasticsearch
cancelling all snapshot lifecycle jobs,trace,elasticsearch
cancelling snapshot lifecycle job [*] as it no longer exists,debug,elasticsearch
snapshot lifecycle policy task triggered from job [*],debug,elasticsearch
"snapshot lifecycle policy for job [*] no longer exists, snapshot not created",warn,elasticsearch
failed to record snapshot [*] for snapshot [*] in policy [*]: snapshot lifecycle metadata is null,error,elasticsearch
failed to record snapshot [*] for snapshot [*] in policy [*]: policy not found,warn,elasticsearch
"failed to record snapshot policy execution status for snapshot [*] in policy [*], (source: [*]): *",error,elasticsearch
adding new snapshot lifecycle [*],info,elasticsearch
adding new snapshot lifecycle [*],info,elasticsearch
updating existing snapshot lifecycle [*],info,elasticsearch
Failed to connect to ML native controller,trace,elasticsearch
Starting ML daily maintenance service,debug,elasticsearch
Stopping ML daily maintenance service,debug,elasticsearch
failed to schedule next maintenance task; shutting down,debug,elasticsearch
triggering scheduled [ML] maintenance tasks,info,elasticsearch
ml job configurations migrated: *,info,elasticsearch
ml datafeed configurations migrated: *,info,elasticsearch
updating persistent task params for job [*],debug,elasticsearch
cannot find job for task [*],error,elasticsearch
Updating persistent task params for datafeed [*],debug,elasticsearch
cannot find datafeed for task [*],error,elasticsearch
adding job to migrate: ,debug,elasticsearch
adding datafeed to migrate: ,debug,elasticsearch
taking a snapshot of ml_metadata,debug,elasticsearch
failed to serialise ml_metadata,error,elasticsearch
creating the .ml-config index,info,elasticsearch
error writing the .ml-config mappings,error,elasticsearch
"failed to index ml configuration [ | ], ",info,elasticsearch
ml configuration [ | ] indexed,info,elasticsearch
[*] *,warn,elasticsearch
cannot close all jobs,warn,elasticsearch
Cannot get native code info for Machine Learning,error,elasticsearch
Get stats for running task [*],debug,elasticsearch
Get stats for data frame analytics [*],debug,elasticsearch
failed to parse progress from doc with it [*],error,elasticsearch
finalizing jobs [*],debug,elasticsearch
Get stats for job [*],debug,elasticsearch
Cannot update doc mapping because clusterState == null,warn,elasticsearch
Get job '*',debug,elasticsearch
"Search for buckets in: [*, *)",debug,elasticsearch
[ | ] Failed to cancel persistent task that could  | not be assigned due to [ | ],error,elasticsearch
$$$Empty Message$$$,debug,elasticsearch
$$$Empty Message$$$,debug,elasticsearch
[*] Cancelling job task because: *,trace,elasticsearch
[*] *,warn,elasticsearch
[*] *,warn,elasticsearch
[ | ] Failed to cancel persistent task that could  | not be assigned due to [ | ],error,elasticsearch
[*] Cancelling reindex task [*],debug,elasticsearch
[*] Reindex task was successfully cancelled,debug,elasticsearch
$$$Empty Message$$$,debug,elasticsearch
$$$Empty Message$$$,debug,elasticsearch
[*] Starting data frame analytics,info,elasticsearch
$$$Empty Message$$$,error,elasticsearch
$$$Empty Message$$$,error,elasticsearch
Deleting job '*',debug,elasticsearch
[*] Deletion task [*] will wait for existing deletion task to complete,debug,elasticsearch
[*] No deletion job listeners could be found,error,elasticsearch
Force deleting job [*],debug,elasticsearch
Received request to update model snapshot [*] for job [*],debug,elasticsearch
Get stats for datafeed '*',debug,elasticsearch
[*] Killing job,info,elasticsearch
[*] Cannot kill the process because job is not open,debug,elasticsearch
"Un-assigning persistent tasks :  | , ",info,elasticsearch
Isolating datafeeds: ,info,elasticsearch
Get datafeed '*',debug,elasticsearch
Received request to stop data frame analytics [*],debug,elasticsearch
Deleting expired data,info,elasticsearch
Completed deletion of expired data,info,elasticsearch
"Get model snapshots for job * snapshot ID *. from = *, size = * start = '*', end='*', sort=* descending=*",debug,elasticsearch
"Received request to revert to snapshot id '*' for job '*', deleting intervening results: *",debug,elasticsearch
Reverting to snapshot ' | ',info,elasticsearch
datafeed already started,debug,elasticsearch
[ | ] Failed to cancel persistent task that could  | not be assigned due to [ | ],error,elasticsearch
[*] *,info,elasticsearch
[*] Lookback has finished,info,elasticsearch
[*] Lookback finished after being stopped,debug,elasticsearch
[*] Skipped to time [*],info,elasticsearch
$$$Empty Message$$$,error,elasticsearch
$$$Empty Message$$$,error,elasticsearch
"[*] Searching data in: [*, *)",trace,elasticsearch
[ | ] error while extracting data,debug,elasticsearch
[*] Processed another * records,trace,elasticsearch
[ | ] error while posting data,debug,elasticsearch
"[*] Complete iterating data extractor [*], [*], [*], [*], [*]",debug,elasticsearch
[ | ] Sending flush request,trace,elasticsearch
[ | ] error while flushing job,debug,elasticsearch
[ | ] Sending persist request,trace,elasticsearch
[ | ] error while persisting job,debug,elasticsearch
$$$Empty Message$$$,debug,elasticsearch
$$$Empty Message$$$,debug,elasticsearch
$$$Empty Message$$$,debug,elasticsearch
$$$Empty Message$$$,debug,elasticsearch
[*] attempt to stop datafeed [*] [*],info,elasticsearch
"Closing [*] datafeeds, because [*]",info,elasticsearch
Failed lookback import for job [ | ],error,elasticsearch
[*] *,warn,elasticsearch
Failed lookback import for job [ | ],error,elasticsearch
Waiting [*] before executing next realtime import for job [*],debug,elasticsearch
Unexpected datafeed failure for job [ | ] stopping...,error,elasticsearch
Unexpected datafeed failure for job [ | ] stopping...,error,elasticsearch
[*] attempt to stop datafeed [*] for job [*],info,elasticsearch
[*] try lock [*] to stop datafeed [*] for job [*]...,info,elasticsearch
"[*] stopping datafeed [*] for job [*], acquired [*]...",info,elasticsearch
[*] datafeed [*] for job [*] has been stopped*,info,elasticsearch
[*] datafeed [*] for job [*] was already stopped,info,elasticsearch
[*] No need to auto-close job as job state is [*],debug,elasticsearch
[*] job close action was not acknowledged,error,elasticsearch
[*] *,debug,elasticsearch
[ | ] failed to auto-close job,error,elasticsearch
Failed to remove datafeed persistent task - will not auto close job [ | ],error,elasticsearch
Datafeed [*] is waiting for job [*] to be opened,info,elasticsearch
Datafeed [*] is stopping because job [*] state is [*],warn,elasticsearch
"Skipping bucket at [*], startTime is [*]",debug,elasticsearch
[*] Data extractor received cancel request,debug,elasticsearch
[*] Executing aggregated search,debug,elasticsearch
[*] Search response was obtained,debug,elasticsearch
"[*] Chunked search configured: kind = *, dataTimeSpread = * ms, chunk span = * ms",debug,elasticsearch
"[*] advances time to [*, *)",trace,elasticsearch
[*] Scrolling Data summary response was obtained,debug,elasticsearch
[*] Aggregating Data summary response was obtained,debug,elasticsearch
[*] Data extractor received cancel request,trace,elasticsearch
[*] Initializing scroll,debug,elasticsearch
[*] Search response was obtained,debug,elasticsearch
[*] Resetting scroll search after shard failure,debug,elasticsearch
[*] Continuing scroll with id [*],debug,elasticsearch
[*] Reinitializing scroll due to SearchPhaseExecutionException,debug,elasticsearch
[*] Search response was obtained,debug,elasticsearch
[*] incompatible field [*] because it is missing from mappings,debug,elasticsearch
[*] field [*] is compatible as it is numerical,debug,elasticsearch
[*] field [*] is compatible as it is categorical,debug,elasticsearch
[*] field [*] is compatible as it is boolean,debug,elasticsearch
[*] incompatible field [*]; types *; supported *,debug,elasticsearch
[*] Data extractor was cancelled,debug,elasticsearch
[*] Initializing scroll,debug,elasticsearch
[*] Search response was obtained,debug,elasticsearch
[*] Search resulted to failure; retrying once,warn,elasticsearch
[*] Continuing scroll with id [*],debug,elasticsearch
Data frame analytics tasks * have no configs,warn,elasticsearch
[*] Waiting for result processor to complete,info,elasticsearch
[*] Result processor has completed,info,elasticsearch
Removed process context for task [*]; [*] processes still running,debug,elasticsearch
[*] Marking task completed,info,elasticsearch
[*] Marking task failed; *,error,elasticsearch
[*] Closing process,info,elasticsearch
[*] Closed process,info,elasticsearch
[*] Stopping process,debug,elasticsearch
[*] No process context to stop,debug,elasticsearch
[*] Stopping process,debug,elasticsearch
[*] Failed to kill process,error,elasticsearch
[*] creating analytics process with config [*],trace,elasticsearch
[*] no data found to analyze. Will not start analytics native process.,info,elasticsearch
[*] Interrupted waiting for results processor to complete,error,elasticsearch
[*] Error parsing data frame analytics output,error,elasticsearch
Can't close data frame analytics memory usage estimation process,error,elasticsearch
$$$Empty Message$$$,error,elasticsearch
[*] Closing process,info,elasticsearch
[*] Closed process,info,elasticsearch
[*] Failed to join results ,error,elasticsearch
[*] Failed to join results,error,elasticsearch
[*] Failed to consume data extractor,error,elasticsearch
Can't close data frame analytics process,error,elasticsearch
$$$Empty Message$$$,error,elasticsearch
Error while processing next job update,error,elasticsearch
Job update was submitted to non-master node [ | ]; update for job [ | ] will be ignored,error,elasticsearch
Successfully updated remote job [*],info,elasticsearch
$$$Empty Message$$$,error,elasticsearch
Remote job [*] not updated as it has been deleted,debug,elasticsearch
Remote job [*] not updated as it is no longer open,debug,elasticsearch
Failed to update remote job [ | ],error,elasticsearch
Falling back to allocating job [*] by job counts because a memory requirement refresh could not be scheduled,warn,elasticsearch
$$$Empty Message$$$,trace,elasticsearch
$$$Empty Message$$$,trace,elasticsearch
$$$Empty Message$$$,trace,elasticsearch
$$$Empty Message$$$,trace,elasticsearch
$$$Empty Message$$$,trace,elasticsearch
$$$Empty Message$$$,trace,elasticsearch
Falling back to allocating job [*] by job counts because its memory requirement was not available,debug,elasticsearch
Falling back to allocating job [*] by job counts because machine memory was not available for node [*],debug,elasticsearch
"no node selected for job [*], reasons [*]",debug,elasticsearch
selected node [*] for job [*],debug,elasticsearch
Falling back to allocating job [*] by job counts because the memory requirement for job [*] was not available,debug,elasticsearch
adding ,debug,elasticsearch
Falling back to allocating job [*] by job counts because the memory requirement for job [*] was not available,debug,elasticsearch
[*] Pattern [*] did not match example [*],error,elasticsearch
[*] Error serialising result,error,elasticsearch
[*] ES API CALL: bulk request with * actions,trace,elasticsearch
[*] Bulk index of results has errors: *,error,elasticsearch
ES API CALL: get ID * from index *,trace,elasticsearch
Expected * documents for model state for * snapshot * but failed to find *,error,elasticsearch
ES API CALL: get ID * from index *,trace,elasticsearch
[*] ES API CALL: index bucket to index [*] with ID [*],trace,elasticsearch
[*] ES BULK ACTION: index bucket influencer to index [*] with ID [*],trace,elasticsearch
[*] ES BULK ACTION: index record to index [*] with ID [*],trace,elasticsearch
[*] ES BULK ACTION: index influencer to index [*] with ID [*],trace,elasticsearch
[*] ES BULK ACTION: index model plot to index [*] with ID [*],trace,elasticsearch
[*] ES BULK ACTION: index forecast to index [*] with ID [*],trace,elasticsearch
[*] ES BULK ACTION: index forecast request stats to index [*] with ID [*],trace,elasticsearch
[*] Error serialising *,error,elasticsearch
[*] ES API CALL: bulk request with * actions,trace,elasticsearch
[*] Bulk index of results has errors: *,error,elasticsearch
"[*] Persisting model size stats, for size *",trace,elasticsearch
"[*] Persisting model size stats, for size *",trace,elasticsearch
[*] ES API CALL: refresh index *,trace,elasticsearch
[*] ES API CALL: refresh index *,trace,elasticsearch
[*] Persisting datafeed timing stats,trace,elasticsearch
[*] Error writing [*],error,elasticsearch
[*] ES API CALL: to index * with ID [*],trace,elasticsearch
[*] ES API CALL: to index * with auto-generated ID,trace,elasticsearch
$$$Empty Message$$$,warn,elasticsearch
[ | ] An error occurred while deleting interim results,error,elasticsearch
"* result, * quantile state and * categorizer state documents exist for a prior job with Id [*]",warn,elasticsearch
ES API CALL: create index *,trace,elasticsearch
ES API CALL: search all of category definitions from index * sort ascending * from * size *,trace,elasticsearch
ES API CALL: search all of records from index * with query *,trace,elasticsearch
ES API CALL: search all model snapshots from index * sort ascending * with filter after sort from * size *,trace,elasticsearch
ES API CALL: search model plots from index * from * size *,trace,elasticsearch
ES API CALL: search latest * for job *model_size_stats,trace,elasticsearch
ES API CALL: search index *,trace,elasticsearch
$$$Empty Message$$$,info,elasticsearch
Failed to acquire process lock for job [*],error,elasticsearch
Killing job [*]*,info,elasticsearch
"Killing job [*]*, because [*]",info,elasticsearch
[*] Failed to kill autodetect process for job,error,elasticsearch
Process set to [running] while it was already in that state,debug,elasticsearch
Process set to [running] while it was in [dying],debug,elasticsearch
Process set to [dying] while it was already in that state,debug,elasticsearch
[*] Timed out waiting for killed job,warn,elasticsearch
[*] waiting for flush,debug,elasticsearch
[*] Flush completed,debug,elasticsearch
[*] Unexpected exception writing to process,error,elasticsearch
Error restoring model state for job ,error,elasticsearch
error handling job operation,error,elasticsearch
Can't close autodetect,error,elasticsearch
$$$Empty Message$$$,error,elasticsearch
"Closing [*] jobs, because [*]",info,elasticsearch
[*] Killing process: awaitCompletion = [*]; reason = [*],trace,elasticsearch
[*] Marking job task as completed,trace,elasticsearch
$$$Empty Message$$$,debug,elasticsearch
Flushing job *,debug,elasticsearch
$$$Empty Message$$$,debug,elasticsearch
Forecasting job *,debug,elasticsearch
$$$Empty Message$$$,debug,elasticsearch
$$$Empty Message$$$,debug,elasticsearch
Opening job [*],info,elasticsearch
Cannot open job [*] when its state is [*],debug,elasticsearch
[*] *,warn,elasticsearch
[*] *,warn,elasticsearch
Can't close autodetect,error,elasticsearch
[*] *,info,elasticsearch
"Attempting to close job [*], because [*]",debug,elasticsearch
Cannot close job [*] as it has already been closed,debug,elasticsearch
Cannot close job [*] as it has been marked as dying,debug,elasticsearch
Closing job [*],info,elasticsearch
"Closing job [*], because [*]",info,elasticsearch
Job [*] is being closed before its process is started,debug,elasticsearch
[ | ] Exception closing autodetect process,warn,elasticsearch
[*] Failed to delete temporary files,error,elasticsearch
Successfully set job state to [*] for job [*],info,elasticsearch
Could not set job state to [ | ] for job [ | ],error,elasticsearch
Error while delegating response,warn,elasticsearch
Error while delegating exception [ | ],warn,elasticsearch
[*] Periodic operations staggered by * seconds,debug,elasticsearch
[*] Will not persist model state - * setting was set,info,elasticsearch
Restoring quantiles for job ' | ',info,elasticsearch
[*] Error persisting autodetect results,warn,elasticsearch
[*] * buckets parsed from autodetect output,info,elasticsearch
[*] some results not processed due to the process being killed,warn,elasticsearch
[*] some results not processed due to the termination of autodetect,warn,elasticsearch
[*] error parsing autodetect output,error,elasticsearch
[*] Bucket number * parsed from output,trace,elasticsearch
[*] Error processing autodetect result,warn,elasticsearch
[*] Deleting interim results,trace,elasticsearch
Received Forecast Stats [*],trace,elasticsearch
[*] Parsed Quantiles with timestamp *,debug,elasticsearch
[*] Quantiles queued for renormalization,debug,elasticsearch
[*] Flush acknowledgement parsed from output for ID *,debug,elasticsearch
[*] Parsed ModelSizeStats: * / * / * / * / * / *,trace,elasticsearch
[*] Interrupted acquiring update model snapshot semaphore,info,elasticsearch
[*] Updated job with model snapshot id [*],debug,elasticsearch
[ | ] Failed to update job with new model snapshot id [ | ],error,elasticsearch
[*] Interrupted waiting for results processor to complete,info,elasticsearch
[*] Persisting job state document,trace,elasticsearch
FieldConfig:\n,debug,elasticsearch
$$$Empty Message$$$,error,elasticsearch
Attempting to recover from malformed JSON data.,warn,elasticsearch
Failed to recover from malformed JSON data.,error,elasticsearch
"Not enough fields in csv record, expected at least  | . ",warn,elasticsearch
$$$Empty Message$$$,error,elasticsearch
Could not set up no-op pipe,error,elasticsearch
[*] Quantiles not supplied in time order - * after *,warn,elasticsearch
[ | ] Normalization failed,error,elasticsearch
Can't close normalizer,error,elasticsearch
$$$Empty Message$$$,error,elasticsearch
"[*] Normalization resulted in: * updates, * no-ops",debug,elasticsearch
[*] No buckets to renormalize for job,debug,elasticsearch
[*] No records to renormalize for job,debug,elasticsearch
[*] Will renormalize a batch of * records,debug,elasticsearch
[*] No influencers to renormalize for job,debug,elasticsearch
[*] Will renormalize a batch of * influencers,debug,elasticsearch
[ | ] Error writing to the normalizer,error,elasticsearch
[ | ] Error closing normalizer,error,elasticsearch
[*] Error processing normalizer results,error,elasticsearch
[*] Unused normalized scores remain after updating all results: * for *,error,elasticsearch
[*] *,error,elasticsearch
Removing forecasts that expire before [*],debug,elasticsearch
Deleted [*] documents corresponding to [*] expired forecasts,info,elasticsearch
More than [*] forecasts were found. This run will only delete [*] of them1000010000,info,elasticsearch
Found [*] unused state documents; attempting to delete,info,elasticsearch
Removing results of job [*] that have a timestamp before [*],debug,elasticsearch
[*] *,debug,elasticsearch
Removing model snapshots of job [*] that have a timestamp before [*],debug,elasticsearch
$$$Empty Message$$$,error,elasticsearch
[*] * process exited,debug,elasticsearch
[*] Exception closing the running * process,warn,elasticsearch
[*] Exception closing the running * process,warn,elasticsearch
[*] Killing * process,debug,elasticsearch
[*] Failed to get PID of * process to kill,warn,elasticsearch
[*] Deleted file *,debug,elasticsearch
[*] Failed to delete file *,warn,elasticsearch
Failed to cleanup native storage from previous invocation,warn,elasticsearch
"Previous tmp storage for [*] run out, returning null",debug,elasticsearch
Failed to obtain information about path [*]: *,debug,elasticsearch
"Failed to find native storage for [*], returning null",debug,elasticsearch
Failed to optain information about path [*]: *,debug,elasticsearch
Not enough space left for path [*],debug,elasticsearch
$$$Empty Message$$$,error,elasticsearch
Starting process with command: ,debug,elasticsearch
$$$Empty Message$$$,error,elasticsearch
Killing process with PID: ,debug,elasticsearch
ML memory tracker on master,trace,elasticsearch
ML memory tracker off master,trace,elasticsearch
ML memory tracker stop called,trace,elasticsearch
ML memory tracker stopped,debug,elasticsearch
Couldn't schedule ML memory update - node might be shutting down,warn,elasticsearch
[ | ] failed to calculate anomaly detector job established model memory requirement,error,elasticsearch
io error while parsing,debug,elasticsearch
Expecting Json Field name token after the Start Object token,error,elasticsearch
$$$Empty Message$$$,error,elasticsearch
$$$Empty Message$$$,warn,elasticsearch
$$$Empty Message$$$,warn,elasticsearch
monitoring service is starting,debug,elasticsearch
monitoring service started,debug,elasticsearch
$$$Empty Message$$$,error,elasticsearch
monitoring service is stopping,debug,elasticsearch
monitoring service stopped,debug,elasticsearch
monitoring service is closing,debug,elasticsearch
monitoring service closed,debug,elasticsearch
monitoring execution is skipped,debug,elasticsearch
monitoring execution is skipped until previous execution terminated,debug,elasticsearch
$$$Empty Message$$$,warn,elasticsearch
monitoring execution failed,warn,elasticsearch
monitoring execution has been rejected,warn,elasticsearch
monitoring execution failed,warn,elasticsearch
monitoring execution did not complete after waiting for 10s,warn,elasticsearch
starting cleaning service,debug,elasticsearch
cleaning service started,debug,elasticsearch
stopping cleaning service,debug,elasticsearch
cleaning service stopped,debug,elasticsearch
closing cleaning service,debug,elasticsearch
cleaning service closed,debug,elasticsearch
[*] setting will be ignored until an appropriate license is applied,warn,elasticsearch
cleaning service is disabled due to invalid license,debug,elasticsearch
cleaning up indices with retention [*],trace,elasticsearch
listener failed to clean indices,error,elasticsearch
done cleaning up indices,trace,elasticsearch
scheduling next execution in [*] seconds,debug,elasticsearch
"couldn't schedule new execution of the cleaner, executor is shutting down",debug,elasticsearch
failed to clean indices,error,elasticsearch
collector [*] can not collect data due to invalid license,trace,elasticsearch
collector [*] - collecting data...,trace,elasticsearch
$$$Empty Message$$$,error,elasticsearch
$$$Empty Message$$$,error,elasticsearch
$$$Empty Message$$$,trace,elasticsearch
$$$Empty Message$$$,error,elasticsearch
exporter [*/*] is disabled,debug,elasticsearch
skipping exporters because the cluster state is not loaded,trace,elasticsearch
skipping exporter [*] as it is not ready yet,debug,elasticsearch
$$$Empty Message$$$,error,elasticsearch
connection failed to node at [*://*:*],warn,elasticsearch
"http exporter [*] - added index request [index=*, id=*, monitoring data type=*]",trace,elasticsearch
$$$Empty Message$$$,warn,elasticsearch
$$$Empty Message$$$,warn,elasticsearch
unexpected error while indexing monitoring document: [*],warn,elasticsearch
checking if * [*] exists on the [*] *,trace,elasticsearch
* [*] found on the [*] *,debug,elasticsearch
* [*] does not exist on the [*] *,debug,elasticsearch
$$$Empty Message$$$,error,elasticsearch
$$$Empty Message$$$,error,elasticsearch
$$$Empty Message$$$,error,elasticsearch
uploading * [*] to the [*] *,trace,elasticsearch
* [*] uploaded to the [*] *,debug,elasticsearch
$$$Empty Message$$$,error,elasticsearch
deleting * [*] from the [*] *,trace,elasticsearch
* [*] deleted from the [*] *,debug,elasticsearch
$$$Empty Message$$$,error,elasticsearch
checking [*] to ensure that it supports the minimum version [*],trace,elasticsearch
$$$Empty Message$$$,error,elasticsearch
version [*] >= [*] and supported for [*],debug,elasticsearch
version [*] < [*] and NOT supported for [*],error,elasticsearch
checking sub-resources existence and publishing on the [*],trace,elasticsearch
all sub-resources exist [*] on the [*],trace,elasticsearch
all sub-resources exist [false] on the [*],trace,elasticsearch
exporter [*] using host sniffing,debug,elasticsearch
exporter [*] using hosts *,debug,elasticsearch
"exporter [*] is not using https, but using user authentication with plaintext username/password!",warn,elasticsearch
an error occurred while closing the internal client sniffer,error,elasticsearch
an error occurred while closing the internal client,error,elasticsearch
stopped,trace,elasticsearch
waiting for elected master node [*] to setup local exporter [*] (does it have x-pack installed?),info,elasticsearch
started,debug,elasticsearch
"monitoring index template [*] does not exist, so service cannot start (waiting on master)",debug,elasticsearch
"monitoring ingest pipeline [*] does not exist, so service cannot start (waiting on master)",debug,elasticsearch
"monitoring index templates and pipelines are installed, service can start",trace,elasticsearch
waiting until metadata writes are unblocked,debug,elasticsearch
"already installing something, waiting for install to complete",trace,elasticsearch
$$$Empty Message$$$,debug,elasticsearch
pipeline [*] not found,debug,elasticsearch
all pipelines found,trace,elasticsearch
cannot manage cluster alerts because [.watches] index is not allocated,trace,elasticsearch
"monitoring index templates and pipelines are installed on master node, service can start",debug,elasticsearch
all installation requests returned a response,trace,elasticsearch
installing ingest pipeline [*],debug,elasticsearch
installing template [*],debug,elasticsearch
checking monitoring watch [*],trace,elasticsearch
pruning monitoring watch [*],trace,elasticsearch
adding monitoring watch [*],trace,elasticsearch
exporter not ready,debug,elasticsearch
"cleaning indices [expiration=*, retention=*]",debug,elasticsearch
"detected expired index [name=*, created=*, expired=*]",debug,elasticsearch
cleaning up [*] old indices,info,elasticsearch
no old indices found for clean up,debug,elasticsearch
deleting * indices: [*],trace,elasticsearch
* indices deleted,debug,elasticsearch
deletion of * indices wasn't acknowledged,warn,elasticsearch
failed to delete indices,error,elasticsearch
successfully set monitoring * [*],trace,elasticsearch
failed to set monitoring * [*],error,elasticsearch
successfully handled monitoring * [*],trace,elasticsearch
$$$Empty Message$$$,error,elasticsearch
found monitoring watch [*],trace,elasticsearch
$$$Empty Message$$$,error,elasticsearch
"local exporter [*] - added index request [index=*, id=*, pipeline=*, monitoring data type=*]",trace,elasticsearch
exporter [*] - exporting * documents,trace,elasticsearch
unexpected error while indexing monitoring document,warn,elasticsearch
Creating msearch with only normal request,debug,elasticsearch
$$$Empty Message$$$,warn,elasticsearch
Rollup job [ | ] created.,info,elasticsearch
Updating persistent state of job [ | ] to [ | ],debug,elasticsearch
Finished indexing for job [ | ],debug,elasticsearch
Rollup job [ | ] failed with an exception: ,warn,elasticsearch
"We have existing state, setting state to [ | ]  | and current position to [ | ] for job [ | ]",debug,elasticsearch
Updating state for rollup job [ | ] to [ | ][ | ],debug,elasticsearch
"Rollup indexer [ | ] received abort request, stopping indexer.",info,elasticsearch
"Received cancellation request for Rollup job [ | ], state: [ | ]",info,elasticsearch
"Rollup indexer [ | ] schedule has triggered, state: [ | ]",debug,elasticsearch
Buckets: [ | ][ | ],debug,elasticsearch
Using authorization engine from extension [ | ],debug,elasticsearch
Using default authentication failure handler,debug,elasticsearch
Using authentication failure handler from extension [ | ],debug,elasticsearch
Attempting to authenticate delegated x509Token [*],trace,elasticsearch
"blocking [*] operation due to expired license. Cluster health, cluster stats and indices stats  operations are blocked on license expiration. All data operations (read and write) continue to work.  If you have a new license, please update it. Otherwise, please reach out to your support contact.",error,elasticsearch
$$$Empty Message$$$,error,elasticsearch
added role [*],info,elasticsearch
updated role [*],info,elasticsearch
Attempting to authenticate SamlToken [*],trace,elasticsearch
Failed to invalidate SAML session,info,elasticsearch
"Logout request [*] has no NameID value, so cannot invalidate any sessions",debug,elasticsearch
added user [*],info,elasticsearch
updated user [*],info,elasticsearch
$$$Empty Message$$$,error,elasticsearch
$$$Empty Message$$$,info,elasticsearch
$$$Empty Message$$$,info,elasticsearch
$$$Empty Message$$$,info,elasticsearch
$$$Empty Message$$$,info,elasticsearch
$$$Empty Message$$$,info,elasticsearch
$$$Empty Message$$$,info,elasticsearch
$$$Empty Message$$$,info,elasticsearch
$$$Empty Message$$$,info,elasticsearch
$$$Empty Message$$$,info,elasticsearch
$$$Empty Message$$$,info,elasticsearch
$$$Empty Message$$$,info,elasticsearch
$$$Empty Message$$$,info,elasticsearch
$$$Empty Message$$$,info,elasticsearch
$$$Empty Message$$$,info,elasticsearch
$$$Empty Message$$$,info,elasticsearch
$$$Empty Message$$$,info,elasticsearch
$$$Empty Message$$$,info,elasticsearch
$$$Empty Message$$$,info,elasticsearch
$$$Empty Message$$$,info,elasticsearch
$$$Empty Message$$$,info,elasticsearch
$$$Empty Message$$$,info,elasticsearch
failed to get access token [*] because index [*] is not available,warn,elasticsearch
"invalid token, smaller than [*] bytes27",debug,elasticsearch
"invalid token, smaller than [*] bytes49",debug,elasticsearch
built in token service unable to decode token,debug,elasticsearch
built in token service unable to decode token,warn,elasticsearch
No access token provided,trace,elasticsearch
No refresh token provided,trace,elasticsearch
No realm name or username provided,trace,elasticsearch
No [*] tokens provided for invalidation,warn,elasticsearch
"Assuming an unversioned refresh token [*], generated for node versions prior to the introduction of the version-header format.",debug,elasticsearch
Assuming a hashed refresh token [*] retrieved from the tokens index,debug,elasticsearch
Assuming a refresh token [*] provided from a client,debug,elasticsearch
Decoded refresh token [*] with version [*] is invalid.,debug,elasticsearch
index [*] does not exist therefore refresh token cannot be validated,warn,elasticsearch
"index [*] is not available to find token from refresh token, retrying",debug,elasticsearch
Attempting to refresh token stored in token document [*],debug,elasticsearch
"Token document [*] was recently refreshed, when a new token document was generated. Reusing that result.",debug,elasticsearch
could not encrypt access token and refresh token string,warn,elasticsearch
Decrypted tokens string is not correctly formatted,warn,elasticsearch
Could not get stored superseding token values,warn,elasticsearch
Token was originally created by [*] but [*] attempted to refresh it,warn,elasticsearch
[*] created the refresh token while authenticated by [*] but is now authenticated by [*],warn,elasticsearch
failed to validate access token because the index [ | ] doesn't exist,warn,elasticsearch
unable to decode bearer token,debug,elasticsearch
keeping key * ,debug,elasticsearch
prune key * ,debug,elasticsearch
rotate keys on master,info,elasticsearch
unable to install token metadata,error,elasticsearch
$$$Empty Message$$$,error,elasticsearch
An exception occurred while attempting to find authentication credentials,warn,elasticsearch
Authentication failed using realms [*]. Realms [*] were skipped because they are not permitted on the current license,warn,elasticsearch
user [*] attempted to runAs with an empty username,debug,elasticsearch
user [*] is disabled. failing authentication,debug,elasticsearch
"delete by query of api keys finished with [*] deletions, [*] bulk failures, [*] search failures",debug,elasticsearch
"deletion failed for index [*], type [*], id [*]",debug,elasticsearch
"search failed for index [*], shard [*] on node [*]",debug,elasticsearch
failed to delete expired or invalidated api keys,debug,elasticsearch
failed to delete expired or invalidated api keys,error,elasticsearch
realm [*] is disabled,debug,elasticsearch
nodes prior to the minimum supported version for api keys * exist in the cluster; these nodes will not be able to use api keys,warn,elasticsearch
"none of the parameters [api key id, api key name, username, realm name] were specified for invalidation",trace,elasticsearch
"none of the parameters [api key id, api key name, username, realm name] were specified for retrieval",trace,elasticsearch
"delete by query of tokens finished with [*] deletions, [*] bulk failures, [*] search failures",debug,elasticsearch
"deletion failed for index [*], type [*], id [*]",debug,elasticsearch
"search failed for index [*], shard [*] on node [*]",debug,elasticsearch
failed to delete expired tokens,debug,elasticsearch
failed to delete expired tokens,error,elasticsearch
Marking user [*] as disabled because the security mapping is not at the required version,debug,elasticsearch
could not retrieve user [*] because security index does not exist,trace,elasticsearch
security index is unavailable. short circuiting retrieval of user [*],error,elasticsearch
unable to clear realm cache for user [*],error,elasticsearch
error in the format of data for user [*],error,elasticsearch
$$$Empty Message$$$,error,elasticsearch
reading users file [*]...,trace,elasticsearch
"invalid entry in users file [*], line [*]. skipping...",error,elasticsearch
"invalid username [*] in users file [*], skipping... (*)",error,elasticsearch
parsed [*] users from file [*],debug,elasticsearch
users file [*] changed. updating users... ),info,elasticsearch
$$$Empty Message$$$,error,elasticsearch
reading users_roles file [*]...,trace,elasticsearch
"invalid entry in users_roles file [*], line [*]. skipping...",error,elasticsearch
"invalid role entry in users_roles file [*], line [*] - *. skipping...",error,elasticsearch
"invalid entry for role [*] in users_roles file [*], line [*]. no users found. skipping...",error,elasticsearch
"invalid entry for role [*] in users_roles file [*], line [*]. no users found. skipping...",error,elasticsearch
parsed [*] user to role mappings from file [*],debug,elasticsearch
users roles file [*] changed. updating users roles...,info,elasticsearch
"failed to authenticate user, service login failure",debug,elasticsearch
"failed to authenticate user, gss context negotiation failure",debug,elasticsearch
failed to authenticate user,debug,elasticsearch
"validateTicket isGSSContextEstablished = *, username = *, outToken = *",trace,elasticsearch
Could not dispose GSS Context,debug,elasticsearch
Could not close LoginContext,debug,elasticsearch
Realm [*] is in user-dn-template mode: [*],info,elasticsearch
"Realm [*] is in user-search mode - base_dn=[*], search filter=[*]",info,elasticsearch
"[*] and [*} have not been specified or are not valid distinguished names, | so connection health checking is disabled",warn,elasticsearch
Exception occurred during * for *,debug,elasticsearch
execution of ldap runnable failed,error,elasticsearch
skipping execution of ldap runnable as the current state is [*],trace,elasticsearch
skipping execution of ldap runnable as it has been waiting for execution too long,warn,elasticsearch
Resolving LDAP groups + meta-data for user [*],debug,elasticsearch
ldap_search timeout [*] is less than the minimum supported search timeout of 1s. using 1s,warn,elasticsearch
using encryption for LDAP connections with hostname verification,debug,elasticsearch
using encryption for LDAP connections without hostname verification,debug,elasticsearch
LDAP bind [*] succeeded for [*],trace,elasticsearch
LDAP bind [*] failed for [*] - [*],debug,elasticsearch
LDAP bind [*] succeeded for [*],trace,elasticsearch
LDAP bind [*] failed for [*] - [*],debug,elasticsearch
LDAP Search * => * (*),trace,elasticsearch
Referral limit exceeded * => * (*),trace,elasticsearch
LDAP referred elsewhere * => *,trace,elasticsearch
$$$Empty Message$$$,warn,elasticsearch
OpenID Connect Provider redirected user to [*]. Expected Nonce is [*] and expected State is [*],trace,elasticsearch
Received and validated the Id Token for the user: [*],trace,elasticsearch
UserInfo endpoint is configured but the OP didn't return an access token so we can't query it,debug,elasticsearch
OP returned an access token but the UserInfo endpoint is not configured.,debug,elasticsearch
"Access Token incorrectly returned from the OpenId Connect Provider while using ""id_token"" response type.",warn,elasticsearch
Received UserInfo Response from OP with status [*] and content [*] ,trace,elasticsearch
Successfully retrieved user information: [*],trace,elasticsearch
Received Token Response from OP with status [*] and content [*] ,trace,elasticsearch
Successfully exchanged code for ID Token: [*] and Access Token [*],trace,elasticsearch
Unable to close the HttpAsyncClient,debug,elasticsearch
An error occurred while reloading file *,warn,elasticsearch
$$$Empty Message$$$,debug,elasticsearch
$$$Empty Message$$$,debug,elasticsearch
$$$Empty Message$$$,debug,elasticsearch
$$$Empty Message$$$,debug,elasticsearch
$$$Empty Message$$$,debug,elasticsearch
failed certificate validation for Subject DN [ | ],trace,elasticsearch
failed certificate validation for Subject DN [*],debug,elasticsearch
PKI Realm * uses truststore * which has no accepted certificate issuers,warn,elasticsearch
PKI Realm * uses CAs * with no accepted certificate issuers,warn,elasticsearch
Rejecting SAML logout request * because *,trace,elasticsearch
Failed to decode base64 string [*] - *,info,elasticsearch
Error marshalling SAMLObject ,info,elasticsearch
XML transformation error,debug,elasticsearch
XML transformation error,debug,elasticsearch
XML transformation error,debug,elasticsearch
XML Parser error ,debug,elasticsearch
XML Parser error ,debug,elasticsearch
XML Parser error ,debug,elasticsearch
Cannot perform logout because the IDP * does not provide a logout service,debug,elasticsearch
Rejecting SAML response * because *,trace,elasticsearch
$$$Empty Message$$$,trace,elasticsearch
The SAML Response with ID * is unsolicited. A user might have used a stale URL or the Identity Provider incorrectly populates the InResponseTo attribute,debug,elasticsearch
$$$Empty Message$$$,trace,elasticsearch
The Attribute Statements of SAML Response with ID * contained no attributes and the SAML Assertion Subject didnot contain a SAML NameID. Please verify that the Identity Provider configuration with regards to attribute release is correct. ,debug,elasticsearch
(Possibly decrypted) Assertion: *,trace,elasticsearch
$$$Empty Message$$$,trace,elasticsearch
SAML AttributeStatement has [*] attributes and [*] encrypted attributes,trace,elasticsearch
Successfully decrypted attribute: *,trace,elasticsearch
"SAML message has encrypted attribute [ | ], but no encryption key has been configured",info,elasticsearch
Failed to decrypt SAML attribute ,info,elasticsearch
SAML Assertion was intended for the following Service providers: *,trace,elasticsearch
SAML Assertion is only valid between:  |  and ,trace,elasticsearch
SAML Assertion Subject Confirmation intended recipient is: ,trace,elasticsearch
SAML Assertion Subject Confirmation is only valid before: ,trace,elasticsearch
SAML Assertion Subject Confirmation is in response to: ,trace,elasticsearch
The XML Signature of this SAML message cannot be validated. Please verify that the saml realm uses the correct SAMLmetadata file/URL for this Identity Provider,warn,elasticsearch
The XML Signature of this SAML message cannot be validated. Please verify that the saml realm uses the correct SAMLmetadata file/URL for this Identity Provider,warn,elasticsearch
Received SAML Message: *  ,trace,elasticsearch
Parsed token [*] to attributes [*],debug,elasticsearch
SAML assertion contains multiple values for attribute [*] returning first one,info,elasticsearch
Ignoring setting [*] because the IdP metadata is being loaded from a file,info,elasticsearch
Constructed SAML Authentication Request: *,trace,elasticsearch
Constructed SAML Logout Request: *,trace,elasticsearch
Constructed SAML Logout Response: *,trace,elasticsearch
An error occurred while reloading file *,warn,elasticsearch
$$$Empty Message$$$,error,elasticsearch
reading realm [*/*] role mappings file [*]...,trace,elasticsearch
 Role mapping will be skipped.,warn,elasticsearch
 skipping...,error,elasticsearch
[*] role mappings found in file [*] for realm [*/*],debug,elasticsearch
"the roles [*], are mapped from these [*] groups [*] using file [*] for realm [*/*]",debug,elasticsearch
"the roles [*], are mapped from the user [*] using file [*] for realm [*/*]",debug,elasticsearch
role mappings file [*] changed for realm [*/*]. updating mappings...,info,elasticsearch
invalidating cache for user [*] in realm [*],trace,elasticsearch
invalidating cache for all users in realm [*],trace,elasticsearch
failed to parse [*] as a DN,trace,elasticsearch
Role mapping [*] cannot be parsed and will be skipped,warn,elasticsearch
failed to modify role-mapping [*],error,elasticsearch
The security index is not yet available - no role mappings can be loaded,info,elasticsearch
Security Index [*] [exists: *] [available: *] [mapping up to date: *].security,debug,elasticsearch
denying access as action [*] is not an index or cluster action,warn,elasticsearch
action [*] is unauthorized for user [*] run as [*],debug,elasticsearch
action [*] is unauthorized for API key id [*] of user [*],debug,elasticsearch
action [*] is unauthorized for user [*],debug,elasticsearch
Checking privileges for application *,debug,elasticsearch
No resources defined in application privilege *,trace,elasticsearch
"full cache clear, reason [*]",debug,elasticsearch
not opting out of the query cache; authorization is not allowed,debug,elasticsearch
opting out of the query cache. current request doesn't hold indices permissions,debug,elasticsearch
not opting out of the query cache. request for index [*] is safe to cache,trace,elasticsearch
opting out of the query cache. request for index [*] is unsafe to cache,trace,elasticsearch
not opting out of the query cache. request for index [*] has field level security disabled,trace,elasticsearch
aborting bulk item update request for index [*],trace,elasticsearch
"intercepted bulk request for index [*] without any update requests, continuing execution",trace,elasticsearch
intercepted request for index [*] with field level access controls [*] document level access controls [*]. disabling conflicting features,trace,elasticsearch
intercepted request for index [*] without field or document level access controls,trace,elasticsearch
attempting to read roles file located at [*],debug,elasticsearch
role [*] is reserved. the relevant role definition in the mapping file will be ignored,warn,elasticsearch
"role [*] uses document and/or field level security, which is not enabled by the current license. this role will be ignored",warn,elasticsearch
$$$Empty Message$$$,error,elasticsearch
roles file does not exist,debug,elasticsearch
parsed [*] roles from file [*],info,elasticsearch
attempting to read roles file located at [*],trace,elasticsearch
$$$Empty Message$$$,error,elasticsearch
invalid role definition [*] in roles file [*]. invalid role name - *. skipping role... ,error,elasticsearch
invalid role definition [*] in roles file [*]. skipping role...,error,elasticsearch
invalid role definition [*] in roles file [*]. skipping role...,error,elasticsearch
$$$Empty Message$$$,debug,elasticsearch
. skipping role...,error,elasticsearch
$$$Empty Message$$$,error,elasticsearch
$$$Empty Message$$$,error,elasticsearch
invalid role definition [*] in roles file [*]. document and field level security is not enabled. set [*] to [true] in the configuration file. skipping role...,error,elasticsearch
updated roles (roles file [*] *),info,elasticsearch
$$$Empty Message$$$,error,elasticsearch
unable to clear cache for role [*],error,elasticsearch
error in the format of data for role [*],error,elasticsearch
Building role from descriptors [*] for names [*] from source [*],trace,elasticsearch
Failed to produce role deprecation messages,warn,elasticsearch
Failed to start working on role alias permisssion deprecation messages,warn,elasticsearch
Begin role [ | ] check for alias permission deprecation,trace,elasticsearch
Completed role [ | ] check for alias permission deprecation,trace,elasticsearch
Failed to start working on role alias permisssion deprecation messages,warn,elasticsearch
failed to load privilege [*] index not available,warn,elasticsearch
Failed to put privilege * - *,warn,elasticsearch
unable to clear role cache,error,elasticsearch
Building privilege from [*] [*],trace,elasticsearch
cannot parse application privilege [*],error,elasticsearch
The '*' realm is not available under the current licensepki,info,elasticsearch
API Keys are not available under the current [*] license,info,elasticsearch
Failed to create token,debug,elasticsearch
failed to send failure response,error,elasticsearch
Security tokens are not available under the current [*] license,info,elasticsearch
The '*' realm is not available under the current licenseoidc,info,elasticsearch
OIDC Authenticate: ,trace,elasticsearch
OIDC Prepare Authentication: ,trace,elasticsearch
The '*' realm is not available under the current licensesaml,info,elasticsearch
SAML Authenticate: [*...] [*],trace,elasticsearch
Failed to decode base64 string [*] - *,info,elasticsearch
security index manager waiting until state has been recovered,debug,elasticsearch
Index [*] is closed. This is likely to prevent security from functioning correctly,warn,elasticsearch
Index [*] is not available - no metadata,debug,elasticsearch
Index [*] is closed,warn,elasticsearch
Index [*] is not yet active,debug,elasticsearch
Missing _meta field in mapping [*] of index [*],info,elasticsearch
Cannot parse the mapping for index [*],error,elasticsearch
security index does not exist. Creating [*] with alias [*],info,elasticsearch
Index [*] (alias [*]) is not up to date. Updating mapping,info,elasticsearch
Active license is now [*]; Security is *,info,elasticsearch
"received plaintext http traffic on an https channel, closing connection *",trace,elasticsearch
"received plaintext http traffic on an https channel, closing connection *",warn,elasticsearch
connection * closed during ssl handshake,trace,elasticsearch
connection * closed during ssl handshake,debug,elasticsearch
"http client did not trust server's certificate, closing connection *",trace,elasticsearch
"http client did not trust this server's certificate, closing connection *",warn,elasticsearch
failed to send exception response for action [ | ],warn,elasticsearch
$$$Empty Message$$$,trace,elasticsearch
SSL Peer did not present a certificate on channel [*],debug,elasticsearch
skipping ip filter rules for profile [*] since the profile is not bound to any addresses,warn,elasticsearch
loaded ip filtering profiles: *,debug,elasticsearch
Attempting to resolve *,trace,elasticsearch
Trying to resolve conflicts  |  between left  |  and right ,trace,elasticsearch
About to execute composite query * on *,trace,elasticsearch
About to execute scroll query *,trace,elasticsearch
About to execute query * on *,trace,elasticsearch
Parsing as statement: *,debug,elasticsearch
Parsing as expression: *,debug,elasticsearch
  %-15s '%s',info,elasticsearch
Parse tree * ,info,elasticsearch
About to apply rule *,trace,elasticsearch
Rule * applied *,trace,elasticsearch
Rule * applied w/o changes,trace,elasticsearch
Batch * applied took * *,trace,elasticsearch
Tree transformation took * *,debug,elasticsearch
out: *,info,elasticsearch
out: *,info,elasticsearch
out: *;,info,elasticsearch
in : *,info,elasticsearch
in : *,info,elasticsearch
Geo data loaded,info,elasticsearch
Data loaded,info,elasticsearch
$$$Empty Message$$$,info,elasticsearch
^^^ Assertion failure ^^^,info,elasticsearch
$$$Empty Message$$$,info,elasticsearch
"triggered watches could not be deleted *, failure [*]",error,elasticsearch
"watch history could not be written *, failure [*]",error,elasticsearch
"overwrote watch history entries *, possible second execution of a triggered watch, failure [*]",info,elasticsearch
error executing bulk,error,elasticsearch
"the [action.auto_create_index] setting is configured to be restrictive [*].  for the next 6 months daily history indices are allowed to be created, but please make sure that any future history indices after 6 months with the pattern [.watcher-history-yyyy.MM.dd] are allowed to be created",warn,elasticsearch
failed to properly close watcher bulk processor,warn,elasticsearch
"missing watcher index templates, not starting watcher service",debug,elasticsearch
"not starting watcher, upgrade API run required: .watches[*], .triggered_watches[*]",warn,elasticsearch
error validating to start watcher,debug,elasticsearch
"stopping watch service, reason [*]",info,elasticsearch
"stopping watch service, reason [shutdown initiated]",info,elasticsearch
"reloading watcher, reason [*], cancelled [*] queued tasks",info,elasticsearch
"watch service has not been reloaded for state [*], another reload for state [*] in progress",debug,elasticsearch
"watch service has been reloaded, reason [*]",debug,elasticsearch
"watch service has not been reloaded for state [*], another reload for state [*] in progress",debug,elasticsearch
"paused watch execution, reason [*], cancelled [*] queued tasks",info,elasticsearch
$$$Empty Message$$$,error,elasticsearch
Loaded [*] watches for execution,debug,elasticsearch
"no distributed watch execution info found for watch [*] on shard [*], got configuration for *",debug,elasticsearch
adding watch [*] to trigger service,debug,elasticsearch
removing watch [*] to trigger service,debug,elasticsearch
watch [*] should not be triggered,debug,elasticsearch
error loading watches index: [*],error,elasticsearch
$$$Empty Message$$$,error,elasticsearch
$$$Empty Message$$$,warn,elasticsearch
$$$Empty Message$$$,info,elasticsearch
$$$Empty Message$$$,debug,elasticsearch
$$$Empty Message$$$,trace,elasticsearch
Using default proxy for http input and slack/pagerduty/webhook actions [*:*],info,elasticsearch
$$$Empty Message$$$,error,elasticsearch
$$$Empty Message$$$,error,elasticsearch
trying to find triggered watches for ids *: found [*] docs,debug,elasticsearch
"watcher execution service paused, not processing [*] events",debug,elasticsearch
"watcher execution service paused, not processing [*] events",debug,elasticsearch
saving watch records [*],debug,elasticsearch
"unable to find watch [*] in watch index, perhaps it has been deleted",warn,elasticsearch
could not store triggered watch with id [*]: [*],error,elasticsearch
not executing watch [*] because it is already queued,trace,elasticsearch
executing watch [*],debug,elasticsearch
not executing watch [*],debug,elasticsearch
$$$Empty Message$$$,error,elasticsearch
finished [*]/[*],debug,elasticsearch
$$$Empty Message$$$,debug,elasticsearch
failed to execute watch [*],warn,elasticsearch
indexed watch history record [*],debug,elasticsearch
overwrote watch history record [*],debug,elasticsearch
$$$Empty Message$$$,error,elasticsearch
successfully deleted triggered watch with id [*],trace,elasticsearch
triggered execution of [*] watches,debug,elasticsearch
$$$Empty Message$$$,error,elasticsearch
"failed to execute [*] input for watch [*], reason [*]chain",error,elasticsearch
"failed to execute [*] input for watch [*], reason [*]http",error,elasticsearch
"[*] [*] input expected content type [*] but read [*] from headers, using expected one",warn,elasticsearch
"failed to execute [*] input for watch [*], reason [*]search",error,elasticsearch
[*] running query for [*] [*],trace,elasticsearch
[*] found [*] hits,debug,elasticsearch
[*] hit [*],debug,elasticsearch
Keystore exception while reloading watcher notification service,error,elasticsearch
failed to close email transport for account [*],error,elasticsearch
"Watch[*] reporting[*] pdf is not ready, polling in [*] again",trace,elasticsearch
"Watch[*] reporting[*] invalid interval configuration [*], using configured default [*]",trace,elasticsearch
failed to execute slack api http request,error,elasticsearch
$$$Empty Message$$$,error,elasticsearch
$$$Empty Message$$$,error,elasticsearch
failed to parse [*],error,elasticsearch
"could not update watcher stopped status to [*], source [*]",error,elasticsearch
triggered job [*] at [*] (scheduled time was [*]),debug,elasticsearch
checking jobs [*],trace,elasticsearch
stopping ticker thread,trace,elasticsearch
caught an interrupted exception when waiting while closing ticker thread,warn,elasticsearch
ticker thread stopped,trace,elasticsearch
parsing watch [*] ,trace,elasticsearch
Unexpected failure,error,elasticsearch
adding watch [*],debug,elasticsearch
not executing watch [*] on this scheduler because it is paused,info,elasticsearch
firing watch [*] at [*],debug,elasticsearch
SpnegoClient with userPrincipalName : *,info,elasticsearch
"privileged action exception, with root cause",error,elasticsearch
SimpleKdcLdapServer started.,info,elasticsearch
error occurred while cleaning up after init failure for SimpleKdcLdapServer,debug,elasticsearch
SimpleKdcServer stoppped.,info,elasticsearch
